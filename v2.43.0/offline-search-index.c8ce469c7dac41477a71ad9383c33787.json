[{"body":"","categories":"","description":"","excerpt":"","ref":"/v2.43.0/docs/api_sdk/sdk/reference/","tags":"","title":"SDK API Reference"},{"body":"All URIs are relative to http://localhost\nClass Method HTTP request Description AssetsApi create POST /api/assets Create an asset AssetsApi destroy DELETE /api/assets/{uuid} Delete an asset AssetsApi retrieve GET /api/assets/{uuid} Get an asset AuthApi create_login POST /api/auth/login AuthApi create_logout POST /api/auth/logout AuthApi create_password_change POST /api/auth/password/change AuthApi create_password_reset POST /api/auth/password/reset AuthApi create_password_reset_confirm POST /api/auth/password/reset/confirm AuthApi create_register POST /api/auth/register AuthApi retrieve_rules GET /api/auth/rules CloudstoragesApi create POST /api/cloudstorages Create a cloud storage CloudstoragesApi destroy DELETE /api/cloudstorages/{id} Delete a cloud storage CloudstoragesApi list GET /api/cloudstorages List cloud storages CloudstoragesApi partial_update PATCH /api/cloudstorages/{id} Update a cloud storage CloudstoragesApi retrieve GET /api/cloudstorages/{id} Get cloud storage details CloudstoragesApi retrieve_actions GET /api/cloudstorages/{id}/actions Get allowed actions for a cloud storage CloudstoragesApi retrieve_content_v2 GET /api/cloudstorages/{id}/content-v2 Get cloud storage content CloudstoragesApi retrieve_preview GET /api/cloudstorages/{id}/preview Get a preview image for a cloud storage CloudstoragesApi retrieve_status GET /api/cloudstorages/{id}/status Get the status of a cloud storage CommentsApi create POST /api/comments Create a comment CommentsApi destroy DELETE /api/comments/{id} Delete a comment CommentsApi list GET /api/comments List comments CommentsApi partial_update PATCH /api/comments/{id} Update a comment CommentsApi retrieve GET /api/comments/{id} Get comment details ConsensusApi create_merge POST /api/consensus/merges Create a consensus merge ConsensusApi list_settings GET /api/consensus/settings List consensus settings instances ConsensusApi partial_update_settings PATCH /api/consensus/settings/{id} Update a consensus settings instance ConsensusApi retrieve_settings GET /api/consensus/settings/{id} Get consensus settings instance details EventsApi create POST /api/events Log client events EventsApi create_export POST /api/events/export Initiate a process to export events EventsApi list GET /api/events Get an event log GuidesApi create POST /api/guides Create an annotation guide GuidesApi destroy DELETE /api/guides/{id} Delete an annotation guide GuidesApi partial_update PATCH /api/guides/{id} Update an annotation guide GuidesApi retrieve GET /api/guides/{id} Get annotation guide details InvitationsApi accept POST /api/invitations/{key}/accept Accept an invitation InvitationsApi create POST /api/invitations Create an invitation InvitationsApi decline POST /api/invitations/{key}/decline Decline an invitation InvitationsApi destroy DELETE /api/invitations/{key} Delete an invitation InvitationsApi list GET /api/invitations List invitations InvitationsApi partial_update PATCH /api/invitations/{key} Update an invitation InvitationsApi resend POST /api/invitations/{key}/resend Resend an invitation InvitationsApi retrieve GET /api/invitations/{key} Get invitation details IssuesApi create POST /api/issues Create an issue IssuesApi destroy DELETE /api/issues/{id} Delete an issue IssuesApi list GET /api/issues List issues IssuesApi partial_update PATCH /api/issues/{id} Update an issue IssuesApi retrieve GET /api/issues/{id} Get issue details JobsApi create POST /api/jobs Create a job JobsApi create_annotations POST /api/jobs/{id}/annotations/ Import annotations into a job JobsApi create_dataset_export POST /api/jobs/{id}/dataset/export Initialize process to export resource as a dataset in a specific format JobsApi destroy DELETE /api/jobs/{id} Delete a job JobsApi destroy_annotations DELETE /api/jobs/{id}/annotations/ Delete job annotations JobsApi list GET /api/jobs List jobs JobsApi partial_update PATCH /api/jobs/{id} Update a job JobsApi partial_update_annotations PATCH /api/jobs/{id}/annotations/ Update job annotations JobsApi partial_update_data_meta PATCH /api/jobs/{id}/data/meta Update metainformation for media files in a job JobsApi partial_update_validation_layout PATCH /api/jobs/{id}/validation_layout Allows updating current validation configuration JobsApi retrieve GET /api/jobs/{id} Get job details JobsApi retrieve_annotations GET /api/jobs/{id}/annotations/ Get job annotations JobsApi retrieve_data GET /api/jobs/{id}/data Get data of a job JobsApi retrieve_data_meta GET /api/jobs/{id}/data/meta Get metainformation for media files in a job JobsApi retrieve_preview GET /api/jobs/{id}/preview Get a preview image for a job JobsApi retrieve_validation_layout GET /api/jobs/{id}/validation_layout Allows getting current validation configuration JobsApi update_annotations PUT /api/jobs/{id}/annotations/ Replace job annotations LabelsApi destroy DELETE /api/labels/{id} Delete a label LabelsApi list GET /api/labels List labels LabelsApi partial_update PATCH /api/labels/{id} Update a label LabelsApi retrieve GET /api/labels/{id} Get label details LambdaApi create_functions POST /api/lambda/functions/{func_id} LambdaApi create_requests POST /api/lambda/requests Method calls the function LambdaApi delete_requests DELETE /api/lambda/requests/{id} Method cancels the request LambdaApi list_functions GET /api/lambda/functions Method returns a list of functions LambdaApi list_requests GET /api/lambda/requests Method returns a list of requests LambdaApi retrieve_functions GET /api/lambda/functions/{func_id} Method returns the information about the function LambdaApi retrieve_requests GET /api/lambda/requests/{id} Method returns the status of the request MembershipsApi destroy DELETE /api/memberships/{id} Delete a membership MembershipsApi list GET /api/memberships List memberships MembershipsApi partial_update PATCH /api/memberships/{id} Update a membership MembershipsApi retrieve GET /api/memberships/{id} Get membership details OrganizationsApi create POST /api/organizations Create an organization OrganizationsApi destroy DELETE /api/organizations/{id} Delete an organization OrganizationsApi list GET /api/organizations List organizations OrganizationsApi partial_update PATCH /api/organizations/{id} Update an organization OrganizationsApi retrieve GET /api/organizations/{id} Get organization details ProjectsApi create POST /api/projects Create a project ProjectsApi create_backup POST /api/projects/backup/ Recreate a project from a backup ProjectsApi create_backup_export POST /api/projects/{id}/backup/export Initiate process to backup resource ProjectsApi create_dataset POST /api/projects/{id}/dataset/ Import a dataset into a project ProjectsApi create_dataset_export POST /api/projects/{id}/dataset/export Initialize process to export resource as a dataset in a specific format ProjectsApi destroy DELETE /api/projects/{id} Delete a project ProjectsApi list GET /api/projects List projects ProjectsApi partial_update PATCH /api/projects/{id} Update a project ProjectsApi retrieve GET /api/projects/{id} Get project details ProjectsApi retrieve_preview GET /api/projects/{id}/preview Get a preview image for a project QualityApi create_report POST /api/quality/reports Create a quality report QualityApi list_conflicts GET /api/quality/conflicts List annotation conflicts in a quality report QualityApi list_reports GET /api/quality/reports Method returns a paginated list of quality reports. QualityApi list_settings GET /api/quality/settings List quality settings instances QualityApi partial_update_settings PATCH /api/quality/settings/{id} Update a quality settings instance QualityApi retrieve_report GET /api/quality/reports/{id} Get quality report details QualityApi retrieve_report_data GET /api/quality/reports/{id}/data Get quality report contents QualityApi retrieve_settings GET /api/quality/settings/{id} Get quality settings instance details RequestsApi create_cancel POST /api/requests/{id}/cancel Cancel request RequestsApi list GET /api/requests List requests RequestsApi retrieve GET /api/requests/{id} Get request details SchemaApi retrieve GET /api/schema/ ServerApi list_share GET /api/server/share List files/directories in the mounted share ServerApi retrieve_about GET /api/server/about Get basic CVAT information ServerApi retrieve_annotation_formats GET /api/server/annotation/formats Get supported annotation formats ServerApi retrieve_plugins GET /api/server/plugins Get enabled plugins TasksApi create POST /api/tasks Create a task TasksApi create_annotations POST /api/tasks/{id}/annotations/ Import annotations into a task TasksApi create_backup POST /api/tasks/backup/ Recreate a task from a backup TasksApi create_backup_export POST /api/tasks/{id}/backup/export Initiate process to backup resource TasksApi create_data POST /api/tasks/{id}/data/ Attach data to a task TasksApi create_dataset_export POST /api/tasks/{id}/dataset/export Initialize process to export resource as a dataset in a specific format TasksApi destroy DELETE /api/tasks/{id} Delete a task TasksApi destroy_annotations DELETE /api/tasks/{id}/annotations/ Delete task annotations TasksApi list GET /api/tasks List tasks TasksApi partial_update PATCH /api/tasks/{id} Update a task TasksApi partial_update_annotations PATCH /api/tasks/{id}/annotations/ Update task annotations TasksApi partial_update_data_meta PATCH /api/tasks/{id}/data/meta Update metainformation for media files in a task TasksApi partial_update_validation_layout PATCH /api/tasks/{id}/validation_layout Allows updating current validation configuration TasksApi retrieve GET /api/tasks/{id} Get task details TasksApi retrieve_annotations GET /api/tasks/{id}/annotations/ Get task annotations TasksApi retrieve_data GET /api/tasks/{id}/data/ Get data of a task TasksApi retrieve_data_meta GET /api/tasks/{id}/data/meta Get metainformation for media files in a task TasksApi retrieve_preview GET /api/tasks/{id}/preview Get a preview image for a task TasksApi retrieve_status GET /api/tasks/{id}/status Get the creation status of a task TasksApi retrieve_validation_layout GET /api/tasks/{id}/validation_layout Allows getting current validation configuration TasksApi update_annotations PUT /api/tasks/{id}/annotations/ Replace task annotations UsersApi destroy DELETE /api/users/{id} Delete a user UsersApi list GET /api/users List users UsersApi partial_update PATCH /api/users/{id} Update a user UsersApi retrieve GET /api/users/{id} Get user details UsersApi retrieve_self GET /api/users/self Get details of the current user WebhooksApi create POST /api/webhooks Create a webhook WebhooksApi create_deliveries_redelivery POST /api/webhooks/{id}/deliveries/{delivery_id}/redelivery Redeliver a webhook delivery WebhooksApi create_ping POST /api/webhooks/{id}/ping Send a ping webhook WebhooksApi destroy DELETE /api/webhooks/{id} Delete a webhook WebhooksApi list GET /api/webhooks List webhooks WebhooksApi list_deliveries GET /api/webhooks/{id}/deliveries List deliveries for a webhook WebhooksApi partial_update PATCH /api/webhooks/{id} Update a webhook WebhooksApi retrieve GET /api/webhooks/{id} Get webhook details WebhooksApi retrieve_deliveries GET /api/webhooks/{id}/deliveries/{delivery_id} Get details of a webhook delivery WebhooksApi retrieve_events GET /api/webhooks/events List available webhook events WebhooksApi update PUT /api/webhooks/{id} Replace a webhook ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nClass Method HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/","tags":"","title":"APIs"},{"body":"In CVAT, it’s possible to evaluate the quality of annotation through the creation of a validation subset of images. To estimate the task quality, CVAT compares all other jobs in the task against the established Ground truth job, and calculates annotation quality based on this comparison.\nNote Quality estimation only supports 2d tasks. It supports all the annotation types except 2d cuboids. Note Quality estimation is available for projects, tasks, and jobs. CVAT has the following features for automated quality control of annotations:\nValidation set configuration for a task Job validation on job finish (“Immediate feedback”) Review mode for problems found Quality analytics Basics There are several approaches to quality estimation used in the industry. In CVAT, we can use a method known as Ground Truth or Honeypots. The method assumes there are Ground Truth annotations for images in the dataset. This method is statistical, which means that we can use only a small portion of the whole dataset to estimate quality on the full dataset, so we don’t need to annotate the whole dataset twice. Here we assume that the images in the dataset are similar (represent the same task).\nWe will call the validation portion of the whole dataset (or a task in CVAT) a validation set. In practice, it is typically expected that annotations in the validation set are carefully validated and curated. It means that they are more expensive - creating them might require expert annotators or just several iterations of annotation and validation. It means that it’s desirable to keep the validation set small enough. At the same time, it must be representative enough to provide reliable estimations. To achieve this, it’s advised that the validation set images are sampled randomly and independently from the full dataset. That is, for the quality assurance to function correctly, the validation set must have some portion of the task frames, and the frames must be chosen randomly.\nDepending on the dataset size, data variance, and task complexity, 5-15% of the data is typically good enough for quality estimation, while keeping extra annotation overhead for the Ground Truth acceptable.\nFor example, in a typical task with 2000 frames, selecting just 5%, which is 100 extra frames to annotate, is enough to estimate the annotation quality. If the task contains only 30 frames, it’s advisable to select 8-10 frames, which is about 30%. It is more than 15%, but in the case of smaller datasets, we need more samples to estimate quality reliably, as data variance is higher.\nGround truth jobs A Ground Truth job (GT job) is a way to represent the validation set in a CVAT task. This job is similar to regular annotation jobs - you can edit the annotations manually, use auto-annotation features, and import annotations in this job. There can be no more than 1 Ground Truth job in a task.\nTo enable quality estimation in a task, you need to create a Ground truth job in the task, annotate it, switch the job stage to acceptance, and set the job state to completed. Once the Ground Truth job is configured, CVAT will start using this job for quality estimation.\nRead more about Ground Truth management here.\nConfiguring quality estimation There are 2 key components related to quality estimation configuration: Ground Truth jobs and Quality settings. Ground Truth jobs are configured at the Task level. In this section, we explain how to set up a Ground Truth job. Read more about quality settings here.\nA Ground truth job is considered configured if it is at the acceptance stage and in the completed state.\nA configured Ground Truth job is required for all quality computations in CVAT.\nIn a new task In an existing task Go to the task creation page Configure basic and advanced parameters according to your requirements, and attach a dataset to be annotated Scroll down to the Quality Control section below Select one of the validation modes available Create the task and open the task page Upload or create Ground Truth annotations in the Ground Truth job in the task Switch the Ground Truth job into the acceptance stage and completed state For already existing tasks only the Ground Truth validation mode is available. If you want to use Honeypots for your task, you will need to recreate the task.\nOpen the task page Click +. In the Add new job window, fill in the following fields: Job type: Use the default parameter Ground truth. Frame selection method: Use the default parameter Random. Quantity %: Set the desired percentage of frames for the Ground truth job. Note that when you use Quantity %, the Frames field will be autofilled. Frame count: Set the desired number of frames for the Ground truth job. Note that when you use Frames, the Quantity % field will be autofilled. Seed: (Optional) If you need to make the random selection reproducible, specify this number. It can be any integer number, the same value will yield the same random selection (given that the frame number is unchanged). Note that if you want to use a custom frame sequence, you can do this using the server API instead, see Job API create(). Click Submit. The Ground truth job will appear in the jobs list.\nAnnotate frames and save your work or upload annotations. Switch the Ground Truth job into the acceptance stage and completed state Validation modes Currently, there are 2 validation modes available for tasks: Ground Truth and Honeypots. These names are often used interchangeably, but in CVAT they have some differences. Both modes rely on the use of Ground Truth annotations in a task, stored in a Ground Truth job, where they can be managed.\nGround Truth In this mode some of the task frames are selected into the validation set, represented as a separate Ground Truth job. The regular annotation jobs in the task are not affected in any way.\nGround Truth jobs can be created at the task creation automatically or manually at any moment later. They can also be removed manually at any moment. This validation mode is available for any tasks and annotations.\nThis is a flexible mode that can be enabled or disabled at any moment without any disruptions to the annotation process.\nFrame selection This validation mode can use several frame selection methods.\nRandom This is a simple method that selects frames into the validation set randomly, representing the basic approach, described above.\nParameters:\nframe count - the number or percent of the task frames to be used for validation. Can be specified as an absolute number in the Frame count field or a percent in the Quantity field. If there are both fields on the page, they are linked, which means changing one of them will adjust the other one automatically. random seed - a number to be used to initialize the random number generator. Can be useful if you want to create a reproducible sequence of frames. Random per job This method selects frames into the validation set randomly from each annotation job in the task.\nIt solves one of the issues with the simple Random method that some of the jobs can get no validation frames, which makes it impossible to estimate quality in such jobs. Note that using this method can result in increased total size of the validation set.\nParameters:\nframe count per job - the percent of the job frames to be used for validation. This method uses segment size of the task to select the same number of validation frames in each job, if possible. Can be specified as an absolute number in the Frame count field or a percent in the Quantity per job field. If there are both fields on the page, they are linked, which means changing one of them will adjust the other one automatically. random seed - a number to be used to initialize the random number generator. Can be useful if you want to create a reproducible sequence of frames. Honeypots In this mode some random frames of the task are selected into the validation set. Then, validation frames are randomly mixed into regular annotation jobs. This mode can also be called “Ground Truth pool”, reflecting the way validation frames are used. This mode can only be used at task creation and cannot be changed later.\nThe mode has some limitations on the compatible tasks:\nIt’s not possible to use it for an already existing task, the task has to be recreated. This mode assumes random frame ordering, so it is only available for image annotation tasks and not for ordered sequences like videos. Tracks are not supported in such tasks. The validation set can be managed after the task is created - annotations can be edited, frames can be excluded and restored, and honeypot frames in the regular jobs can be changed. However, it’s not possible to select new validation frames after the task is created. The Ground truth job created for this validation mode cannot be deleted.\nParameters:\nframe count per job (%) - the percent of job frames (segment size) to be added into each annotation job from the validation set. Can be specified in the Overhead per job field. total frame count (%) - the percent of the task frames to be included into the validation set. This value must result in at least frame count per job * segment size frames. Can be specified in the Total honeypots field. Mode summary Here is a brief comparison of the validation modes:\nAspect Ground Truth Honeypots When can be used any time at task creation only Frame management options exclude, restore exclude, restore, change honeypots in jobs Ground Truth job management options create, delete create Task frame requirements - random ordering only Annotations any tracks are not supported Minimum validation frames count - manual and random_uniform - any (but some jobs can get no validation frames)- random_per_job - jobs count * GT frames per job not less than honeypots count per job Task annotation import GT annotations and regular annotations do not affect each other Annotations are imported both into the GT job and regular jobs. Annotations for validation frames are copied into corresponding honeypot frames. Task annotation export GT annotations and regular annotations do not affect each other Annotations for non-validation frames are exported as is. Annotations for validation frames are taken from the GT frames. Honeypot frames are skipped. Choosing the right mode Here are some examples on how to choose between these options. The general advice is to use Ground Truth for better flexibility, but keep in mind that it can require more resources for validation set annotation. Honeypots, on the other hand, can be beneficial if you want to minimize the number of validation images required, but the downside here is that there are some limitations on where this mode can be used.\nExample: a video annotation with tracks. In this case there is only 1 option - the Ground Truth mode, so just use it.\nExample: an image dataset annotation, image order is not important. Here you can use both options. You can choose Ground Truth for better flexibility in validation. This way, you will have the full control of validation frames in the task, annotation options won’t be limited, and the regular jobs will not be affected in any way. However, if you have a limited budget for the validation (for instance, you have only a small number of validation frames) or you want to allow more scalability (with this approach the number of validation frames doesn’t depend on the number of regular annotation jobs), it makes sense to consider using Honeypots instead.\nQuality management If a task has a validation configured, there are several options to manage validation set images. With any of the validation modes, there will be a special Ground Truth (GT) job in the task.\nValidation set management Validation frames can be managed on the task Quality Management page. Here it’s possible to check the number of validation frames, current validation mode and review the frame details. For each frame you can see the number of uses in the task. When in the Ground Truth mode, this number will be 1 for all frames. With Honeypots, these numbers can be 0, 1 or more.\nFrame changes In both validation modes it’s possible to exclude some of the validation frames from being used for validation. This can be useful if you find that some of the validation frames are “bad”, extra, or if they have incorrect annotations, which you don’t want to fix. Once a frame is marked “excluded”, it will not be used for validation. There is also an option to restore a previously excluded frame if you decide so.\nThere is an option to exclude or restore frames in bulk mode. To use it, select the frames needed using checkboxes, and click one of the buttons next to the table header.\nGround Truth job management In the Ground Truth validation mode, there will be an option to remove the Ground Truth job from the task. It can be useful if you want to change validation set frames completely, add more frames, or remove some of the frames for any reason. This is available in the job Actions menu.\nIn the Honeypots mode, it’s not possible to add or remove the GT job, so it’s not possible to add more validation frames.\nCreate A Ground Truth job can be added manually in a task without a selected validation mode or in a task with the Ground Truth validation mode, after the existing Ground Truth job is deleted manually.\nDelete To delete the Ground Truth job, do the following:\nOpen the task and find the Ground Truth job in the jobs list. Click on three dots to open the menu. From the menu, select Delete. Note The Ground truth job in the “Honeypots” task validation mode cannot be deleted. Import annotations If you want to import annotations into the Ground truth job, do the following:\nOpen the task and find the Ground truth job in the jobs list. Click on three dots to open the menu. From the menu, select Import annotations. Select import format and select file. Click OK. Note If there are imported annotations for the frames that exist in the task, but are not included in the Ground truth job, they will be ignored. This way, you don’t need to worry about “cleaning up” your Ground truth annotations for the whole dataset before importing them. Importing annotations for the frames that are not known in the task still raises errors. Export annotations To export annotations from the Ground Truth job, do the following:\nOpen the task and find a job in the jobs list. Click on three dots to open the menu. From the menu, select Export annotations. Annotation management Annotations for validation frames can be displayed and edited in a special Ground Truth job in the task. You can edit the annotations manually, use auto-annotation features, import and export annotations in this job.\nIn the Ground Truth task validation mode, annotations of the ground Truth job do not affect other jobs in any way. The Ground Truth job is just a separate job, which can only be changed directly. Annotations from Ground truth jobs are not included in the dataset export, they also cannot be imported during task annotations import or with automatic annotation for the task.\nIn the Honeypots task validation mode, the annotations of the GT job also do not affect other jobs in any way. However, import and export of task annotations works differently. When importing task annotations, annotations for validation frames will be copied both into GT job frames and into corresponding honeypot frames in annotation jobs. When exporting task annotations, honeypot frames in annotation jobs will be ignored, and validation frames in the resulting dataset will get annotations from the GT job.\nNote That it means that exporting from a task with honeypots and importing the results back will result in changed annotations on the honeypot frames. If you want to backup annotations, use a task backup or export job annotations instead. Import and export of Ground Truth job annotations works the same way in both modes.\nGround Truth jobs are included in task backups, so can be saved and restored this way.\nImport, Export, and Delete options are available from the Ground Truth job Actions menu. Read more.\nAnnotation quality settings Quality settings provide options to tweak some aspects of annotation comparisons and quality estimation in general. For instance, you can configure which annotation overlap should be considered good enough or how specific annotation types must be compared.\nQuality settings can be set up at the Task or the Project level. If a task is not bound to a project, it uses its own quality settings. Tasks inside a project can use individual quality settings or inherit settings from the project they belong to. Read more about quality settings in projects here.\nTo set up quality settings, open the Quality Settings tab on the Quality Control page for a task or project, available in the Actions menu.\nThere is a number of parameters available for configuration. Hover the mouse over a ? mark to display a description for a setting.\nAfter the settings are updated, remember to save the values using the Save button. The updated settings will take effect on the next quality update.\nAnnotation quality settings have the following parameters:\nParameter Description General reporting Target metric The primary metric used for quality estimation. It affects which metric is displayed in the UI and used for overall quality estimation. Job selection filter The filter for the jobs included in quality computation. Only jobs matching the filter criteria will be included in the quality results. Immediate feedback Max validations per job Configures maximum job validations per assignment for the Immediate feedback feature. Target metric threshold Defines the minimal quality requirements in terms of the selected target metric. Serves as an acceptance threshold for the Immediate feedback feature. Shape matching Min overlap threshold Min overlap threshold used for the distinction between matched and unmatched shapes. Used to match all types of annotations. It corresponds to the Intersection over union (IoU) for spatial annotations, such as bounding boxes and masks. Low overlap threshold Low overlap threshold used for the distinction between strong and weak matches. Only affects Low overlap warnings. It’s supposed that Min similarity threshold \u003c= Low overlap threshold. Empty frames are annotated Consider frames annotated as “empty” if there are no annotations on a frame. If a frame is empty in both GT and job annotations, it will be considered a matching annotation. Point and Skeleton matching OKS Sigma Relative size of points. The percent of the bbox side, used as the radius of the circle around the GT point, where the checked point is expected to be. For boxes with different width and height, the “side” is computed as a geometric mean of the width and height. Point matching Point size base When comparing point annotations (including both separate points and point groups), the OKS sigma parameter defines a matching area for each GT point based on the object size. The point size base parameter allows configuring how to determine the object size. If set to image_size, the image size is used. Useful if each point annotation represents a separate object or boxes grouped with points do not represent object boundaries. If set to group_bbox_size, the object size is based on the point group bounding box size. Useful if each point group represents an object or there is a bbox grouped with points, representing the object size. Polyline matching Relative thickness Thickness of polylines, relative to the (image area) ^ 0.5. The distance to the boundary around the GT line inside of which the checked line points should be. Check orientation Indicates that polylines have direction. Used to produce Mismatching direction warnings Min similarity gain (%) The minimal gain in IoU between the given and reversed line directions to consider the line inverted. Only useful with the Check orientation parameter. Group matching Compare groups Enables or disables annotation group checks. This check will produce Group mismatch warnings for grouped annotations, if the annotation groups do not match with the specified threshold. Each annotation within a group is expected to match with a corresponding annotation in a GT group. Min group match threshold Minimal IoU for groups to be considered matching, used when Compare groups is enabled. Mask and polygon matching Check object visibility Check for partially-covered annotations. Masks and polygons will be compared to each other. Min visibility threshold Minimal visible area percent of the mask annotations (polygons, masks). Used for reporting Covered annotation warnings, useful with the Check object visibility option. Match only visible parts Use only the visible part of the masks and polygons in comparisons. Project quality settings In CVAT, it is possible to group tasks into projects to share common configurations or establish a logical grouping for datasets. In this section, we explain options for quality management inside projects.\nWhen tasks are inside a project, it can be convenient to reuse the same quality setup for all the project tasks. There is an option to use quality settings from the parent project for all or only for specific tasks inside a project. This is controlled by the corresponding toggle on the Quality control page of the task:\nIf some of the project tasks have individual settings, a notification is displayed on the project settings page. You can enforce project settings for all the project tasks by clicking the Force project settings button.\nBy default, new tasks inside a project inherit the quality settings of the project. You can freely switch between these 2 modes without losing the individual configuration for the task.\nUpdating project quality includes quality computation for all the nested tasks. If the task quality is updated in a specific task manually, project quality has to be recomputed to display relevant values.\nJob filtering Depending on the situation, you may need or don’t need to include specific jobs in the quality report. For example, your workflow may require quality checks only for completed jobs or maybe you want to exclude jobs from a specific task from a project quality report. There is an option to filter which jobs are included in quality computations. You can configure this by changing the Job selection filter in quality settings. Only jobs matching the filter criteria will be included in the quality results. If a filter is changed, quality must be recomputed for the filter to take effect.\nComparisons Tags The equality is used for matching.\nShapes A pair of shapes is considered matching, if both their shapes and labels match. For each shape, spatial parameters are matched first, then labels are matched.\nEach shape type can have their own spatial matching details. Specifically:\nbounding box - IoU (including rotation). For example, for a pair of bounding boxes it can be visualized this way:\nIoU = intersection area / union area. The green part is the intersection, and green, yellow and red ones together are the union.\npolygons, masks - IoU. Polygons and masks are considered interchangeable, which means a mask can be matched with a polygon and vice versa. Polygons and masks in groups are merged into a single object first. If the Match only visible parts option is enabled, objects will be cut to only the visible (non-covered) parts only, which is determined by the shape z order.\nskeletons - The OKS metric from the COCO dataset is used. Briefly, each skeleton point gets a circular area around, determined by the object size (bounding box side) and relative point size (sigma) values, where this point can be matched with the specified probability. If a bounding box is grouped with the skeleton, it is used for object size computation, otherwise a bounding box of visible points of the skeleton is used.\nFor example, consider a skeleton with 6 points and a square bounding box attached:\nIn this example, the Sigma parameter is 0.05 (5%) of the bbox side. Areas shown in the green color cover ~68.2% (1 sigma) of the points, corresponding to each GT point. A point on the boundary of such an area will have ~88% of probability to be correct. The blue-colored zone contains ~95% (2 sigma) of the correct points for the corresponding GT point. A point on the boundary of such an area will have ~60% of probability to be correct. These probabilities are then averaged over the visible points of the skeleton, and the resulting values are compared against the Min similarity threshold to determine whether the skeletons are matching. Sigma corresponds to one from the normal distribution.\npoints - The OKS metric is used for each point group annotation. Same as for skeletons, OKS Sigma determines relative point sizes. The Point size base setting allows configuring whether points in point groups should use the group bounding box or the image space. Using image space for object size can be useful if you want to treat each point as a separate annotation.\npolylines - A pair of lines is considered matching if all the points of one line lie within a “hull” of the other one. The “hull” is determined as the area around the polyline, such as if the line had some “thickness”. For example, the black polyline can have a hull shown in the green color:\nThe line thickness can be configured via the Relative thickness setting. The value is relative to the image side and determines a half of the hull width.\nellipses - IoU, described in more detail above.\nNote 2D cuboids are not supported. Tracks Tracks are split into separate shapes and compared on the per-frame basis with other tracks and shapes.\nQuality Analytics Note Quality analytics is a paid feature. Please check how to get access to this functionality in the Paid features section of the site. Once the quality estimation is enabled in a task and the Ground Truth job is configured, quality analytics becomes available for the task and its jobs.\nWhen you open the Quality Analytics page, it displays quality metrics from the most recent quality estimation. If it’s your first time accessing the page, no quality report will be available yet. The date of the last computation is shown next to the report download button.\nIf you want to request updating of quality metrics in a task (e.g. after the settings were changed), you can do this by pressing the Refresh button on the task Quality Management \u003e Analytics page.\nNote The process of quality calculation may take up to several hours, depending on the amount of data and labeled objects, and is not updated immediately after task updates. Once quality metrics are computed, they are available for detailed review on this page. Conflicts can be reviewed in the Review mode of jobs. A job must have at least 1 validation frame (shown in the Frame intersection column) to be included in quality computation.\nAnalytics page contents The Analytics page has the following elements:\nField Description Mean annotation quality Displays the average quality of annotations, which includes: counts of the accurate annotations, total task annotations, ground truth annotations, accuracy, precision, and recall. The currently selected Target metric is displayed as the primary score. GT Conflicts Conflicts identified during quality assessment, including extra or missing annotations. Mouse over the ? icon for a detailed conflict report on your dataset. Issues Number of opened issues. If no issues were reported, 0 will be shown. Quality report Quality report in JSON format. Ground truth job data Information about ground truth job, including date, time, and number of issues. List of jobs List of all the jobs in the task Problem Reporting CVAT reports 2 possible error types: errors and warnings. Errors affect the resulting quality scores and highlight significant problems in annotations. Warnings do not affect the resulting quality metrics, but they still can highlight significant problems, depending on the project requirements.\nProblem Type Description Missing annotation error No matching annotation found in the regular job annotations. Configured by Min overlap threshold and shape type-specific parameters. Extra annotation error No matching annotation found in the GT job annotations. Configured by Min overlap threshold and shape type-specific parameters. Mismatching label error A GT and a regular job annotations match, but their labels are different. Low overlap warning A GT and a regular job annotations match, but the similarity is low. Configured by Low overlap threshold. Mismatching direction warning A GT and a regular lines match, but the lines have different direction. Configured by Compare orientation. Mismatching attributes warning A GT and a regular annotations match, but their attributes are different. Configured by Compare attributes. Mismatching groups warning A GT and a regular annotation groups do not match. Configured by Compare groups. Covered annotation warning The visible part of a regular mask or polygon annotation is too small. The visibility is determined by arranging mask and polygon shapes on the frame in the specified z order. Configured by Check object visibility. Quality Reports For each job included in quality computation there is a quality report downloading button on the Analytics page. There is also a button to download the aggregated task quality report. These buttons provide an option to download a Quality Report for a task or job in JSON format. Such reports can be useful if you want to process quality reported by CVAT automatically in your scripts etc.\nQuality Reports contain quality metrics and conflicts, and include all the information available on the quality analytics page. You can find additional quality metrics in these reports, such as mean_iou for shapes, confusion matrices, per-label and per-frame quality estimations.\nAdditional information on how to compute and use various metrics for dataset quality estimation is available here.\nReviewing GT conflicts To see GT Conflicts in the CVAT interface, go to Review \u003e Issues \u003e Show ground truth annotations and conflicts.\nGround Truth annotations are displayed with a dotted-line border. The associated label and the (Ground Truth) marker are shown on hovering.\nUpon hovering over an issue on the right-side panel with your mouse, the corresponding annotations are highlighted.\nUse arrows in the Issue toolbar to move between GT conflicts.\nTo create an issue related to the conflict, right-click on the bounding box and from the menu select the type of issue you want to create.\nAnnotation quality \u0026 Honeypot video tutorial This video demonstrates the process:\n","categories":"","description":"Guidelines for assessing annotation quality in CVAT automatically","excerpt":"Guidelines for assessing annotation quality in CVAT automatically","ref":"/v2.43.0/docs/manual/advanced/analytics-and-monitoring/auto-qa/","tags":"","title":"Automated QA, Review \u0026 Honeypots"},{"body":"","categories":"","description":"This section contains basic documents for system administrators.","excerpt":"This section contains basic documents for system administrators.","ref":"/v2.43.0/docs/administration/basics/","tags":"","title":"Basics"},{"body":"","categories":"","description":"This section contains basic documents for CVAT users","excerpt":"This section contains basic documents for CVAT users","ref":"/v2.43.0/docs/manual/basics/","tags":"","title":"Basics"},{"body":"Before you start, you have to make sure that Cuboid is selected and choose a drawing method from rectangle or by 4 points.\nDrawing cuboid by 4 points Choose a drawing method by 4 points and select Shape to enter the drawing mode. There are many ways to draw a cuboid. You can draw the cuboid by placing 4 points, after that the drawing will be completed automatically. The first 3 points determine the plane of the cuboid while the last point determines the depth of that plane. For the first 3 points, it is recommended to only draw the 2 closest side faces, as well as the top and bottom face.\nA few examples:\nDrawing cuboid from rectangle Choose a drawing method from rectangle and select Shape to enter the drawing mode. When you draw using the rectangle method, you must select the frontal plane of the object using the bounding box. The depth and perspective of the resulting cuboid can be edited.\nExample:\n","categories":"","description":"","excerpt":"Before you start, you have to make sure that Cuboid is selected and …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-cuboids/creating-the-cuboid/","tags":"","title":"Creating the cuboid"},{"body":"This guide is designed to provide a comprehensive overview of the architecture and components of the CVAT and to illustrate how each component interacts within the system.\nDomain Component Functionality Description Analytics Vector Event processing There are several components that process events (backend, frontend, web UI). All events are sent to a single point - Vector, where they are processed and then redirected to ClickHouse. For more information, see Analytics. ClickHouse Event database Stores events. For more information, see Analytics. Grafana Dashboards Data based on the web interface. For more information, see Analytics. Data storage NFS RVVX access mode storage is required in case of multi-node deployment. Available with different types of storages: AWS: Amazon Elastic File System (EFS)Azure: Azure Files with NFS GCP: Filestore NFS Contains data required for CVAT operations It is necessary to have the capability for multiple mounting (across several nodes) in RWX mode. For more information, see K8 Deployment with Helm Data cache Apache kvrocks Used for data caching (queries and search). Suitable for environments that require frequent database queries. Apache Kvrocks Job queue Redis Queue manager Database PostgreSQL Database A database where data is stored in a structured form. CVAT.ai Components Ingress Controller (can be disabled) Routing traffic. CVAT deployment on Kubernetes with Helm Authorization Authorization service based on Open Policy Agent. Backend CVAT Backend Main framework Main engine, uses Django + Django DRF. Workers Import Worker Everything related to loading data - creating tasks, uploading annotations, etc. Export Worker Everything related to exporting data - exporting results, creating dumps, etc. Annotation Worker Auto-annotation tasks. Utils Worker Responsible for tracking various file changes and more. Analytics Report Reports and analytics that are displayed in the CVAT interface. Quality Report Analysis and reports on data quality. Webhook Worker Manages webhooks. Auto annotation Auto Annotation Nucio Microservice application, used for auto annotation. How to enable auto annotation feature. ","categories":"","description":"Description of CVAT architecture and components","excerpt":"Description of CVAT architecture and components","ref":"/v2.43.0/docs/administration/advanced/cvat-architecture/","tags":"","title":"CVAT Architecture"},{"body":" Prerequisites Installing dependencies Optional steps Configuration Postgresql password? (Optional) Enable Auto annotation feature Analytics Deployment With overrides: Without overrides: Post-deployment configuration How to create superuser? FAQ What is kubernetes and how it is working? What is helm and how it is working? How to setup Minikube How to understand what diff will be inflicted by ‘helm upgrade’? I want to use my own postgresql/redis with your chart. I want to override some settings in values.yaml. Why you used external charts to provide redis and postgres? Prerequisites Installed and configured kubernetes cluster. If you do not already have a cluster, you can create one by using Minikube. How to setup Minikube. Installed kubectl Installed Helm. Installed dependencies Installing dependencies To install and/or update run:\nhelm dependency update Optional steps Ingress configuration for the Traefik ingress controller is enabled by default.\nNote for Minikube use:\nbecause the Traefik creates its main service with Loadbalanser type, which involve the assignment of externalIP by Cloud, what never happens on Minikube, you need to explicitly set the externalIP address for the traefic service. Add the following to values.override.yaml file: traefik: service: externalIPs: - \"your minikube IP (can be obtained with `minikube ip` command)\" Also ensure that your CVAT ingress appears on your hosts file (/etc/hosts). You can do this by running this command: cvat.local is default domainname, you can override it via values.override.yaml. echo \"$(minikube ip) cvat.local\" | sudo tee -a /etc/hosts Configuration Create values.override.yaml file inside helm-chart directory. Fill values.override.yaml with new parameters for chart. Override postgresql password Postgresql password? Put below into your values.override.yaml\npostgresql: secret: password: \u003cinsert_password\u003e postgres_password: \u003cinsert_postgres_password\u003e replication_password: \u003cinsert_replication_password\u003e Or create your own secret and use it with:\npostgresql: global: postgresql: existingSecret: \u003csecret\u003e (Optional) Enable Auto annotation feature Before starting, ensure that the following prerequisites are met:\nThe Nuclio CLI (nuctl) is installed. To install the CLI, simply download the appropriate CLI version to your installation machine. Set nuclio.enabled: true in your values.override.yaml\nRun helm dependency update in helm-chart directory\nBecause Nuclio functions are images that need to be pushed and pulled to/from the registry, you need to configure credentials to pull from your preferable registry with the following settings: Options:\nvalues.override.yaml file:\nregistry: loginUrl: someurl credentials: username: someuser password: somepass Or you can create a secret with credentials as described in the guide and set registry.secretName=your-registry-credentials-secret-name in the values.override.yaml file.\nIn the case of using Minikube, you can run a local unsecured registry with minikube add-ons:\nminikube addons enable registry minikube addons enable registry-aliases Before Docker container images can be pushed to your newly created insecure registry, you need to add its address ($(minikube ip):5000) to the list of insecure registries to instruct Docker to accept working against it: follow the instructions in the Docker documentation\nYou might also need to log into your registry account (docker login) on the installation machine before running the deployment command.\nCreate cvat project:\nnuctl --namespace \u003cyour cvat namespace\u003e create project cvat Finally deploy the function, i.e.:\nusing minikube registry: nuctl deploy --project-name cvat --path serverless/tensorflow/faster_rcnn_inception_v2_coco/nuclio --registry $(minikube ip):5000 --run-registry registry.minikube using Docker hub: nuctl deploy --project-name cvat --path serverless/tensorflow/faster_rcnn_inception_v2_coco/nuclio --registry docker.io/your_username Analytics Analytics is enabled by default, to disable set analytics.enabled: false in your values.override.yaml\nDeployment Make sure you are using correct kubernetes context. You can check it with kubectl config current-context.\nWarning The k8s service name of Open Policy Agent is fixed to opa by default. This is done to be compatible with CVAT 2.0 but limits this helm chart to a single release per namespace. The OPA url currently can´t be set as an environment variable. As soon as this is possible you can set cvat.opa.composeCompatibleServiceName to false in your value.override.yaml and configure the opa url as additional env. Execute following command from repo root directory\nWith overrides: helm upgrade -n \u003cdesired_namespace\u003e \u003crelease_name\u003e -i --create-namespace ./helm-chart -f ./helm-chart/values.yaml -f ./helm-chart/values.override.yaml\nWithout overrides: helm upgrade -n \u003cdesired_namespace\u003e \u003crelease_name\u003e -i --create-namespace ./helm-chart -f ./helm-chart/values.yaml\nPost-deployment configuration Create super user How to create superuser? HELM_RELEASE_NAMESPACE=\"\u003cdesired_namespace\u003e\" \u0026\u0026\\ HELM_RELEASE_NAME=\"\u003crelease_name\u003e\" \u0026\u0026\\ BACKEND_POD_NAME=$(kubectl get pod --namespace $HELM_RELEASE_NAMESPACE -l tier=backend,app.kubernetes.io/instance=$HELM_RELEASE_NAME,component=server -o jsonpath='{.items[0].metadata.name}') \u0026\u0026\\ kubectl exec -it --namespace $HELM_RELEASE_NAMESPACE $BACKEND_POD_NAME -c cvat-backend -- python manage.py createsuperuser FAQ What is kubernetes and how it is working? See https://kubernetes.io/\nWhat is helm and how it is working? See https://helm.sh/\nHow to setup Minikube Please follow the official Minikube installation guide minikube start --addons registry,registry-aliases How to understand what diff will be inflicted by ‘helm upgrade’? You can use https://github.com/databus23/helm-diff#install for that\nI want to use my own postgresql with your chart. Just set postgresql.enabled to false in the override file, then put the parameters of your database instance in the external field. You may also need to configure username, database and password fields to connect to your own database:\npostgresql: enabled: false external: host: postgresql.default.svc.cluster.local port: 5432 auth: username: cvat database: cvat secret: password: cvat_postgresql In example above corresponding secret will be created automatically, but if you want to use existing secret change secret.create to false and set name of existing secret:\npostgresql: enabled: false external: host: postgresql.default.svc.cluster.local port: 5432 secret: create: false name: \"my-postgresql-secret\" The secret must contain the database, username and password keys to access to the database like:\napiVersion: v1 kind: Secret metadata: name: \"my-postgresql-secret\" namespace: default type: generic stringData: database: cvat username: cvat password: secretpassword I want to use my own redis with your chart. Just set redis.enabled to false in the override file, then put the parameters of your Redis instance in the external field. You may also need to configure password field to connect to your own Redis:\nredis: enabled: false external: host: redis.hostname.local secret: password: cvat_redis In the above example the corresponding secret will be created automatically, but if you want to use an existing secret change secret.create to false and set name of the existing secret:\nredis: enabled: false external: host: redis.hostname.local secret: create: false name: \"my-redis-secret\" The secret must contain the redis-password key like:\napiVersion: v1 kind: Secret metadata: name: \"my-redis-secret\" namespace: default type: generic stringData: redis-password: secretpassword I want to override some settings in values.yaml. Just create file values.override.yaml and place your changes here, using same structure as in values.yaml. Then reference it in helm update/install command using -f flag\nWhy you used external charts to provide redis and postgres? Because they definitely know what they do better then we are, so we are getting more quality and less support\nHow to use custom domain name with k8s deployment: The default value cvat.local may be overridden with --set ingress.hosts[0].host option like this:\nhelm upgrade -n default cvat -i --create-namespace helm-chart -f helm-chart/values.yaml -f helm-chart/values.override.yaml --set ingress.hosts[0].host=YOUR_FQDN How to fix fail of helm upgrade due label field is immutable reason? If an error message like this:\nError: UPGRADE FAILED:cannot patch \"cvat-backend-server\" with kind Deployment: Deployment.apps \"cvat-backend-server\" is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\"app\":\"cvat-app\", \"app.kubernetes.io/instance\":\"cvat\", \"app.kubernetes.io/managed-by\":\"Helm\", \"app.kubernetes.io/name\":\"cvat\", \"app.kubernetes.io/version\":\"latest\", \"component\":\"server\", \"helm.sh/chart\":\"cvat\", \"tier\":\"backend\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable To fix that, delete CVAT Deployments before upgrading\nkubectl delete deployments --namespace=foo -l app=cvat-app How to use existing PersistentVolume to store CVAT data instead of default storage It is assumed that you have created a PersistentVolumeClaim named my-claim-name and a PersistentVolume that backing the claim. Claims must exist in the same namespace as the Pod using the claim. For details see. Add these values in the values.override.yaml:\ncvat: backend: permissionFix: enabled: false defaultStorage: enabled: false server: additionalVolumes: - name: cvat-backend-data persistentVolumeClaim: claimName: my-claim-name worker: export: additionalVolumes: - name: cvat-backend-data persistentVolumeClaim: claimName: my-claim-name import: additionalVolumes: - name: cvat-backend-data persistentVolumeClaim: claimName: my-claim-name annotation: additionalVolumes: - name: cvat-backend-data persistentVolumeClaim: claimName: my-claim-name utils: additionalVolumes: - name: cvat-backend-data persistentVolumeClaim: claimName: my-claim-name ","categories":"","description":"Instructions for deploying CVAT on a Kubernetes cluster.","excerpt":"Instructions for deploying CVAT on a Kubernetes cluster.","ref":"/v2.43.0/docs/administration/advanced/k8s_deployment_with_helm/","tags":"","title":"CVAT deployment on Kubernetes with Helm"},{"body":"This is CVAT’s native annotation format, which fully supports all of CVAT’s annotation features. It is ideal for creating data backups.\nFor more information, see:\nFormat specification Dataset examples CVAT for image export Applicable for all computer vision tasks in 2D except for Video Tracking.\nFor export of images:\nSupported annotations: Bounding Boxes, Polygons, Polylines, Points, Cuboids, Ellipses, Skeletons, Tags, Masks. Attributes: Supported. Tracks: Can be exported, but track id will be lost. The downloaded file is a zip archive with following structure:\ntaskname.zip/ ├── images/ | ├── img1.png | └── img2.jpg └── annotations.xml CVAT for video export Applicable for all computer vision tasks in 2D except for Classification\nFor export of images:\nSupported annotations: Bounding Boxes, Polygons, Polylines, Points, Cuboids, Ellipses, Skeletons,Masks. Attributes: Supported. Tracks: Supported (tracks are split by frames). Shapes are exported as single-frame tracks Downloaded file is a zip archive with following structure:\ntaskname.zip/ ├── images/ | ├── frame_000000.png | └── frame_000001.png └── annotations.xml CVAT loader Uploaded file: either an XML file or a .zip file containing the aforementioned structures.\n","categories":"","description":"How to export and import data in CVAT for image format","excerpt":"How to export and import data in CVAT for image format","ref":"/v2.43.0/docs/manual/advanced/formats/format-cvat/","tags":"","title":"CVAT for image"},{"body":"Datumaro serves as a versatile format capable of handling complex dataset and annotation transformations, format conversions, dataset statistics, and merging, among other features. It functions as the dataset support provider within CVAT. Essentially, anything you can do in CVAT, you can also achieve in Datumaro, but with the added benefit of specialized dataset operations.\nFor more information, see:\nDatumaro specification Export annotations in Datumaro format For export of images: any 2D shapes, tags\nSupported annotations: Bounding Boxes, Polygons, Polylines, Points, Cuboids, Tags, Ellipses, Masks, Skeletons. Attributes: Supported. Tracks: Supported. The downloaded file is a zip archive with the following structure:\ntaskname.zip/ ├── annotations/ │ └── default.json # fully description of classes and all dataset items └── images/ # if the option `save images` was selected └── default ├── image1.jpg ├── image2.jpg ├── ... Import annotations in Datumaro format supported annotations: Bounding Boxes, Polygons, Polylines, Masks, Points, Cuboids, Labels, Skeletons supported attributes: any Uploaded file: a zip archive of the following structure:\n\u003carchive_name\u003e.zip/ └── annotations/ ├── subset1.json # fully description of classes and all dataset items └── subset2.json # fully description of classes and all dataset items JSON annotations files in the annotations directory should have similar structure:\n{ \"info\": {}, \"categories\": { \"label\": { \"labels\": [ { \"name\": \"label_0\", \"parent\": \"\", \"attributes\": [] }, { \"name\": \"label_1\", \"parent\": \"\", \"attributes\": [] } ], \"attributes\": [] } }, \"items\": [ { \"id\": \"img1\", \"annotations\": [ { \"id\": 0, \"type\": \"polygon\", \"attributes\": {}, \"group\": 0, \"label_id\": 1, \"points\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0], \"z_order\": 0 }, { \"id\": 1, \"type\": \"bbox\", \"attributes\": {}, \"group\": 1, \"label_id\": 0, \"z_order\": 0, \"bbox\": [1.0, 2.0, 3.0, 4.0] }, { \"id\": 2, \"type\": \"mask\", \"attributes\": {}, \"group\": 1, \"label_id\": 0, \"rle\": { \"counts\": \"d0d0:F\\\\0\", \"size\": [10, 10] }, \"z_order\": 0 } ] } ] } ","categories":"","description":"How to export and import data in Datumaro format","excerpt":"How to export and import data in Datumaro format","ref":"/v2.43.0/docs/manual/advanced/formats/format-datumaro/","tags":"","title":"Datumaro"},{"body":"\nFiftyOne is an open-source tool for building high-quality datasets and computer vision models. FiftyOne supercharges your machine learning workflows by enabling you to visualize datasets and interpret models faster and more effectively.\nFiftyOne provides an API to create tasks and jobs, upload data, define label schemas, and download annotations using CVAT, all programmatically in Python. All of the following label types are supported, for both image and video datasets:\nClassifications Detections Instance segmentations Polygons and polylines Keypoints Scalar fields Semantic segmentation ","categories":"","description":"","excerpt":"\nFiftyOne is an open-source tool for building high-quality datasets …","ref":"/v2.43.0/docs/integration/fiftyone/","tags":"","title":"FiftyOne"},{"body":"","categories":"","description":"","excerpt":"","ref":"/v2.43.0/docs/getting_started/","tags":"","title":"Getting started"},{"body":"Quick installation guide Before you can use CVAT, you’ll need to get it installed. The document below contains instructions for the most popular operating systems. If your system is not covered by the document it should be relatively straightforward to adapt the instructions below for other systems.\nProbably you need to modify the instructions below in case you are behind a proxy server. Proxy is an advanced topic and it is not covered by the guide.\nFor access from China, read sources for users from China section.\nUbuntu 22.04/20.04 (x86_64/amd64) Open a terminal window. If you don’t know how to open a terminal window on Ubuntu please read the answer.\nType commands below into the terminal window to install Docker and Docker Compose. More instructions can be found here.\n# Add Docker's official GPG key: sudo apt-get update sudo apt-get install ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc # Add the repository to Apt sources: echo \\ \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026\u0026 echo \"${UBUNTU_CODENAME:-$VERSION_CODENAME}\") stable\" | \\ sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt-get update # Install the Docker packages. sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin (Optional) To avoid prefacing Docker commands with sudo, you can perform the post-installation steps. This involves creating a Unix group named docker and adding your current user to this group.\nsudo groupadd docker sudo usermod -aG docker $USER Log out and log back in (or reboot) so that your group membership is re-evaluated. You can type groups command in a terminal window after that and check if docker group is in its output.\nClone CVAT source code from the GitHub repository with Git.\nFollowing command will clone the latest develop branch:\ngit clone https://github.com/cvat-ai/cvat cd cvat See alternatives if you want to download one of the release versions or use the wget or curl tools.\nTo access CVAT over a network or through a different system, export CVAT_HOST environment variable\nexport CVAT_HOST=FQDN_or_YOUR-IP-ADDRESS Run docker containers. It will take some time to download the latest CVAT and other required images like postgres, redis, and start containers.\ndocker compose up -d (Optional) Use CVAT_VERSION environment variable to specify the version of CVAT you want to install specific version (e.g v2.1.0, dev). Default behavior: dev images will be pulled for develop branch, and corresponding release images for release versions.\nCVAT_VERSION=dev docker compose up -d Alternative: if you want to build the images locally with unreleased changes see How to pull/build/update CVAT images section\nYou can register a user but by default, it will not have rights even to view the list of tasks. Thus you should create a superuser. The superuser can use an admin panel to assign the correct groups to the user. Please use the command below:\ndocker exec -it cvat_server bash -ic 'python3 ~/manage.py createsuperuser' Choose a username and a password for your admin account. For more information please read Django documentation.\nGoogle Chrome is the only browser that is supported by CVAT. You need to install it as well. Type commands below in a terminal window:\nsudo curl https://dl-ssl.google.com/linux/linux_signing_key.pub -o /etc/apt/trusted.gpg.d/google.asc sudo sh -c 'echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" \u003e\u003e /etc/apt/sources.list.d/google-chrome.list' sudo apt-get update sudo apt-get --no-install-recommends install -y google-chrome-stable Open the installed Google Chrome browser and go to localhost:8080. Type your login/password for the superuser on the login page and press the Login button. Now you should be able to create a new annotation task. Please read the CVAT manual for more details.\nWindows 10 Install WSL2 (Windows subsystem for Linux) refer to this official guide. WSL2 requires Windows 10, version 2004 or higher. After installing WSL2, install a Linux Distribution of your choice.\nDownload and install Docker Desktop for Windows. Double-click Docker for Windows Installer to run the installer. More instructions can be found here. Official guide for docker WSL2 backend can be found here. Note: Check that you are specifically using WSL2 backend for Docker.\nIn Docker Desktop, go to Settings \u003e\u003e Resources \u003e\u003e WSL Integration, and enable integration with the Linux Distribution that you chose.\nDownload and install Git for Windows. When installing the package please keep all options by default. More information about the package can be found here.\nDownload and install Google Chrome. It is the only browser which is supported by CVAT.\nGo to windows menu, find the Linux distribution you installed and run it. You should see a terminal window.\nClone CVAT source code from the GitHub repository.\nThe following command will clone the latest develop branch:\ngit clone https://github.com/cvat-ai/cvat cd cvat See alternatives if you want to download one of the release versions.\nRun docker containers. It will take some time to download the latest CVAT release and other required images like postgres, redis, etc. from DockerHub and create containers.\ndocker compose up -d (Optional) Use CVAT_VERSION environment variable to specify the version of CVAT you want to install specific version (e.g v2.1.0, dev). Default behavior: dev images will be pulled for develop branch, and corresponding release images for release versions.\nCVAT_VERSION=dev docker compose up -d Alternative: if you want to build the images locally with unreleased changes see How to pull/build/update CVAT images section\nYou can register a user but by default, it will not have rights even to view the list of tasks. Thus you should create a superuser. A superuser can use an admin panel to assign correct groups to other users. Please use the command below:\nsudo docker exec -it cvat_server bash -ic 'python3 ~/manage.py createsuperuser' If you don’t have winpty installed or the above command does not work, you may also try the following:\n# enter docker image first docker exec -it cvat_server /bin/bash # then run python3 ~/manage.py createsuperuser Choose a username and a password for your admin account. For more information please read Django documentation.\nOpen the installed Google Chrome browser and go to localhost:8080. Type your login/password for the superuser on the login page and press the Login button. Now you should be able to create a new annotation task. Please read the CVAT manual for more details.\nMac OS Mojave Download Docker for Mac. Double-click Docker.dmg to open the installer, then drag Moby the whale to the Applications folder. Double-click Docker.app in the Applications folder to start Docker. More instructions can be found here.\nThere are several ways to install Git on a Mac. The easiest is probably to install the Xcode Command Line Tools. On Mavericks (10.9) or above you can do this simply by trying to run git from the Terminal the very first time.\ngit --version If you don’t have it installed already, it will prompt you to install it. More instructions can be found here.\nDownload and install Google Chrome. It is the only browser which is supported by CVAT.\nOpen a terminal window. The terminal app is in the Utilities folder in Applications. To open it, either open your Applications folder, then open Utilities and double-click on Terminal, or press Command - spacebar to launch Spotlight and type “Terminal,” then double-click the search result.\nClone CVAT source code from the GitHub repository with Git.\nThe following command will clone the latest develop branch:\ngit clone https://github.com/cvat-ai/cvat cd cvat See alternatives if you want to download one of the release versions or use the wget or curl tools.\nRun docker containers. It will take some time to download the latest CVAT release and other required images like postgres, redis, etc. from DockerHub and create containers.\ndocker compose up -d (Optional) Use CVAT_VERSION environment variable to specify the version of CVAT you want to install specific version (e.g v2.1.0, dev). Default behavior: dev images will be pulled for develop branch, and corresponding release images for release versions.\nCVAT_VERSION=dev docker compose up -d Alternative: if you want to build the images locally with unreleased changes see How to pull/build/update CVAT images section\nYou can register a user but by default, it will not have rights even to view the list of tasks. Thus you should create a superuser. A superuser can use an admin panel to assign correct groups to other users. Please use the command below:\ndocker exec -it cvat_server bash -ic 'python3 ~/manage.py createsuperuser' Choose a username and a password for your admin account. For more information please read Django documentation.\nOpen the installed Google Chrome browser and go to localhost:8080. Type your login/password for the superuser on the login page and press the Login button. Now you should be able to create a new annotation task. Please read the CVAT manual for more details.\nAdvanced Topics How to get CVAT source code Git (Linux, Mac, Windows) Install Git on your system if it’s not already installed\nUbuntu: sudo apt-get --no-install-recommends install -y git Windows: Follow instructions from https://git-scm.com/download/win Clone CVAT source code from the GitHub repository.\nThe command below will clone the default branch (develop):\ngit clone https://github.com/cvat-ai/cvat cd cvat To clone specific tag, e.g. v2.1.0:\ngit clone -b v2.1.0 https://github.com/cvat-ai/cvat cd cvat Wget (Linux, Mac) To download latest develop branch:\nwget https://github.com/cvat-ai/cvat/archive/refs/heads/develop.zip unzip develop.zip \u0026\u0026 mv cvat-develop cvat cd cvat To download specific tag:\nwget https://github.com/cvat-ai/cvat/archive/refs/tags/v1.7.0.zip unzip v1.7.0.zip \u0026\u0026 mv cvat-1.7.0 cvat cd cvat Curl (Linux, Mac) To download the latest develop branch:\ncurl -LO https://github.com/cvat-ai/cvat/archive/refs/heads/develop.zip unzip develop.zip \u0026\u0026 mv cvat-develop cvat cd cvat To download specific tag:\ncurl -LO https://github.com/cvat-ai/cvat/archive/refs/tags/v1.7.0.zip unzip v1.7.0.zip \u0026\u0026 mv cvat-1.7.0 cvat cd cvat CVAT healthcheck command The following command allows testing the CVAT container to make sure it works.\ndocker exec -t cvat_server python manage.py health_check The expected output of a healthy CVAT container:\nCache backend: default ... working DatabaseBackend ... working DiskUsage ... working MemoryUsage ... working MigrationsHealthCheck ... working OPAHealthCheck ... working Deploying CVAT behind a proxy If you deploy CVAT behind a proxy and do not plan to use any of serverless functions for automatic annotation, the exported environment variables http_proxy, https_proxy and no_proxy should be enough to build images. Otherwise please create or edit the file ~/.docker/config.json in the home directory of the user which starts containers and add JSON such as the following:\n{ \"proxies\": { \"default\": { \"httpProxy\": \"http://proxy_server:port\", \"httpsProxy\": \"http://proxy_server:port\", \"noProxy\": \"*.test.example.com,.example2.com\" } } } These environment variables are set automatically within any container. Please see the Docker documentation for more details.\nUsing the Traefik dashboard If you are customizing the docker compose files and you come upon some unexpected issues, using the Traefik dashboard might be very useful to see if the problem is with Traefik configuration, or with some of the services.\nYou can enable the Traefik dashboard by uncommenting the following lines from docker-compose.yml\nservices: traefik: # Uncomment to get Traefik dashboard # - \"--entryPoints.dashboard.address=:8090\" # - \"--api.dashboard=true\" # labels: # - traefik.enable=true # - traefik.http.routers.dashboard.entrypoints=dashboard # - traefik.http.routers.dashboard.service=api@internal # - traefik.http.routers.dashboard.rule=Host(`${CVAT_HOST:-localhost}`) and if you are using docker-compose.https.yml, also uncomment these lines\nservices: traefik: command: # Uncomment to get Traefik dashboard # - \"--entryPoints.dashboard.address=:8090\" # - \"--api.dashboard=true\" Note that this “insecure” dashboard is not recommended in production (and if your instance is publicly available); if you want to keep the dashboard in production you should read Traefik’s documentation on how to properly secure it.\nAdditional components Semi-automatic and automatic annotation Please follow this guide.\nStop all containers The command below stops and removes containers and networks created by up.\ndocker compose down Use your own domain If you want to access your instance of CVAT outside of your localhost (on another domain), you should specify the CVAT_HOST environment variable, like this:\nexport CVAT_HOST=\u003cYOUR_DOMAIN\u003e Share path You can use shared storage for uploading data when you create a task. To do that, you need to mount the shared storage to the CVAT docker container. Example of docker-compose.override.yml for this purpose:\nservices: cvat_server: volumes: - cvat_share:/home/django/share:ro cvat_worker_import: volumes: - cvat_share:/home/django/share:ro cvat_worker_export: volumes: - cvat_share:/home/django/share:ro cvat_worker_annotation: volumes: - cvat_share:/home/django/share:ro cvat_worker_chunks: volumes: - cvat_share:/home/django/share:ro volumes: cvat_share: driver_opts: type: none device: /mnt/share o: bind You can change the share device path to your actual share.\nYou can mount your cloud storage as a FUSE and use it later as a share.\nEmail verification You can enable email verification for newly registered users. Specify these options in the settings file to configure Django allauth to enable email verification (ACCOUNT_EMAIL_VERIFICATION = ‘mandatory’). Access is denied until the user’s email address is verified.\nACCOUNT_AUTHENTICATION_METHOD = 'username_email' ACCOUNT_CONFIRM_EMAIL_ON_GET = True ACCOUNT_EMAIL_REQUIRED = True ACCOUNT_EMAIL_VERIFICATION = 'mandatory' # Email backend settings for Django EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend' Also, you need to configure the Django email backend to send emails. This depends on the email server you are using and is not covered in this tutorial, please see Django SMTP backend configuration for details.\nDeploy CVAT on the Scaleway public cloud Please follow this tutorial to install and set up remote access to CVAT on a Scaleway cloud instance with data in a mounted object storage bucket.\nDeploy secure CVAT instance with HTTPS Using Traefik, you can automatically obtain a TLS certificate for your domain from Let’s Encrypt, enabling you to use HTTPS protocol to access your website.\nTo enable this, first set the CVAT_HOST (the domain of your website) and ACME_EMAIL (contact email for Let’s Encrypt) environment variables:\nexport CVAT_HOST=\u003cYOUR_DOMAIN\u003e export ACME_EMAIL=\u003cYOUR_EMAIL\u003e Then, use the docker-compose.https.yml file to override the base docker-compose.yml file:\ndocker compose -f docker-compose.yml -f docker-compose.https.yml up -d In the firewall, ports 80 and 443 must be open for inbound connections from any\nThen, the CVAT instance will be available at your domain on ports 443 (HTTPS) and 80 (HTTP, redirects to 443).\nDeploy CVAT with an external database By default, docker compose up will start a PostgreSQL database server, which will be used to store CVAT’s data. If you’d like to use your own PostgreSQL instance instead, you can do so as follows. Note that CVAT only supports the same major version of PostgreSQL as is used in docker-compose.yml.\nFirst, define environment variables with database connection settings:\nexport CVAT_POSTGRES_HOST=\u003cPostgreSQL hostname\u003e # mandatory export CVAT_POSTGRES_PORT=\u003cPostgreSQL port\u003e # defaults to 5432 export CVAT_POSTGRES_DBNAME=\u003cPostgreSQL database name\u003e # defaults to \"cvat\" export CVAT_POSTGRES_USER=\u003cPostgreSQL role name\u003e # defaults to \"root\" export CVAT_POSTGRES_PASSWORD=\u003cPostgreSQL role password\u003e # mandatory Then, add the docker-compose.external_db.yml file to your docker compose up command:\ndocker compose -f docker-compose.yml -f docker-compose.external_db.yml up -d How to pull/build/update CVAT images For a CVAT version lower or equal to 2.1.0, you need to pull images using docker because the compose configuration always points to the latest image tag, e.g.\ndocker pull cvat/server:v1.7.0 docker tag cvat/server:v1.7.0 openvino/cvat_server:latest docker pull cvat/ui:v1.7.0 docker tag cvat/ui:v1.7.0 openvino/cvat_ui:latest For CVAT version more than v2.1.0 it’s possible to pull specific version of prebuilt images from DockerHub using CVAT_VERSION environment variable to specify the version (e.g. dev):\nCVAT_VERSION=dev docker compose pull To build images yourself include docker-compose.dev.yml compose config file to docker compose command. This can be useful if you want to build a CVAT with some source code changes.\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml build To update local images to latest or dev tags run:\nCVAT_VERSION=dev docker compose pull or\nCVAT_VERSION=latest docker compose pull Troubleshooting Sources for users from China If you stay in China, for installation you need to override the following sources.\nFor use apt update using:\nUbuntu mirroring help\nPre-compiled packages:\ndeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse Or source packages:\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse Docker mirror station\nAdd registry mirrors into daemon.json file:\n{ \"registry-mirrors\": [ \"http://f1361db2.m.daocloud.io\", \"https://docker.mirrors.ustc.edu.cn\", \"https://hub-mirror.c.163.com\", \"https://mirror.ccs.tencentyun.com\" ] } For using pip:\nPyPI mirroring help\npip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple For using npm:\nnpm mirroring help\nnpm config set registry https://registry.npm.taobao.org/ Instead of git using gitee:\nCVAT repository on gitee.com\nFor replace acceleration source docker.com run:\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ For replace acceleration source google.com run:\ncurl https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add - HTTPS is not working because of a certificate If you’re having trouble with an SSL connection, to find the cause, you’ll need to get the logs from traefik by running:\ndocker logs traefik The logs will help you find out the problem.\nIf the error is related to a firewall, then:\nOpen ports 80 and 443 for inbound connections from any. Delete acme.json. The location should be something like: /var/lib/docker/volumes/cvat_cvat_letsencrypt/_data/acme.json. After acme.json is removed, stop all cvat docker containers:\ndocker compose -f docker-compose.yml -f docker-compose.https.yml down Make sure variables set (with your values):\nexport CVAT_HOST=\u003cYOUR_DOMAIN\u003e export ACME_EMAIL=\u003cYOUR_EMAIL\u003e and restart docker:\ndocker compose -f docker-compose.yml -f docker-compose.https.yml up -d ","categories":"","description":"A CVAT installation guide for different operating systems.","excerpt":"A CVAT installation guide for different operating systems.","ref":"/v2.43.0/docs/administration/basics/installation/","tags":"","title":"Installation Guide"},{"body":"Machine learning systems often struggle due to poor-quality data. Without effective tools, improving a model can be tough and inefficient.\nCVAT is a versatile tool for annotating images and videos, serving the computer vision community worldwide.\nOur goal is to help developers, businesses, and organizations globally by using a Data-centric AI approach.\nCVAT offers three versions:\nCVAT Online: Start online with CVAT, available for free. You can also choose a subscription for unlimited data, collaboration, auto-annotations, and more.\nSelf-hosted CVAT Community Edition: Follow the Self-hosted Installation Guide for setup.\nSelf-hosted CVAT Enterprise Edition: We provide Enterprise-level support for this version, including premium features like SSO, LDAP, advanced integrations with Roboflow and HuggingFace, and advanced analytics. We also offer professional training and 24-hour SLA support.\nSee:\nTools and formats Supported formats Annotation tools Automated labeling Useful links Online Self-Hosted Integrations License Information Get in touch Tools and formats CVAT stands as a comprehensive tool for image and video annotation, essential for various computer vision tasks.\nIt emphasizes user-friendliness, adaptability, and compatibility with a range of formats and tools.\nSupported formats CVAT’s supports the following formats:\nFor 3D: .pcd, .bin For image: everything supported by the Python Pillow library, including formats like JPEG, PNG, BMP, GIF, PPMand TIFF. For video: all formats, supported by ffmpeg, including MP4, AVI, and MOV. For annotation export and import formats, see Export annotations and data from CVAT\nAnnotation tools CVAT offers a wide range of annotation tools, each catering to different aspects of image and video labeling:\nAnnotation Tool Use Cases 3D Object Annotation Ideal for projects that require depth perception and volume estimation, like autonomous vehicle training. Attribute Annotation Mode Useful for adding detailed information to objects, like color, size, or other specific characteristics. Annotation with Rectangles Best for simple object detection where objects have a box-like shape, such as detecting windows in a building. Annotation with Polygons Suited for complex shapes in images, like outlining geographical features in maps or detailed product shapes. Annotation with Polylines Great for annotating linear objects like roads, pathways, or limbs in pose estimation. Annotation with Ellipses Ideal for objects like plates, balls, or eyes, where a circular or oval annotation is needed. Annotation with Cuboids Useful for 3D objects in 2D images, like boxes or furniture in room layouts. Annotation with Skeletons Ideal for human pose estimation, animation, and movement analysis in sports or medical fields. Annotation with Brush Tool Perfect for intricate and detailed annotations where precision is key, such as in medical imaging. Annotation with Tags Useful for image and video classification tasks, like identifying scenes or themes in a dataset. These tools make CVAT a versatile platform for a range of annotation needs, from basic labeling to complex, multidimensional tasks in advanced computer vision projects.\nAutomated labeling CVAT has an automated labeling features, enhancing the annotation process significantly, potentially speeding it up by up to 10 times.\nNote For more information, see OpenCV and AI Tools Below is a detailed table of the supported algorithms and the platforms they operate on:\nAlgorithm Name Category Framework CPU Support GPU Support Segment Anything Interactor PyTorch ✔️ ✔️ Deep Extreme Cut Interactor OpenVINO ✔️ Faster RCNN Detector OpenVINO ✔️ Mask RCNN Detector OpenVINO ✔️ YOLO v3 Detector OpenVINO ✔️ YOLO v7 Detector ONNX ✔️ ✔️ Object Reidentification ReID OpenVINO ✔️ Semantic Segmentation for ADAS Detector OpenVINO ✔️ Text Detection v4 Detector OpenVINO ✔️ SiamMask Tracker PyTorch ✔️ ✔️ TransT Tracker PyTorch ✔️ ✔️ f-BRS Interactor PyTorch ✔️ HRNet Interactor PyTorch ✔️ Inside-Outside Guidance Interactor PyTorch ✔️ Faster RCNN Detector TensorFlow ✔️ ✔️ RetinaNet Detector PyTorch ✔️ ✔️ Face Detection Detector OpenVINO ✔️ Useful links Start here if you’re unsure where to begin with CVAT.\nOnline Name Description User Manual This comprehensive guide covers all CVAT tools available for work. It includes descriptions of all available tools, quality control methods, and procedures for importing and exporting data. This manual is relevant for both CVAT Online and Self-Hosted versions. CVAT Complete Workflow Guide for Organizations This guide provides a comprehensive overview of using CVAT for collaboration in organizations. Subscription Management Learn how to choose a plan, subscribe, and manage your subscription effectively. XML Annotation Format Detailed documentation on the XML format used for annotations in CVAT essential for understanding data structure and compatibility. Self-Hosted Name Description Self-hosted Installation Guide Start here to install self-hosted solution on your premises. Dataset Management Framework Specifically for the Self-Hosted version, this framework and CLI tool are essential for building, transforming, and analyzing datasets. Server API The CVAT server offers a HTTP REST API for interactions. This section explains how client applications, whether they are command line tools, browsers, or scripts, interact with CVAT through HTTP requests and responses. Python SDK The CVAT SDK is a Python library providing access to server interactions and additional functionalities like data validation and serialization. Command Line Tool This tool offers a straightforward command line interface for managing CVAT tasks. Currently featuring basic functionalities, it has the potential to develop into a more advanced administration tool for CVAT. XML Annotation Format Detailed documentation on the XML format used for annotations in CVAT essential for understanding data structure and compatibility. AWS Deployment Guide A step-by-step guide for deploying CVAT on Amazon Web Services, covering all necessary procedures and tips. Frequently Asked Questions This section addresses common queries and provides helpful answers and insights about using CVAT. Integrations CVAT is a global tool, trusted and utilized by teams worldwide. Below is a list of key companies that contribute significantly to our product support or are an integral part of our ecosystem.\nNote If you’re using CVAT, we’d love to hear from you at contact@cvat.ai. Integrated Service Available In Description Human Protocol Online and Self-hosted Incorporates CVAT to augment annotation services within the Human Protocol framework, enhancing its capabilities in data labeling. FiftyOne Online and Self-hosted An open-source tool for dataset management and model analysis in computer vision, FiftyOne is closely integrated with CVAT to enhance annotation capabilities and label refinement. Hugging Face \u0026 Roboflow Online In CVAT Online, models from Hugging Face and Roboflow can be added to enhance computer vision tasks. For more information, see Integration with Hugging Face and Roboflow License Information CVAT includes the following licenses:\nLicense Type Applicable To Description MIT License Self-hosted This code is distributed under the MIT License, a permissive free software license that allows for broad use, modification, and distribution. LGPL License (FFmpeg) Online and Self-hosted Incorporates LGPL-licensed components from the FFmpeg project. Users should verify if their use of FFmpeg requires additional licenses. CVAT.ai Corporation does not provide these licenses and is not liable for any related licensing fees. Commercial License Self-hosted Enterprise For commercial use of the Enterprise solution of CVAT, a separate commercial license is applicable. This is tailored for businesses and commercial entities. Terms of Use Online and Self-hosted Outlines the terms of use and confidential information handling for CVAT. Important for understanding the legal framework of using the platform. Privacy Policy Online Our Privacy Policy governs your visit to https://cvat.ai and your use of https://app.cvat.ai, and explains how we collect, safeguard and disclose information that results from your use of our Service. Get in touch To get in touch, use one of the following channels:\nSupport Channel Applicable To Description Discord Channel Online and Self-hosted A space for broader discussions, questions, and all things related to CVAT. LinkedIn Online and Self-hosted Follow for company updates, news, and employment opportunities. YouTube Channel Online and Self-hosted Find tutorials and screencasts about CVAT tools. GitHub Issues Online and Self-hosted Report bugs or contribute to the ongoing development of CVAT. Customer Support Channel Online (Paid Users) Exclusive support for CVAT Online paid users. Commercial Support Inquiries Online and Self-hosted For direct commercial support inquiries, email contact@cvat.ai. ","categories":"","description":"The open-source tool for image and video annotation","excerpt":"The open-source tool for image and video annotation","ref":"/v2.43.0/docs/getting_started/overview/","tags":"","title":"CVAT Overview"},{"body":"It is used for semantic / instance segmentation.\nBefore starting, you need to select Polygon on the controls sidebar and choose the correct Label.\nClick Shape to enter drawing mode. There are two ways to draw a polygon: either create points by clicking or by dragging the mouse on the screen while holding Shift. Clicking points Holding Shift+Dragging When Shift isn’t pressed, you can zoom in/out (when scrolling the mouse wheel) and move (when clicking the mouse wheel and moving the mouse), you can also delete the previous point by right-clicking on it. You can use the Selected opacity slider in the Objects sidebar to change the opacity of the polygon. You can read more in the Objects sidebar section. Press N again or click the Done button on the top panel for completing the shape. After creating the polygon, you can move the points or delete them by right-clicking and selecting Delete point or clicking with pressed Alt key in the context menu. ","categories":"","description":"","excerpt":"It is used for semantic / instance segmentation.\nBefore starting, you …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polygons/manual-drawing/","tags":"","title":"Manual drawing"},{"body":"","categories":"","description":"","excerpt":"","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/","tags":"","title":"Models"},{"body":"The navigation panel and drop-down Menu, allow you to switch between frames, change the annotation mode, save your work, and more.\nSee:\nMenu Navigation bar Save, Undo, Done Navigation controls Job information and Annotation Mode switcher Menu Use the Menu options to upload and download annotations, change the status of the job, and access other features listed in the table below:\nPanel Item Description Upload annotations Upload annotations into a task. Export as a dataset Download a dataset in one of the supported formats. Remove annotations Delete all annotations for the current job. Use Select range to remove annotations for a specific range of frames.\nEnable the Delete only keyframe for tracks checkbox to delete only keyframes from the tracks within the selected range. Run actions Run annotation actions on the annotated dataset. Annotations action is a feature that allows you to modify a bulk of annotations on many frames. It supports only shape objects. Open the task Opens a page with details about the task. Change job state Changes the state of the job: New: The job is newly created and has not been started yet. It is waiting for annotation work to begin. In Progress: The job is currently being worked on. Annotations are being added or edited.Rejected: The job has been reviewed and deemed unsatisfactory or incorrect. It requires revisions and further work.Completed: The job has been finished, reviewed, and approved. No further changes are necessary. Finish the job Saves annotations and sets job state to Completed. Navigation bar Use the navigation bar to save annotation results, switch between frames, and access other features listed in the tables below.\nSave, Undo, Done Use the following buttons, to save your work, undo changes, and move tasks to done.\nFunction Description Save work\nSaves annotations for the current job. The button indicates the saving process. Undo/Redo\nUse buttons to undo actions or redo them. Done\nUsed to complete the creation of the object. This button appears only when the object is being created. Block\nUsed to pause automatic line creation when drawing a polygon with OpenCV Intelligent scissors. Also used to postpone server requests when creating an object using AI Tools. Navigation controls Overview of how to navigate through frames within the interface, with detailed descriptions provided in the table below.\nFunction Description Go to the first/last frame\nNavigate to the first or the last frame of the sequence. Go back with a step/Go next with a step\nMove to the previous or next frame by a predefined step. Shortcuts:\nC — previous frame. V — next frame. Default step size is 10 frames. To modify this, navigate to Nickname \u003e Settings \u003e Player Step. Go back/Go next\nNavigate to the neighboring frames. Shortcuts:\nD — previous frame. F — next frame.\nGo back/Go next buttons are customizable: To customize, right-click on the button and select one of three options (left to right): The default setting moves to the next or previous frame (step size is 1 frame).Move to the next or previous frame that contains objects (e.g., filtered). For more information, refer to Filters.Move to the next or previous frame without annotations. Use this option to quickly locate missed frames.. Play/Pause\nSwitch between playing and pausing the sequence of frames or set of images. Shortcut: Space. To adjust the playback speed, go to Nickname \u003e Settings \u003e Player Speed. Go to the specific frame\nEnter the number of the frame you want to go to and press Enter. Search frame by filename\nClick to open the search pop-up. Type a frame filename to search for it within the job. Select the filename and press Enter to navigate to the selected frame. Copy frame name\nClick to copy frame name to the clipboard. Copy frame link\nClick to copy link to the frame. Delete frame\nClick to delete or restore current frame. Job information and Annotation Mode switcher This section outlines various functionalities, including how to switch to the fullscreen player mode, access job information, and use the Workspace Switcher to toggle between different annotation and QA modes.\nFunction Description Fullscreen\nThe fullscreen player mode. The keyboard shortcut is F11. Info\nOpen the job info. Overview:Assignee - the individual to whom the job is assigned. Reviewer– the user tasked with conducting the review. For more information, see Manual QAStart frame - the number of the first frame in this job.Stop frame - the number of the last frame in this job.Frames - the total number of frames in the job.\nAnnotations Statistics table displays the number of created shapes, categorized by labels (e.g., vehicle, person) and the type of annotation (shape, track), as well as the count of manual and interpolated frames. Filters\nSwitches on Filters. Workplace Switcher The drop-down list to switch between different annotation modes: Overview:Standard – default mode.Attribute – annotation with AttributesSingle Shape – Single shape annotation mode.Tag annotation- annotation with TagsReview – Manual QA mode. ","categories":"","description":"Features navigation arrows to switch between frames, provides access to main functions, and Menu.","excerpt":"Features navigation arrows to switch between frames, provides access …","ref":"/v2.43.0/docs/manual/basics/cvat-annotation-interface/navbar/","tags":"","title":"Navigation bar \u0026 Menu"},{"body":"It is used for face, landmarks annotation etc.\nBefore you start you need to select the Points. If necessary you can set a fixed number of points in the Number of points field, then drawing will be stopped automatically.\nClick Shape to entering the drawing mode. Now you can start annotation of the necessary area. Points are automatically grouped — all points will be considered linked between each start and finish. Press N again or click the Done button on the top panel to finish marking the area. You can delete a point by clicking with pressed Ctrl or right-clicking on a point and selecting Delete point. Clicking with pressed Shift will open the points shape editor. There you can add new points into an existing shape. You can zoom in/out (when scrolling the mouse wheel) and move (when clicking the mouse wheel and moving the mouse) while drawing. You can drag an object after it has been drawn and change the position of individual points after finishing an object.\n","categories":"","description":"","excerpt":"It is used for face, landmarks annotation etc.\nBefore you start you …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-points/points-in-shape-mode/","tags":"","title":"Points in shape mode"},{"body":"Projects page On this page, you can create a new project, create a project from a backup, and also see the created projects.\nIn the upper left corner there is a search bar, using which you can find the project by project name, assignee etc. In the upper right corner there are sorting, quick filters and filter.\nFilter Applying a filter disables the quick filters.\nThe filter works similarly to the filters for annotation, you can create rules from properties, operators and values and group rules into groups. For more details, see the filter section. Learn more about date and time selection.\nTo clear all filters, press Clear filters.\nSupported properties for projects list Properties Supported values Description Assignee username Assignee is the user who is working on the project, task or job. (is specified on task page) Owner username The user who owns the project, task, or job Last updated last modified date and time (or value range) The date can be entered in the dd.MM.yyyy HH:mm format or by selecting the date in the window that appears when you click on the input field ID number or range of job ID Name name On the tasks page - name of the task,\non the project page - name of the project Create a project In CVAT, you can create a project containing tasks of the same type. All tasks related to the project will inherit a list of labels.\nTo create a project, go to the projects section by clicking on the Projects item in the top menu. On the projects page, you can see a list of projects, use a search, or create a new project by clicking on the + button and select Create New Project.\nNote Note that the project will be created in the organization that you selected at the time of creation. Read more about organizations. You can change: the name of the project, the list of labels (which will be used for tasks created as parts of this project) and a skeleton if it’s necessary. In advanced configuration also you can specify: a link to the issue, source and target storages. Learn more about creating a label list, creating the skeleton and attach cloud storage.\nTo save and open a project, click on Submit \u0026 Open button. Also, you can click on Submit \u0026 Continue button to create several projects in sequence.\nOnce created, the project will appear on the projects page. To open a project, just click on it.\nHere you can do the following:\nChange the project’s title.\nOpen the Actions menu. Each button is responsible for a specific function in the Actions menu:\nExport dataset/Import dataset - download/upload annotations or annotations and images in a specific format. More information is available in the export/import datasets section. Backup project - make a backup of the project read more in the backup section. Delete - remove the project and all related tasks. Change issue tracker or open issue tracker if it is specified.\nChange labels and skeleton. You can add new labels or add attributes for the existing labels in the Raw mode or the Constructor mode. You can also change the color for different labels. By clicking Setup skeleton you can create a skeleton for this project.\nAssigned to — is used to assign a project to a person. Start typing an assignee’s name and/or choose the right person out of the dropdown list.\nTasks — is a list of all tasks for a particular project, with the ability to search, sort and filter for tasks in the project. Read more about search. Read more about sorting and filter It is possible to choose a subset for tasks in the project. You can use the available options (Train, Test, Validation) or set your own.\n","categories":"","description":"Creating and exporting projects in CVAT.","excerpt":"Creating and exporting projects in CVAT.","ref":"/v2.43.0/docs/manual/advanced/projects/","tags":"","title":"Projects page"},{"body":"To start annotating in CVAT, you must create an account or log in to the existing one.\nCheck out:\nUser registration User registration with social accounts Account access Password reset Change password To create an account or log in, go to the CVAT Online login page:\nNote By default, authentication and registration with Google and GitHub work only for CVAT Online. If you want to use Google and GitHub authentication on a local installation, consult Social auth configuration. User registration To register:\nSelect Create an account.\nFill in all blank fields, accept terms of use, and select Create an account.\nA username generates from the email automatically. You can edit it if needed.\nUser registration with social accounts To register with Google or GitHub, select the button with the service name and follow the instructions.\nAccount access To access your account:\nGo to the login page. Enter username or email. The password field will appear. Enter the password and click Next. To log in with Google or GitHub, select the button with the service name.\nPassword reset To reset password:\nGo to the CVAT Online page and select Forgot password?\nEnter email you used for registration and select Send.\nOpen email and select on the link from CVAT.\nEnter new password in both fields and select Change password.\nChange password To change password:\nLog in to your CVAT account.\nIn the top right corner, select the username.\nSelect Change password.\nFollow the instructions on the screen.\n","categories":"","description":"CVAT registration and account access.","excerpt":"CVAT registration and account access.","ref":"/v2.43.0/docs/manual/basics/registration/","tags":"","title":"Registration \u0026 Account Access"},{"body":"","categories":"","description":"This section contains advanced documents for system administrators.","excerpt":"This section contains advanced documents for system administrators.","ref":"/v2.43.0/docs/administration/advanced/","tags":"","title":"Advanced"},{"body":"","categories":"","description":"This section contains advanced documents for CVAT users","excerpt":"This section contains advanced documents for CVAT users","ref":"/v2.43.0/docs/manual/advanced/","tags":"","title":"Advanced"},{"body":"Overview CVAT server provides HTTP REST API for interaction. Each client application - be it a command line tool, browser or a script - all interact with CVAT via HTTP requests and responses:\nAPI schema You can obtain schema for your server at \u003cyourserver\u003e/api/docs. For example, the official CVAT.ai application has API documentation here.\nExamples Here you can see how a task is created in CVAT:\nAt first, we have to login Then we create a task from its configuration Then we send task data (images, videos etc.) We wait for data processing and finish Design principles Common pattern for our REST API is \u003cVERB\u003e [namespace] \u003cobjects\u003e \u003cid\u003e \u003caction\u003e.\nVERB can be POST, GET, PATCH, PUT, DELETE. namespace should scope some specific functionality like auth, lambda. It is optional in the scheme. Typical objects are tasks, projects, jobs. When you want to extract a specific object from a collection, just specify its id. An action can be used to simplify REST API or provide an endpoint for entities without objects endpoint like annotations, data, data/meta. Note: action should not duplicate other endpoints without a reason. When you’re developing new endpoints, follow these guidelines:\nUse nouns instead of verbs in endpoint paths. For example, POST /api/tasks instead of POST /api/tasks/create. Accept and respond with JSON whenever it is possible Name collections with plural nouns (e.g. /tasks, /projects) Try to keep the API structure flat. Prefer two separate endpoints for /projects and /tasks instead of /projects/:id1/tasks/:id2. Use filters to extract necessary information like /tasks/:id2?project=:id1. In some cases it is useful to get all tasks. If the structure is hierarchical, it cannot be done easily. Also you have to know both :id1 and :id2 to get information about the task. Note: for now we accept GET /tasks/:id2/jobs but it should be replaced by /jobs?task=:id2 in the future. Handle errors gracefully and return standard error codes (e.g. 201, 400) Allow filtering, sorting, and pagination Maintain good security practices Cache data to improve performance Versioning our APIs. It should be done when you delete an endpoint or modify its behaviors. Versioning uses a schema with Accept header with vendor media type. Links Best practices for REST API design Flat vs. nested resources REST API Design Best Practices for Sub and Nested Resources A specification for building APIs in JSON ","categories":"","description":"","excerpt":"Overview CVAT server provides HTTP REST API for interaction. Each …","ref":"/v2.43.0/docs/api_sdk/api/","tags":"","title":"Server API"},{"body":"\nYou can use auto borders when drawing a polygon. Using automatic borders allows you to automatically trace the outline of polygons existing in the annotation.\nTo do this, go to settings -\u003e workspace tab and enable Automatic Bordering or press Ctrl while drawing a polygon.\nStart drawing / editing a polygon.\nPoints of other shapes will be highlighted, which means that the polygon can be attached to them.\nDefine the part of the polygon path that you want to repeat.\nClick on the first point of the contour part.\nThen click on any point located on part of the path. The selected point will be highlighted in purple.\nClick on the last point and the outline to this point will be built automatically.\nBesides, you can set a fixed number of points in the Number of points field, then drawing will be stopped automatically. To enable dragging you should right-click inside the polygon and choose Switch pinned property.\nBelow you can see results with opacity and black stroke:\nIf you need to annotate small objects, increase Image Quality to 95 in Create task dialog for your convenience.\n","categories":"","description":"","excerpt":"\nYou can use auto borders when drawing a polygon. Using automatic …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polygons/automatic-borders/","tags":"","title":"Drawing using automatic borders"},{"body":"Navigation Navigation block - contains tools for moving and rotating images.\nIcon Description Cursor (Esc)- a basic annotation editing tool. Move the image- a tool for moving around the image without the possibility of editing. Rotate- two buttons to rotate the current frame a clockwise (Ctrl+R) and anticlockwise (Ctrl+Shift+R). You can enable Rotate all images in the settings to rotate all the images in the job Zoom Zoom block - contains tools for image zoom.\nIcon Description Fit image- fits image into the workspace size. Shortcut - double click on an image Select a region of interest- zooms in on a selected region. You can use this tool to quickly zoom in on a specific part of the frame. Shapes Shapes block - contains all the tools for creating shapes.\nIcon Description Links to section AI Tools AI Tools OpenCV OpenCV Rectangle Shape mode; Track mode; Drawing by 4 points Polygon Annotation with polygons; Track mode with polygons Polyline Annotation with polylines Points Annotation with points Ellipses Annotation with ellipses Cuboid Annotation with cuboids Brushing tools Annotation with brushing Tag Annotation with tags Open an issue Review (available only in review mode) Edit Edit block - contains tools for editing tracks and shapes.\nIcon Description Links to section Merge Shapes(M) - starts/stops the merging shapes mode. Track mode (basics) Group Shapes (G) - starts/stops the grouping shapes mode. Shape grouping Split - splits a track. Track mode (advanced) Joins multiple labels into one Joining mask tool Slices one label into several. Slice mask/polygon Move image Switching between user interface modes.\nUse arrows below to move to the next/previous frame. Use the scroll bar slider to scroll through frames. Almost every button has a shortcut. To get a hint about a shortcut, just move your mouse pointer over an UI element.\nTo navigate the image, use the button on the controls sidebar. Another way an image can be moved/shifted is by holding the left mouse button inside an area without annotated objects. If the Mouse Wheel is pressed, then all annotated objects are ignored. Otherwise the a highlighted bounding box will be moved instead of the image itself.\nYou can use the button on the sidebar controls to zoom on a region of interest. Use the button Fit the image to fit the image in the workspace. You can also use the mouse wheel to scale the image (the image will be zoomed relatively to your current cursor position).\n","categories":"","description":"Offers tools for navigating within the image, annotation tools, and additional options to merge, split, and group labels.","excerpt":"Offers tools for navigating within the image, annotation tools, and …","ref":"/v2.43.0/docs/manual/basics/cvat-annotation-interface/controls-sidebar/","tags":"","title":"Controls sidebar"},{"body":"To start annotating in CVAT, you must create an annotation task and specify its parameters.\nCheck out:\nCreate a task Label shape Add an attribute Select files Editing labels in RAW format Data formats for a 3D task Advanced configuration Create a task To create a task:\nOn the Tasks page, select + Select Create new task. Next, specify the task parameters in the configurator:\nIn the Name field, enter the name of the new task.\n(Optional) From the Projects drop-down, select a project for the new task. Leave this field empty if you do not want to assign the task to any project.\nNote Following steps are valid if the task does not belong to a project. If the task has been assigned to a project, the project’s labels will be applied to the task. On the Constructor tab, select Add label. The label constructor menu will open:\nIn the Label name field, enter the name of the label.\n(Optional) To limit the use of the label to a certain shape tool, from the Label shape drop-down select the shape.\n(Optional) Select the color for the label.\n(Optional) Select Add an attribute and set up its properties.\nSelect Select files to upload files for annotation.\nSelect Continue to submit the label and start adding a new one or Cancel to terminate the current label and return you to the labels list.\nSelect Submit and open to submit the configuration and open the created task, or Submit and continue, to submit the configuration and start a new task.\nLabel shape Labels (or classes) are categories of objects that you can annotate.\nLabel shape limits the use of the label to certain shape tool.\nAny is the default setting that does not limit the use of the label to any particular shape tool.\nFor example, if you added:\nLabel sun with the Label shape type ellipse Label car with the Label shape type any As a result:\nThe sun label will be available only for ellipse shape.\nThe car label will be available for all shapes.\nThe tools on the Controls sidebar will be limited to the selected types of shapes.\nFor example, if you select Any, all tools will be available, but if you select Rectangle for all labels, only the Rectangle tool will be visible on the sidebar.\nNote You cannot apply the Label shape to the AI and OpenCV tools, these tools will always be available. You can change the shape of the label as needed. This change will not affect the existing annotation.\nFor example, if you created objects using polygons and then changed the label shape to polylines, all previously created objects will remain polygons. However, you will not be able to add new polygon objects with the same label.\nNote You cannot change the shape of the skeleton label. The Label shape field for the skeleton label is disabled. Add an attribute Attribute is a property of an annotated object, such as color, model, or other quality.\nFor example, you have a label for face and want to specify the type of face. Instead of creating additional labels for male and female, you can use attributes to add this information.\nThere are two types of attributes:\nImmutable attributes are unique and do not change from frame to frame. For example, age, gender, and color. Mutable attributes are temporary and can change from frame to frame. For example, pose, quality, and truncated. Added attributes will be available from the Objects menu:\nTo add an attribute:\nGo to the Constructor tab and select Add attribute.\nIn the Name field, enter the attribute name.\nIn the drop-down menu, select the way to display the attribute in the Objects menu:\nSelect enables a drop-down list, from which you can select an attribute. If in the Attribute value field you add __undefined__, the drop-down list will have a blank value.\nThis is useful for cases where the attribute of the object cannot be clarified:\nRadio enables the selection of one option from several options.\nCheckbox enables the selection of multiple options.\nText sets the attribute to a text field.\nNumber sets the attribute to numerical field in the following format: min;max;step.\nIn the Attribute values field, add attribute values. To separate values use Enter. To delete value, use Backspace or click x next to the value name.\n(Optional) For mutable attributes, select Mutable.\n(Optional) To set an attribute value as default, select it. The default value will change color to blue.\nTo delete an attribute, select Delete attribute.\nSelect files There are several ways to upload files:\nData source Description My computer Use this option to select files from your laptop or PC. To select file: 1. Select Select files field: . 2. Select files to upload. Connected file share Advanced option. Upload files from a local or cloud shared folder. Note, that you need to mount a fileshare first. For more information, consult Share path Remote source Enter a list of URLs (one per line) in the field. Cloud Storage Advanced option. To upload files from cloud storage, type the cloud storage name, (optional) choose the manifest file, and select the required files. For more information, consult Attach cloud storage. Use the search feature to find a file (by file name) from the connected cloud storage. Editing labels in RAW format The Raw is a way of working with labels for an advanced user.\nIt is useful when you need to copy labels from one independent task to another.\nNote Be careful with changing the raw specification of an existing task/project. Removing any “id” properties will lead to losing existing annotations. This property will be removed automatically from any text you insert to this field. Raw presents label data in .json format with an option of editing and copying labels as text. The Done button applies the changes and the Reset button cancels the changes.\nData formats for a 3D task To create a 3D task, you must prepare an archive with one of the following directory structures.\nNote You can’t mix 2D and 3D data in the same task. Velodyne 3D pointcloud 3D Option 1 3D Option 2 VELODYNE FORMAT Structure: velodyne_points/ data/ image_01.bin IMAGE_00 # unknown dirname, # generally image_01.png can be under IMAGE_00, IMAGE_01, IMAGE_02, IMAGE_03, etc data/ image_01.png 3D POINTCLOUD DATA FORMAT Structure: pointcloud/ 00001.pcd related_images/ 00001_pcd/ image_01.png # or any other image 3D, DEFAULT DATAFORMAT Option 1 Structure: data/ image.pcd image.png 3D, DEFAULT DATAFORMAT Option 2 Structure: data/ image_1/ image_1.pcd context_1.png # or any other name context_2.jpg Advanced configuration Use advanced configuration to set additional parameters for the task and customize it to meet specific needs or requirements.\nThe following parameters are available:\nElement Description Sorting method Note: Does not work for the video data. Several methods to sort the data. For example, the sequence 2.jpeg, 10.jpeg, 1.jpeg after sorting will be: Lexicographical: 1.jpeg, 10.jpeg, 2.jpeg Natural: 1.jpeg, 2.jpeg, 10.jpeg Predefined: 2.jpeg, 10.jpeg, 1.jpeg Random uploads data in random order. Prefer zip chunks Use this parameter to divide your video or image dataset for annotation into short video clips a zip file of frames. Zip files are larger but do not require decoding on the client side, and video clips are smaller but require decoding. It is recommended to turn off this parameter for video tasks to reduce traffic between the client side and the server. Use cache Select the checkbox to enable on-the-fly data processing to reduce task creation time and store data in a cache with a policy of evicting less popular items. For more information, see Data preparation on the fly. Image quality CVAT has two types of data: original quality and compressed. Original quality images are used for dataset export\nand automatic annotation. Compressed images are used only for annotations to reduce traffic between the server and client side. It is recommended to adjust the compression level only if the images contain small objects that are not visible in the original quality. Values range from 5 (highly compressed images) to 100 (not compressed). Overlap size Use this parameter to create overlapped segments, making tracking continuous from one segment to another. Note that this functionality only works for bounding boxes. This parameter has the following options: Interpolation task (video sequence). If you annotate with a bounding box on two adjacent segments, they will be\nmerged into a single bounding box. In case the overlap is zero or the bounding box is inaccurate (not enclosing the object properly, misaligned or distorted) on the adjacent segments, it may be difficult to accurately interpolate the object’s movement between the segments. As a result, multiple tracks will be created for the same object. Annotation task (independent images). If an object exists on overlapped segments with overlap greater than zero, and the annotation of these segments is done properly, then the segments will be automatically merged into a single\nobject. If the overlap is zero or the annotation is inaccurate (not enclosing the object properly, misaligned, distorted) on the\nadjacent segments, it may be difficult to accurately track the object. As a result, multiple bounding boxes will be created for the same object. If the annotations on different segments (on overlapped frames) are very different, you will have two shapes for the same object. To avoid this, accurately annotate the object on the first segment and the same object on the second segment to create a track between two annotations. Segment size Use this parameter to divide a dataset into smaller parts. For example, if you want to share a dataset among multiple\nannotators, you can split it into smaller sections and assign each section to a separate job. This allows annotators to work on the same dataset concurrently. Start frame Defines the first frame of the video. Stop frame Defines the last frame of the video. Frame step Use this parameter to filter video frames or images in a dataset. Specify frame step value to include only certain frames or images in the dataset. For example, if the frame step value is 25, the dataset will include every 25th frame or image. If a video has 100 frames, setting the frame step to 25 will include only frames 1, 26, 51, 76, and 100 in the dataset. This can be useful for reducing the size of the dataset, or for focusing on specific frames or images\nof particular interest. Chunk size Defines amount of frames to be packed in a chunk when send from client to server. The server defines automatically if the chunk is empty. Recommended values: 1080p or less: 36 2k or less: 8 16 - 4k or less: 4 8 - More: 1 - 4 Issue tracker Use this parameter to specify the issue tracker URL. Source storage Specify the source storage for importing resources like annotations and backups. If the task was assigned to the project, use the Use project source storage toggle to determine whether to use project values or specify new ones. Target storage Specify the target storage (local or cloud) for exporting resources like annotations and backups. If the task is created in the project, use the Use project target storage toggle to determine whether to\nuse project values or specify new ones. To save and open the task, select Submit \u0026 Open .\nTo create several tasks in sequence, select Submit \u0026 Continue.\nCreated tasks will be displayed on the tasks page.\n","categories":"","description":"How to create and configure an annotation task.","excerpt":"How to create and configure an annotation task.","ref":"/v2.43.0/docs/manual/basics/create-annotation-task/","tags":"","title":"Create annotation task"},{"body":"Welcome to CVAT, this page is the place to start your team’s annotation process using the Computer Vision Annotation Tool (CVAT).\nThis guide aims to equip your organization with the knowledge and best practices needed to use CVAT effectively.\nWe’ll walk you through every step of the CVAT workflow, from initial setup to advanced features.\nSee:\nWorkflow diagram End-to-end workflow for Organizations Complete Workflow Guide video tutorial Workflow diagram The workflow diagram presents an overview of the general process at a high level.\nEnd-to-end workflow for Organizations To use CVAT within your organization, please follow these steps:\nCreate an account in CVAT. Create Organization. Switch to the Organization that you’ve created and subscribe to the Team plan. Invite members to Organization and assign User roles to invited members. Create Project. (Optional) Attach Cloud storages to the Project. Create Task or Multitask. At this step the CVAT platform will automatically create jobs. (Optional) Create Ground truth job. This step can be skipped if you’re employing a manual QA approach. (Optional) Add Instructions for annotators. (Optional) Configure Webhooks. Assign jobs to annotators by adding the annotator name to Assignee and changing the Job stage to Annotation. Annotator will see assigned jobs and annotate them. (Optional) In case you’ve created a Ground truth job give the CVAT platform some time to accumulate the data and check the accuracy of the annotation. If you are using the manual validation, assign jobs to validators by adding the validator name to Assignee and changing the Job stage to Validation. Validator will see assigned jobs and report issues. Note, that validators can correct issues, see Manual QA and Review Check issues and if there is a need for additional improvement, reassign jobs to either the Validator or Annotator. (Optional) Check Analytics. Export Data. Complete Workflow Guide video tutorial ","categories":"","description":"","excerpt":"Welcome to CVAT, this page is the place to start your team’s …","ref":"/v2.43.0/docs/getting_started/workflow-org/","tags":"","title":"CVAT Complete Workflow Guide for Organizations"},{"body":"Setup the dependencies: Install necessary dependencies:\nUbuntu 22.04/20.04\nsudo apt-get update \u0026\u0026 sudo apt-get --no-install-recommends install -y build-essential curl git python3-dev python3-pip python3-venv python3-tk libldap2-dev libsasl2-dev libgeos-dev cargo # Install Node.js 20 and yarn curl -fsSL https://deb.nodesource.com/setup_20.x | sudo bash - sudo apt-get install -y nodejs sudo npm install --global yarn MacOS 10.15\nbrew install git python pyenv redis curl openssl node sqlite3 geos rust Arch Linux\n# Update the system and AUR (you can use any other AUR helper of choice) first: sudo pacman -Syyu pikaur -Syu # Install the required dependencies: sudo pacman -S base-devel curl git redis cmake gcc python python-pip tk libldap libsasl pkgconf ffmpeg geos openldap rust # CVAT supports only Python 3.10, so install it if you don’t have it: pikaur -S python310 # Install Node.js, yarn and npm sudo pacman -S nodejs-lts-gallium yarn npm Install Chrome\nInstall VS Code.\nInstall the following VScode extensions:\nJavaScript Debugger Python ESLint Stylelint Trailing Spaces Code Spell Checker Make sure to use Python 3.10.0 or higher\npython3 --version Install CVAT on your local host:\ngit clone https://github.com/cvat-ai/cvat cd cvat \u0026\u0026 mkdir logs keys python3 -m venv .env . .env/bin/activate pip install -U pip wheel setuptools pip install -r cvat/requirements/development.txt -r dev/requirements.txt Note that the .txt files in the cvat/requirements directory have pinned dependencies intended for the main target OS/Python version (the one used in the main Dockerfile). If you’re unable to install those dependency versions, you can substitute the corresponding .in files instead. That way, you’re more likely to be able to install the dependencies, but their versions might not correspond to those used in production.\nNote for Mac users If you have any problems with installing dependencies from cvat/requirements/*.txt, you may need to reinstall your system python In some cases after system update it can be configured incorrectly and cannot compile some native modules\nMake sure Homebrew lib path is in DYLD_LIBRARY_PATH. For Apple Silicon: export DYLD_LIBRARY_PATH=/opt/homebrew/lib:$DYLD_LIBRARY_PATH\nHomebrew will install FFMpeg 5.0 by default, which does not work, so you should install 4.X. You can install older 4.X FFMpeg using Homebrew like that:\ncd \"$(brew --repo homebrew/core)\" git checkout addd616edc9134f057e33694c420f4900be59db8 brew unlink ffmpeg HOMEBREW_NO_AUTO_UPDATE=1 brew install ffmpeg git checkout master if you are still facing error Running setup.py install for av ... error, you may try more radical variant\ncd \"$(brew --repo homebrew/core)\" git checkout addd616edc9134f057e33694c420f4900be59db8 brew uninstall ffmpeg --force HOMEBREW_NO_AUTO_UPDATE=1 brew install ffmpeg git checkout master If you faced with error Failed building wheel for h5py, you may need install hdf5\nbrew install hdf5 export HDF5_DIR=\"$(brew --prefix hdf5)\" pip install --no-binary=h5py h5py If you faced with error OSError: Could not find library geos_c or load any of its variants ['libgeos_c.so.1', 'libgeos_c.so']. You may fix this using\nsudo ln -s /opt/homebrew/lib/libgeos_c.dylib /usr/local/lib Note for Arch Linux users Because PyAV as of version 10.0.0 already works with FFMPEG5, you may consider changing the av version requirement in /cvat/cvat/requirements/base.txt to 10.0.0 or higher.\nPerform this action before installing cvat requirements from the list mentioned above.\nInstall Docker Engine and Docker Compose\nStart service dependencies:\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build \\ cvat_opa cvat_db cvat_redis_inmem cvat_redis_ondisk cvat_server Note: this runs an extra copy of the CVAT server in order to supply rules to OPA. If you update the OPA rules, rerun this command to recreate the server image and container.\nNote: to stop these services, use docker compose -f docker-compose.yml -f docker-compose.dev.yml down. You can add -v to remove the data, as well.\nApply migrations and create a super user for CVAT:\npython manage.py migrate python manage.py migrateredis python manage.py collectstatic python manage.py syncperiodicjobs python manage.py createsuperuser Install npm packages for UI (run the following command from CVAT root directory):\nyarn --frozen-lockfile Note for Mac users If you faced with error Node Sass does not yet support your current environment: OS X 64-bit with Unsupported runtime (57), read this article Node Sass does not yet support your current environment Run CVAT Start npm UI debug server (run the following command from CVAT root directory):\nIf you want to run CVAT in localhost: yarn run start:cvat-ui If you want to access CVAT from outside of your host: CVAT_UI_HOST='\u003cYOUR_HOST_IP\u003e' CVAT_UI_PORT='\u003cYOUR_PORT\u003e' yarn run start:cvat-ui Open a new terminal window.\nRun VScode from the virtual environment (run the following command from CVAT root directory):\nsource .env/bin/activate \u0026\u0026 code Inside VScode, Open CVAT root dir\nSelect server: debug configuration and run it (F5) to run REST server and its workers\nMake sure that Uncaught Exceptions option under breakpoints section is unchecked\nIf you choose to run CVAT in localhost: Select server: chrome configuration and run it (F5) to open CVAT in Chrome\nAlternative: If you changed CVAT_UI_HOST just enter \u003cYOUR_HOST_IP\u003e:3000 in your browser.\nNote for Mac users You may have a permission denied problem starting the server because AirPlay Receiver running on port 5000/7000.\nTurn off AirPlay Receiver: Go to System Settings → General → AirDrop \u0026 Handoff → Untick Airplay Receiver.\nYou have done! Now it is possible to insert breakpoints and debug server and client of the tool. Instructions for running tests locally are available here.\nNote for Windows users You develop CVAT under WSL (Windows subsystem for Linux) following next steps.\nInstall WSL using this guide.\nFollowing this guide install Ubuntu 18.04 Linux distribution for WSL.\nRun Ubuntu using start menu link or execute next command\nwsl -d Ubuntu-18.04 Install the VS Code extension for WSL, which helps you to open VS Code correctly inside WSL. You can find the extension here.\nRun all commands from this installation guide in WSL Ubuntu shell.\nYou might have to manually start the redis server in wsl before you can start the configuration inside Visual Studio Code. You can do this with sudo service redis-server start. Alternatively you can also use a redis docker image instead of using the redis-server locally.\nNote for Mac users You might have to manually start the redis server. You can do this with redis-server. Alternatively you can also use a redis docker image instead of using the redis-server locally. Note for Arch Linux users You need to start redis and docker services manually in order to begin debugging/running tests: sudo systemctl start redis.service sudo systemctl start docker.service CVAT Analytics Ports In case you cannot access analytics, check if the following ports are open:\ncvat_vector: ports: - '8282:80' cvat_clickhouse: ports: - '8123:8123' In addition, you can completely disable analytics if you don’t need it by deleting the following data from launch.json:\n\"DJANGO_LOG_SERVER_HOST\": \"localhost\", \"DJANGO_LOG_SERVER_PORT\": \"8282\" Analytics on GitHub: Analytics Components\n","categories":"","description":"Installing a development environment for different operating systems.","excerpt":"Installing a development environment for different operating systems.","ref":"/v2.43.0/docs/contributing/development-environment/","tags":"","title":"Development environment"},{"body":"\nThe cuboid can be edited in multiple ways: by dragging points, by dragging certain faces or by dragging planes. First notice that there is a face that is painted with gray lines only, let us call it the front face.\nYou can move the cuboid by simply dragging the shape behind the front face. The cuboid can be extended by dragging on the point in the middle of the edges. The cuboid can also be extended up and down by dragging the point at the vertices.\nTo draw with perspective effects it should be assumed that the front face is the closest to the camera. To begin simply drag the points on the vertices that are not on the gray/front face while holding Shift. The cuboid can then be edited as usual.\nIf you wish to reset perspective effects, you may right click on the cuboid, and select Reset perspective to return to a regular cuboid.\nThe location of the gray face can be swapped with the adjacent visible side face. You can do it by right clicking on the cuboid and selecting Switch perspective orientation. Note that this will also reset the perspective effects.\nCertain faces of the cuboid can also be edited, these faces are: the left, right and dorsal faces, relative to the gray face. Simply drag the faces to move them independently from the rest of the cuboid.\nYou can also use cuboids in track mode, similar to rectangles in track mode (basics and advanced) or Track mode with polygons.\n","categories":"","description":"","excerpt":"\nThe cuboid can be edited in multiple ways: by dragging points, by …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-cuboids/editing-the-cuboid/","tags":"","title":"Editing the cuboid"},{"body":"The integration of CVAT with HUMAN Protocol offers a groundbreaking approach to data annotation for AI and machine learning projects.\nThis collaboration combines CVAT’s advanced annotation tools with HUMAN Protocol’s innovative task distribution and compensation system, creating a seamless, efficient workflow for crowdsourcing annotations.\nFor more details on how to leverage the features of both platforms for your projects, check out these articles:\nCVAT.ai \u0026 HUMAN Protocol: A New Dawn in Visual Data Annotation Mastering Image Annotation Crowdsourcing for Computer Vision with CVAT.ai and HUMAN Protocol Crowdsourcing Annotation with CVAT and Human Protocol: Real Data Experiment Showed Amazing Results See: Basic terms Requester: How to get data annotated? Annotator: How to earn money? Video tutorial Basic terms In the realm of computer vision and AI, understanding the roles and components within data annotation projects is crucial.\nHere’s a quick overview of basic terms related to CVAT and Human Protocol integration, providing a clear picture of the workflow and participants involved.\nTerm Explanation Requester An individual or organization that needs data annotated for AI models. Annotator A person who labels data, such as images or videos, for machine learning. Dataset A collection of data, often images or videos, used for training AI models. Requester: How to get data annotated? Note Either you are Requester or Annotator, to access this feature, you’ll need to send a request to HUMAN Protocol. To register and launch a job on the HUMAN Protocol site, follow these steps:\nCreate a Requester account on the Human Protocol site. Log in to your account and launch a Job. The job will appear on the Annotators’ dashboard and will be annotated according to the specified requirements and quality standards.\nAnnotator: How to earn money? Note Either you are Requester or Annotator, to access this feature, you’ll need to send a request to HUMAN Protocol. To start earning money on the Human Protocol site, follow these simple steps:\nRegister on the Human Protocol site Complete KYC process. Connect crypto wallet to your account. Select job from Data Labeling Jobs menu. Annotate. After annotation is complete, change job status to Complete. After the job is reviewed and accepted by the Requester, the money will be deposited into your account.\nVideo tutorial ","categories":"","description":"","excerpt":"The integration of CVAT with HUMAN Protocol offers a groundbreaking …","ref":"/v2.43.0/docs/integration/human-protocol/","tags":"","title":"CVAT and Human Protocol"},{"body":"","categories":"","description":"This section contains information about the tools that are integrated with CVAT.","excerpt":"This section contains information about the tools that are integrated …","ref":"/v2.43.0/docs/integration/","tags":"","title":"Integrations"},{"body":"The LabelMe format is often used for image segmentation tasks in computer vision. While it may not be specifically tied to any particular models, it’s designed to be versatile and can be easily converted to formats that are compatible with popular frameworks like TensorFlow or PyTorch.\nFor more information, see:\nLabelMe Dataset examples LabelMe export For export of images:\nSupported annotations: Bounding Boxes, Polygons. Attributes: Supported for Polygons. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── img1.jpg └── img1.xml LabelMe import Uploaded file: a zip archive of the following structure:\ntaskname.zip/ ├── Masks/ | ├── img1_mask1.png | └── img1_mask2.png ├── img1.xml ├── img2.xml └── img3.xml supported annotations: Rectangles, Polygons, Masks (as polygons) ","categories":"","description":"How to export and import data in LabelMe format","excerpt":"How to export and import data in LabelMe format","ref":"/v2.43.0/docs/manual/advanced/formats/format-labelme/","tags":"","title":"LabelMe"},{"body":"You can use linear interpolation for points to annotate a moving object:\nBefore you start, select the Points.\nLinear interpolation works only with one point, so you need to set Number of points to 1.\nAfter that select the Track.\nClick Track to enter the drawing mode left-click to create a point and after that shape will be automatically completed.\nMove forward a few frames and move the point to the desired position, this way you will create a keyframe and intermediate frames will be drawn automatically. You can work with this object as with an interpolated track: you can hide it using the Outside, move around keyframes, etc.\nThis way you’ll get linear interpolation using the Points.\n","categories":"","description":"","excerpt":"You can use linear interpolation for points to annotate a moving …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-points/liner-interpolation-with-one-point/","tags":"","title":"Linear interpolation with one point"},{"body":"In the demanding process of annotation, ensuring accuracy is paramount.\nCVAT introduces a specialized Review mode, designed to streamline the validation of annotations by pinpointing errors or discrepancies in annotation.\nNote The Review mode is not applicable for 3D tasks. See:\nReview and report issues: review only mode Assigning reviewer Reporting issues Quick issue Assigning corrector Correcting reported issues Review and report issues: review and correct mode Issues navigation and interface Issues tab Issues workspace Issues comments Manual QA complete video tutorial Review and report issues: review only mode Review mode is a user interface (UI) setting where a specialized Issue tool is available. This tool allows you to identify and describe issues with objects or areas within the frame.\nNote While in review mode, all other tools will be hidden. Review mode screen looks like the following:\nAssigning reviewer Note Reviewers can be assigned by project or task owner, assignee, and maintainer. To assign a reviewer to the job, do the following:\nLog in to the Owner or Maintainer account.\n(Optional) If the person you wish to assign as a reviewer is not a member of Organization, you need to Invite this person to the Organization.\nClick on the Assignee field and select the reviewer.\nFrom the Stage drop-down list, select Validation.\nReporting issues To report an issue, do the following:\nLog in to the reviewer’s account.\nOn the Controls sidebar, click Open and issue ().\nClick on the area of the frame where the issue is occurring, and the Issue report popup will appear.\nIn the text field of the Issue report popup, enter the issue description.\nClick Submit.\nQuick issue The Quick issue function streamlines the review process. It allows reviewers to efficiently select from a list of previously created issues or add a new one, facilitating a faster and more organized review.\nTo create a Quick issue do the following:\nRight-click on the area of the frame where the issue is occurring.\nFrom the popup menu select one of the following:\nOpen an issue…: to create new issue. Quick issue: incorrect position: to report incorrect position of the label. Quick issue: incorrect attribute: to report incorrect attribute of the label. Quick issue…: to open the list of issues that were reported by you before. Assigning corrector Note Only project owners and maintainers can assign reviewers. To assign a corrector to the job, do the following:\nLog in to the Owner or Maintainer account.\n(Optional) If the person you wish to assign as a corrector is not a member of Organization, you need to Invite this person to the Organization.\nClick on the Assignee field and select the reviewer.\nFrom the Stage drop-down list, select Annotation.\nCorrecting reported issues To correct the reported issue, do the following:\nLog in to the corrector account.\nGo to the reviewed job and open it.\nClick on the issue report, to see details of what needs to be corrected.\nCorrect annotation.\nAdd a comment to the issue report and click Resolve.\nAfter all issues are fixed save work, go to the Menu select the Change the job state and change state to Complete.\nReview and report issues: review and correct mode The person, assigned as assigned as reviewer can switch to correction mode and correct all annotation issues.\nTo correct annotation issues as a reviewer, do the following:\nLog in to the reviewer account.\nGo to the assigned job and open it.\nIn the top right corner, from the drop-down list, select Standard.\nIssues navigation and interface This section describes navigation, interface and comments section.\nIssues tab The created issue will appear on the Objects sidebar, in the Issues tab.\nIt has has the following elements:\nElement Description Arrows You can switch between issues by clicking on arrows Hide all issues Click on the eye icon to hide all issues Hide resolved issues Click on the check mark to hide only resolved issues Ground truth Show ground truth annotations and objects Issues workspace In the workspace, you can click on the issue, and add a comment on the issue, remove (Remove) it, or resolve (Resolve) it.\nTo reopen the resolved issue, click Reopen.\nYou can easily access multiple issues created in one location by hovering over an issue and scrolling the mouse wheel.\nIssues comments You can add as many comments as needed to the issue.\nIn the Objects toolbar, only the first and last comments will be displayed\nYou can copy and paste comments text.\nManual QA complete video tutorial This video demonstrates the process:\n","categories":"","description":"Guidelines on evaluating annotation quality in CVAT manually","excerpt":"Guidelines on evaluating annotation quality in CVAT manually","ref":"/v2.43.0/docs/manual/advanced/analytics-and-monitoring/manual-qa/","tags":"","title":"Manual QA and Review"},{"body":"Organization is a feature for teams of several users who work together on projects and share tasks.\nCreate an Organization, invite your team members, and assign roles to make the team work better on shared tasks.\nSee:\nPersonal workspace Create new organization Switching between organizations Organization page Invite members into organization: menu and roles Inviting members to Organization Invitations list Resending and removing invitations Delete organization Personal workspace The account’s default state is activated when no Organization is selected.\nIf you do not select an Organization, the system links all new resources directly to your personal account, that inhibits resource sharing with others.\nWhen Personal workspace is selected, it will be marked with a tick in the menu.\nCreate new organization To create an organization, do the following:\nLog in to the CVAT.\nOn the top menu, click your Username \u003e Organization \u003e + Create.\nFill in the following fields and click Submit.\nField Description Short name A name of the organization that will be displayed in the CVAT menu. Full name Optional. Full name of the organization. Description Optional. Description of organization. Email Optional. Your email. Phone number Optional. Your phone number. Location Optional. Organization address. Upon creation, the organization page will open automatically.\nFor future access to your organization, navigate to Username \u003e Organization\nSwitching between organizations If you have more than one Organization, it is possible to switch between these Organizations at any given time.\nFollow these steps:\nIn the top menu, select your Username \u003e Organization. From the drop-down menu, under the Personal space section, choose the desired Organization. Note If you’ve created more than 10 organizations, a Switch organization line will appear in the drop-down menu. Click on it to see the Select organization dialog, and select organization from drop-down list.\nOrganization page Organization page is a place, where you can edit the Organization information and manage Organization members.\nNote In order to access the organization page, you must first activate the organization (see Switching between organizations). Without activation, the organization page will remain inaccessible. An organization is considered activated when it’s ticked in the drop-down menu and its name is visible in the top-right corner under the username. To go to the Organization page, do the following:\nOn the top menu, click your Username \u003e Organization. In the drop-down menu, select Organization. In the drop-down menu, click Settings. Invite members into organization: menu and roles Invite members form is available from Organization page.\nIt has the following fields:\nField Description Email Specifies the email address of the user who is being added to the Organization. Role drop-down list Defines the role of the user which sets the level of access within the Organization: Worker: Has access only to the tasks, projects, and jobs assigned to them. Supervisor: Can create and assign jobs, tasks, and projects to the Organization members. Maintainer: Has the same capabilities as the Supervisor, but with additional visibility over all tasks and projects created by other members, complete access to Cloud Storages, and the ability to modify members and their roles. Owner: role assigned to the creator of the organization by default. Has maximum capabilities and cannot be changed or assigned to the other user. Invite more Button to add another user to the Organization. Members of Organization will appear on the Organization page:\nThe member of the organization can leave the organization by going to Organization page \u003e Leave organization.\nThe organization owner can remove members, by clicking on the Bin icon.\nInviting members to Organization To invite members to Organization do the following:\nGo to the Organization page, and click Invite members.\nFill in the form (see below).\nClick OK.\nThe person being invited will receive an email with the link.\nPerson must click the link and:\nIf the invitee does not have the CVAT account, then set up an account. If the invitee has a CVAT account, then log in to the account. Invitations list User can see the list of active invitations.\nTo see the list, Go to Username \u003e Organization \u003e Invitations.\nYou will see the page with the list of invitations.\nYou will also see pop-up notification the link to the page with invitations list.\nResending and removing invitations The organization owner and maintainers can remove members, by clicking on the three dots, and selecting Remove invitation\nDelete organization You can remove an organization that you created.\nNote Removing an organization will delete all related resources (annotations, jobs, tasks, projects, cloud storage, and so on). To remove an organization, do the following:\nGo to the Organization page. In the top-right corner click Actions \u003e Remove organization. Enter the short name of the organization in the dialog field. Click Remove. ","categories":"","description":"Using organization in CVAT.","excerpt":"Using organization in CVAT.","ref":"/v2.43.0/docs/manual/advanced/organization/","tags":"","title":"Organization"},{"body":"Search Search within all fields (owner, assignee, task name, task status, task mode). To execute enter a search string in search field.\nThe search is case insensitive.\nThe applied search will be displayed in the URL of your browser, Thus, you can share the page with applied parameters.\n","categories":"","description":"Overview of available search options.","excerpt":"Overview of available search options.","ref":"/v2.43.0/docs/manual/advanced/search/","tags":"","title":"Search"},{"body":"This article provides tips on how to effectively manage your CVAT Online subscriptions, including tracking expenses and canceling unnecessary subscriptions, to optimize your finances and save time.\nWhether you’re a business owner or an individual, you’ll learn how to take control of your subscriptions and manage them.\nSee:\nAvailable paid plans Monthly plans Annual plans Billing How to add VAT/tax and other information to the CVAT Online invoice before the first payment? How to update VAT/tax information and other details for upcoming invoices from CVAT Online? Can a paid invoice be modified? How can I get a quote before I subscribe? How to add a PO number to my invoices? Can you sign an agreement before I subscribe? Can you handle a bank transfer with 30-day payment terms? Where can I find my invoices? I am a student, can I have a discount or free access? Payment methods Paying with bank transfer How to change the payment method? Adding and removing team members Change plan How to change the plan from Solo to Team? How to switch from a monthly subscription to an annual one? Can I subscribe to several plans? Cancel plan What will happen to my data? How to cancel any plan? How can I get a refund? Plan renewal Subscription management video tutorial Available paid plans This section outlines the paid plans available on CVAT Online.\nMonthly plans Name Description Solo The Solo plan has a fixed price and is designed for personal use only. It does not assume collaboration with team members and is not suitable for use within organizations, but it removes all other limitations of the Free plan. Note: Although it allows the creation of an organization and access for up to 2 members – it is for trial purposes only! Organization and members will have all the limitations of the Free plan. Team The Team is for collaboration, it removes limitations of the Free plan for the whole organization, allowing you to share paid benefits with your colleagues. The monthly payment for the plan depends on the number of team members you’ve added. All limits of the Free plan will be removed. Note: The organization owner is also part of the team. So, if you have two annotators working, you’ll need to pay for 3 seats (2 annotators + 1 organization owner). Annual plans Whether you’re a new user, or have a subscription to Team or Solo plan, you can subscribe to our annual plan and save up to 30% on CVAT Online usage costs.\nThe annual subscription offers all the benefits of our paid plans but at a more affordable monthly rate.\nFor more information, see How to switch from monthly subscription to annual?\nBilling This section describes the billing model and gives short a description of limitations for each plan.\nThere are two types of subscriptions available for both the Solo and Team plans: monthly and annual.\nFor more information, see: Pricing Plans\nHow to add VAT/tax and other information to the CVAT Online invoice before the first payment? To ensure VAT (tax) information and other relevant details are included on your CVAT Online invoices, it’s important to add this information before making the first payment.\nHere’s how you can do it:\nSign up for a CVAT Online account and log in. (Optional) If you add the VAT/tax number to the organization, first create an organization and switch to an Organization account. Navigate to the top right corner, next to the nickname, click on the arrow \u003e upgrade to the plan. Switch on the I would like the invoice to include additional data (address, phone number, VAT information) toggle, select the best payment period for you, and click Get Started. You will see the billing page: Phone number (1). Billing Address: Enter the billing address you want to appear on the invoice in the address field (2). VAT Information and Business Name: Select the checkbox I am purchasing as a business and enter your VAT and business name information (3). Select checkbox I agree to refund policy (4).\nNote Please read the Refund policy before selecting the checkbox. Click Pay \u0026 Subscribe.\nAll information you’ve added will appear on the billing page and in the invoice.\nBy following these steps, you can seamlessly add VAT and other crucial information to your invoices, making your financial transactions with CVAT Online transparent and compliant.\nHow to update VAT/tax information and other details for upcoming invoices from CVAT Online? In the top right corner, near the nickname, click on the arrow \u003e manage plan.\nYou will see the Stripe page. Go to the Billing Information \u003e Update Information.\nCan a paid invoice be modified? Once an invoice has been paid, it is not possible to modify it. This restriction is due to the limitations of the payment processing platform used, which in the case of CVAT Online, is Stripe.\nStripe’s policy dictates that revisions to an invoice can only be made before payment. For more comprehensive information on this policy, please refer to Stripe’s official documentation on invoice edits at their website.\nHow can I get a quote before I subscribe? How to add a PO number to my invoices? If you require a quote from CVAT Online for payment via bank transfer, certain criteria must be met:\nThe total subscription cost must be $396 and up per year. Quotes are available exclusively for annual subscriptions. Should you meet these requirements, please write to support@cvat.ai\nCan you sign an agreement before I subscribe? Sign of specific agreements and approvals are available if you meet specific criteria (the total subscription cost must be $10,000 and up per year), for more details contact support@cvat.ai\nCan you handle a bank transfer with 30-day payment terms? Yes, it is available if you fit the quota criteria, for details contact support@cvat.ai.\nWhere can I find my invoices? In the top right corner, near the nickname, click on the arrow \u003e manage plan.\nYou will see the Stripe page. At the bottom of the page, you will see the Invoice History section with all invoices.\nInvoices are automatically sent to the account owner’s address used for the registration.\nTo see the invoice click on the Show Invoice Icon icon.\nI am a student, can I have a discount or free access? To consider your request for a discount, we’d need a few details from you:\nA copy of your valid student ID or any document confirming your university affiliation. Your university advisor’s contact details. The name and contact information of the dean of your faculty. A brief outline of your project plan. This helps us understand how we might collaborate on a joint marketing statement highlighting your use of CVAT Online, and how it can benefit your project. We’d also appreciate a positive LinkedIn post about your experience using CVAT Online, making sure to tag @CVAT.ai. All these details must be sent to support@cvat.ai. Once we have this information, we’ll gladly offer you a 50% discount for one year.\nPayment methods This section describes how to change or add payment methods.\nPaying with bank transfer Note At the moment this method of payment works only with US banks. To pay with a bank transfer:\nGo to the Upgrade to Solo/Team plan\u003e Get started. Click US Bank Transfer. Upon successful completion of the payment, you will receive a receipt via email. Note The completion of the payment process may take up to three banking days. How to change the payment method? In the top right corner, near the nickname, click on the arrow \u003e manage plan \u003e +Add Payment Method\nAdding and removing team members Solo plan is for personal use only, you cannot add or remove team members.\nTeam plan is for collaboration. To add members to your Organization, go to the Manage Team plan \u003e Update quantity.\nIf you’ve added a user before the current billing period ends, the payment will be prorated for the remaining time until the next billing cycle begins. From the following month onward, the full payment will be charged.\nIn case you removed the user before the current billing period ends, funds will not be returned to your account, but next month you will pay less by the amount of unused funds.\nChange plan How to change the plan from Solo to Team? The procedure is the same for both Solo and Team plans.\nIf for some reason you want to change your plan, you need to:\nUnsubscribe from the previous plan. If you need a refund, contact us at support@cvat.ai. Subscribe to a new plan. How to switch from a monthly subscription to an annual one? If you have monthly subscription, and wish to switch to the Annual plan, please follow these steps:\nIn the top-right corner, near the nickname, click on the arrow. Select Manage Solo/Team Plan. On the Stripe page that appears, click Update Plan. Choose Yearly and then click Continue. The price will be adjusted according to the number of members, selected in the Quantity field (if updated), taking into account the amount of money that was not spent in the current period.\nUpon payment, your subscription will be renewed and the start date will be reset to the day you switch to the new plan.\nCan I subscribe to several plans? Paid plans are not mutually exclusive. You can have several active subscriptions, for example, the Solo plan and several Team plans for different organizations.\nCancel plan This section describes how to cancel your CVAT subscription and what will happen to your data.\nWhat will happen to my data? Once you have terminated your subscription, your data will remain accessible within the system for a month. During this period, you will be unable to add new tasks and free plan limits will be applied.\nIn case you possess a substantial amount of data, it will be switched to read-only mode. It means you will not be able to save annotations, add any resources, and so on.\nFollowing the one month, you will receive a notification requesting you to either remove the excess data or it will be deleted automatically.\nHow to cancel any plan? To cancel the plan, in the top right corner, near the nickname, click on the arrow\u003e manage plan \u003e Cancel plan\nPlease, fill out the feedback form, to help us improve our platform.\nHow can I get a refund? To understand if you are eligible for a refund, see Refund policy.\nCancel the subscription before asking for a refund. Contact our support team at support@cvat.ai or use the “Support” option in the app.cvat.ai interface. Provide your account details and a brief explanation of the reason for the refund: Send us your last invoice. Send us the username and e-mail address you’ve used to register in CVAT Online. Our team will review your request. We may request additional information if needed. Once approved, the refund will be processed to your original payment method within 5-10 business days.\nPlan renewal To renew your CVAT Online subscription, in the top right corner, near the nickname, click on the arrow\u003e manage plan \u003e Renew plan.\nSubscription management video tutorial ","categories":"","description":"How to manage your subscription","excerpt":"How to manage your subscription","ref":"/v2.43.0/docs/enterprise/subscription-management/","tags":"","title":"Subscription management"},{"body":"This section is for users who want to be a bit more flexible with CVAT use.\nThe user you register by default does not have full permissions on the instance, so you must create a superuser. The superuser can use Django administration panel to assign groups (roles) to other users. Available roles are: user (default), admin, worker.\nPrerequisites Before you register an admin account (superuser), you need to install CVAT locally, see Installation Guide.\nSteps of installation are partly different, depending on the type of operation system (OS).\nThis section starts with Create superuser step that is common for all OS.\nRegister as a superuser In the process of installation you need to create a superuser:\nIn a terminal run the following command: docker exec -it cvat_server bash -ic 'python3 ~/manage.py createsuperuser' Set up username, email address, and password. Go to localhost:8080, and log in with credentials from step 2. (Optional) Go to Django administration panel panel to: Create/edit/delete users Control permissions of users and access to the tool. To manage users’ permission, in the Django administration panel:\nOn the left menu click Users. On the main pane click Admin and scroll down to Permissions section. Select user groups and add/remove permissions. ","categories":"","description":"A CVAT installation guide to create a superuser.","excerpt":"A CVAT installation guide to create a superuser.","ref":"/v2.43.0/docs/administration/basics/admin-account/","tags":"","title":"Superuser registration"},{"body":"CVAT provides analytics data for projects, tasks, and jobs to help you to track annotation progress and performance metrics at every level. Analytics support a wide range of use cases, including:\nDefining the working time a user spent on a job during a specific period. Tracking time spent in each job stage. Calculating the total number of ground truth objects in a project. Determining the number of ground truth images in a project. Checking interpolation rates to assess annotator efficiency. Identifying how many objects of a specific label were annotated in a resource. Calculating the average annotation speed of a user in a project or task. Analyzing how many objects or images were present in removed resources. Analytics is a paid feature available in CVAT Online (paid tiers) and CVAT Enterprise.\nIn personal workspaces, analytics are available only to the workspace owner. In organizations, access depends on the user’s organizational role:\nOwners and Maintainers: Full access to all analytics. Supervisors: Access only to analytics for visible projects, tasks, and jobs. Workers: Access only to analytics for tasks and jobs assigned to them. Workers cannot update the analytics data. Access To open analytics:\nFor a project For a task For a job Open Projects. Open the project menu using or open a project and select Actions. Select View analytics. You can open analytics for a task using the Tasks or Projects pages. To open a task analytics on the Tasks page:\nOpen Tasks. Open the Actions menu for a task, or open a task and select Actions. Select View analytics. To open a task analytics from a project:\nOpen Projects Open a project Open the Actions menu for a task. Select View analytics. You can open analytics for a job using the Jobs or Tasks pages. To open a job analytics on the Jobs page:\nOpen Jobs. Open the job menu using button. Select View analytics. To open a job analytics from a task:\nOpen Tasks. Open a task. Open the job menu using button. Select View analytics. Analytics page The Analytics page displays the data relevant to the specific resource (project, task, or job). Use the link in the page title to return to the corresponding project, task, or job.\nAnalytics data is not fetched automatically. When you first open the Analytics page, it will be empty. To fetch and display the analytical data, select the Request button.\nNote The analytical data is fetched for all resource children. So, when you request data for a task, the data for all task jobs is also fetched. Once the data is fetched and displayed on the page, you can check its relevance under the page title. A warning icon indicates that the resource was updated after the last analytics update.\nTo update the data, select button.\nThe Analytics page includes:\nSummary tab. Annotations tab. Events tab. Date filter. Export events button. Note The date filter is applied to the Summary and Events tabs. The Summary tab provides a statistics overview, while the Annotations and Events tabs contain the detailed data in table form.\nTo download a CSV file with all event data, select the Export events button.\nSummary tab The Summary tab displays the quantitative metrics:\nObjects diff: Difference between created and deleted objects in the selected time period. The value may be negative, if the number of the deleted objects exceeds the number of the created objects during the selected time period. Total working time: Total hours spent across all users, based on annotation-related events. Avg. annotation speed: Average number of objects annotated per hour. The value may be negative, if the number of the deleted objects exceeds the number of the created objects during the selected time period. The Summary tab includes charts for object statistics, annotation speed, and diagrams for annotation distribution by labels and types. Hover over a chart or diagram to display tooltips.\nAnnotations tab The Annotations tab shows annotation statistics for:\nShape mode (the Detections tab). Track mode (the Tracking tab). Both tabs always reflect the current state of the resource. Each tab includes a filterable, customizable table (learn how to work with tables).\nYou can search entries by the Label name column:\nIn the search box, enter the value or part of the value to find. Select button or press Enter. The Detection tab table contains the columns:\nColumn name Content Label ID The ID of the label. Label name The name of the label. Columns with label types names The number of objects per label type. By default, the columns with zero values are hidden. Total shapes The total number of all label shapes. The Tracking tab table contains the columns:\nColumn name Content Label ID The ID of the label. Label name The name of the label. Columns with label type names The number of objects per label type. By default, the columns with zero values are hidden. Keyframes The number of the label keyframes. Interpolated The number of interpolated frames with the label. Tracks The number of the label tracks. Total objects The total number of all label objects. Events tab The Events tab displays the following metrics:\nTotal objects: Total number of objects in the filtered jobs. Total images: Total number of images in the filtered jobs. Total working time: Total user time spent. Avg. annotation speed: : Average number of objects annotated per hour. Note All metrics are recalculated when you apply the date or table filter. The Events tab table contains the aggregated events for the selected resource. Each event is defined by a unique status signature, which is a combination of the job’s assignee, stage, state, and the user who performed the action. As long as this status signature stays the same, all events are combined into one row. For example, if the same user creates two objects in the same job, the Events table will display one event that includes both actions.\nHowever, if the job’s status signature changes (for example, due to an action performed by a different user) the analytics register a new event. As a result, actions that might otherwise be aggregated are instead recorded as separate events in the table.\nYou can filter the events by date range:\nSelect the date filter near the page title. Select the first and last dates or enter them in YYYY-MM-DD format. If the date filter is empty, the Events tab shows the metrics and events for the lifetime of the project, task, or job.\nTo reset the date range, select button in the date filter.\nYou can search the table entries by values in Task name, Assignee, Stage, State, User columns:\nIn the search box, enter the value or part of the value to find. Select button or press Enter. Other common operations with tables are described in the Working with tables paragraph.\nThe events table columns:\nColumn name Content Task ID The ID of the task. If the task exists (the Exists column has the value true), you can select the value to open the task. Task name The task name. By default, the column is hidden. Select the value to open the task. Job ID The ID of the job. If the job exists (the Exists column has the value true), you can select the value to open the job. Type The job (Job ID) type. Possible values: Annotation, Ground truth, Consensus replica. Frame Count The total number of frames in the job (Job ID) Exists Indicates if the job (Job ID) existed at the last data fetch. Objects The total number of existing objects on the job (Job ID) frames Assignee The job (Job ID) assignee when the event occurred. Stage The stage of the job (Job ID) when the event occurred. State The state of the job (Job ID) when the event occurred. User The name of the user who triggered the event. Working time Displays the total time in milliseconds spent during the events. By default, the column is hidden. Start UTC time UTC time when the event started. End UTC time UTC time when the event finished. By default, the column is hidden. Created objects The total number of created objects. By default, the column is hidden. Updated objects The total number of updated objects. By default, the column is hidden. Deleted objects The total number of deleted objects. By default, the column is hidden. Working with tables The tables in the Annotations and Events tabs support:\nExporting the data: select button.\nNote Visible columns do not affect the file with exported data. It always contains the complete table with all columns and rows. Filtering entries by a custom rule: select Filter, and set filtering criteria. To learn more about how to set a filter, refer to the Filter article.\nClearing filters: select Clear filters.\nCustomizing columns:\nSelect above the right side of the table. Toggle the checkboxes for the columns to display or hide them in the table. Sorting entries: select the column name to apply sorting. The arrows near the column name indicate the applied sorting order. The arrow up indicates ascending order, the arrow down indicates descending order. You can sort the entries by one column only.\nLarge tables are split into pages. You can find the pagination controls under the table. You can also change the number of entries per page.\n","categories":"","description":"Learn how to access and analyze detailed data and metrics in CVAT Online and Enterprise.","excerpt":"Learn how to access and analyze detailed data and metrics in CVAT …","ref":"/v2.43.0/docs/manual/advanced/analytics-and-monitoring/analytics/","tags":"","title":"Analytics"},{"body":"Use Create multi tasks to create multiple video annotation tasks with the same configuration.\nNote The Create multi tasks feature is available for videos only. Check out:\nCreate multi tasks Example Errors Advanced configuration Create multi tasks To create the multi tasks:\nOn the Tasks page select +. Select Create multi tasks. Next, specify the parameters in the task configurator:\nIn the Name field, enter the name of the new task:\nEnter the name of the task (Optional) {{index}} adds an index to the file in the set (starting from 0). (Optional) {{file_name}} adds the file’s name to the task’s name. (Optional) From the Projects drop-down, select a project for the tasks. Leave this field empty if you do not want to assign tasks to any project.\nNote Following steps are valid if the tasks do not belong to a project. If the tasks have been assigned to a project, the project’s labels will be applied to the tasks. On the Constructor tab, select Add label.\nIn the Label name field, enter the name of the label.\n(Optional) Select the color for the label.\n(Optional) Select Add an attribute and set up its properties.\nSelect Select files to upload files for annotation.\nNote You cannot upload multiple tasks from the cloud storage. Select Submit N tasks\nExample A step-by-step example for creating the multiple tasks:\nIn the Name field, enter the Create_multitask-{{index}}-{{file_name}}.\nAdd labels.\nSelect files. In case there are more than four files, only the total number of selected files will be displayed: Select Submit N tasks\nYou will see a progress bar that shows the progress of the tasks being created:\nSelect Ok.\nThe result will look like the following:\nErrors During the process of adding multiple tasks, the following errors may occur:\nError Description Wrong file format. You can add only video files. In the process of creating a task, CVAT was not able to process the video file. The name of the failed file will be displayed on the progress bar. To fix this issue: If you want to try again, click Retry failed tasks. If you want to skip the file, click OK. Advanced configuration Use advanced configuration to set additional parameters for the task and customize it to meet specific needs or requirements.\nFor more information, consult Advanced configuration\n","categories":"","description":"Step-by-step guide on how to create and set up multiple tasks","excerpt":"Step-by-step guide on how to create and set up multiple tasks","ref":"/v2.43.0/docs/manual/basics/create-multi-tasks/","tags":"","title":"Create multi tasks"},{"body":"This section of the documentation describes the annotation interface and all available options that you can use to annotate image data accurately and quickly.\nThe interface includes the following areas:\n","categories":"","description":"This section describes CVAT annotation interface and it's features","excerpt":"This section describes CVAT annotation interface and it's features","ref":"/v2.43.0/docs/manual/basics/cvat-annotation-interface/","tags":"","title":"CVAT Annotation Interface"},{"body":" How to migrate data from CVAT.org to CVAT.ai Please follow the export tasks and projects guide to download an archive with data which corresponds to your task or project. The backup for a project will have all tasks which are inside the project. Thus you don’t need to export them separately.\nPlease follow the import tasks and projects guide to upload your backup with a task or project to a CVAT instance.\nSee a quick demo below. It is really a simple process. If your data is huge, it may take some time. Please be patient.\nHow to upgrade CVAT Before upgrading, please follow the backup guide and backup all CVAT volumes.\nFollow the upgrade guide.\nHow to change default CVAT hostname or port To change the hostname, simply set the CVAT_HOST environment variable\nexport CVAT_HOST=\u003cYOUR_HOSTNAME_OR_IP\u003e NOTE, if you’re using docker compose with sudo to run CVAT, then please add the -E (or --preserve-env) flag to preserve the user environment variable which set above to take effect in your docker containers:\nsudo -E docker compose up -d If you want to change the default web application port, change the ports part of traefik service configuration in docker-compose.yml\nservices: traefik: ... ... ports: - \u003cYOUR_WEB_PORTAL_PORT\u003e:8080 - 8090:8090 Note that changing the port does not make sense if you are using HTTPS - port 443 is conventionally used for HTTPS connections, and is needed for Let’s Encrypt TLS challenge.\nHow to configure connected share folder on Windows Follow the Docker manual and configure the directory that you want to use as a shared directory:\nDocker toolbox manual Docker for windows (see FILE SHARING section) After that, it should be possible to use this directory as a CVAT share:\nservices: cvat_server: volumes: - cvat_share:/home/django/share:ro cvat_worker_import: volumes: - cvat_share:/home/django/share:ro cvat_worker_export: volumes: - cvat_share:/home/django/share:ro cvat_worker_annotation: volumes: - cvat_share:/home/django/share:ro cvat_worker_chunks: volumes: - cvat_share:/home/django/share:ro volumes: cvat_share: driver_opts: type: none device: /d/my_cvat_share o: bind Where are uploaded images/videos stored The uploaded data is stored in the cvat_data docker volume:\nvolumes: - cvat_data:/home/django/data Where are annotations stored Annotations are stored in the PostgreSQL database. The database files are stored in the cvat_db docker volume:\nvolumes: - cvat_db:/var/lib/postgresql/data How to install CVAT on Windows 10 Home Follow this guide.\nI do not have the Analytics tab on the header section. How can I add analytics You should build CVAT images with ‘Analytics’ component.\nHow to upload annotations to an entire task from UI when there are multiple jobs in the task You can upload annotation for a multi-job task from the Dashboard view or the Task view. Uploading of annotation from the Annotation view only affects the current job.\nHow to specify multiple hostnames To do this, you will need to edit traefik.http.\u003crouter\u003e.cvat.rule docker label for both the cvat and cvat_ui services, like so (see the documentation on Traefik rules for more details):\ncvat_server: labels: traefik.http.routers.cvat.rule: (Host(`example1.com`) || Host(`example2.com`)) \u0026\u0026 (PathPrefix(`/api/`) || PathPrefix(`/static/`) || PathPrefix(`/admin`) || PathPrefix(`/django-rq`)) cvat_ui: labels: traefik.http.routers.cvat-ui.rule: Host(`example1.com`) || Host(`example2.com`) How to create a task with multiple jobs Set the segment size when you create a new task, this option is available in the Advanced configuration section.\nHow to transfer CVAT to another machine Follow the backup/restore guide.\nHow to load your own DL model into CVAT See the information here in the Serverless tutorial.\nMy server uses a custom SSL certificate and I don’t want to check it. You can call control SSL certificate check with the --insecure CLI argument. For SDK, you can specify ssl_verify = True/False in the cvat_sdk.core.client.Config object.\n","categories":"","description":"Answers to frequently asked questions","excerpt":"Answers to frequently asked questions","ref":"/v2.43.0/docs/faq/","tags":"","title":"Frequently asked questions"},{"body":"We are excited to introduce the first video in our course series designed to help you annotate data faster and better using CVAT. In this introductory 4 minute video, we walk through:\nwhat problems CVAT and Datumaro solve, how they can speed up your model training process, and some resources you can use to learn more about how to use them. ","categories":"","description":"","excerpt":"We are excited to introduce the first video in our course series …","ref":"/v2.43.0/docs/getting_started/introduction-to-cvat-and-datumaro/","tags":"","title":"Introduction to CVAT and Datumaro"},{"body":"Overview The low-level API is useful if you need to work directly with REST API, but want to have data validation and syntax assistance from your code editor. The code on this layer is autogenerated.\nCode of this component is located in cvat_sdk.api_client.\nExample Let’s see how a task with local files can be created. We will use the basic auth to make things simpler.\nfrom time import sleep from cvat_sdk.api_client import Configuration, ApiClient, models, apis, exceptions configuration = Configuration( host=\"http://localhost\", username='YOUR_USERNAME', password='YOUR_PASSWORD', ) # Enter a context with an instance of the API client with ApiClient(configuration) as api_client: # Parameters can be passed as a plain dict with JSON-serialized data # or as model objects (from cvat_sdk.api_client.models), including # mixed variants. # # In case of dicts, keys must be the same as members of models.I\u003cModelName\u003e # interfaces and values must be convertible to the corresponding member # value types (e.g. a date or string enum value can be parsed from a string). # # In case of model objects, data must be of the corresponding # models.\u003cModelName\u003e types. # # Let's use a dict here. It should look like models.ITaskWriteRequest task_spec = { 'name': 'example task', \"labels\": [{ \"name\": \"car\", \"color\": \"#ff00ff\", \"attributes\": [ { \"name\": \"a\", \"mutable\": True, \"input_type\": \"number\", \"default_value\": \"5\", \"values\": [\"4\", \"5\", \"6\"] } ] }], } try: # Apis can be accessed as ApiClient class members # We use different models for input and output data. For input data, # models are typically called like \"*Request\". Output data models have # no suffix. (task, response) = api_client.tasks_api.create(task_spec) except exceptions.ApiException as e: # We can catch the basic exception type, or a derived type print(\"Exception when trying to create a task: %s\\n\" % e) # Here we will use models instead of a dict task_data = models.DataRequest( image_quality=75, client_files=[ open('image1.jpg', 'rb'), open('image2.jpg', 'rb'), ], ) # If we pass binary file objects, we need to specify content type. (result, response) = api_client.tasks_api.create_data(task.id, data_request=task_data, _content_type=\"multipart/form-data\", # we can choose to check the response status manually # and disable the response data parsing _check_status=False, _parse_response=False ) assert response.status == 202, response.msg # Wait till task data is processed for _ in range(100): request_details, response = api_client.requests_api.retrieve(result.rq_id) status, message = request_details.status, request_details.message if status.value in {'finished', 'failed'}: break sleep(0.1) assert status.value == 'finished', status.message # Update the task object and check the task size (task, _) = api_client.tasks_api.retrieve(task.id) assert task.size == 4 ApiClient and configuration The starting point in the low-level API is the cvat_sdk.api_client.ApiClient class. It encapsulates session and connection logic, manages headers and cookies, and provides access to various APIs.\nTo create an instance of ApiClient, you need to set up a cvat_sdk.api_client.Configuration object and pass it to the ApiClient class constructor. Additional connection-specific options, such as extra headers and cookies can be specified in the class constructor. ApiClient implements the context manager protocol. Typically, you create ApiClient this way:\nfrom cvat_sdk.api_client import ApiClient, Configuration configuration = Configuration(host=\"http://localhost\") with ApiClient(configuration) as api_client: ... After creating an ApiClient instance, you can send requests to various server endpoints via *_api member properties and directly, using the rest_client member. Read more about API wrappers below.\nTypically, the first thing you do with ApiClient is log in. Read more about authentication options below.\nAuthentication CVAT supports 3 authentication options:\nBasic authentication, with a username and a password Session authentication, with a session ID and a CSRF token Token authentication, with an API key (deprecated) Token authentication requires an API key, which can be obtained after logging in via the /api/auth/login endpoint using the basic authentication credentials.\nSession authentication requires a session ID and a CSRF token, which can be obtained after logging in via the /api/auth/login endpoint using the basic authentication credentials.\nAuthentication credentials for an ApiClient instance can be specified in a Configuration object:\nBasic authentication Session authentication Token authentication (deprecated) configuration = Configuration( username='YOUR_USERNAME', password='YOUR_PASSWORD', ... ) with ApiClient(configuration) as api_client: ... configuration = Configuration( api_key={ \"sessionAuth\": \"\u003csessionid cookie value\u003e\", \"csrfAuth\": \"\u003ccsrftoken cookie value\u003e\", }, ... ) with ApiClient(configuration) as api_client: ... This authentication option is deprecated and will be removed in future.\nconfiguration = Configuration( api_key={ \"tokenAuth\": \"Token \u003capi key value\u003e\", }, ... ) with ApiClient(configuration) as api_client: ... Session authentication and token authentication tokens can be received by logging in using the ApiClient.auth_api.create_login() function. Then, the authentication keys can be set in the ApiClient instance.\nSession authentication Token authentication (deprecated) from cvat_sdk.api_client import models (auth, _) = api_client.auth_api.create_login( models.LoginSerializerExRequest(username=\"username\", password=\"password\") ) # Set up required headers assert \"sessionid\" in api_client.cookies # managed by ApiClient automatically api_client.set_default_header(\"X-CSRFToken\", api_client.cookies[\"csrftoken\"].value) api_client.set_default_header(\"Origin\", api_client.build_origin_header()) This authentication option is deprecated and will be removed in future.\nfrom cvat_sdk.api_client import models (auth, _) = api_client.auth_api.create_login( models.LoginSerializerExRequest(username=\"username\", password=\"password\") ) api_client.set_default_header(\"Authorization\", \"Token \" + auth.key) API wrappers API endpoints are grouped by tags into separate classes in the cvat_sdk.api_client.apis package.\nAPIs can be accessed as ApiClient object members:\napi_client.auth_api.\u003coperation\u003e(...) api_client.tasks_api.\u003coperation\u003e(...) And APIs can be instantiated directly like this:\nfrom cvat_sdk.api_client import ApiClient, apis api_client = ApiClient(...) auth_api = apis.AuthApi(api_client) auth_api.\u003coperation\u003e(...) tasks_api = apis.TasksApi(api_client) tasks_api.\u003coperation\u003e(...) For each operation, the API wrapper class has a corresponding \u003coperation\u003e_endpoint member. This member represents the endpoint as a first-class object, which provides metainformation about the endpoint, such as the relative URL of the endpoint, parameter names, types and their placement in the request. It also allows to pass the operation to other functions and invoke it from there.\nFor a typical server entity like Task, Project, Job etc., the *Api classes provide methods that reflect Create-Read-Update-Delete (CRUD) operations: create, retrieve, list, update, partial_update, delete. The set of available operations depends on the entity type.\nYou can find the list of the available APIs and their documentation here.\nModels Requests and responses can include data. It can be represented as plain Python data structures and model classes (or models). In CVAT API, model for requests and responses are separated: the request models have the Request suffix in the name, while the response models have no suffix. Models can be found in the cvat_sdk.api_client.models package.\nModels can be instantiated like this:\nfrom cvat_sdk.api_client import models user_model = models.User(...) Model parameters can be passed as models, or as plain Python data structures. This rule applies recursively, starting from the method parameters. In particular, this means you can pass a dict into a method or into a model constructor, and corresponding fields will be parsed from this data automatically:\ntask_spec = models.TaskWriteRequest( name='example task', labels=[ models.PatchedLabelRequest( name=\"car\", color=\"#ff00ff\", attributes=[ model.AttributeRequest( name=\"a\", mutable=True, input_type=\"number\", default_value=\"5\", values=[\"4\", \"5\", \"6\"] ) ] ) ], ) api_client.tasks_api.create(task_spec) Is equivalent to:\napi_client.tasks_api.create({ 'name': 'example task', \"labels\": [{ \"name\": \"car\", \"color\": \"#ff00ff\", \"attributes\": [ { \"name\": \"a\", \"mutable\": True, \"input_type\": \"number\", \"default_value\": \"5\", \"values\": [\"4\", \"5\", \"6\"] } ] }], }) You can mix these variants.\nMost models provide corresponding interface classes called like I\u003cmodel name\u003e. They can be used to implement your own classes or describe APIs. They just provide type annotations and descriptions for model fields.\nYou can export model values to plain Python dicts using the to_dict() method and the cvat_sdk.api_client.model_utils.to_json() function.\nYou can find the list of the available models and their documentation here.\nSending requests To send a request to a server endpoint, you need to obtain an instance of the corresponding *Api class. You can find summary about available API classes and supported endpoints here. The *Api instance object allows to send requests to the relevant server endpoints.\nBy default, all operations return 2 objects: the parsed response data and the response itself.\nThe first returned value is a model parsed from the response data. If a method does not have any return value, None is always returned as the first value. You can control automatic parsing using the _parse_response method kwarg. When disabled, None is returned.\nThe second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. By default, the status code of the response is checked to be positive. In the case of request failure, an exception is raised by default. This behavior can be controlled by the _check_status method kwarg. If the status is not checked, you will need to manually check the response status code and perform actions needed.\nA typical endpoint call looks like this:\nfrom cvat_sdk.api_client import ApiClient, apis with ApiClient(...) as api_client: ... (data, response) = api_client.tasks_api.list() # process the response ... Operation parameters can be passed as positional or keyword arguments. API methods provide extra common arguments which control invocation logic:\n_parse_response (bool) - Allows to enable and disable response data parsing. When enabled, the response data is parsed into a model or a basic type and returned as the first value. When disabled, the response is not parsed, and None is returned. Can be useful, for instance, if you need to parse data manually, or if you expect an error in the response. Default is True. _check_status (bool) - Allows to enable or disable response status checks. When enabled, the response status code is checked to be positive as defined in the HTTP standards. In the case of negative status, an exception is raised. Default is True. _validate_inputs (bool): specifies if type checking should be done on the data sent to the server. Default is True. _validate_outputs (bool): specifies if type checking should be done on the data received from the server. Default is True. _request_timeout (None | int | float | Tuple[int | float, int | float]) - Allows to control timeouts. If one number is provided, it will be the total request timeout. It can also be a tuple with (connection, read) timeouts. Default is None, which means no timeout. _content_type (None | str) - Allows to specify the Content-Type header value for the request. Endpoints can support different content types and behave differently depending on the value. For file uploads _content_type=\"multipart/form-data\" must be specified. Read more about file uploads here. Default is application/json. Note The API is autogenerated. In some cases the server API schema may be incomplete or underspecified. Please report to us all the problems found. A typical problem is that a response data can’t be parsed automatically due to the incorrect schema. In this case, the simplest workaround is to disable response parsing using the _parse_response=False method argument. You can find many examples of API client usage in REST API tests here.\nOrganizations To create resource in the context of an organization, use one of these method arguments:\norg - The unique organization slug org_id- The organization id ... (task, response) = api_client.tasks_api.create(task_spec, org_id=org_id) Paginated responses There are several endpoints that allow to request multiple server entities. Typically, these endpoints are called list_.... When there are lots of data, the responses can be paginated to reduce server load. If an endpoint returns paginated data, a single page is returned per request. In some cases all entries need to be retrieved. CVAT doesn’t provide specific API or parameters for this, so the solution is to write a loop to collect and join data from multiple requests. SDK provides an utility function for this at cvat_sdk.core.helpers.get_paginated_collection().\nExample:\nfrom cvat_sdk.core.helpers import get_paginated_collection ... project_tasks = get_paginated_collection( api_client.projects_api.list_tasks_endpoint, id=project_id, ) Binary data in requests and responses At the moment, sending and receiving binary data - such as files - can be difficult via the low-level SDK API. Please use the following recommendations.\nSending data By default, requests use the application/json content type, which is a text type. However, it’s inefficient to send binary data in this encoding, and the data passed won’t be converted automatically. If you need to send files or other binary data, please specify _content_type=\"multipart/form-data\" in the request parameters:\nExample:\n(result, response) = api_client.tasks_api.create_data( id=42, data_request=models.DataRequest( client_files=[ open(\"image.jpg\", 'rb') ], image_quality=70, ), _content_type=\"multipart/form-data\", # required ) Please also note that if there are complex fields in the data (such as nested lists or dicts), they, in turn, cannot be encoded as multipart/form-data, so the recommended solution is to split fields into files and others, and send them in different requests with different content types:\nExample:\ndata = { 'client_files': [...], # a list of binary files 'image_quality': ..., # a simple type - int 'job_file_mapping': [...], # a complex type - list } # Initialize uploading api_client.tasks_api.create_data( id=42, data_request=models.DataRequest(image_quality=data[\"image_quality\"]), upload_start=True, ) # Upload binary data api_client.tasks_api.create_data( id=42, data_request=models.DataRequest( client_files=data.pop(\"client_files\"), image_quality=data[\"image_quality\"], ), upload_multiple=True, _content_type=\"multipart/form-data\", ) # Finalize the uploading and send the remaining fields api_client.tasks_api.create_data( id=42, data_request=models.DataRequest(**data), upload_finish=True, ) Receiving data Receiving binary files can also be difficult with the low-level API. To avoid unexpected behavior, it is recommended to specify _parse_response=False in the request parameters. In this case, SDK will not try to parse models from responses, and the response data can be fetched directly from the response:\nimport json from http import HTTPStatus from time import sleep from urllib.parse import parse_qsl, urlparse from cvat_sdk.api_client import ApiClient, Configuration, models interval = 1 with ApiClient( configuration=Configuration(host=\"\u003ccvat_host\u003e\", username=\"\u003cusername\u003e\", password=\"\u003cpassword\u003e\") ) as api_client: # Initiate the process to export a task as a dataset (_, response) = api_client.tasks_api.create_dataset_export( id=task_id, format=\"COCO 1.0\", save_images=True, _parse_response=False, ) assert response.status == HTTPStatus.ACCEPTED # Obtain the background request ID from the server response rq_id = json.loads(response.data).get(\"rq_id\") assert rq_id, \"The rq_id parameter was not found in the server response\" # Check the status of the background process while True: (background_request, response) = api_client.requests_api.retrieve(rq_id) assert response.status == HTTPStatus.OK process_status = background_request.status.value if process_status in ( models.RequestStatus.allowed_values[(\"value\",)][\"FINISHED\"], models.RequestStatus.allowed_values[(\"value\",)][\"FAILED\"], ): break sleep(interval) if process_status != models.RequestStatus.allowed_values[(\"value\",)][\"FINISHED\"]: exception_msg = f\"Export failed with status: {process_status}\" if background_request.message: exception_msg += f\". Details: {background_request.message}\" assert False, exception_msg # Download a prepared file result_url = background_request.result_url assert result_url, \"No 'result_url' in the server response\" parsed_result_url = urlparse(result_url) query_params = parse_qsl(parsed_result_url.query) _, response = api_client.call_api( parsed_result_url.path, method=\"GET\", query_params=query_params, auth_settings=api_client.configuration.auth_settings(), _parse_response=False, ) # Save the resulting file with open(\"output_file.zip\", \"wb\") as output_file: while (chunk := response.read(8192)): output_file.write(chunk) Different versions of API endpoints The cloudstorages/id/content REST API endpoint Warning The retrieve_content method of cloudstorages_api will be deprecated in 2.5.0 version. We recommend using retrieve_content_v2 method that matches to revised API when using SDK. For backward compatibility, we continue to support the prior interface version until version 2.6.0 is released. Here you can find the example how to get the bucket content using new method retrieve_content_v2.\nfrom pprint import pprint from cvat_sdk.api_client import ApiClient, Configuration next_token = None files, prefixes = [], [] prefix = \"\" with ApiClient( configuration=Configuration(host=BASE_URL, username=user, password=password) ) as api_client: while True: data, response = api_client.cloudstorages_api.retrieve_content_v2( cloud_storage_id, **({\"prefix\": prefix} if prefix else {}), **({\"next_token\": next_token} if next_token else {}), ) # the data will have the following structure: # {'content': [ # {'mime_type': \u003cimage|video|archive|pdf|DIR\u003e, 'name': \u003cname\u003e, 'type': \u003cREG|DIR\u003e}, # ], # 'next': \u003cnext_token_string|None\u003e} files.extend( [ prefix + f[\"name\"] for f in data[\"content\"] if str(f[\"type\"]) == \"REG\" ] ) prefixes.extend( [ prefix + f[\"name\"] for f in data[\"content\"] if str(f[\"type\"]) == \"DIR\" ] ) next_token = data[\"next\"] if next_token: continue if not len(prefixes): break prefix = f\"{prefixes.pop()}/\" pprint(files) # ['sub/image_1.jpg', 'image_2.jpg'] ","categories":"","description":"","excerpt":"Overview The low-level API is useful if you need to work directly with …","ref":"/v2.43.0/docs/api_sdk/sdk/lowlevel-api/","tags":"","title":"Low-level API"},{"body":"The MOT (Multiple Object Tracking) sequence format is widely used for evaluating multi-object tracking algorithms, particularly in the domains of pedestrian tracking, vehicle tracking, and more. The MOT sequence format essentially contains frames of video along with annotations that specify object locations and identities over time.\nFor more information, see:\nMOT sequence paper Dataset examples MOT export For export of images and videos:\nSupported annotations: Bounding Boxes. Attributes: visibility (number), ignored (checkbox) Tracks: Supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── img1/ | ├── image1.jpg | └── image2.jpg └── gt/ ├── labels.txt └── gt.txt # labels.txt cat dog person ... # gt.txt # frame_id, track_id, x, y, w, h, \"not ignored\", class_id, visibility, \u003cskipped\u003e 1,1,1363,569,103,241,1,1,0.86014 ... MOT import Uploaded file: a zip archive of the structure above or:\narchive.zip/ └── gt/ └── gt.txt └── labels.txt # optional, mandatory for non-official labels supported annotations: Rectangle tracks ","categories":"","description":"How to export and import data in MOT format","excerpt":"How to export and import data in MOT format","ref":"/v2.43.0/docs/manual/advanced/formats/format-mot/","tags":"","title":"MOT"},{"body":"We provide a variety of premium features exclusively for our paying customers.\nFor further details, please visit:\nTailored Plans for individuals and teams to explore paid plans on CVAT Online. Self-hosted Pricing Plans to discover pricing options for community and enterprise self-hosted solutions. All about Pricing Plans to determine the CVAT Online Plan that best fits your needs. Advantages for Enterprise Clients to learn about the exclusive features available to Enterprise clients. ","categories":"","description":"Setting up paid features in CVAT.","excerpt":"Setting up paid features in CVAT.","ref":"/v2.43.0/docs/enterprise/","tags":"","title":"Paid features"},{"body":"Overview CVAT SDK is a Python library. It provides you access to Python functions and objects that simplify server interaction and provide additional functionality like data validation and serialization.\nSDK API includes several layers:\nLow-level API with REST API wrappers. Located at cvat_sdk.api_client. Read more High-level API. Located at cvat_sdk.core. Read more PyTorch adapter. Located at cvat_sdk.pytorch. Read more Auto-annotation API. Located at cvat_sdk.auto_annotation. Read more Miscellaneous utilities, grouped by topic. Located at cvat_sdk.attributes and cvat_sdk.masks. In general, the low-level API provides single-request operations, while the high-level one implements composite, multi-request operations, and provides local proxies for server objects. For most uses, the high-level API should be good enough, and it should be the right point to start your integration with CVAT.\nThe PyTorch adapter is a specialized layer that represents datasets stored in CVAT as PyTorch Dataset objects. This enables direct use of such datasets in PyTorch-based machine learning pipelines.\nThe auto-annotation API is a specialized layer that lets you automatically annotate CVAT datasets by running a custom function on the local machine. See also the auto-annotate command in the CLI.\nInstallation To install an official release of CVAT SDK use this command:\npip install cvat-sdk To use the cvat_sdk.masks module, request the masks extra:\npip install \"cvat-sdk[masks]\" To use the PyTorch adapter or the built-in PyTorch-based auto-annotation functions, request the pytorch extra:\npip install \"cvat-sdk[pytorch]\" We support Python versions 3.9 and higher.\nUsage To import package components, use the following code:\nFor the high-level API:\nimport cvat_sdk # or import cvat_sdk.core For the low-level API:\nimport cvat_sdk.api_client For the PyTorch adapter:\nimport cvat_sdk.pytorch ","categories":"","description":"","excerpt":"Overview CVAT SDK is a Python library. It provides you access to …","ref":"/v2.43.0/docs/api_sdk/sdk/","tags":"","title":"CVAT Python SDK"},{"body":"DL models as serverless functions Follow this guide to install Nuclio:\nYou have to install nuctl command line tool to build and deploy serverless functions. The simplest way to explore Nuclio is to run its graphical user interface (GUI) of the Nuclio dashboard. All you need in order to run the dashboard is Docker. See nuclio documentation for more details. Deploy a couple of functions. This will automatically create a cvat Nuclio project to contain the functions. ./serverless/deploy_cpu.sh serverless/openvino/dextr ./serverless/deploy_cpu.sh serverless/openvino/omz/public/yolo-v3-tf Display a list of running serverless functions using nuctl command or see them in nuclio dashboard: nuctl get function NAMESPACE | NAME | PROJECT | STATE | NODE PORT | REPLICAS nuclio | openvino-dextr | cvat | ready | 55274 | 1/1 nuclio | openvino-omz-public-yolo-v3-tf | cvat | ready | 57308 | 1/1 Test your deployed DL model as a serverless function. The command below should work on Linux and Mac OS. image=$(curl https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png --output - | base64 | tr -d '\\n') cat \u003c\u003c EOF \u003e /tmp/input.json {\"image\": \"$image\"} EOF cat /tmp/input.json | nuctl invoke openvino-omz-public-yolo-v3-tf -c 'application/json' 23.05.11 22:14:17.275 nuctl.platform.invoker (I) Executing function {\"method\": \"POST\", \"url\": \"http://0.0.0.0:32771\", \"bodyLength\": 631790, \"headers\": {\"Content-Type\":[\"application/json\"],\"X-Nuclio-Log-Level\":[\"info\"],\"X-Nuclio-Target\":[\"openvino-omz-public-yolo-v3-tf\"]}} 23.05.11 22:14:17.788 nuctl.platform.invoker (I) Got response {\"status\": \"200 OK\"} 23.05.11 22:14:17.789 nuctl (I) \u003e\u003e\u003e Start of function logs 23.05.11 22:14:17.789 ino-omz-public-yolo-v3-tf (I) Run yolo-v3-tf model {\"worker_id\": \"0\", \"time\": 1683828857301.8765} 23.05.11 22:14:17.789 nuctl (I) \u003c\u003c\u003c End of function logs \u003e Response headers: Server = nuclio Date = Thu, 11 May 2023 18:14:17 GMT Content-Type = application/json Content-Length = 100 \u003e Response body: [ { \"confidence\": \"0.9992254\", \"label\": \"person\", \"points\": [ 39, 124, 408, 512 ], \"type\": \"rectangle\" } ] Run Cypress tests Install Cypress as described in the documentation. Run cypress tests: cd \u003ccvat_local_repository\u003e/tests \u003ccypress_installation_directory\u003e/node_modules/.bin/cypress run --headless --browser chrome For more information, see the documentation.\n","categories":"","description":"Deploying a DL model as a serverless function and Cypress tests.","excerpt":"Deploying a DL model as a serverless function and Cypress tests.","ref":"/v2.43.0/docs/contributing/setup-additional-components/","tags":"","title":"Setup additional components in development environment"},{"body":"Basic operations in the mode were described in section shape mode (basics).\nOccluded Occlusion is an attribute used if an object is occluded by another object or isn’t fully visible on the frame. Use Q shortcut to set the property quickly.\nExample: the three cars on the figure below should be labeled as occluded.\nIf a frame contains too many objects and it is difficult to annotate them due to many shapes placed mostly in the same place, it makes sense to lock them. Shapes for locked objects are transparent, and it is easy to annotate new objects. Besides, you can’t change previously annotated objects by accident. Shortcut: L.\n","categories":"","description":"Advanced operations available during annotation in shape mode.","excerpt":"Advanced operations available during annotation in shape mode.","ref":"/v2.43.0/docs/manual/advanced/shape-mode-advanced/","tags":"","title":"Shape mode (advanced)"},{"body":"The CVAT Single Shape annotation mode accelerates the annotation process and enhances workflow efficiency for specific scenarios.\nBy using this mode you can label objects with a chosen annotation shape and label when an image contains only a single object. By eliminating the necessity to select tools from the sidebar and facilitating quicker navigation between images without the reliance on hotkeys, this feature makes the annotation process significantly faster.\nSee:\nSingle Shape mode annotation interface Annotating in Single Shape mode Query parameters Video tutorial Single Shape mode annotation interface A set of controls in the interface of the Single Shape annotation mode may vary depending on different settings.\nImages below displays the complete interface, featuring all available fields; as mentioned above, certain fields may be absent depending on the scenario.\nFor instance, when annotating with rectangles, the Number of points field will not appear, and if annotating a single class, the Labels selector will be omitted.\nTo access Single Shape mode, open the job, navigate to the top right corner, and from the drop-down menu, select Single Shape.\nThe interface will be different if the shape type was set to Any in the label Constructor:\nThe Single Shape annotation mode has the following fields:\nFeature Explanation Prompt for Shape and Label Displays the selected shape and label for the annotation task, for example: “Annotate cat on the image using rectangle”. Skip Button Enables moving to the next frame without annotating the current one, particularly useful when the frame does not have anything to be annotated. List of Hints Offers guidance on using the interface effectively, including: - Click Skip for frames without required annotations. - Hold the Alt button to avoid unintentional drawing (e.g. when you want only move the image). - Use the Ctrl+Z combination to undo the last action if needed. - Use the Esc button to completely reset the current drawing progress. Label selector Allows for the selection of different labels (cat, or dog in our example) for annotation within the interface. Label type selector A drop-down list to select type of the label (rectangle, ellipse, etc). Only visible when the type of the shape is Any. Options to Enable or Disable Provides configurable options to streamline the annotation process, such as: - Automatically go to the next frame. - Automatically save when finish. - Navigate only empty frames. - Predefined number of points - Specific to polyshape annotations, enabling this option auto-completes a shape once a predefined number of points is reached. Otherwise, pressing N is required to finalize the shape. Number of Points Applicable for polyshape annotations, indicating the number of points to use for image annotation. Annotating in Single Shape mode To annotate in Single Shape mode, follow these steps:\nOpen the job and switch to Single Shape mode. Annotate the image based on the selected shape. For more information on shapes, see Annotation Tools. (Optional) If the image does not contain any objects to annotate, click Skip at the top of the right panel. Submit your work. Query parameters Also, we introduced additional query parameters, which you may append to the job link, to initialize the annotation process and automate workflow:\nQuery Parameter Possible Values Explanation defaultWorkspace Workspace identifier (e.g., single_shape, tags, review, attributes) Specifies the workspace to be used initially, streamlining the setup for different annotation tasks. defaultLabel A string representation of a label (label name) Sets a default label for the annotation session, facilitating consistency across similar tasks. defaultPointsCount Integer - number of points for polyshapes Defines a preset number of points for polyshape annotations, optimizing the annotation process. You can combine these parameters to customize the workspace for an annotator, for example:\n/tasks/\u003ctid\u003e/jobs/\u003cjid\u003e?defaultWorkspace=single_shape\u0026defaultLabel=dog\u0026defaultPointsCount=10 Will open the following job:\nVideo tutorial For a better understanding of how Single Shape mode operates, we recommend watching the following tutorial.\n","categories":"","description":"Guide to annotating tasks using Single Shape mode","excerpt":"Guide to annotating tasks using Single Shape mode","ref":"/v2.43.0/docs/manual/advanced/single-shape/","tags":"","title":"Single Shape"},{"body":" Note This is a paid feature available for Enterprise clients. You can now easily set up authentication with popular social services, which opens doors to such benefits as:\nConvenience: you can use the existing social service credentials to sign in to CVAT. Time-saving: with just two clicks, you can sign in without the hassle of typing in credentials, saving time and effort. Security: social auth service providers have high-level security measures in place to protect your accounts. Currently, we offer three options:\nAuthentication with Google Authentication with GitHub Authentication with Amazon Cognito With more to come soon. Stay tuned!\nAuthentication with Google To enable authentication, do the following:\nLog in to the Google Cloud console\nCreate a project, and go to APIs \u0026 Services\nOn the left menu, select OAuth consent, then select User type (Internal or External), and click Create.\nOn the OAuth consent screen fill all required fields, and click Save and Continue.\nOn the Scopes screen, click Add or remove scopes and select auth/userinfo.email, auth/userinfo.profile, and openid. Click Update, and Save and Continue. For more information, see Configure Auth Consent.\nOn the left menu, click Credentials, on the top menu click + Create credentials, and select OAuth client ID.\nFrom the Application Type select Web application and configure: Application name, Authorized JavaScript origins, Authorized redirect URIs. For example, if you plan to deploy CVAT instance on https://localhost:8080, add https://localhost:8080 to authorized JS origins and https://localhost:8080/api/auth/social/goolge/login/callback/ to redirect URIs.\nCreate configuration file in CVAT:\nCreate the auth_config.yml file with the following content:\n--- social_account: enabled: true google: client_id: \u003csome_client_id\u003e client_secret: \u003csome_client_secret\u003e Set AUTH_CONFIG_PATH=\"\u003cpath_to_auth_config\u003e environment variable.\nIn a terminal, run the following command:\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml -f docker-compose.override.yml up -d --build Authentication with GitHub There are 2 basic steps to enable GitHub account authentication.\nOpen the GitHub settings page.\nOn the left menu, click \u003c\u003e Developer settings \u003e OAuth Apps \u003e Register new application. For more information, see Creating an OAuth App\nFill in the name field, set the homepage URL (for example: https://localhost:8080), and authentication callback URL (for example: https://localhost:8080/api/auth/social/github/login/callback/).\nCreate configuration file in CVAT:\nCreate the auth_config.yml file with the following content:\n--- social_account: enabled: true github: client_id: \u003csome_client_id\u003e client_secret: \u003csome_client_secret\u003e Set AUTH_CONFIG_PATH=\"\u003cpath_to_auth_config\u003e environment variable.\nIn a terminal, run the following command:\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml -f docker-compose.override.yml up -d --build Note You can also configure GitHub App, but don’t forget to add required permissions. In the Permission \u003e Account permissions \u003e Email addresses must be set to read-only. Authentication with Amazon Cognito To enable authentication with Amazon Cognito for your CVAT instance, follow these steps:\nCreate an Amazon Cognito pool (Optional) Set up a new app client Configure social authentication in CVAT Now, let’s dive deeper into how to accomplish these steps.\nAmazon Cognito pool creation This step is optional and should only be performed if a user pool has not already been created. To create a user pool, follow these instructions:\nGo to the AWS Management Console Locate Cognito in the list of services Click Create user pool Fill in the required fields App client creation To create a new app client, follow these steps:\nGo to the details page of the created user pool Find the App clients item in the menu on the left Click Create app client Fill out the form as shown bellow: Application type: Traditional web application Application name: Specify a desired name, or leave the autogenerated one Return URL (optional): Specify the CVAT redirect URL (\u003chttp|https\u003e://\u003ccvat_domain\u003e/api/auth/social/amazon-cognito/login/callback/). This setting can also be updated or specified later after the app client is created. Navigate to the Login pages tab of the created app client Check the parameters in the Managed login pages configuration section and edit them if needed: Allowed callback URLs: Must be set to the CVAT redirect URL Identity providers: Must be specified OAuth grant types: The Authorization code grant must be selected OpenID Connect scopes: OpenID, Profile, Email scopes must be selected Setting up social authentication in CVAT To configure social authentication in CVAT, create a configuration file (auth_config.yml) with the following content:\n--- social_account: enabled: true amazon_cognito: client_id: \u003cclient_id\u003e client_secret: \u003cclient_secret\u003e domain: \u003ccustom-domain\u003e or https://\u003ccustom-cognito-prefix\u003e.auth.us-east-1.amazoncognito.com To find the client_id and client_secret values, navigate to the created app client page and check the App client information section. To find domain, look for the Domain item in the list on the left.\nOnce the configuration file is updated, several environment variables must be exported before running CVAT:\nexport AUTH_CONFIG_PATH=\"\u003cpath_to_auth_config\u003e\" export CVAT_HOST=\"\u003ccvat_host\u003e\" # cvat_port is optional export CVAT_BASE_URL=\"\u003chttp|https\u003e://${CVAT_HOST}:\u003ccvat_port\u003e\" Start the CVAT enterprise instance as usual. That’s it! On the CVAT login page, you should now see the option Continue with Amazon Cognito. ","categories":"","description":"Social accounts authentication for a Self-Hosted solution","excerpt":"Social accounts authentication for a Self-Hosted solution","ref":"/v2.43.0/docs/enterprise/social-accounts-configuration/","tags":"","title":"Social auth configuration"},{"body":" Note This is a paid feature available only to Enterprise clients. CVAT supports Single Sign-On (SSO) using both OpenID Connect (OIDC) and Security Assertion Markup Language (SAML) protocols.\nTo configure SSO, complete the following 2 main steps:\nConfigure the Identity Provider (IdP) — set up an application on your IdP platform. Update the CVAT configuration — provide the necessary identity provider settings in the CVAT configuration file. If the application is already configured, refer to the Configuring SSO in CVAT section. Otherwise, you may follow one of the detailed platform-specific guides to set up such an application:\nMicrosoft Azure Okta Auth0 keycloak Platform specific IdP configuration Microsoft Azure OpenID Connect Follow these steps to configure an application on the Microsoft Azure platform and integrate it with CVAT:\nStep 1: Register an OIDC-based application To start, log into your Microsoft Azure Portal. Once you’re in:\nNavigate to the Microsoft Entra ID service -\u003e App registrations section in the menu on the left.\nClick on the + New registration button.\nEnter application name.\nSelect Supported account types based on your needs.\nAdd Redirect URI: choose Web platform and set \u003cscheme:cvat_domain\u003e/api/auth/oidc/\u003cidp-id:azure-oidc\u003e/login/callback/ to the value field.\nClick on the Register button.\nNote More information on how to configure an OIDC-based application on the Azure platform can be found here. You’ve created an app, now you should configure the credentials for it.\nStep 2: Configure credentials Navigate to the Overview tab of your newly created application. In the Client credentials section, click the Add a certificate or secret link. This will take you to the Certificates \u0026 secrets page. Click + New client secret. In the popup form, enter a description and select an expiration period, then click Add. The newly created secret will appear in the list. Make sure to copy the value now — you won’t be able to see it again later. Step 3: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:azure-oidc\u003e protocol: OIDC name: Azure OIDC-based IdP server_url: https://\u003cDirectory (tenant) ID\u003e/v2.0/ client_id: \u003cSecret ID\u003e client_secret: \u003cSecret Value\u003e email_domain: \u003ccompany_email_domain\u003e Tip Actual Secret ID and Secret Value values may be found on Certificates \u0026 secrets tab of the application, while Directory (tenant) ID - on the Overview tab. You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nSAML Follow these steps to configure an application on the Microsoft Azure platform and integrate it with CVAT:\nStep 1: Register an SAML-based application To start, log into your Microsoft Azure Portal. Once you’re in:\nNavigate to the Microsoft Entra ID service -\u003e Enterprise applications section in the menu on the left. Click + New application and enter a name for the application in the popup window, then click Create. You’ve created an app, now you should finalize its configuration and assign users or groups.\nStep 2: Configure a created application Navigate to the Single sign-on section in the menu on the left. Choose the SAML protocol as the single sign-on method. Edit Basic SAML Configuration: Identifier (Entity ID): \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:azure-saml\u003e/metadata/ Reply URL (Assertion Consumer Service URL): \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:azure-saml\u003e/acs/ Save changes Edit Attributes \u0026 Claims by adding a new uid claim: Name: uid Namespace: http://schemas.xmlsoap.org/ws/2005/05/identity/claims Source: attribute Source attribute: user.objectid Note More information on how to configure an application on Azure platform can be found here. Step 3: Assign users and groups At this point, no users or groups have been assigned to the application. To grant access:\nNavigate to the Users and groups section of the application. Click the + Add user/group button. Select the users or groups you want to assign. Confirm selection. The selected users or groups will now appear in the assignment list.\nThat’s it, now we can move on to the configuration in CVAT.\nStep 4: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:azure-saml\u003e protocol: SAML name: Azure SAML-based IdP entity_id: \u003cMicrosoft Entra Identifier\u003e (https://sts.windows.net/\u003ctenantId\u003e/) metadata_url: \u003cApp Federation Metadata Url\u003e attribute_mapping: uid: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/uid username: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier email: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress first_name: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname last_name: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname # email_verified: it is not possible to configure SAML-based application to send this claim to the SP email_domain: \u003ccompany_email_domain\u003e Tip Actual Microsoft Entra Identifier and App Federation Metadata Url values may be found on the Single sign-on tab of the created application\nYou can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nOkta OpenID Connect Follow these steps to configure an application on the Okta platform and integrate it with CVAT:\nStep 1: Register an OIDC-based application To start, log into your Okta admin dashboard. Once you’re in:\nNavigate to the Applications section in the menu on the left.\nClick on the Create App integration button.\nSelect OIDC - OpenID Connect as a sign-in method and Web Application type. Fill the form with the following content:\nApp integration name: enter a name for the application Sign-in redirect URIs: \u003cscheme:cvat_domain\u003e/api/auth/oidc/\u003cidp-id:okta-oidc\u003e/login/callback/ Select option in the Controlled access to match your requirements. In this example, we’ll use Skip group assignment for now. Note More information on how to configure an OIDC-based application on the Okta platform can be found here. You’ve created and configured the app, now you should assign users or groups to the application.\nStep 2: Assign users or groups At this point, no users or groups have been assigned to the application. To grant access:\nNavigate to the Assignments tab of the application. Click the Assign button and select Assign to People or Assign to Groups based on your needs. Identify the users or groups you want to assign, then click assign. The selected users or groups will now appear in the assignment list. Step 3: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:okta-oidc\u003e protocol: OIDC name: Okta OIDC-based IdP server_url: https://\u003cokta_domain\u003e/ client_id: \u003cclient_id\u003e client_secret: \u003cclient_secret\u003e email_domain: \u003ccompany_email_domain\u003e Tip Actual Client ID and Client secret key values may be found on the General tab of the created application You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nSAML Follow these steps to configure an application on the Okta platform and integrate it with CVAT:\nStep 1: Register an SAML-based application To start, log into your Okta admin dashboard. Once you’re in:\nNavigate to the Applications section in the menu on the left.\nClick on the Create App integration button.\nSelect SAML 2.0 as a sign-in method, then click Next. Fill the form with the general settings and go to the next configuration step.\nOn the Configure SAML form set the following fields:\nSingle sign-on URL: \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:okta-saml\u003e/acs/ Audience URI (SP Entity ID: \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:okta-saml\u003e/metadata/ Define attribute statements that will be shared with CVAT. In our example we will use the Basic attribute name format and set the mapping as shown below:\nfirstName: user.firstName lastName: user.lastName username: user.login email: user.email uid: user.getInternalProperty(\"id\") Tip If attribute mapping needs to be adapted, follow the official documentation on how to configure Attribute Statements Navigate to the next configuration step and fill the Feedback form.\nYou’ve created and configured the app. You can now either complete an optional step to simplify the login process in CVAT or proceed directly to the CVAT configuration step.\nStep 2: Simplify login process If CVAT is configured to require email verification, it expects the Identity Provider to include the email_verified claim. However, Okta does not send this claim by default. As a result, users will receive a confirmation email with a verification link.\nThere is an option to include email verification claim on the sign-in step:\nAdd one more mapping emailVerified -\u003e user.emailVerified on SAML-based application configuration step: Navigate to the SAML Settings on the General tab and click Edit. Add one more attribute mapping as it was described in the app configuration step. Add custom user attribute emailVerified: Navigate to the Directory section in the menu on the left -\u003e Profile Editor item Select the default user profile from the list (User (default)) Click + Add Attribute Fill out the form with your desired values, making sure to select the boolean data type Click Save Update user profiles: Navigate to the People section in the menu on the left Set the value for the recently created attribute for each person Step 3: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:okta-saml\u003e protocol: SAML name: Okta SAML-based Identity Provider entity_id: \u003cIssuer\u003e metadata_url: \u003cMetadata URL\u003e attribute_mapping: uid: uid username: username email: email first_name: firstName last_name: lastName email_verified: emailVerified # if configured email_domain: \u003ccompany_email_domain\u003e Tip Metadata URL and Issuer values may be found on the Sign On tab of the application setting You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nAuth0 OpenID Connect Follow these steps to configure an application in the Auth0 platform and integrate it with CVAT:\nStep 1: Register an OIDC-based application To start, log into your Auth0 dashboard. Once you’re in:\nNavigate to the Applications section in the menu on the left, click + Create Application. Enter a name for the application and choose the Regular Web Applications type, then click Create. You’ve created an app, now you should finalize its configuration.\nStep 2: Configure a created application In the Settings tab of your new application, scroll down to the Application URIs section. Add \u003cscheme:cvat_domain\u003e/api/auth/oidc/\u003cidp-id:auth0-oidc\u003e/login/callback/ to the Allowed Callback URLs. Save changes. That’s it, now we can move on to the configuration in CVAT.\nStep 3: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:auth0-oidc\u003e protocol: OIDC name: Auth0 OIDC-based IdP server_url: https://\u003cauth0_domain\u003e/ client_id: \u003cclient_id\u003e client_secret: \u003cclient_secret\u003e email_domain: \u003ccompany_email_domain\u003e Tip Client ID, Client Secret and Domain can be found in the Basic Information section of application settings You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nSAML Follow these steps to configure an application in the Auth0 platform and integrate it with CVAT:\nStep 1: Register an SAML-based application To start, log into your Auth0 dashboard. Once you’re in:\nNavigate to the Applications section in the menu on the left, click + Create Application. Enter a name for the application and choose the Regular Web Applications type, then click Create. You’ve created an app, now you should finalize its configuration.\nStep 2: Configure a created application Navigate to the Addons tab of the created application and click on the SAML2 WEB APP button. Open the Settings tab in the popup window and set the following configuration: Application Callback URL: \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:auth0-saml\u003e/acs/ Settings: enter a JSON object like the following: { \"audience\": \"\u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:auth0-saml\u003e/metadata/\", \"recipient\": \"\u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:auth0-saml\u003e/acs/\", \"destination\": \"\u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:auth0-saml\u003e/acs/\", \"mappings\": { \"user_id\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier\", \"email\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress\", \"nickname\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/username\", \"given_name\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname\", \"family_name\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname\", \"email_verified\": \"http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailverified\" }, \"createUpnClaim\": false, \"passthroughClaimsWithNoMapping\": false, \"mapIdentities\": false } Scroll down and click Enable.\nNote More information on how to configure an application on Auth0 platform can be found here. That’s it, now we can move on to the configuration in CVAT.\nStep 3: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:auth0-saml\u003e protocol: SAML name: Auth0 SAML-based IdP entity_id: \u003cIssuer\u003e metadata_url: \u003cMetadata URL\u003e attribute_mapping: uid: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/nameidentifier username: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/username email: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress first_name: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/givenname last_name: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/surname email_verified: http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailverified email_domain: \u003ccompany_email_domain\u003e Tip Actual Metadata URL and Issuer values may be found on the Usage tab of the SAML2 Web App plugin You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nKeycloak To configure SSO in terms of Keycloak we need to create a client.\nOpenID Connect Follow these steps to do that:\nStep 1: Register an OIDC-based client To start, go to the Keycloak service (by default it is listening for HTTP and HTTPS requests using the ports 8080 and 8443, respectively) and log into your admin account. Once you’re in:\nUnder the desired realm navigate to the Clients section and click create client. Fill out the general client settings: Client type: OpenID Connect Client ID: enter client identifier Enter a name for the client, e.g. OIDC-based client In the next step, enable the Client authentication toggle. In the Login settings section, provide the following values: Home URL: \u003cscheme:cvat_domain\u003e Valid redirect URIs: \u003cscheme:cvat_domain\u003e/api/auth/oidc/\u003cidp-id:keycloak-oidc\u003e/login/callback/ Web origins: \u003cscheme:cvat_domain\u003e That’s it, now we can move on to the configuration in CVAT.\nStep 2: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:keycloak-oidc\u003e protocol: OIDC name: Keycloak OIDC-based Identity Provider server_url: \u003cscheme:keycloak_domain\u003e/realms/\u003ccustom_realm\u003e/.well-known/openid-configuration client_id: \u003cClient ID\u003e client_secret: \u003cClient Secret\u003e email_domain: \u003ccompany_email_domain\u003e Tip Actual Client Secret value can be found on the Credentials tab of the created OIDC client You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nSAML Follow these steps to configure a client:\nStep 1: Register a SAML-based client To start, go to the Keycloak service (by default it is listening for HTTP and HTTPS requests using the ports 8080 and 8443, respectively) and log into your admin account. Once you’re in:\nUnder the desired realm navigate to the Clients section and click create client. Fill out the general client settings: Client type: SAML Set the Clint ID the URL: \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:keycloak-saml\u003e/metadata/ Enter a name for the client, e.g. SAML client In the Login settings section, provide the following values: Home URL: \u003cscheme:cvat_domain\u003e Valid redirect URIs: \u003cscheme:cvat_domain\u003e/api/auth/saml/\u003cidp-id:keycloak-saml\u003e/acs/ You’ve created a client, now you should finalize its configuration.\nStep 2: Configure a created client Navigate to the general settings of the created client, scroll down to the SAML capabilities section. Update the following parameters: Name ID format: email Force name ID format: On Navigate to the Keys tab and enable the Client signature required toggle. Configure attributes \u0026 claims: Navigate to the Client scopes tab on the created client -\u003e dedicated scopes for the client. You will see that there is no configured mappers. Set up mappers for the following attributes:\nuid first_name last_name username email For attributes like email, first name, and last name, you can either\nUse the predefined mappers Or follow the manual configuration steps to create them yourself. To configure other mappers click Configure a new mapper if it is a first mapper or Add mapper -\u003e By configuration and then select User Property.\nFor instance, to configure a mapper for the username attribute, fill in the form as it is done below: Name: username Property: username SAML Attribute Name: usernameAttribute That’s it, now we can move on to the configuration in CVAT.\nStep 3: Configure CVAT Utilize the example below as a template for your configuration:\nsso: enabled: true selection_mode: email_address identity_providers: - id: \u003cidp-id:keycloak-saml\u003e protocol: SAML name: Keycloak SAML-based Identity Provider entity_id: \u003cscheme:keycloak_domain\u003e/realms/\u003ccustom_realm\u003e metadata_url: \u003cscheme:keycloak_domain\u003e/realms/\u003ccustom_realm\u003e/protocol/saml/descriptor attribute_mapping: uid: uidAttribute email_verified: emailVerifiedAttribute email: emailAttribute last_name: lastNameAttribute first_name: firstNameAttribute username: usernameAttribute email_domain: \u003ccompany_email_domain\u003e Tip Actual Metadata URL may be found in the Realm settings on the General tab You can now proceed to start CVAT. For additional CVAT configuration details, refer to Configuring SSO in CVAT.\nConfiguring SSO in CVAT CVAT provides a dedicated configuration file to customize the login and registration flow. The sso section of this file specifies which external Identity Provider (IdP) integrations are enabled. To set up SSO, you typically create a custom YAML configuration file (e.g., auth_config.yml) and supply its path when starting CVAT.\nSSO settings Setting Description enabled Enables or disables Single Sign-On (SSO) functionality. selection_mode Defines how the Identity Provider (IdP) is selected for authenticating a given user.\nAvailable modes:\nemail_address (default): Selects the IdP based on the domain of the user’s email address.lowest_weight: Selects the IdP with the lowest configured weight. enable_pkce Controls whether Proof Key for Code Exchange (PKCE) is enabled for the authentication flow (disabled by default). This setting applies to all configured OIDC-based Identity Providers --- sso: enabled: true|false selection_mode: email_address|lowest_weight enable_pkce: true|false ... IdP Configuration Structure To integrate an Identity Provider, you must define its configuration block under the identity_providers section in the CVAT config file. Each provider’s configuration includes both general and protocol-specific settings.\nSetting Required Description id required A unique, URL-safe identifier for the IdP. Used in callback URLs. name required A human-readable name for the IdP. protocol required Authentication protocol (OIDC/SAML). email_domain optional Company email domain (used with email_address selection mode). weight optional Determines priority (used with lowest_weight selection mode). The default is 10. Additionally, each IdP configuration must include several protocol-specific parameters: OpenID Connect SAML client_id and client_secret (required): These values can be obtained from the configuration page of the specific provider.\nserver_url (required): URL is used to obtain IdP OpenID Configuration Metadata.\nNOTE: How to check server_url correctness: server_url + /.well-known/openid-configuration API should exist and return OpenID Provider Metadata. Generally, each authentication platform provides a list of all endpoints. You need to find the corresponding endpoint and select the part in front of /.well-known/openid-configuration. For example, in the case of integrating an OIDC Microsoft Entry ID application, don’t forget to specify the second version of API (https://login.microsoftonline.com/\u003ctenant_id\u003e/v2.0).\ntoken_auth_method (optional): Token endpoint authentication method which can be one of client_secret_basic, client_secret_post. If this field is omitted, a method from the server’s token auth methods list will be used.\nentity_id (required): IdP entity ID, should be equal to the corresponding setting in the IdP configuration. metadata_url (optional): SAML metadata URL. This can typically be found on the IdP configuration page. x509_cert (optional): The SAML X.509 certificate. Also could be found in the IdP’s configuration. If the metadata_url is not specified, this parameter becomes required. sso_url (optional): SAML endpoint for the Single Sign-On service. Also could be found in the IdP’s configuration. If the metadata_url is not specified, this parameter becomes required. attribute_mapping (required): A mapping between user account attributes and attributes sent by the Identity Provider. Below are examples of SSO configuration file for both protocols: Integrate OIDC-based IdP Integrate SAML-based IdP --- sso: enabled: true selection_mode: email_address identity_providers: - id: oidc-idp protocol: OIDC name: OIDC-based IdP server_url: https://example.com client_id: xxx client_secret: xxx email_domain: example.com --- sso: enabled: true selection_mode: lowest_weight identity_providers: - id: saml-idp protocol: SAML name: SAML-based IdP entity_id: \u003cidp-entity-id\u003e weight: 1 # specify only metadata_url or sso_url and x509_cert metadata_url: http://example.com/path/to/saml/metadata/ sso_url: \u003cLogin URL\u003e x509_cert: | -----BEGIN CERTIFICATE----- certificate content -----END CERTIFICATE----- attribute_mapping: uid: uidAttribute email_verified: emailVerifiedAttribute email: emailAttribute last_name: lastNameAttribute first_name: firstNameAttribute username: usernameAttribute More information about OIDC-based and SAML-based IdP configuration expected by Django Allauth can be found here and here respectively.\nStart CVAT Restart required If CVAT is already running, don’t forget to restart the containers to apply the SSO configuration Once the configuration file is created, several environment variables must be exported before running CVAT:\nexport AUTH_CONFIG_PATH=\"\u003cpath_to_auth_config\u003e\" export CVAT_HOST=\"\u003ccvat_host\u003e\" # cvat_port is optional export CVAT_BASE_URL=\"\u003chttp|https\u003e://${CVAT_HOST}:\u003ccvat_port\u003e\" Start the CVAT Enterprise instance as usual.\nThat’s it! The CVAT login page now should have the Continue with SSO option, allowing users to authenticate using the configured Identity Provider.\n","categories":"","description":"SSO for a Self-Hosted solution","excerpt":"SSO for a Self-Hosted solution","ref":"/v2.43.0/docs/enterprise/sso/","tags":"","title":"SSO configuration"},{"body":"There are two ways of deploying the CVAT.\nOn Nvidia GPU Machine: Tensorflow annotation feature is dependent on GPU hardware. One of the easy ways to launch CVAT with the tf-annotation app is to use AWS P3 instances, which provides the NVIDIA GPU. Read more about P3 instances here. Overall setup instruction is explained in main readme file, except Installing Nvidia drivers. So we need to download the drivers and install it. For Amazon P3 instances, download the Nvidia Drivers from Nvidia website. For more check Installing the NVIDIA Driver on Linux Instances link.\nOn Any other AWS Machine: We can follow the same instruction guide mentioned in the installation instructions. The additional step is to add a security group and rule to allow incoming connections.\nFor any of above, don’t forget to set the CVAT_HOST environment variable to the exposed AWS public IP address or hostname:\nexport CVAT_HOST=your-instance.amazonaws.com In case of problems with using hostname, you can also use the public IPV4 instead of hostname. For AWS or any cloud based machines where the instances need to be terminated or stopped, the public IPV4 and hostname changes with every stop and reboot. To address this efficiently, avoid using spot instances that cannot be stopped, since copying the EBS to an AMI and restarting it throws problems. On the other hand, when a regular instance is stopped and restarted, the new hostname/IPV4 can be used to set the CVAT_HOST environment variable.\n","categories":"","description":"Instructions for deploying CVAT on Nvidia GPU and other AWS machines.","excerpt":"Instructions for deploying CVAT on Nvidia GPU and other AWS machines.","ref":"/v2.43.0/docs/administration/basics/aws-deployment-guide/","tags":"","title":"AWS-Deployment Guide"},{"body":"Overview A simple command line interface for working with CVAT. At the moment it implements a basic feature set but may serve as the starting point for a more comprehensive CVAT administration tool in the future.\nThe following subcommands are supported:\nProjects:\ncreate - create a new project delete - delete projects ls - list all projects Tasks:\ncreate - create a new task create-from-backup - create a task from a backup file delete - delete tasks ls - list all tasks frames - download frames from a task export-dataset - export a task as a dataset import-dataset - import annotations into a task from a dataset backup - back up a task auto-annotate - automatically annotate a task using a local function Functions (Enterprise/Cloud only):\ncreate-native - create a function that can be powered by an agent delete - delete a function run-agent - process requests for a native function Installation To install an official release of CVAT CLI, use this command:\npip install cvat-cli We support Python versions 3.9 and higher.\nUsage The general form of a CLI command is:\n$ cvat-cli \u003ccommon options\u003e \u003cresource\u003e \u003caction\u003e \u003coptions\u003e where:\n\u003ccommon options\u003e are options shared between all subcommands; \u003cresource\u003e is a CVAT resource, such as task; \u003caction\u003e is the action to do with the resource, such as create; \u003coptions\u003e is any options specific to a particular resource and action. You can list available subcommands and options using the --help option:\n$ cvat-cli --help # get help on available common options and resources $ cvat-cli \u003cresource\u003e --help # get help on actions for the given resource $ cvat-cli \u003cresource\u003e \u003caction\u003e --help # get help on action-specific options The CLI implements alias subcommands for some task actions, so that, for example, cvat-cli ls works the same way as cvat-cli task ls. These aliases are provided for backwards compatibility and are deprecated. Use the task \u003caction\u003e form instead.\nExamples - tasks Create Description of the options you can find in Creating an annotation task section.\nFor create a task you need file contain labels in the json format, you can create a JSON label specification by using the label constructor.\nExample JSON labels file [ { \"name\": \"cat\", \"attributes\": [] }, { \"name\": \"dog\", \"attributes\": [] } ] Create a task named “new task” on the default server http://localhost, labels from the file “labels.json” and local images “file1.jpg” and “file2.jpg”, the task will be created as current user: cvat-cli task create \"new task\" --labels labels.json local file1.jpg file2.jpg Create a task named “task 1” on the server https://example.com labels from the file “labels.json” and local image “image1.jpg”, the task will be created as user “user-1”: cvat-cli --server-host https://example.com --auth user-1 task create \"task 1\" \\ --labels labels.json local image1.jpg Create a task named “task 1” on the default server, with labels from “labels.json” and local image “file1.jpg”, as the current user, in organization “myorg”: cvat-cli --org myorg task create \"task 1\" --labels labels.json local file1.jpg Create a task named “task 1”, labels from the project with id 1 and with a remote video file, the task will be created as user “user-1”: cvat-cli --auth user-1:password task create \"task 1\" --project_id 1 \\ remote https://github.com/opencv/opencv/blob/master/samples/data/vtest.avi?raw=true Create a task named “task 1 sort random”, with labels “cat” and “dog”, with chunk size 8, with sorting-method random, frame step 10, copy the data on the CVAT server, with use zip chunks and the video file will be taken from the shared resource: cvat-cli task create \"task 1 sort random\" --labels '[{\"name\": \"cat\"},{\"name\": \"dog\"}]' --chunk_size 8 \\ --sorting-method random --frame_step 10 --copy_data --use_zip_chunks share //share/dataset_1/video.avi Create a task named “task from dataset_1”, labels from the file “labels.json”, with link to bug tracker, image quality will be reduced to 75, annotation in the format “CVAT 1.1” will be taken from the file “annotation.xml”, the data will be loaded from “dataset_1/images/”, the task will be created as user “user-2”, and the password will need to be entered additionally: cvat-cli --auth user-2 task create \"task from dataset_1\" --labels labels.json \\ --bug_tracker https://bug-tracker.com/0001 --image_quality 75 --annotation_path annotation.xml \\ --annotation_format \"CVAT 1.1\" local dataset_1/images/ Create a task named “segmented task 1”, labels from the file “labels.json”, with overlay size 5, segment size 100, with frames 5 through 705, using cache and with a remote video file: cvat-cli task create \"segmented task 1\" --labels labels.json --overlap 5 --segment_size 100 \\ --start_frame 5 --stop_frame 705 --use_cache \\ remote https://github.com/opencv/opencv/blob/master/samples/data/vtest.avi?raw=true Create a task named “task with filtered cloud storage data”, with filename_pattern test_images/*.jpeg and using the data from the cloud storage resource described in the manifest.jsonl: cvat-cli task create \"task with filtered cloud storage data\" --labels '[{\"name\": \"car\"}]'\\ --use_cache --cloud_storage_id 1 --filename_pattern \"test_images/*.jpeg\" share manifest.jsonl Create a task named “task with filtered cloud storage data” using all data from the cloud storage resource described in the manifest.jsonl by specifying filename_pattern *: cvat-cli task create \"task with filtered cloud storage data\" --labels '[{\"name\": \"car\"}]'\\ --use_cache --cloud_storage_id 1 --filename_pattern \"*\" share manifest.jsonl Delete Delete tasks with IDs “100”, “101”, “102” , the command will be executed from “user-1” having delete permissions: cvat-cli --auth user-1:password task delete 100 101 102 List List all tasks: cvat-cli task ls List all tasks in organization “myorg”: cvat-cli --org myorg task ls Save list of all tasks into file “list_of_tasks.json”: cvat-cli task ls --json \u003e list_of_tasks.json Frames Save frame 12, 15, 22 from task with id 119, into “images” folder with compressed quality: cvat-cli task frames --outdir images --quality compressed 119 12 15 22 Export as a dataset Export annotation task with id 103, in the format CVAT for images 1.1 and save to the file “output.zip”: cvat-cli task export-dataset --format \"CVAT for images 1.1\" 103 output.zip Export annotation task with id 104, in the format COCO 1.0 and save to the file “output.zip”: cvat-cli task export-dataset --format \"COCO 1.0\" 104 output.zip Import annotations from a dataset Import annotation into task with id 105, in the format CVAT 1.1 from the file “annotation.xml”: cvat-cli task import-dataset --format \"CVAT 1.1\" 105 annotation.xml Back up a task Back up task with id 136 to file “task_136.zip”: cvat-cli task backup 136 task_136.zip Create from backup Create a task from backup file “task_backup.zip”: cvat-cli task create-from-backup task_backup.zip Auto-annotate This command provides a command-line interface to the auto-annotation API.\nIt can auto-annotate using AA functions implemented in one of the following ways:\nAs a Python module directly implementing the AA function protocol. Such a module must define the required attributes at the module level.\nFor example:\nimport cvat_sdk.auto_annotation as cvataa spec = cvataa.DetectionFunctionSpec(...) def detect(context, image): ... As a Python module implementing a factory function named create. This function must return an object implementing the AA function protocol. Any parameters specified on the command line using the -p option will be passed to create.\nFor example:\nimport cvat_sdk.auto_annotation as cvataa class _MyFunction: def __init__(...): ... spec = cvataa.DetectionFunctionSpec(...) def detect(context, image): ... def create(...) -\u003e cvataa.DetectionFunction: return _MyFunction(...) Annotate the task with id 137 with the predefined torchvision detection function, which is parameterized:\ncvat-cli task auto-annotate 137 --function-module cvat_sdk.auto_annotation.functions.torchvision_detection \\ -p model_name=str:fasterrcnn_resnet50_fpn_v2 -p box_score_thresh=float:0.5 Annotate the task with id 138 with an AA function defined in my_func.py:\ncvat-cli task auto-annotate 138 --function-file path/to/my_func.py Note that this command does not modify the Python module search path. If your function module needs to import other local modules, you must add your module directory to the search path if it isn’t there already.\nAnnotate the task with id 139 with a function defined in the my_func module located in the my-project directory, letting it import other modules from that directory. PYTHONPATH=path/to/my-project cvat-cli task auto-annotate 139 --function-module my_func Examples - projects Create While creating a project, you may optionally define its labels. The project create command accepts labels in the same format as the task create command; see that command’s examples for more information.\nCreate a project named “new project” on the default server http://localhost, with labels from the file “labels.json”: cvat-cli project create \"new project\" --labels labels.json Create a project from a dataset in the COCO format: cvat-cli project create \"new project\" --dataset_file coco.zip --dataset_format \"COCO 1.0\" Delete Delete projects with IDs “100”, “101”, “102”: cvat-cli project delete 100 101 102 List List all projects: cvat-cli project ls Save list of all projects into file “list_of_projects.json”: cvat-cli project ls --json \u003e list_of_projects.json Examples - functions Note: The functionality described in this section can only be used with the CVAT Enterprise or CVAT Cloud.\nCreate Create a function that uses a detection model from torchvision and run an agent for it:\ncvat-cli function create-native \"Faster R-CNN\" \\ --function-module cvat_sdk.auto_annotation.functions.torchvision_detection \\ -p model_name=str:fasterrcnn_resnet50_fpn_v2 cvat-cli function run-agent \u003cID printed by previous command\u003e \\ --function-module cvat_sdk.auto_annotation.functions.torchvision_detection \\ -p model_name=str:fasterrcnn_resnet50_fpn_v2 These commands accept functions that implement the auto-annotation function interface from the SDK, same as the task auto-annotate command. See that command’s examples for information on how to implement these functions and specify them in the command line.\nDelete Delete functions with IDs 100 and 101: cvat-cli function delete 100 101 ","categories":"","description":"","excerpt":"Overview A simple command line interface for working with CVAT. At the …","ref":"/v2.43.0/docs/api_sdk/cli/","tags":"","title":"Command line interface (CLI)"},{"body":"We use the Airbnb JavaScript Style Guide for JavaScript/TypeScript code with a little exception - we prefer 4 spaces for indentation of nested blocks and statements.\nFor Python, we use Black and isort to enforce the coding style and autoformat files. You can use dev/format_python_code.sh to apply these formatters.\n","categories":"","description":"Information about coding style that is used in CVAT development.","excerpt":"Information about coding style that is used in CVAT development.","ref":"/v2.43.0/docs/contributing/coding-style/","tags":"","title":"Coding style"},{"body":"With CVAT you can annotate the same data several times and then merge annotations automatically to obtain more reliable annotations.\nNote Consensus merging only supports 2D tasks. It supports all annotation types except cuboids. Note Consensus merging is currently available only for tasks and jobs. Projects are not supported. CVAT has the following features related to consensus-based annotation:\nCreation of consensus replica jobs for regular annotation jobs in a task Automatic merging for annotations inside consensus replica jobs Basics If you want to improve the quality of your annotations, there are several widespread ways to achieve this. One of the methods is called consensus-based annotation or just consensus. In this method, the same data is annotated several times. Once there are several different annotations (“opinions”) for the same objects, they can be merged in order to obtain annotations of higher quality.\nLet’s consider an explanatory example. Imagine there is a group of people and you want to learn whether something is true or not from them. To accomplish this, you decided to ask everyone and pick the most popular answer in the end. With such an idea, you can get many possible combinations of votes, including unanimous ones. This strategy is called majority voting - and it requires such a majority to exist. If there is an even number of votes for both options, you don’t have enough information to prefer one of the options to the other, so, in general, it’s desirable to have an odd number of people in the group. With larger groups the method becomes less sensitive to this requirement, as when the voters are independent and the question is meaningful, the answers are less likely to separate evenly between the possible options. This method can also be used if the question has more than 2 possible answers. In this case, there are more possible distributions of the votes, but the same logic can be applied.\nReturning back to datasets, consensus annotation works very similar to the example above. Each image is annotated several times, typically by different persons, then the resulting annotations are compared between each other and merged, using majority voting or a different strategy. The key advantage of consensus annotation is that it helps to reduce personal annotator bias in annotation. This improves the quality of annotation by filtering out errors, noise (variance) and outliers in the annotation, leaving only the most representative ones.\nDatasets, typically, have a large number of images and objects. This method of annotation requires several different annotations for the whole dataset, so it is expected to have several times of the annotation costs compared to the simple single-annotation approach. Depending on the annotation resources available, budget, and requirements, consensus annotation may or may not be feasible in a particular task.\nOne application for this approach that can be recommended is Ground Truth annotation. This type of annotation typically requires especially high quality annotations, because it is used to validate model or annotator answers. Ground Truth is typically limited only to a small portion of the whole dataset images, for example 3%. If a 3- or 5-fold consensus is applied to GT annotations, it is possible to obtain more reliable GT annotations for 10-15% of the full dataset annotation cost. Once there is such a reliable GT dataset, it can be used for annotator validation, on the remaining dataset ensuring the quality metrics are representative and objective.\nConsensus replica jobs A Consensus Replica job (replica) is the way to represent one of the annotator “opinions” in CVAT. Consensus replicas work similarly to regular annotation jobs - they can be assigned, annotated, imported and exported. When you decide to merge annotations from replicas, the results will be written to the parent annotation job.\nKey properties of consensus replica jobs:\nReplicas are connected to annotation jobs. Each annotation job can have several related replicas. Only annotation jobs can have replicas. Ground Truth jobs cannot have replicas. Replicas use the same frame range as their parent annotation jobs. Annotations in replicas and parent jobs are independent from each other. Modifying a replica doesn’t affect the parent job or other replicas and vice versa. Removing annotations in a parent job doesn’t change annotations in its replicas. Replicas are not included in task annotation import or export. Per-job import and export still work for all job types, including replicas. Read more about merging here.\nWorkflow When annotating with consensus, the typical workflow looks this way:\nCreate a task with consensus enabled. Optionally, configure validation Assign annotators to consensus replicas, wait until all the jobs are completed Once all replicas in a parent job are completed, merge annotations Review and resolve problems in the parent jobs How to enable consensus in a task Consensus annotation is configured at the Task level. It can only be specified at task creation. If you want to enable consensus for one of your existing tasks, you’ll need to recreate the task.\nGo to the task creation page Configure basic and advanced parameters according to your requirements, and attach a dataset to be annotated. To enable consensus for the task, open the Advanced section and set Consensus Replicas to a value greater than 1. Create the task and open the task page If a task has consensus enabled, you’ll see the Consensus tag in the task summary. Existing Consensus replica jobs will be displayed in the job list under their parent annotation jobs.\nMerging For a given parent job with related annotated consensus jobs, merging will match annotations between the replicas and save merged annotations into the parent job.\nPlease note that merging overrides annotations in the parent job. This operation cannot be undone. Please make sure that the parent job is ready for merging and backup annotations if needed.\nThere are 2 merging options available:\nmerge replicas in all available parent jobs in a task merge replicas in a specific parent job Merging is only available for a parent job if it is in the annotation stage and it has at least 1 replica not in the annotation - new stage and state. For simplicity, this can be read as “if there are any annotated replicas in the parent job”.\nAfter merging, parent jobs are switched to the completed state automatically. If you prefer merging at the task level, it is recommended to switch merged parent jobs to the validation stage after they are merged to exclude them from the next merging and avoid losing the reviewed annotations.\nHow to merge all replicas in a task Open the task Actions menu Click Merge consensus jobs Click Merge in the dialog window The operation can take some time to be completed. Once it is completed, you will receive a status notification in the top right corner.\nHow to merge replicas in a specific parent job Open the job Actions menu Click Merge consensus job Click Merge in the dialog window The operation can take some time to be completed. Once it is completed, you will receive a status notification in the top right corner.\nConfiguration Merging settings If you want to tweak some aspects of merging, you can do this on the Consensus Management page. It is available in the task Actions menu. Hover over the ? marks to understand what each field represents.\nAfter you set values for the parameters, click the Save button. The updated settings will take effect on the next merging.\nThe following parameters are available:\nParameter Description General Quorum The minimum percentage of replicas that must contain an annotation for it to be included in the results. The number is rounded up to get the job count. For instance, if there are 5 replicas in a parent job and quorum is 70%, an annotation will be included in the results only if it has ceil(5 * 0.7) = 4 votes from replicas. Shape matching Min overlap Min overlap threshold used for the distinction between matched and unmatched annotations. Used to match all types of annotations. It corresponds to the Intersection over union (IoU) for spatial annotations, such as bounding boxes and masks. Read more about annotation matching here. Keep in mind that quality settings do not affect consensus merging. ","categories":"","description":"Annotate the same data several times to get better annotations","excerpt":"Annotate the same data several times to get better annotations","ref":"/v2.43.0/docs/manual/advanced/analytics-and-monitoring/consensus/","tags":"","title":"Consensus-based annotation"},{"body":"CVAT offers two distinct types of roles:\nGlobal Roles: These are universal roles that apply to the entire system. Anyone who logs into the CVAT platform is automatically assigned a global role. It sets the basic permissions that every registered user has across CVAT, regardless of their specific tasks or responsibilities. Organization Roles: These roles determine what a user can do within the Organization, allowing for more tailored access based on the user’s specific duties and responsibilities. Organization roles complement global roles by determining the visibility of different resources for example, tasks or jobs.\nLimits: Limits are applicable to all users of CVAT Online using the Free plan and can be lifted upon choosing a subscription.\nAll roles are predefined and cannot be modified through the user interface. However, within the self-hosted solution, roles can be adjusted using .rego files stored in cvat/apps/*/rules/. Rego is a declarative language employed for defining OPA (Open Policy Agent) policies, and its syntax is detailed in the OPA documentation.\nNote Once you’ve made changes to the .rego files, you must rebuild and restart the Docker Compose for those changes to be applied. In this scenario, be sure to include the docker-compose.dev.yml compose configuration file when executing the Docker Compose command. See:\nGlobal roles in CVAT Organization roles in CVAT Job Stage Global roles in CVAT Note Global roles can be adjusted only on self-hosted solution. CVAT has implemented three Global roles, categorized as user Groups. These roles are:\nRole Description Administrator An administrator possesses unrestricted access to the CVAT instance and all activities within this instance. The administrator has visibility over all tasks and projects, with the ability to modify or manage each comprehensively. This role is exclusive to self-hosted instances, ensuring comprehensive oversight and control. User (default role) A User is a default role who is assigned to any user who is registered in CVAT*. Users can view and manage all tasks and projects within their registered accounts, but their activities are subject to specific limitations, see Free plan. * If a user, that did not have a CVAT account, has been invited to the organization by the organization owner or maintainer, it will be automatically assigned the Organization role and will be subject to the role’s limitations when operating within the Organization. Worker Workers are limited to specific functionalities and do not have the permissions to create tasks, assign roles, or perform other administrative actions. Their activities are primarily focused on viewing and interacting with the content within the boundaries of their designated roles (validation or annotation of the jobs). Organization roles in CVAT Organization Roles are available only within the CVAT Organization.\nOrganization roles are assigned when users are invited to the Organization.\nThere are the following roles available in CVAT:\nRole Description Owner The Owner is the person who created the Organization. The Owner role is assigned to the creator of the organization by default. This role has maximum capabilities and cannot be changed or assigned to the other user. The Owner has no extra restrictions in the organization and is only limited by the chosen organization plan (see Free and Team plans). Owners can invite other users to the Organization and assign roles to the invited users so the team can collaborate. Maintainer The maintainer is the person who can invite users to organization, create and update tasks and jobs, and see all tasks within the organization. Maintainer has complete access to Cloud Storages, and the ability to modify members and their roles. Supervisor The supervisor is a manager role. Supervisor can create and assign jobs, tasks, and projects to the Organization members. Supervisor cannot invite new members and modify members roles. Worker Workers’ primary focus is actual annotation and reviews. They are limited to specific functionalities and has access only to the jobs assigned to them. Job Stage Job Stage can be assigned to any team member.\nStages are not roles.\nJobs can have an assigned user (with any role) and that Assignee will perform a Stage specific work which is to annotate, validate, or accept the job.\nJob Stage can be:\nStage Description Annotation Provides access to annotation tools. Assignees will be able to see their assigned jobs and annotate them. By default, assignees with the Annotation stage cannot report annotation errors or issues. Validation Grants access to QA tools. Assignees will see their assigned jobs and can validate them while also reporting issues. By default, assignees with the Validation stage cannot correct errors or annotate datasets. Acceptance Does not grant any additional access or change the annotator’s interface. It just marks the job as done. Any Assignee can modify their assigned Stage specific functions via the annotation interface toolbar:\nStandard: switches interface to Annotation mode. Review: switches interface to the Validation mode. ","categories":"","description":"","excerpt":"CVAT offers two distinct types of roles:\nGlobal Roles: These are …","ref":"/v2.43.0/docs/manual/advanced/user-roles/","tags":"","title":"CVAT User roles"},{"body":"To edit a polygon you have to click on it while holding Shift, it will open the polygon editor.\nIn the editor you can create new points or delete part of a polygon by closing the line on another point.\nWhen Intelligent polygon cropping option is activated in the settings, CVAT considers two criteria to decide which part of a polygon should be cut off during automatic editing.\nThe first criteria is a number of cut points. The second criteria is a length of a cut curve. If both criteria recommend to cut the same part, algorithm works automatically, and if not, a user has to make the decision. If you want to choose manually which part of a polygon should be cut off, disable Intelligent polygon cropping in the settings. In this case after closing the polygon, you can select the part of the polygon you want to leave.\nYou can press Esc to cancel editing.\n","categories":"","description":"","excerpt":"To edit a polygon you have to click on it while holding Shift, it will …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polygons/edit-polygon/","tags":"","title":"Edit polygon"},{"body":"Overview This layer provides high-level APIs, allowing easier access to server operations. API includes Repositories and Entities. Repositories provide management operations for Entities. Entities represent objects on the server (e.g. projects, tasks, jobs etc) and simplify interaction with them. The key difference from the low-level API is that operations on this layer are not limited by a single server request per operation and encapsulate low-level request machinery behind a high-level object-oriented API.\nThe code of this component is located in the cvat_sdk.core package.\nExample from cvat_sdk import make_client, models from cvat_sdk.core.proxies.tasks import ResourceType, Task # Create a Client instance bound to a local server and authenticate using basic auth with make_client(host=\"http://localhost\", credentials=('user', 'password')) as client: # Let's create a new task. # Fill in task parameters first. # Models are used the same way as in the layer 1. task_spec = { \"name\": \"example task\", \"labels\": [ { \"name\": \"car\", \"color\": \"#ff00ff\", \"attributes\": [ { \"name\": \"a\", \"mutable\": True, \"input_type\": \"number\", \"default_value\": \"5\", \"values\": [\"4\", \"5\", \"6\"], } ], } ], } # Now we can create a task using a task repository method. # Repositories can be accessed as the Client class members. # In this case we use 2 local images as the task data. task = client.tasks.create_from_data( spec=task_spec, resource_type=ResourceType.LOCAL, resources=['image1.jpg', 'image2.png'], ) # The returned task object is already up-to-date with its server counterpart. # Now we can access task fields. The fields are read-only and can be optional. # Let's check that we have 2 images in the task data. assert task.size == 2 # If an object is modified on the server, the local object is not updated automatically. # To reflect the latest changes, the local object needs to be fetch()-ed. task.fetch() # Let's obtain another task. Again, it can be done via the task repository. # Suppose we have already created the task earlier and know the task id. task2 = client.tasks.retrieve(42) # The task object fields can be update()-d. Note that the set of fields that can be # modified can be different from what is available for reading. task2.update({'name': 'my task'}) # And the task can also be remove()-d from the server. The local copy will remain # untouched. task2.remove() Client The cvat_sdk.core.client.Client class provides session management, implements authentication operations and simplifies access to server APIs. It is the starting point for using CVAT SDK.\nA Client instance allows you to:\nconfigure connection options with the Config class check server API compatibility with the current SDK version deduce server connection scheme (https or http) automatically manage user session with the login(), logout() and other methods obtain Repository objects with the users, tasks, jobs and other members reach to lower-level APIs with the corresponding members An instance of Client can be created directly by calling the class constructor or with the utility function cvat_sdk.core.client.make_client() which can handle some configuration for you. A Client can be configured with the cvat_sdk.core.client.Config class instance. A Config object can be passed to the Client constructor and then it will be available in the Client.config field.\nThe Client class implements the context manager protocol. When the context is closed, the session is finished, and the user is logged out automatically. Otherwise, these actions can be done with the close() and logout() methods.\nYou can create and start using a Client instance this way:\nfrom cvat_sdk import make_client with make_client('http://localhost', port='8080', credentials=('user', 'password')) as client: ... The make_client() function handles configuration and object creation for you. It also allows to authenticate right after the object is created.\nIf you need to configure Client parameters, you can do this:\nfrom cvat_sdk import Config, Client config = Config() # set up some config fields ... with Client('http://localhost:8080', config=config) as client: client.login(('user', 'password')) ... Note Historically, the SDK has allowed the URL scheme (http: or https:) to be omitted, and would attempt to automatically detect the protocol. This behavior is deprecated due to being inherently insecure, and will be removed in a future version. To avoid future breakage, make sure to specify the scheme explicitly. When the server is located, its version is checked. If an unsupported version is found, an error can be raised or suppressed (controlled by config.allow_unsupported_server). If the error is suppressed, some SDK functions may not work as expected with this server. By default, a warning is raised and the error is suppressed.\nUsers and organizations All Client operations rely on the server API and depend on the current user rights. This affects the set of available APIs, objects and actions. For example, a regular user can only see and modify their tasks and jobs, while an admin user can see all the tasks etc.\nOperations are also affected by the current organization context, which can be set with the organization_slug property of Client instances. The organization context affects which entities are visible, and where new entities are created.\nSet organization_slug to an organization’s slug (short name) to make subsequent operations work in the context of that organization:\nclient.organization_slug = 'myorg' # create a task in the organization task = client.tasks.create_from_data(...) You can also set organization_slug to an empty string to work in the context of the user’s personal workspace. By default, it is set to None, which means that both personal and organizational entities are visible, while new entities are created in the personal workspace.\nTo temporarily set the organization slug, use the organization_context function:\nwith client.organization_context('myorg'): task = client.tasks.create_from_data(...) # the slug is now reset to its previous value Entities and Repositories Entities represent objects on the server. They provide read access to object fields and implement additional relevant operations, including both the general Read-Update-Delete and object-specific ones. The set of available general operations depends on the object type.\nRepositories provide management operations for corresponding Entities. You don’t need to create Repository objects manually. To obtain a Repository object, use the corresponding Client instance member:\nclient.projects client.tasks client.jobs client.users ... An Entity can be created on the server with the corresponding Repository method create():\ntask = client.tasks.create(\u003ctask config\u003e) We can retrieve server objects using the retrieve() and list() methods of the Repository:\njob = client.jobs.retrieve(\u003cjob id\u003e) tasks = client.tasks.list() After calling these functions, we obtain local objects representing their server counterparts.\nObject fields can be updated with the update() method. Note that the set of fields that can be modified can be different from what is available for reading.\njob.update({'stage': 'validation'}) The server object will be updated and the local object will reflect the latest object state after calling this operation.\nNote that local objects may fall out of sync with their server counterparts for different reasons. If you need to update the local object with the latest server state, use the fetch() method:\n# obtain 2 local copies of the same job job_ref1 = client.jobs.retrieve(1) job_ref2 = client.jobs.retrieve(1) # update the server object with the first reference job_ref1.update(...) # job_ref2 is outdated now job_ref2.fetch() # job_ref2 is synced Finally, if you need to remove the object from the server, you can use the remove() method. The server object will be removed, but the local copy of the object will remain untouched.\ntask = client.tasks.retrieve(\u003ctask id\u003e) task.remove() Repositories can also provide group operations over entities. For instance, you can retrieve all available objects using the list() Repository method. The list of available Entity and Repository operations depends on the object type.\nYou can learn more about entity members and how model parameters are passed to functions here.\nThe implementation for these components is located in cvat_sdk.core.proxies.\n","categories":"","description":"","excerpt":"Overview This layer provides high-level APIs, allowing easier access …","ref":"/v2.43.0/docs/api_sdk/sdk/highlevel-api/","tags":"","title":"High-level API"},{"body":"On the Jobs page, users (for example, with the worker role) can see the jobs that are assigned to them without having access to the task page, as well as track progress, sort, and apply filters to the job list.\nOn the page, there is a list of jobs presented in the form of tiles, where each tile is one job. Each element contains:\njob ID dimension 2D or 3D preview stage and state when hovering over an element, you can see: size assignee menu to navigate to a task, project, or bug tracker. To open the job in a new tab, click on the job by holding Ctrl.\nIn the upper left corner, there is a search bar, using which you can find the job by assignee, stage, state, etc. In the upper right corner, there are sorting, quick filters, and filter.\nFilter Applying a filter disables the quick filter.\nThe filter works similarly to the filters for annotation, you can create rules from properties, operators, and values and group rules into groups. For more details, consult the filter section. Learn more about date and time selection.\nTo clear all filters, select Clear filters.\nSupported properties for jobs list Properties Supported values Description State all the state names The state of the job (can be changed in the menu inside the job) Stage all the stage names The stage of the job (is specified by a drop-down list on the task page) Dimension 2D or 3D Depends on the data format (read more in creating an annotation task) Assignee username Assignee is the user who is working on the job. (is specified on task page) Last updated last modified date and time (or value range) The date can be entered in the dd.MM.yyyy HH:mm format or by selecting the date in the window that appears when you click on the input field ID number or range of job ID Task ID number or range of task ID Project ID number or range of project ID Task name task name Set when creating a task, can be changed on the (task page) Project name project name Specified when creating a project, can be changed on the (project section) ","categories":"","description":"","excerpt":"On the Jobs page, users (for example, with the worker role) can see …","ref":"/v2.43.0/docs/manual/basics/jobs-page/","tags":"","title":"Jobs page"},{"body":"","categories":"","description":"This section contains documents for CVAT simple and advanced users","excerpt":"This section contains documents for CVAT simple and advanced users","ref":"/v2.43.0/docs/manual/","tags":"","title":"Manual"},{"body":"The MOT (Multiple Object Tracking) sequence format is widely used for evaluating multi-object tracking algorithms, particularly in the domains of pedestrian tracking, vehicle tracking, and more. The MOT sequence format essentially contains frames of video along with annotations that specify object locations and identities over time.\nThis version encoded as .png. Supports masks.\nFor more information, see:\nMOTS PNG Specification Dataset examples MOTS PNG export For export of images and videos:\nSupported annotations: Bounding Boxes, Masks Attributes: visibility (number), ignored (checkbox). Tracks: Supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ └── \u003cany_subset_name\u003e/ | images/ | ├── image1.jpg | └── image2.jpg └── instances/ ├── labels.txt ├── image1.png └── image2.png # labels.txt cat dog person ... supported annotations: Rectangle and Polygon tracks MOTS PNG import Uploaded file: a zip archive of the structure above\nsupported annotations: Polygon tracks ","categories":"","description":"How to export and import data in MOTS format","excerpt":"How to export and import data in MOTS format","ref":"/v2.43.0/docs/manual/advanced/formats/format-mots/","tags":"","title":"MOTS"},{"body":"The shapes converter is a feature that enables bulk actions on filtered shapes. It allows you to perform mutual conversion between masks, polygons and rectangles.\nNote All shapes converter work only when the filter is set up. See:\nRun actions menu Convert shapes Convert shapes video tutorial Run actions menu Annotations actions can be accessed from the annotation menu. To access it, click on the burger icon and then select Run actions.\nNote All Shapes converter functions work in alignment with set up filter. You will see the following dialog:\nWith the following fields:\nField Description Select action Drop-down list with available actions: Remove filtered shapes - removes all shapes in alignment with the set-up filter. Doesn’t work with tracks.Propagate shapes - propagates all the filtered shapes from the current frame to the target frame.Shapes converter: masks to polygons - converts all masks to polygons.Shapes converter: masks to rectangles - converts all masks to rectangles in alignment with the set-up filter.Shapes converter: polygon to masks - converts all polygons to masks.Shapes converter: polygon to rectangles - converts all polygons to rectangles.Shapes converter: rectangles to masks - converts all rectangles to masks.Shapes converter: rectangles to polygons - converts all rectangles to polygons.\nNote: only Propagate shapes and Remove filtered shapes is available in the community version. Specify frames to run action Field where you can specify the frame range for the selected action. Enter the starting frame in the Starting from frame: field, and the ending frame in the up to frame field. If nothing is selected here or in Choose one of the predefined options section, the action will be applied to all fields. Choose one of the predefined options Predefined options to apply to frames. Selection here is mutually exclusive with Specify frames to run action. If nothing is selected here or in Specify frames to run action section, the action will be applied to all fields. Convert shapes Recommended Precautions Before Running Annotation Actions\nSaving changes: It is recommended to save all changes prior to initiating the annotation action. If unsaved changes are detected, a prompt will advise to save these changes to avoid any potential loss of data.\nDisable auto-save: Prior to running the annotation action, disabling the auto-save feature is advisable. A notification will suggest this action if auto-save is currently active.\nCommitting changes: Changes applied during the annotation session will not be committed to the server until the saving process is manually initiated. This can be done either by the user or through the auto-save feature, should it be enabled.\nTo convert shapes, do the following:\nAnnotate your dataset.\nSet up filters.\nFrom the burger menu, select Run actions.\nChoose the action you need from the Select action drop-down list.\n(Optional) In the Starting from frame field, enter the frame number where the action should begin, and in the up to frame field, specify the frame number where the action should end.\n(Optional) Select an option from Or choose one of the predefined options to apply the action.\nClick Run. A progress bar will appear. You may abort the process by clicking Cancel until the process commits modified objects at the end of pipeline.\nNote Once the action is applied, it cannot be undone. Convert shapes video tutorial ","categories":"","description":"How to perform bulk actions on filtered shapes","excerpt":"How to perform bulk actions on filtered shapes","ref":"/v2.43.0/docs/enterprise/shapes-converter/","tags":"","title":"Shapes converter"},{"body":"Basic operations in the mode were described in section track mode (basics).\nShapes that were created in the track mode, have extra navigation buttons.\nThese buttons help to jump to the previous/next keyframe.\nThe button helps to jump to the initial frame and to the last keyframe.\nYou can use the Split function to split one track into two tracks:\n","categories":"","description":"Advanced operations available during annotation in track mode.","excerpt":"Advanced operations available during annotation in track mode.","ref":"/v2.43.0/docs/manual/advanced/track-mode-advanced/","tags":"","title":"Track mode (advanced)"},{"body":"As well as 2D-task objects, 3D-task objects support the ability to change appearance, attributes, properties and have an action menu. Read more in objects sidebar section.\nMoving an object If you hover the cursor over a cuboid and press Shift+N, the cuboid will be cut, so you can paste it in other place (double-click to paste the cuboid).\nCopying As well as in 2D task you can copy and paste objects by Ctrl+C and Ctrl+V, but unlike 2D tasks you have to place a copied object in a 3D space (double click to paste).\nImage of the projection window You can copy or save the projection-window image by left-clicking on it and selecting a “save image as” or “copy image”.\nCuboid orientation The feature enables or disables the display of cuboid orientation arrows in the 3D space. It is controlled by a checkbox located in the appearance block. When enabled, arrows representing the cuboid’s axis orientation (X - red, Y - green, Z - blue) are displayed, providing a visual reference for the cuboid’s alignment within the 3D environment. This feature is useful for understanding the spatial orientation of the cuboid.\nCuboid size input The size input feature allows users to manually specify the dimensions of a cuboid in the 3D space. This feature is accessible through the objects sidebar - details panel, where you can input precise values for the width, height, and length (X - width, Y - height, Z - length) of the cuboid. By entering these values, the cuboid’s size is adjusted accordingly to its orientation, providing greater control and accuracy when annotating objects in 3D tasks.\n","categories":"","description":"Overview of advanced operations available when annotating 3D objects.","excerpt":"Overview of advanced operations available when annotating 3D objects.","ref":"/v2.43.0/docs/manual/advanced/3d-object-annotation-advanced/","tags":"","title":"3D Object annotation (advanced)"},{"body":"","categories":"","description":"This section contains documents for system administrators.","excerpt":"This section contains documents for system administrators.","ref":"/v2.43.0/docs/administration/","tags":"","title":"Administration"},{"body":"The project uses a successful Git branching model. Thus it has a couple of branches. Some of them are described below:\norigin/master to be the main branch where the source code of HEAD always reflects a production-ready state\norigin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the “integration branch”.\n","categories":"","description":"Information about the branching model that is used in the project.","excerpt":"Information about the branching model that is used in the project.","ref":"/v2.43.0/docs/contributing/branching-model/","tags":"","title":"Branching model"},{"body":"A widely-used machine learning structure, the COCO dataset is instrumental for tasks involving object identification and image segmentation. This format is compatible with projects that employ bounding boxes or polygonal image annotations.\nFor more information, see:\nCOCO Object Detection site Format specification Dataset examples COCO export For export of images and videos:\nSupported annotations: Bounding Boxes, Polygons. Attributes: is_crowd This can either be a checkbox or an integer (with values of 0 or 1). It indicates that the instance (or group of objects) should include an RLE-encoded mask in the segmentation field. All shapes within the group coalesce into a single, overarching mask, with the largest shape setting the properties for the entire object group. score: This numerical field represents the annotation score. Arbitrary attributes: These will be stored within the attributes section of the annotation. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\narchive.zip/ ├── images/ │ ├── train/ │ │ ├── \u003cimage_name1.ext\u003e │ │ ├── \u003cimage_name2.ext\u003e │ │ └── ... │ └── val/ │ ├── \u003cimage_name1.ext\u003e │ ├── \u003cimage_name2.ext\u003e │ └── ... └── annotations/ ├── \u003ctask\u003e_\u003csubset_name\u003e.json └── ... When exporting a dataset from a Project, subset names will mirror those used within the project itself. Otherwise, a singular default subset will be created to house all the dataset information. The section aligns with one of the specific COCO tasks, such as instances, panoptic, image_info, labels, captions, or stuff.\nCOCO import Upload format: a single unpacked *.json or a zip archive with the structure described above or here (without images).\nNote Even though licenses and info fields are required according to format specifications, CVAT does not require them to import annotations. Supported annotations: Polygons, Rectangles (if the segmentation field is empty) Supported tasks: instances, person_keypoints (only segmentations will be imported), panoptic How to create a task from MS COCO dataset Download the MS COCO dataset.\nFor example val images and instances annotations\nCreate a CVAT task with the following labels:\nperson bicycle car motorcycle airplane bus train truck boat \"traffic light\" \"fire hydrant\" \"stop sign\" \"parking meter\" bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard \"sports ball\" kite \"baseball bat\" \"baseball glove\" skateboard surfboard \"tennis racket\" bottle \"wine glass\" cup fork knife spoon bowl banana apple sandwich orange broccoli carrot \"hot dog\" pizza donut cake chair couch \"potted plant\" bed \"dining table\" toilet tv laptop mouse remote keyboard \"cell phone\" microwave oven toaster sink refrigerator book clock vase scissors \"teddy bear\" \"hair drier\" toothbrush Select val2017.zip as data (See Creating an annotation task guide for details)\nUnpack annotations_trainval2017.zip\nclick Upload annotation button, choose COCO 1.1 and select instances_val2017.json annotation file. It can take some time.\n","categories":"","description":"How to export and import data in COCO format","excerpt":"How to export and import data in COCO format","ref":"/v2.43.0/docs/manual/advanced/formats/format-coco/","tags":"","title":"COCO"},{"body":"The COCO Keypoints format is designed specifically for human pose estimation tasks, where the objective is to identify and localize body joints (keypoints) on a human figure within an image.\nThis specialized format is used with a variety of state-of-the-art models focused on pose estimation.\nFor more information, see:\nCOCO Keypoint site Format specification Example of the archive COCO Keypoints export For export of images:\nSupported annotations: Skeletons Attributes: is_crowd This can either be a checkbox or an integer (with values of 0 or 1). It indicates that the instance (or group of objects) should include an RLE-encoded mask in the segmentation field. All shapes within the group coalesce into a single, overarching mask, with the largest shape setting the properties for the entire object group. score: This numerical field represents the annotation score. Arbitrary attributes: These will be stored within the attributes section of the annotation. Tracks: Not supported. Downloaded file is a .zip archive with the following structure:\narchive.zip/ ├── images/ │ │ ├── \u003cimage_name1.ext\u003e │ ├── \u003cimage_name2.ext\u003e │ └── ... ├──\u003cannotations\u003e.xml COCO import Uploaded file: a single unpacked *.json or a zip archive with the structure described here (without images).\nsupported annotations: Skeletons person_keypoints,\nSupport for COCO tasks via Datumaro is described here For example, support for COCO keypoints over Datumaro:\nInstall Datumaro pip install datumaro Export the task in the Datumaro format, unzip Export the Datumaro project in coco / coco_person_keypoints formats datum export -f coco -p path/to/project [-- --save-images] This way, one can export CVAT points as single keypoints or keypoint lists (without the visibility COCO flag).\n","categories":"","description":"How to export and import data in COCO Keypoints format","excerpt":"How to export and import data in COCO Keypoints format","ref":"/v2.43.0/docs/manual/advanced/formats/coco-keypoints/","tags":"","title":"COCO Keypoints"},{"body":"Overview The basic idea behind this feature is to provide annotators with quick feedback on their performance in a job. When an annotator finishes a job, a dialog is displayed showing the quality of their annotations. The annotator can either agree or disagree with the feedback. If they disagree, they have the option to re-annotate the job and request feedback again.\nTo ensure transparency with the annotator, the immediate feedback shows the computed score and the minimum required score. Information about the specific errors or frames that have errors is not available to annotators.\nFeedback is only available a limited number of times for each assignment, to prevent Ground Truth revealing by annotators. This is controlled by a configurable parameter, so it can be adjusted to the requirements of each project.\nHow to configure Immediate feedback settings, such as Target metric, Target metric threshold, Max validations per job and others, can be configured on the quality settings page.\nThis feature is considered enabled if the Max validations per job is above 0. You can change the parameters any time.\nNote This feature requires a configured validation set in the task. Read more in the quality overview section or in the full guide. Open the task Actions menu \u003e Quality control \u003e Settings Set the Target metric and Target metric threshold values to what is required in your project. Set Max validations per job to above zero. 3 is a good starting number. Save the updated settings How to receive a feedback Assign an annotator to an annotation job Annotate the job Mark the job finished using the corresponding button in the menu Once the job is completed, you’ll see the job validation dialog Each assignee gets no more than the specified number of validation attempts.\nNote This functionality is only available in regular annotation jobs. For instance, it’s not possible to use it in Ground Truth jobs. Available feedbacks There are three types of feedbacks available for different cases:\nAccepted Rejected, with an option to fix mistakes Finally rejected when the number of attempts is exhausted Additional details Immediate feedback has a default timeout of 20 seconds. Feedback may be unavailable for large jobs or when there are too many immediate feedback requests. In this case annotators do not see any feedback dialogs and annotate jobs as if the feature was disabled.\nThe number of attempts does not decrease for staff members who have access to a job with ground truth annotations. For instance, if you’re trying to test this feature as the task owner, you may be confused if you see the number of attempts doesn’t decrease.\nThe number of attempts resets when the job assignee is updated.\n","categories":"","description":"Quick responses about job annotation quality","excerpt":"Quick responses about job annotation quality","ref":"/v2.43.0/docs/enterprise/immediate-feedback/","tags":"","title":"Immediate job feedback"},{"body":"Overview This layer provides functionality that enables you to treat CVAT projects and tasks as PyTorch datasets.\nThe code of this layer is located in the cvat_sdk.pytorch package. To use it, you must install the cvat_sdk distribution with the pytorch extra.\nExample import torch import torchvision.models from cvat_sdk import make_client from cvat_sdk.pytorch import ProjectVisionDataset, ExtractSingleLabelIndex # create a PyTorch model model = torchvision.models.resnet34( weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1) model.eval() # log into the CVAT server with make_client(host=\"http://localhost\", credentials=('user', 'password')) as client: # get the dataset comprising all tasks for the Validation subset of project 12345 dataset = ProjectVisionDataset(client, project_id=12345, include_subsets=['Validation'], # use transforms that fit our neural network transform=torchvision.models.ResNet34_Weights.IMAGENET1K_V1.transforms(), target_transform=ExtractSingleLabelIndex()) # print the number of images in the dataset (in other words, the number of frames # in the included tasks) print(len(dataset)) # get a sample from the dataset image, target = dataset[0] # evaluate the network on the sample and compare the output to the target output = model(image) if torch.equal(output, target): print(\"correct prediction\") else: print(\"incorrect prediction\") Datasets The key components of this layer are the dataset classes, ProjectVisionDataset and TaskVisionDataset, representing data \u0026 annotations contained in a CVAT project or task, respectively. Both of them are subclasses of the torch.utils.data.Dataset abstract class.\nThe interface of Dataset is essentially that of a sequence whose elements are samples from the dataset. In the case of TaskVisionDataset, each sample represents a frame from the task and its associated annotations. The order of the samples is the same as the order of frames in the task. Deleted frames are omitted.\nIn the case of ProjectVisionDataset, each sample is a sample from one of the project’s tasks, as if obtained from a TaskVisionDataset instance created for that task. The full sequence of samples is built by concatenating the sequences of samples from all included tasks in an unspecified order that is guaranteed to be consistent between executions. For details on what tasks are included, see Task filtering.\nConstruction Both dataset classes are instantiated by passing in an instance of cvat_sdk.Client and the ID of the project or task:\ndataset = ProjectVisionDataset(client, 123) dataset = TaskVisionDataset(client, 456) The referenced project or task must contain image data. Video data is currently not supported.\nThe constructors of these classes also support several keyword-only parameters:\ntransforms, transform, target_transform: see Transform support.\nlabel_name_to_index: see Label index assignment.\ntask_filter, include_subsets (ProjectVisionDataset only): see Task filtering.\nupdate_policy: see Caching.\nDuring construction, the dataset objects either populate or validate the local data cache (see Caching for details). Any necessary requests to the CVAT server are performed at this time. After construction, the objects make no more network requests.\nSample format Indexing a dataset produces a sample. A sample has the form of a tuple with the following components:\nsample[0] (PIL.Image.Image): the image. sample[1] (cvat_sdk.pytorch.Target): the annotations and auxiliary data. The target object contains the following attributes:\ntarget.annotations.tags (list[cvat_sdk.models.LabeledImage]): tag annotations associated with the current frame. target.annotations.shapes (list[cvat_sdk.models.LabeledShape]): shape annotations associated with the current frame. target.label_id_to_index (Mapping[int, int]): see Label index assignment. Note that track annotations are currently inaccessible.\nTransform support The dataset classes support torchvision-like transforms that you can supply to preprocess each sample before it’s returned. You can use this to convert the samples to a more convenient format or to preprocess the data. The transforms are supplied via the following constructor parameters:\ntransforms: a callable that accepts two arguments (the image and the target) and returns a tuple with two elements. transform: a callable that accepts an image. target_transform: a callable that accepts a target. Let the sample value prior to any transformations be (image, target). Here is what indexing the dataset will return for various combinations of supplied transforms:\ntransforms: transforms(image, target). transform: (transform(image), target). target_transform: (image, target_transform(target)). transform and target_transform: (transform(image), target_transform(target)). transforms cannot be supplied at the same time as either transform or target_transform.\nThe cvat_sdk.pytorch module contains some target transform classes that are intended for common use cases. See Transforms.\nLabel index assignment The annotation model classes (LabeledImage and LabeledShape) reference labels by their IDs on the CVAT server. This is usually not very useful for machine learning code, since those IDs are unpredictable and will be different between different projects, even if semantically the set of labels is the same.\nTherefore, the dataset classes assign to each label a unique index that is intended to be a project-independent identifier. These indices are accessible via the label_id_to_index attribute on each sample’s target. This attribute maps IDs on the server to the assigned index. The mapping is the same for every sample.\nBy default, the dataset classes arrange all label IDs in an unspecified order that remains consistent across executions, and assign them sequential indices, starting with 0.\nYou can override this behavior and specify your own label indices with the label_name_to_index constructor parameter. This parameter accepts a mapping from label name to index. The mapping must contain a key for each label in the project/task. When this parameter is specified, label indices are assigned by looking up each label’s name in the provided mapping and using the result.\nTask filtering Note: this section applies only to ProjectVisionDataset.\nBy default, a ProjectVisionDataset includes samples from every task belonging to the project. You can change this using the following constructor parameters:\ntask_filter (Callable[[models.ITaskRead], bool]): if set, the callable will be called for every task, with an instance of ITaskRead corresponding to that task passed as the argument. Only tasks for which True is returned will be included.\ninclude_subsets (Container[str]): if set, only tasks whose subset is a member of the container will be included.\nBoth parameters can be set, in which case tasks must fulfill both criteria to be included.\nCaching The images and annotations of a dataset can be substantial in size, so they are not downloaded from the server every time a dataset object is created. Instead, they are loaded from a cache on the local file system, which is maintained during dataset object construction according to the policy set by the update_policy constructor parameter.\nThe available policies are:\nUpdatePolicy.IF_MISSING_OR_STALE: If some data is already cached, query the server to determine if it is out of date. If so, discard it. Then, download all necessary data that is missing from the cache and cache it.\nThis is the default policy.\nUpdatePolicy.NEVER: If some necessary data is missing from the cache, raise an exception. Don’t make any network requests.\nNote that this policy permits the use of stale data.\nBy default, the cache is located in a platform-specific per-user directory. You can change this location with the cache_dir setting in the Client configuration.\nTransforms The layer provides some classes whose instances are callables suitable for usage with the target_transform dataset constructor parameter that are intended to simplify working with CVAT datasets in common scenarios.\nExtractBoundingBoxes Intended for object detection tasks.\nConstructor parameters:\ninclude_shape_types (Iterable[str]). The values must be from the following list:\n\"ellipse\" \"points\" \"polygon\" \"polyline\" \"rectangle\" Effect: Gathers all shape annotations from the input target object whose types are contained in the value of include_shape_types. Then returns a dictionary with the following string keys (where N is the number of gathered shapes):\n\"boxes\" (a floating-point tensor of shape Nx4). Each row represents the bounding box the corresponding shape in the following format: [x_min, y_min, x_max, y_max].\n\"labels\" (an integer tensor of shape N). Each element is the index of the label of the corresponding shape.\nExample:\nExtractBoundingBoxes(include_shape_types=['rectangle', 'ellipse']) ExtractSingleLabelIndex Intended for image classification tasks.\nConstructor parameters: None.\nEffect: If the input target object contains no tag annotations or more than one tag annotation, raises ValueError. Otherwise, returns the index of the label in the solitary tag annotation as a zero-dimensional tensor.\nExample:\nExtractSingleLabelIndex() ","categories":"","description":"","excerpt":"Overview This layer provides functionality that enables you to treat …","ref":"/v2.43.0/docs/api_sdk/sdk/pytorch-adapter/","tags":"","title":"PyTorch adapter"},{"body":"\nThe Tasks page contains elements and each of them relates to a separate task. They are sorted in creation order. Each element contains: the task name, preview, progress bar, button Open, and menu Actions. Each button is responsible for a menu Actions specific function:\nExport task dataset — download annotations or annotations and images in a specific format. More information is available in the export/import datasets section. Upload annotation upload annotations in a specific format. More information is available in the export/import datasets section. Automatic Annotation — automatic annotation with OpenVINO toolkit. Presence depends on how you build the CVAT instance. Backup task — make a backup of this task into a zip archive. Read more in the backup section. Move to project — Moving a task to a project (you can move only a task that does not belong to any project). In case of a label mismatch, you can create or delete necessary labels in the project/task. Some task labels can be matched with the target project labels. Delete — delete task. In the upper left corner, there is a search bar, using which you can find the task by assignee, task name etc. In the upper right corner, there are sorting, quick filters, and filter.\nFilter Applying a filter disables the quick filter.\nThe filter works similarly to the filters for annotation, you can create rules from properties, operators, and values and group rules into groups. For more details, consult the filter section. Learn more about date and time selection.\nFor clear all filters press Clear filters.\nSupported properties for tasks list Properties Supported values Description Dimension 2D or 3D Depends on the data format (read more in creating an annotation task) Status annotation, validation or completed Data video, images Depends on the data format (read more in creating an annotation task) Subset test, train, validation or custom subset learn more Assignee username Assignee is the user who is working on the project, task or job (they are specified on task page) Owner username The user who owns the project, task, or job Last updated last modified date and time (or value range) The date can be entered in the dd.MM.yyyy HH:mm format or by selecting the date in the window that appears when you click on the input field ID number or range of job ID Project ID number or range of project ID Name name On the tasks page: name of the task,\non the project page: name of the project Project name project name Specified when creating a project, can be changed on the (project section) Select Open to go to task details.\n","categories":"","description":"Overview of the Tasks page.","excerpt":"Overview of the Tasks page.","ref":"/v2.43.0/docs/manual/basics/tasks-page/","tags":"","title":"Tasks page"},{"body":"Polygons in the track mode allow you to mark moving objects more accurately other than using a rectangle (Tracking mode (basic); Tracking mode (advanced)).\nTo create a polygon in the track mode, click the Track button.\nCreate a polygon the same way as in the case of Annotation with polygons. Press N or click the Done button on the top panel to complete the polygon.\nPay attention to the fact that the created polygon has a starting point and a direction, these elements are important for annotation of the following frames.\nAfter going a few frames forward press Shift+N, the old polygon will disappear and you can create a new polygon. The new starting point should match the starting point of the previously created polygon (in this example, the top of the left mirror). The direction must also match (in this example, clockwise). After creating the polygon, press N and the intermediate frames will be interpolated automatically.\nIf you need to change the starting point, right-click on the desired point and select Set starting point. To change the direction, right-click on the desired point and select switch orientation.\nThere is no need to redraw the polygon every time using Shift+N, instead you can simply move the points or edit a part of the polygon by pressing Shift+Click.\n","categories":"","description":"","excerpt":"Polygons in the track mode allow you to mark moving objects more …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polygons/track-mode-with-polygons/","tags":"","title":"Track mode with polygons"},{"body":"Overview In the modern world, it is often necessary to integrate different tools to work together. CVAT provides the following integration layers:\nServer REST API + Swagger schema Python client library (SDK) REST API client High-level wrappers Command-line tool (CLI) In this section, you can find documentation about each separate layer.\nComponent compatibility Currently, the only supported configuration is when the server API major and minor versions are the same as SDK and CLI major and minor versions, e.g. server v2.1.* is supported by SDK and CLI v2.1.*. Different versions may have incompatibilities, which lead to some functions in SDK or CLI may not work properly.\n","categories":"","description":"How to interact with CVAT","excerpt":"How to interact with CVAT","ref":"/v2.43.0/docs/api_sdk/","tags":"","title":"API \u0026 SDK"},{"body":"Basic operations in the mode were described in section attribute annotation mode (basics).\nIt is possible to handle lots of objects on the same frame in the mode.\nIt is more convenient to annotate objects of the same type. In this case you can apply the appropriate filter. For example, the following filter will hide all objects except person: label==\"Person\".\nTo navigate between objects (person in this case), use the following buttons switch between objects in the frame on the special panel:\nor shortcuts:\nTab — go to the next object Shift+Tab — go to the previous object. In order to change the zoom level, go to settings (press F3) in the workspace tab and set the value Attribute annotation mode (AAM) zoom margin in px.\n","categories":"","description":"Advanced operations available in attribute annotation mode.","excerpt":"Advanced operations available in attribute annotation mode.","ref":"/v2.43.0/docs/manual/advanced/attribute-annotation-mode-advanced/","tags":"","title":"Attribute annotation mode (advanced)"},{"body":"Overview This layer provides functionality that allows you to automate the process of annotating a CVAT dataset by delegating this process (or parts of it) to a program running on a machine under your control.\nTo make use of this delegation, you must implement an “auto-annotation function”, or “AA function” for short. This is a Python object that implements one of the protocols defined by this layer. The particular protocol implemented defines which part of the annotation process the AA function will be able to automate.\nAn AA function may be used in one of the following modes:\nImmediate mode. This involves annotating a specific CVAT task by passing the AA function to a driver, along with the identifier of the task and optional additional parameters. This may be done either:\nprogrammatically (consult the “Auto-annotation driver” section (TODO)); or\nvia the CVAT CLI (consult the description of the task auto-annotate command in the CLI documentation).\nAgent mode. This involves registering the AA function with the CVAT server (creating a resource on the server known as a “native function”) and then running one or more agent processes.\nThis makes the AA function usable from the CVAT UI. CVAT users can choose to use the native function as the model when using CVAT’s AI tools. When they do, the agents detect this, and process their requests by calling appropriate methods on the corresponding AA function.\nDepending on how you create the native function, it’ll be accessible to only you, or your organization.\nFor more details, consult the descriptions of the function create-native and function run-agent commands in the CLI documentation.\nThis SDK layer can be divided into several parts:\nThe interface, containing the protocols that an AA function must implement, as well as helpers for use by such functions. Consult “…”\nThe driver, containing functionality to annotate a CVAT dataset using an AA function. Consult “…”\nPredefined AA functions based on torchvision. Consult “…”\nExample An AA function may be implemented in any way that is appropriate for your use case. However, a typical AA function will be based on a machine learning model and consist of the following basic elements:\nCode to load the ML model.\nA specification defining which protocol the AA function implements, as well as static properties of the AA function (such as a description of the annotations that the AA function can produce).\nCode to convert data from SDK data structures to a format the ML model can understand.\nCode to run the ML model.\nCode to convert resulting annotations to SDK data structures.\nThe following code snippet shows an example AA function implementation (specifically, a detection function), as well as code that creates an instance of the function and uses it for auto-annotation.\nfrom typing import List import PIL.Image import torchvision.models from cvat_sdk import make_client import cvat_sdk.models as models import cvat_sdk.auto_annotation as cvataa class TorchvisionDetectionFunction: def __init__(self, model_name: str, weights_name: str, **kwargs) -\u003e None: # load the ML model weights_enum = torchvision.models.get_model_weights(model_name) self._weights = weights_enum[weights_name] self._transforms = self._weights.transforms() self._model = torchvision.models.get_model(model_name, weights=self._weights, **kwargs) self._model.eval() @property def spec(self) -\u003e cvataa.DetectionFunctionSpec: # describe the annotations return cvataa.DetectionFunctionSpec( labels=[ cvataa.label_spec(cat, i, type=\"rectangle\") for i, cat in enumerate(self._weights.meta[\"categories\"]) if cat != \"N/A\" ] ) def detect( self, context: cvataa.DetectionFunctionContext, image: PIL.Image.Image ) -\u003e list[models.LabeledShapeRequest]: # determine the threshold for filtering results conf_threshold = context.conf_threshold or 0 # convert the input into a form the model can understand transformed_image = [self._transforms(image)] # run the ML model results = self._model(transformed_image) # convert the results into the form SDK requires return [ cvataa.rectangle(label.item(), [x.item() for x in box]) for result in results for box, label, score in zip(result[\"boxes\"], result[\"labels\"], result[\"scores\"]) if score \u003e= conf_threshold ] # log into the CVAT server with make_client(host=\"http://localhost\", credentials=(\"user\", \"password\")) as client: # create a function that uses Faster R-CNN func = TorchvisionDetectionFunction(\"fasterrcnn_resnet50_fpn_v2\", \"DEFAULT\", box_score_thresh=0.5) # annotate task 12345 using the function cvataa.annotate_task(client, 12345, func) Auto-annotation interface This part of the auto-annotation layer defines the protocols that an AA function must implement.\nDetection function protocol A detection function is a type of AA function that accepts an image and returns a list of shapes found in that image.\nA detection function can be used in the following ways:\nIn immediate mode, the AA function is run for every image in a given CVAT task, and the resulting lists of shapes are combined and uploaded to CVAT.\nIn agent mode, the AA function can be used from the CVAT UI to either annotate a complete task (similar to immediate mode) or a single frame in a task.\nA detection function must have two attributes, spec and detect.\nspec must contain the AA function’s specification, which is an instance of DetectionFunctionSpec.\nDetectionFunctionSpec must be initialized with a sequence of PatchedLabelRequest objects that represent the labels that the AA function knows about. See the docstring of DetectionFunctionSpec for more information on the constraints that these objects must follow. BadFunctionError will be raised if any constraint violations are detected.\ndetect must be a function/method accepting two parameters:\ncontext (DetectionFunctionContext). Contains invocation parameters and information about the current image. The following fields are available:\nframe_name (str). The file name of the frame on the CVAT server. conf_threshold (float | None). The confidence threshold that the function should use to filter objects. If None, the function may apply a default threshold at its discretion. image (PIL.Image.Image). Contains image data.\ndetect must return a list of LabeledShapeRequest objects, representing shapes found in the image. See the docstring of DetectionFunctionSpec for more information on the constraints that these objects must follow.\nThe same AA function may be used with any dataset that contain labels with the same name as the AA function’s specification. The way it works is that the driver matches labels between the spec and the dataset, and replaces the label IDs in the shape objects with those defined in the dataset.\nFor example, suppose the AA function’s spec defines the following labels:\nName ID bat 0 rat 1 And the dataset defines the following labels:\nName ID bat 100 cat 101 rat 102 Then suppose detect returns a shape with label_id equal to 1. The driver will see that it refers to the rat label, and replace it with 102, since that’s the ID this label has in the dataset.\nThe same logic is used for sublabel and attribute IDs.\nHelper factory functions The CVAT API model types used in the detection function protocol are somewhat unwieldy to work with, so it’s recommended to use the helper factory functions provided by this layer. These helpers instantiate an object of their corresponding model type, passing their arguments to the model constructor and sometimes setting some attributes to fixed values.\nThe following helpers are available for building specifications:\nName Model type Fixed attributes label_spec PatchedLabelRequest - skeleton_label_spec PatchedLabelRequest type=\"skeleton\" keypoint_spec SublabelRequest type=\"points\" attribute_spec AttributeRequest mutable=False checkbox_attribute_spec AttributeRequest mutable=False, input_type=\"checkbox\", values=[] number_attribute_spec AttributeRequest mutable=False, input_type=\"number\" radio_attribute_spec AttributeRequest mutable=False, input_type=\"radio\" select_attribute_spec AttributeRequest mutable=False, input_type=\"select\" text_attribute_spec AttributeRequest mutable=False, input_type=\"number\", values=[] For number_attribute_spec, it’s recommended to use the cvat_sdk.attributes.number_attribute_values function to create the values argument, since this function will enforce the constraints expected for attribute specs of this type. For example:\ncvataa.number_attribute_spec(\"size\", 1, number_attribute_values(0, 10)) The following helpers are available for use in detect:\nName Model type Fixed attributes shape LabeledShapeRequest frame=0 mask LabeledShapeRequest frame=0, type=\"mask\" polygon LabeledShapeRequest frame=0, type=\"polygon\" rectangle LabeledShapeRequest frame=0, type=\"rectangle\" skeleton LabeledShapeRequest frame=0, type=\"skeleton\" keypoint SubLabeledShapeRequest frame=0, type=\"points\" For mask, it is recommended to create the points list using the cvat_sdk.masks.encode_mask function, which will convert a bitmap into a list in the format that CVAT expects. For example:\ncvataa.mask(my_label, encode_mask( my_mask, # boolean 2D array, same size as the input image [x1, y1, x2, y2], # top left and bottom right coordinates of the mask )) To create shapes with attributes, it’s recommended to use the cvat_sdk.attributes.attribute_vals_from_dict function, which returns a list of objects that can be passed to an attributes argument:\ncvataa.rectangle( my_label, [x1, y2, x2, y2], attributes=attribute_vals_from_dict({my_attr1: val1, my_attr2: val2}) ) Tracking function protocol A tracking function is a type of AA function that analyzes an image with one or more shapes on it, and then predicts the positions of those shapes on subsequent images.\nA tracking function can only be used in agent mode. When used with a tracking function, an agent will use it to process requests from the AI tracking tools in the CVAT UI.\nWARNING: Currently, only one agent should be run for each tracking function. If multiple agents for one tracking function are run at the same time, CVAT users may experience intermittent “Tracking state not found” errors when using the function.\nA tracking function must have three attributes, spec, init_tracking_state, and track. It may also optionally have a preprocess_image attribute.\nspec must contain the AA function’s specification, which is an instance of TrackingFunctionSpec. This specification must be initialized with a single supported_shape_types parameter, defining which types of shapes the AA function is able to track. For example:\nspec = cvataa.TrackingFunctionSpec(supported_shape_types=[\"rectangle\"]) init_tracking_state must be a function accepting the following parameters:\ncontext (TrackingFunctionShapeContext). An object with information about the shape being tracked. See details below.\npp_image (type varies). A preprocessed image. Consult the description of preprocess_image for more details.\nshape (TrackableShape). A shape within the preprocessed image. TrackableShape is a minimal version of the LabeledShape SDK model, containing only the type and points fields. The shape’s type is guaranteed to be one of the types listed in the supported_shape_types field of the spec.\ninit_tracking_state must analyze the shape and create a state object containing any information that the AA function will need to predict its location on a subsequent image. It must then return this object.\ninit_tracking_state must not modify either pp_image or shape.\ntrack must be a function accepting the following parameters:\ncontext (TrackingFunctionShapeContext). An object with information about the shape being tracked. See details below.\npp_image (type varies). A preprocessed image. Consult the description of preprocess_image for more details. This image will have the same dimensions as those of the image used to create the state object.\nstate (type varies). The object returned by a previous call to init_tracking_state.\ntrack must locate the shape that was used to create the state object on the new preprocessed image. If it is able to do that, it must return its prediction as a new TrackableShape object. This object must have the same value of type as the original shape.\nIf track is unable to locate the shape, it must return None.\ntrack may modify state as needed to improve prediction accuracy on subsequent frames. It must not modify pp_image.\nA TrackingFunctionShapeContext object passed to both init_tracking_state and track will have the following field:\noriginal_shape_type (str). The type of the shape being tracked. In init_tracking_state, this is the same as shape.type. In track, this is the type of the shape that state was created from. preprocess_image, if implemented, must accept the following parameters:\ncontext (TrackingFunctionContext). This is currently a dummy object and should be ignored. In future versions, this may contain additional information.\nimage (PIL.Image.Image). An image that will be used to either start or continue tracking.\npreprocess_image must perform any analysis on the image that the function can perform independently of the shapes being tracked and return an object representing the results of that analysis. This object will be passed as pp_image to init_tracking_state and track.\nIf preprocess_image is not implemented, then the pp_image object will be the original image. In other words, the default implementation is:\ndef preprocess_image(context, image): return image Auto-annotation driver The annotate_task function uses a detection function to annotate a CVAT task. It must be called as follows:\nannotate_task(\u003cclient\u003e, \u003ctask ID\u003e, \u003cAA function\u003e, \u003coptional arguments...\u003e) The supplied client will be used to make all API calls.\nBy default, new annotations will be appended to the old ones. Use clear_existing=True to remove old annotations instead.\nIf a detection function declares a label that has no matching label in the task, then by default, BadFunctionError is raised, and auto-annotation is aborted. If you use allow_unmatched_label=True, then such labels will be ignored, and any shapes referring to them will be dropped. Same logic applies to sublabels and attributes.\nIt’s possible to pass a custom confidence threshold to the function via the conf_threshold parameter.\nannotate_task will raise a BadFunctionError exception if it detects that the function violated the detection function protocol.\nPredefined AA functions This layer includes several predefined detection functions. You can use them as-is, or as a base on which to build your own.\nEach function is implemented as a module to allow usage via the CLI auto-annotate command. Therefore, in order to use it from the SDK, you’ll need to import the corresponding module.\ncvat_sdk.auto_annotation.functions.torchvision_detection This AA function uses object detection models from the torchvision library. It produces rectangle annotations.\nTo use it, install CVAT SDK with the pytorch extra:\n$ pip install \"cvat-sdk[pytorch]\" Usage from Python:\nfrom cvat_sdk.auto_annotation.functions.torchvision_detection import create as create_torchvision annotate_task(\u003cclient\u003e, \u003ctask ID\u003e, create_torchvision(\u003cmodel name\u003e, ...)) Usage from the CLI:\ncvat-cli auto-annotate \"\u003ctask ID\u003e\" --function-module cvat_sdk.auto_annotation.functions.torchvision_detection \\ -p model_name=str:\"\u003cmodel name\u003e\" ... The create function accepts the following parameters:\nmodel_name (str) - the name of the model, such as fasterrcnn_resnet50_fpn_v2. This parameter is required. weights_name (str) - the name of a weights enum value for the model, such as COCO_V1. Defaults to DEFAULT. It also accepts arbitrary additional parameters, which are passed directly to the model constructor.\ncvat_sdk.auto_annotation.functions.torchvision_instance_segmentation This AA function is analogous to torchvision_detection, except it uses torchvision’s instance segmentation models and produces mask or polygon annotations (depending on the value of conv_mask_to_poly).\nRefer to that function’s description for usage instructions and parameter information.\ncvat_sdk.auto_annotation.functions.torchvision_keypoint_detection This AA function is analogous to torchvision_detection, except it uses torchvision’s keypoint detection models and produces skeleton annotations. Keypoints which the model marks as invisible will be marked as occluded in CVAT.\nRefer to that function’s description for usage instructions and parameter information.\n","categories":"","description":"","excerpt":"Overview This layer provides functionality that allows you to automate …","ref":"/v2.43.0/docs/api_sdk/sdk/auto-annotation/","tags":"","title":"Auto-annotation API"},{"body":"Cutting holes in polygons Currently, CVAT does not support cutting transparent holes in polygons. However, it is possible to generate holes in exported instance and class masks. To do this, one needs to define a background class in the task and draw holes with it as additional shapes above the shapes needed to have holes:\nThe editor window:\nRemember to use z-axis ordering for shapes by [-] and [+, =] keys.\nExported masks:\nNotice that it is currently impossible to have a single instance number for internal shapes (they will be merged into the largest one and then covered by “holes”).\nCreating masks There are several formats in CVAT that can be used to export masks:\nSegmentation Mask (PASCAL VOC masks) CamVid MOTS ICDAR COCO (RLE-encoded instance masks, guide) Datumaro An example of exported masks (in the Segmentation Mask format):\nImportant notices:\nBoth boxes and polygons are converted into masks Grouped objects are considered as a single instance and exported as a single mask (label and attributes are taken from the largest object in the group) Class colors All the labels have associated colors, which are used in the generated masks. These colors can be changed in the task label properties:\nLabel colors are also displayed in the annotation window on the right panel, where you can show or hide specific labels (only the presented labels are displayed):\nA background class can be:\nA default class, which is implicitly-added, of black color (RGB 0, 0, 0) background class with any color (has a priority, name is case-insensitive) Any class of black color (RGB 0, 0, 0) To change background color in generated masks (default is black), change background class color to the desired one.\n","categories":"","description":"","excerpt":"Cutting holes in polygons Currently, CVAT does not support cutting …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polygons/creating-mask/","tags":"","title":"Creating masks"},{"body":"The Pascal VOC (Visual Object Classes) format is one of the earlier established benchmarks for object classification and detection, which provides a standardized image data set for object class recognition.\nThe export data format is XML-based and has been widely adopted in computer vision tasks.\nFor more information, see:\nPascal VOC Format specification Dataset examples Pascal VOC export For export of images:\nSupported annotations: Bounding Boxes (detection), Tags (classification), Polygons (segmentation) Attributes: occluded as both UI option and a separate attribute. truncated and difficult must be defined for labels as checkbox. Arbitrary attributes in the attributes section of XML files. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── JPEGImages/ │ ├── \u003cimage_name1\u003e.jpg │ ├── \u003cimage_name2\u003e.jpg │ └── \u003cimage_nameN\u003e.jpg ├── Annotations/ │ ├── \u003cimage_name1\u003e.xml │ ├── \u003cimage_name2\u003e.xml │ └── \u003cimage_nameN\u003e.xml ├── ImageSets/ │ └── Main/ │ └── default.txt └── labelmap.txt # labelmap.txt # label : color_rgb : 'body' parts : actions background::: aeroplane::: bicycle::: bird::: Pascal VOC import Supported attributes: action attributes (import only, should be defined as checkbox -es)\nUploaded file: a zip archive of the structure declared above or the following:\ntaskname.zip/ ├── \u003cimage_name1\u003e.xml ├── \u003cimage_name2\u003e.xml └── \u003cimage_nameN\u003e.xml It must be possible for CVAT to match the frame name and file name from annotation .xml file (the filename tag, e. g. \u003cfilename\u003e2008_004457.jpg\u003c/filename\u003e ).\nThere are 2 options:\nfull match between frame name and file name from annotation .xml (in cases when task was created from images or image archive).\nmatch by frame number. File name should be \u003cnumber\u003e.jpg or frame_000000.jpg. It should be used when task was created from video.\nHow to create a task from Pascal VOC dataset Download the Pascal Voc dataset (Can be downloaded from the PASCAL VOC website)\nCreate a CVAT task with the following labels:\naeroplane bicycle bird boat bottle bus car cat chair cow diningtable dog horse motorbike person pottedplant sheep sofa train tvmonitor You can add ~checkbox=difficult:false ~checkbox=truncated:false attributes for each label if you want to use them.\nSelect interesting image files (See Creating an annotation task guide for details)\nzip the corresponding annotation files\nclick Upload annotation button, choose Pascal VOC ZIP 1.1\nand select the zip file with annotations from previous step. It may take some time.\n","categories":"","description":"How to export and import data in Pascal VOC format","excerpt":"How to export and import data in Pascal VOC format","ref":"/v2.43.0/docs/manual/advanced/formats/format-voc/","tags":"","title":"Pascal VOC"},{"body":"Overview Segment Anything 2 is a segmentation model that allows fast and precise selection of any object in videos or images. For enterprise customers, this model can be installed in their self-hosted solution. To ensure a good experience, it is strongly recommended to deploy the model using a GPU. Although it is possible to use a CPU-based version, it generally performs much slower and is suitable only for handling a single parallel request. Unlike a regular tracking model, the SAM 2 tracker is implemented as an annotation action. This allows it to be applied to existing objects (polygons and masks) to track them forward for a specified number of frames.\nHow to install Note This feature is not available in the community CVAT version. Note This feature requires the enhanced actions UI plugin, which is enabled by default. Usually, no additional steps are necessary on this. Docker You can use existing scripts from the community repository (./serverless/deploy_cpu.sh or ./serverless/deploy_gpu.sh). To deploy the feature, simply run:\n./serverless/deploy_gpu.sh \"path/to/the/function\" Kubernetes You need to deploy the Nuclio function manually. Note that this function requires a Redis storage configured to keep the tracking state. You may use the same storage as cvat_redis_ondisk uses. When running the nuclio deploy command, make sure to provide the necessary arguments. The minimal command is: nuctl deploy \"path/to/the/function\" --env CVAT_FUNCTIONS_REDIS_HOST=\"\u003credis_host\u003e\" --env CVAT_FUNCTIONS_REDIS_PORT=\"\u003credis_port\u003e\" --env CVAT_FUNCTIONS_REDIS_PASSWORD=\"\u003credis_password\u003e\" # if applicable Running on an object The tracker can be applied to any polygons and masks. To run the tracker on an object, open the object menu and click “Run annotation action”.\nAlternatively, you can use a hotkey: select the object and press Ctrl + E (default shortcut). When the modal opened, in “Select action” list, choose Segment Anything 2: Tracker:\nSpecify the target frame until which you want the object to be tracked, then click the Run button to start tracking. The process begins and may take some time to complete. The duration depends on the inference device, and the number of frames where the object will be tracked.\nOnce the process is complete, the modal window closes. You can review how the object was tracked. If you notice that the tracked shape deteriorates at some point, you can adjust the object coordinates and run the tracker again from that frame.\nRunning on multiple objects Instead of tracking each object individually, you can track multiple objects simultaneously. To do this, click the Menu button in the annotation view and select the Run Actions option:\nAlternatively, you can use a hotkey: just press Ctrl + E (default shortcut) when there are no objects selected. This opens the actions modal. In this case, the tracker will be applied to all visible objects of suitable types (polygons and masks). In the action list of the opened model, select Segment Anything 2: Tracker:\nSpecify the target frame until which you want the objects to be tracked, then click the Run button to start tracking. The process begins and may take some time to complete. The duration depends on the inference device, the number of simultaneously tracked objects, and the number of frames where the object will be tracked.\nOnce the process finishes, you may close the modal and review how the objects were tracked. If you notice that the tracked shapes deteriorate, you can adjust their coordinates and run the tracker again from that frame (for a single object or for many objects).\nTracker parameters Target frame: Objects will be tracked up to this frame. Must be greater than the current frame Convert polygon shapes to tracks: When enabled, all visible polygon shapes in the current frame will be converted to tracks before tracking begins. Use this option if you need tracks as the final output but started with shapes, produced for example by interactors (e.g. SAM2 or another one). ","categories":"","description":"Accelerating video labeling using SAM2 model","excerpt":"Accelerating video labeling using SAM2 model","ref":"/v2.43.0/docs/enterprise/segment-anything-2-tracker/","tags":"","title":"Segment Anything 2 Tracker"},{"body":"Segmentation masks format is often used in the training of models for tasks like semantic segmentation, instance segmentation, and panoptic segmentation.\nSegmentation Mask in CVAT is a format created by CVAT engineers inside the Pascal VOC\nSegmentation mask export For export of images:\nSupported annotations: Bounding Boxes, Polygons. Attributes: Not supported. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── labelmap.txt # optional, required for non-VOC labels ├── ImageSets/ │ └── Segmentation/ │ └── default.txt # list of image names without extension ├── SegmentationClass/ # merged class masks │ ├── image1.png │ └── image2.png └── SegmentationObject/ # merged instance masks ├── image1.png └── image2.png # labelmap.txt # label : color (RGB) : 'body' parts : actions background:0,128,0:: aeroplane:10,10,128:: bicycle:10,128,0:: bird:0,108,128:: boat:108,0,100:: bottle:18,0,8:: bus:12,28,0:: The mask is a png image that can have either 1 or 3 channels. Each pixel in the image has a color that corresponds to a specific label. The colors are generated according to the Pascal VOC algorithm. By default, the color (0, 0, 0) is used to represent the background.\nSegmentation mask import Uploaded file: a zip archive of the following structure:\ntaskname.zip/ ├── labelmap.txt # optional, required for non-VOC labels ├── ImageSets/ │ └── Segmentation/ │ └── \u003cany_subset_name\u003e.txt ├── SegmentationClass/ │ ├── image1.png │ └── image2.png └── SegmentationObject/ ├── image1.png └── image2.png It is also possible to import grayscale (1-channel) PNG masks. For grayscale masks provide a list of labels with the number of lines equal to the maximum color index on images. The lines must be in the right order so that line index is equal to the color index. Lines can have arbitrary, but different, colors. If there are gaps in the used color indices in the annotations, they must be filled with arbitrary dummy labels. Example:\nq:0,128,0:: # color index 0 aeroplane:10,10,128:: # color index 1 _dummy2:2,2,2:: # filler for color index 2 _dummy3:3,3,3:: # filler for color index 3 boat:108,0,100:: # color index 3 ... _dummy198:198,198,198:: # filler for color index 198 _dummy199:199,199,199:: # filler for color index 199 ... the last label:12,28,0:: # color index 200 supported shapes: Polygons ","categories":"","description":"How to export and import data in Segmentation Mask format","excerpt":"How to export and import data in Segmentation Mask format","ref":"/v2.43.0/docs/manual/advanced/formats/format-smask/","tags":"","title":"Segmentation Mask"},{"body":"Task details is a task page that contains a preview, a progress bar, the details of the task (specified when the task was created), and the Jobs section.\nThe next actions are available on this page:\nChange the task’s title.\nOpen Actions menu.\nChange the issue tracker or open it if specified.\nChange labels (available only if the task is not related to the project).\nYou can add new labels or add attributes for the existing labels in the Raw mode or the Constructor mode. By selecting Copy you will copy the labels to the clipboard.\nAssigned to — is used to assign a task to a person. Start typing an assignee’s name and/or choose the right person out of the dropdown list. In the list of users, you will only see the users of the organization where the task is created.\nJobs is a list of all jobs for a particular task. Here you can find the next data:\nJobs name with a hyperlink to it. Frame range — the frame interval. A stage of the job. The stage is specified by a drop-down list. There are three stages: annotation, validation, or acceptance. This value affects the task progress bar. A state of the job. The state can be changed by an assigned user in the menu inside the job. There are several possible states: new, in progress, rejected, completed. Duration — is the amount of time the job is being worked. Assignee is the user who is working on the job (annotator, reviewer, or corrector). You can start typing an assignee’s name and/or choose the right person out of the dropdown list. You can filter or sort jobs by status, assignee, and updated date using the filters panel.\nFollow a link inside Jobs section to start the annotation process. In some cases, you can have several links. It depends on the size of your task and Overlap Size and Segment Size parameters. To improve UX, only the first chunk of several frames will be loaded and you will be able to annotate the first images. Other frames will be loaded in the background.\n","categories":"","description":"Overview of the Task details page.","excerpt":"Overview of the Task details page.","ref":"/v2.43.0/docs/manual/basics/task-details/","tags":"","title":"Task details"},{"body":"The issue tracker is the preferred channel for bug reports, features requests and submitting pull requests, but please respect the following restrictions:\nPlease do not use the issue tracker for personal support requests (use Stack Overflow).\nPlease do not derail or troll issues. Keep the discussion on topic and respect the opinions of others.\n","categories":"","description":"Information and rules for using the issue tracker.","excerpt":"Information and rules for using the issue tracker.","ref":"/v2.43.0/docs/contributing/using-the-issue-tracker/","tags":"","title":"Using the issue tracker"},{"body":"To learn more about annotation using a rectangle, see the sections:\nShape mode (basics) Track mode (basics) Shape mode (advanced) Track mode (advanced) Rotation rectangle To rotate the rectangle, pull on the rotation point. Rotation is done around the center of the rectangle. To rotate at a fixed angle (multiple of 15 degrees), hold shift. In the process of rotation, you can see the angle of rotation.\nAnnotation with rectangle by 4 points It is an efficient method of bounding box annotation, proposed here. Before starting, you need to make sure that the drawing method by 4 points is selected.\nPress Shape or Track for entering drawing mode. Click on four extreme points: the top, bottom, left- and right-most physical points on the object. Drawing will be automatically completed right after clicking the fourth point. Press Esc to cancel editing.\n","categories":"","description":"","excerpt":"To learn more about annotation using a rectangle, see the sections: …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-rectangles/","tags":"","title":"Annotation with rectangles"},{"body":"A bug is a demonstrable problem that is caused by the code in the repository. Good bug reports are extremely helpful - thank you!\nGuidelines for bug reports:\nUse the GitHub issue search — check if the issue has already been reported.\nCheck if the issue has been fixed — try to reproduce it using the latest develop branch in the repository.\nIsolate the problem — ideally create a reduced test case.\nA good bug report shouldn’t leave others needing to chase you up for more information. Please try to be as detailed as possible in your report. What is your environment? What steps will reproduce the issue? What browser(s) and OS experience the problem? What would you expect to be the outcome? All these details will help people to fix any potential bugs.\nExample:\nShort and descriptive example bug report title\nA summary of the issue and the browser/OS environment in which it occurs. If suitable, include the steps required to reproduce the bug.\nThis is the first step This is the second step Further steps, etc. Any other information you want to share that is relevant to the issue being reported. This might include the lines of code that you have identified as causing the bug, and potential solutions (and your opinions on their merits).\n","categories":"","description":"Guidelines and an example of how to report a bug.","excerpt":"Guidelines and an example of how to report a bug.","ref":"/v2.43.0/docs/contributing/bug-reports/","tags":"","title":"Bug reports"},{"body":"Please take a moment to review this document in order to make the contribution process easy and effective for everyone involved.\nFollowing these guidelines helps to communicate that you respect the time of the developers managing and developing this open source project. In return, they should reciprocate that respect in addressing your issue or assessing patches and features.\n","categories":"","description":"This section contains documents for CVAT developers.","excerpt":"This section contains documents for CVAT developers.","ref":"/v2.43.0/docs/contributing/","tags":"","title":"Contributing to this project"},{"body":"The Requests page allows users to track the status of data processing jobs (such as exporting annotations or importing datasets) and most of the background processes (such as task creation, quality calculation, report preparation with analytics, merge consensus jobs). Users can monitor progress, download results, and check for errors if they occur.\nRequests List On the Requests page, requests are displayed as cards. Each card contains the following details (if applicable):\nOperation Name Resource Link Status of the Request Timestamps: Enqueued Date Started Date Finished Date Result Expiration Date Annotations Format Menu to download the result or cancel a Queued job Currently supported operations include creating tasks, importing/exporting annotations and datasets, and backups.\nStatuses for Requests List The following statuses are used to indicate the state of each request:\nStatus Description In Progress The requested job is being executed. The progress percentage is shown. Queued The requested job is waiting to be picked up by a worker. Finished The requested job is finished. Downloading the result is available. Failed The requested job cannot be executed due to an unexpected error. The error description is available. ","categories":"","description":"","excerpt":"The Requests page allows users to track the status of data processing …","ref":"/v2.43.0/docs/manual/basics/requests-page/","tags":"","title":"Requests page"},{"body":"Ultralytics YOLO is a format family which consists of four formats:\nDetection Oriented bounding Box Segmentation Pose Dataset examples:\nDetection Oriented Bounding Boxes Segmentation Pose Ultralytics YOLO export For export of images:\nSupported annotations Detection: Bounding Boxes Oriented bounding box: Oriented Bounding Boxes Segmentation: Polygons, Masks Pose: Skeletons Attributes: Not supported. Tracks: Supported. The downloaded file is a .zip archive with the following structure:\narchive.zip/ ├── data.yaml # configuration file ├── train.txt # list of train subset image paths │ ├── images/ │ ├── train/ # directory with images for train subset │ │ ├── image1.jpg │ │ ├── image2.jpg │ │ ├── image3.jpg │ │ └── ... ├── labels/ │ ├── train/ # directory with annotations for train subset │ │ ├── image1.txt │ │ ├── image2.txt │ │ ├── image3.txt │ │ └── ... # train.txt: images/\u003csubset\u003e/image1.jpg images/\u003csubset\u003e/image2.jpg ... # data.yaml: path: ./ # dataset root dir train: train.txt # train images (relative to 'path') # Ultralytics YOLO Pose specific field # First number is the number of points in a skeleton. # If there are several skeletons with different number of points, it is the greatest number of points # Second number defines the format of point info in annotation txt files kpt_shape: [17, 3] # Classes names: 0: person 1: bicycle 2: car # ... # \u003cimage_name\u003e.txt: # content depends on format # Ultralytics YOLO Detection: # label_id - id from names field of data.yaml # cx, cy - relative coordinates of the bbox center # rw, rh - relative size of the bbox # label_id cx cy rw rh 1 0.3 0.8 0.1 0.3 2 0.7 0.2 0.3 0.1 # Ultralytics YOLO Oriented Bounding Boxes: # xn, yn - relative coordinates of the n-th point # label_id x1 y1 x2 y2 x3 y3 x4 y4 1 0.3 0.8 0.1 0.3 0.4 0.5 0.7 0.5 2 0.7 0.2 0.3 0.1 0.4 0.5 0.5 0.6 # Ultralytics YOLO Segmentation: # xn, yn - relative coordinates of the n-th point # label_id x1 y1 x2 y2 x3 y3 ... 1 0.3 0.8 0.1 0.3 0.4 0.5 2 0.7 0.2 0.3 0.1 0.4 0.5 0.5 0.6 0.7 0.5 # Ultralytics YOLO Pose: # cx, cy - relative coordinates of the bbox center # rw, rh - relative size of the bbox # xn, yn - relative coordinates of the n-th point # vn - visibility of n-th point. 2 - visible, 1 - partially visible, 0 - not visible # if second value in kpt_shape is 3: # label_id cx cy rw rh x1 y1 v1 x2 y2 v2 x3 y3 v3 ... 1 0.3 0.8 0.1 0.3 0.3 0.8 2 0.1 0.3 2 0.4 0.5 2 0.0 0.0 0 0.0 0.0 0 2 0.3 0.8 0.1 0.3 0.7 0.2 2 0.3 0.1 1 0.4 0.5 0 0.5 0.6 2 0.7 0.5 2 # if second value in kpt_shape is 2: # label_id cx cy rw rh x1 y1 x2 y2 x3 y3 ... 1 0.3 0.8 0.1 0.3 0.3 0.8 0.1 0.3 0.4 0.5 0.0 0.0 0.0 0.0 2 0.3 0.8 0.1 0.3 0.7 0.2 0.3 0.1 0.4 0.5 0.5 0.6 0.7 0.5 # Note, that if there are several skeletons with different number of points, # smaller skeletons are padded with points with coordinates 0.0 0.0 and visibility = 0 All coordinates must be normalized. It can be achieved by dividing x coordinates and widths by image width, and y coordinates and heights by image height.\nNote In CVAT you can place an object or some parts of it outside the image, which will cause the coordinates to be outside the [0, 1] range. YOLOv8 framework ignores labels with such coordinates. Each annotation file, with the .txt extension, is named to correspond with its associated image file.\nFor example, frame_000001.txt serves as the annotation for the frame_000001.jpg image.\nTrack support Tracks can be saved on export for Detection by using Ultralytics YOLO Detection Track format. It writes track ids to the end of corresponding annotations:\n# label_id cx cy rw rh \u003coptional track_id\u003e 1 0.3 0.8 0.1 0.3 1 2 0.7 0.2 0.3 0.1 Import Uploaded file: a zip archive of the same structure as above.\nFor compatibility with other tools exporting in Ultralytics YOLO format (e.g. roboflow), CVAT supports datasets with the inverted directory order of subset and “images” or “labels”, i.e. both train/images/, images/train/ are valid inputs.\narchive.zip/ ├── train/ │ ├── images/ # directory with images for train subset │ │ ├── image1.jpg │ │ ├── image2.jpg │ │ └── ... │ ├── labels/ # directory with annotations for train subset │ │ ├── image1.txt │ │ ├── image2.txt │ │ └── ... Track support Import in each of the Ultralytics YOLO formats support tracking. Integer track id can be added to the end of any annotation, e.g. with Detection format:\n# label_id cx cy rw rh \u003coptional track_id\u003e 1 0.3 0.8 0.1 0.3 1 2 0.7 0.2 0.3 0.1 ","categories":"","description":"How to export and import data in Ultralytics YOLO formats","excerpt":"How to export and import data in Ultralytics YOLO formats","ref":"/v2.43.0/docs/manual/advanced/formats/format-yolo-ultralytics/","tags":"","title":"Ultralytics YOLO"},{"body":"For more information, see:\nFormat specification Dataset examples Ultralytics YOLO Classification export For export of images:\nSupported annotations: Tags. Attributes: Not supported. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\narchive.zip/ ├── train │ ├── labels.json # CVAT extension. Contains original ids and labels │ │ # is not needed when using dataset with YOLOv8 framework │ │ # but is useful when importing it back to CVAT │ ├── label_0 │ │ ├── \u003cimage_name_0\u003e.jpg │ │ ├── \u003cimage_name_1\u003e.jpg │ │ ├── \u003cimage_name_2\u003e.jpg │ │ ├── ... │ ├── label_1 │ │ ├── \u003cimage_name_0\u003e.jpg │ │ ├── \u003cimage_name_1\u003e.jpg │ │ ├── \u003cimage_name_2\u003e.jpg │ │ ├── ... ├── ... ","categories":"","description":"How to export and import data in Ultralytics YOLO Classification format","excerpt":"How to export and import data in Ultralytics YOLO Classification …","ref":"/v2.43.0/docs/manual/advanced/formats/format-yolo-ultralytics-classification/","tags":"","title":"Ultralytics-YOLO-Classification"},{"body":"YOLO, which stands for “You Only Look Once,” is a renowned framework predominantly utilized for real-time object detection tasks. Its efficiency and speed make it an ideal choice for many applications. While YOLO has its unique data format, this format can be tailored to suit other object detection models as well.\nFor more information, see:\nYOLO Specification Format specification Dataset examples YOLO export For export of images:\nSupported annotations: Bounding Boxes. Attributes: Not supported. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\narchive.zip/ ├── obj.data ├── obj.names ├── obj_\u003csubset\u003e_data │ ├── image1.txt │ └── image2.txt └── train.txt # list of subset image paths # the only valid subsets are: train, valid # train.txt and valid.txt: obj_\u003csubset\u003e_data/image1.jpg obj_\u003csubset\u003e_data/image2.jpg # obj.data: classes = 3 # optional names = obj.names train = train.txt valid = valid.txt # optional backup = backup/ # optional # obj.names: cat dog airplane # image_name.txt: # label_id - id from obj.names # cx, cy - relative coordinates of the bbox center # rw, rh - relative size of the bbox # label_id cx cy rw rh 1 0.3 0.8 0.1 0.3 2 0.7 0.2 0.3 0.1 Each annotation file, with the .txt extension, is named to correspond with its associated image file.\nFor example, frame_000001.txt serves as the annotation for the frame_000001.jpg image.\nThe structure of the .txt file is as follows: each line describes a label and a bounding box in the format label_id cx cy w h. The file obj.names contains an ordered list of label names.\nYOLO import Uploaded file: a zip archive of the same structure as above It must be possible to match the CVAT frame (image name) and annotation file name. There are 2 options:\nfull match between image name and name of annotation *.txt file (in cases when a task was created from images or archive of images).\nmatch by frame number (if CVAT cannot match by name). File name should be in the following format \u003cnumber\u003e.jpg . It should be used when task was created from a video.\nHow to create a task from YOLO formatted dataset (from VOC for example) Follow the official guide (see Training YOLO on VOC section) and prepare the YOLO formatted annotation files.\nZip train images\nzip images.zip -j -@ \u003c train.txt Create a CVAT task with the following labels:\naeroplane bicycle bird boat bottle bus car cat chair cow diningtable dog horse motorbike person pottedplant sheep sofa train tvmonitor Select images. zip as data. Most likely you should use share functionality because size of images. zip is more than 500Mb. See Creating an annotation task guide for details.\nCreate obj.names with the following content:\naeroplane bicycle bird boat bottle bus car cat chair cow diningtable dog horse motorbike person pottedplant sheep sofa train tvmonitor Zip all label files together (we need to add only label files that correspond to the train subset):\ncat train.txt | while read p; do echo ${p%/*/*}/labels/${${p##*/}%%.*}.txt; done | zip labels.zip -j -@ obj.names Click Upload annotation button, choose YOLO 1.1 and select the zip file with labels from the previous step.\n","categories":"","description":"How to export and import data in YOLO format","excerpt":"How to export and import data in YOLO format","ref":"/v2.43.0/docs/manual/advanced/formats/format-yolo/","tags":"","title":"YOLO"},{"body":"","categories":"","description":"Guide to creating and editing polygons.","excerpt":"Guide to creating and editing polygons.","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polygons/","tags":"","title":"Annotation with polygons"},{"body":"Feature requests are welcome. But take a moment to find out whether your idea fits with the scope and aims of the project. It’s up to you to make a strong case to convince the project’s developers of the merits of this feature. Please provide as much detail and context as possible.\n","categories":"","description":"Information on requesting new features.","excerpt":"Information on requesting new features.","ref":"/v2.43.0/docs/contributing/feature-requests/","tags":"","title":"Feature requests"},{"body":"It is used for road markup annotation etc.\nBefore starting, you need to select the Polyline. You can set a fixed number of points in the Number of points field, then drawing will be stopped automatically.\nClick Shape to enter drawing mode. There are two ways to draw a polyline — you either create points by clicking or by dragging a mouse on the screen while holding Shift. When Shift isn’t pressed, you can zoom in/out (when scrolling the mouse wheel) and move (when clicking the mouse wheel and moving the mouse), you can delete previous points by right-clicking on it. Press N again or click the Done button on the top panel to complete the shape. You can delete a point by clicking on it with pressed Ctrl or right-clicking on a point and selecting Delete point. Click with pressed Shift will open a polyline editor. There you can create new points(by clicking or dragging) or delete part of a polygon closing the red line on another point. Press Esc to cancel editing.\n","categories":"","description":"Guide to annotating tasks using polylines.","excerpt":"Guide to annotating tasks using polylines.","ref":"/v2.43.0/docs/manual/advanced/annotation-with-polylines/","tags":"","title":"Annotation with polylines"},{"body":"The ImageNet is typically used for a variety of computer vision tasks, including but not limited to image classification, object detection, and segmentation.\nIt is widely recognized and used in the training and benchmarking of various machine learning models.\nFor more information, see:\nImageNet site Dataset examples ImageNet export For export of images:\nSupported annotations: Tags. Attributes: Not supported. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\n# if we save images: taskname.zip/ ├── label1/ | ├── label1_image1.jpg | └── label1_image2.jpg └── label2/ ├── label2_image1.jpg ├── label2_image3.jpg └── label2_image4.jpg # if we keep only annotation: taskname.zip/ ├── \u003cany_subset_name\u003e.txt └── synsets.txt ImageNet import Uploaded file: a zip archive of the structure above\nsupported annotations: Labels ","categories":"","description":"How to export and import data in ImageNet format","excerpt":"How to export and import data in ImageNet format","ref":"/v2.43.0/docs/manual/advanced/formats/format-imagenet/","tags":"","title":"ImageNet"},{"body":"Good pull requests - patches, improvements, new features - are a fantastic help. They should remain focused in scope and avoid containing unrelated commits.\nPlease ask first before embarking on any significant pull request (e.g. implementing features, refactoring code, porting to a different language), otherwise you risk spending a lot of time working on something that the project’s developers might not want to merge into the project.\nPlease adhere to the coding conventions used throughout a project (indentation, accurate comments, etc.) and any other requirements (such as test coverage).\nFollow this process if you’d like your work considered for inclusion in the project:\nFork the project, clone your fork, and configure the remotes:\n# Clone your fork of the repo into the current directory git clone https://github.com/\u003cyour-username\u003e/\u003crepo-name\u003e # Navigate to the newly cloned directory cd \u003crepo-name\u003e # Assign the original repo to a remote called \"upstream\" git remote add upstream https://github.com/\u003cupstream-owner\u003e/\u003crepo-name\u003e If you cloned a while ago, get the latest changes from upstream:\ngit checkout \u003cdev-branch\u003e git pull upstream \u003cdev-branch\u003e Create a new topic branch (off the main project development branch) to contain your feature, change, or fix:\ngit checkout -b \u003ctopic-branch-name\u003e Commit your changes in logical chunks. Please adhere to these git commit message guidelines or your code is unlikely be merged into the main project. Use Git’s interactive rebase feature to tidy up your commits before making them public.\nLocally merge (or rebase) the upstream development branch into your topic branch:\ngit pull [--rebase] upstream \u003cdev-branch\u003e Push your topic branch up to your fork:\ngit push origin \u003ctopic-branch-name\u003e Open a Pull Request with a clear title and description.\nIMPORTANT: By submitting a patch, you agree to allow the project owner to license your work under the same license as that used by the project.\n","categories":"","description":"Instructions on how to create a pull request.","excerpt":"Instructions on how to create a pull request.","ref":"/v2.43.0/docs/contributing/pull-requests/","tags":"","title":"Pull requests"},{"body":"The WIDER Face dataset is widely used for face detection tasks. Many popular models for object detection and face detection specifically are trained on this dataset for benchmarking and deployment.\nFor more information, see:\nWIDER Face Specification Dataset examples WIDER Face export For export of images:\nSupported annotations: Bounding Boxes (with attributes), Tags. Attributes: blur, expression, illumination, pose, invalid occluded (both the annotation property \u0026 an attribute). Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── labels.txt # optional ├── wider_face_split/ │ └── wider_face_\u003cany_subset_name\u003e_bbx_gt.txt └── WIDER_\u003cany_subset_name\u003e/ └── images/ ├── 0--label0/ │ └── 0_label0_image1.jpg └── 1--label1/ └── 1_label1_image2.jpg WIDER Face import Uploaded file: a zip archive of the structure above\nsupported annotations: Rectangles (with attributes), Labels supported attributes: blur, expression, illumination, occluded, pose, invalid ","categories":"","description":"How to export and import data in Wider Face format","excerpt":"How to export and import data in Wider Face format","ref":"/v2.43.0/docs/manual/advanced/formats/format-widerface/","tags":"","title":"Wider Face"},{"body":"Properties Name Type Description Notes name str description str version str logo_url str subtitle str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str description str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/about/","tags":"","title":"About class reference"},{"body":"Properties Name Type Description Notes organization_slug str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes organization_slug str ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/accept-invitation-read/","tags":"","title":"AcceptInvitationRead class reference"},{"body":"","categories":"","description":"Guide to annotating tasks using single points or shapes containing multiple points.","excerpt":"Guide to annotating tasks using single points or shapes containing …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-points/","tags":"","title":"Annotation with points"},{"body":"Properties Name Type Description Notes annotation_ids [AnnotationId] id int [optional] [readonly] frame int [optional] [readonly] type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] report_id int [optional] [readonly] severity bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes annotation_ids [AnnotationId] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-conflict/","tags":"","title":"AnnotationConflict class reference"},{"body":" `tag` - TAG * `shape` - SHAPE * `track` - TRACK Properties Name Type Description Notes value str * tag - TAG * shape - SHAPE * track - TRACK must be one of [“tag”, “shape”, “track”, ] ","categories":"","description":"","excerpt":" `tag` - TAG * `shape` - SHAPE * `track` - TRACK Properties Name Type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-conflict-annotation-type/","tags":"","title":"AnnotationConflictAnnotationType class reference"},{"body":" `warning` - WARNING * `error` - ERROR Properties Name Type Description Notes value str * warning - WARNING * error - ERROR must be one of [“warning”, “error”, ] ","categories":"","description":"","excerpt":" `warning` - WARNING * `error` - ERROR Properties Name Type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-conflict-severity/","tags":"","title":"AnnotationConflictSeverity class reference"},{"body":" `missing_annotation` - MISSING_ANNOTATION * `extra_annotation` - EXTRA_ANNOTATION * `mismatching_label` - MISMATCHING_LABEL * `low_overlap` - LOW_OVERLAP * `mismatching_direction` - MISMATCHING_DIRECTION * `mismatching_attributes` - MISMATCHING_ATTRIBUTES * `mismatching_groups` - MISMATCHING_GROUPS * `covered_annotation` - COVERED_ANNOTATION Properties Name Type Description Notes value str * missing_annotation - MISSING_ANNOTATION * extra_annotation - EXTRA_ANNOTATION * mismatching_label - MISMATCHING_LABEL * low_overlap - LOW_OVERLAP * mismatching_direction - MISMATCHING_DIRECTION * mismatching_attributes - MISMATCHING_ATTRIBUTES * mismatching_groups - MISMATCHING_GROUPS * covered_annotation - COVERED_ANNOTATION must be one of [“missing_annotation”, “extra_annotation”, “mismatching_label”, “low_overlap”, “mismatching_direction”, “mismatching_attributes”, “mismatching_groups”, “covered_annotation”, ] ","categories":"","description":"","excerpt":" `missing_annotation` - MISSING_ANNOTATION * `extra_annotation` - …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-conflict-type/","tags":"","title":"AnnotationConflictType class reference"},{"body":"Properties Name Type Description Notes annotation_file file_type ","categories":"","description":"","excerpt":"Properties Name Type Description Notes annotation_file file_type ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-file-request/","tags":"","title":"AnnotationFileRequest class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] task_id int, none_type [optional] [readonly] project_id int, none_type [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] markdown str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-guide-read/","tags":"","title":"AnnotationGuideRead class reference"},{"body":"Properties Name Type Description Notes task_id int, none_type [optional] project_id int, none_type [optional] markdown str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes task_id int, none_type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-guide-write-request/","tags":"","title":"AnnotationGuideWriteRequest class reference"},{"body":"Properties Name Type Description Notes obj_id int [optional] [readonly] job_id int [optional] [readonly] type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] shape_type AnnotationIdShapeType [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes obj_id int [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-id/","tags":"","title":"AnnotationId class reference"},{"body":"Properties Name Type Description Notes ","categories":"","description":"","excerpt":"Properties Name Type Description Notes ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/annotation-id-shape-type/","tags":"","title":"AnnotationIdShapeType class reference"},{"body":"Properties Name Type Description Notes filename str uuid str [optional] [readonly] created_date datetime [optional] [readonly] owner BasicUser [optional] guide_id int [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes filename str uuid str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/asset-read/","tags":"","title":"AssetRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/assets Create an asset destroy DELETE /api/assets/{uuid} Delete an asset retrieve GET /api/assets/{uuid} Get an asset create create( guide_id, file, **kwargs )\nCreate an asset\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: guide_id = 1 # int | file = open('/path/to/file', 'rb') # file_type | try: (data, response) = api_client.assets_api.create( guide_id, file,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AssetsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes guide_id int file file_type There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[AssetRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - destroy destroy( uuid, **kwargs )\nDelete an asset\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: uuid = \"uuid_example\" # str | A UUID string identifying this asset. try: api_client.assets_api.destroy( uuid,) except exceptions.ApiException as e: print(\"Exception when calling AssetsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes uuid str A UUID string identifying this asset. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The asset has been deleted - retrieve retrieve( uuid, **kwargs )\nGet an asset\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: uuid = \"uuid_example\" # str | A UUID string identifying this asset. try: api_client.assets_api.retrieve( uuid,) except exceptions.ApiException as e: print(\"Exception when calling AssetsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes uuid str A UUID string identifying this asset. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Asset file - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/assets-api/","tags":"","title":"AssetsApi class reference"},{"body":"Properties Name Type Description Notes name str mutable bool input_type InputTypeEnum values [str] id int [optional] default_value str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str mutable bool …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/attribute/","tags":"","title":"Attribute class reference"},{"body":"Properties Name Type Description Notes name str mutable bool input_type InputTypeEnum values [str] id int [optional] default_value str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str mutable bool …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/attribute-request/","tags":"","title":"AttributeRequest class reference"},{"body":"Properties Name Type Description Notes spec_id int value str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes spec_id int value str ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/attribute-val/","tags":"","title":"AttributeVal class reference"},{"body":"Properties Name Type Description Notes spec_id int value str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes spec_id int value str ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/attribute-val-request/","tags":"","title":"AttributeValRequest class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create_login POST /api/auth/login create_logout POST /api/auth/logout create_password_change POST /api/auth/password/change create_password_reset POST /api/auth/password/reset create_password_reset_confirm POST /api/auth/password/reset/confirm create_register POST /api/auth/register retrieve_rules GET /api/auth/rules create_login create_login( login_serializer_ex_request, **kwargs )\nCheck the credentials and return the REST Token if the credentials are valid and authenticated. If email verification is enabled and the user has the unverified email, an email with a confirmation link will be sent. Calls Django Auth login method to register User ID in Django session framework. Accept the following POST parameters: username, email, password Return the REST Framework Token Object’s key.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: login_serializer_ex_request = LoginSerializerExRequest( username=\"username_example\", email=\"email_example\", password=\"password_example\", ) # LoginSerializerExRequest | try: (data, response) = api_client.auth_api.create_login( login_serializer_ex_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AuthApi.create_login(): %s\\n\" % e) Parameters Name Type Description Notes login_serializer_ex_request LoginSerializerExRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[Token, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - create_logout create_logout( **kwargs )\nCalls Django logout method and delete the Token object assigned to the current User object. Accepts/Returns nothing.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: (data, response) = api_client.auth_api.create_logout() pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AuthApi.create_logout(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RestAuthDetail, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - create_password_change create_password_change( password_change_request, **kwargs )\nCalls Django Auth SetPasswordForm save method. Accepts the following POST parameters: new_password1, new_password2 Returns the success/fail message.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: password_change_request = PasswordChangeRequest( old_password=\"old_password_example\", new_password1=\"new_password1_example\", new_password2=\"new_password2_example\", ) # PasswordChangeRequest | try: (data, response) = api_client.auth_api.create_password_change( password_change_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AuthApi.create_password_change(): %s\\n\" % e) Parameters Name Type Description Notes password_change_request PasswordChangeRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RestAuthDetail, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - create_password_reset create_password_reset( password_reset_serializer_ex_request, **kwargs )\nCalls Django Auth PasswordResetForm save method. Accepts the following POST parameters: email Returns the success/fail message.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: password_reset_serializer_ex_request = PasswordResetSerializerExRequest( email=\"email_example\", ) # PasswordResetSerializerExRequest | try: (data, response) = api_client.auth_api.create_password_reset( password_reset_serializer_ex_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AuthApi.create_password_reset(): %s\\n\" % e) Parameters Name Type Description Notes password_reset_serializer_ex_request PasswordResetSerializerExRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RestAuthDetail, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - create_password_reset_confirm create_password_reset_confirm( password_reset_confirm_request, **kwargs )\nPassword reset e-mail link is confirmed, therefore this resets the user’s password. Accepts the following POST parameters: token, uid, new_password1, new_password2 Returns the success/fail message.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: password_reset_confirm_request = PasswordResetConfirmRequest( new_password1=\"new_password1_example\", new_password2=\"new_password2_example\", uid=\"uid_example\", token=\"token_example\", ) # PasswordResetConfirmRequest | try: (data, response) = api_client.auth_api.create_password_reset_confirm( password_reset_confirm_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AuthApi.create_password_reset_confirm(): %s\\n\" % e) Parameters Name Type Description Notes password_reset_confirm_request PasswordResetConfirmRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RestAuthDetail, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - create_register create_register( register_serializer_ex_request, **kwargs )\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: register_serializer_ex_request = RegisterSerializerExRequest( username=\"username_example\", email=\"email_example\", password1=\"password1_example\", password2=\"password2_example\", first_name=\"first_name_example\", last_name=\"last_name_example\", ) # RegisterSerializerExRequest | try: (data, response) = api_client.auth_api.create_register( register_serializer_ex_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling AuthApi.create_register(): %s\\n\" % e) Parameters Name Type Description Notes register_serializer_ex_request RegisterSerializerExRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RegisterSerializerEx, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - retrieve_rules retrieve_rules( **kwargs )\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\",) with ApiClient(configuration) as api_client: try: api_client.auth_api.retrieve_rules() except exceptions.ApiException as e: print(\"Exception when calling AuthApi.retrieve_rules(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication No authentication required\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 No response body - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/auth-api/","tags":"","title":"AuthApi class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] slug str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/basic-organization/","tags":"","title":"BasicOrganization class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. url str [optional] [readonly] id int [optional] [readonly] first_name str [optional] last_name str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/basic-user/","tags":"","title":"BasicUser class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. first_name str [optional] last_name str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/basic-user-request/","tags":"","title":"BasicUserRequest class reference"},{"body":"The CamVid (Cambridge-driving Labeled Video Database) format is most commonly used in the realm of semantic segmentation tasks. It is particularly useful for training and evaluating models for autonomous driving and other vision-based robotics applications.\nFor more information, see:\nCamVid Specification Dataset examples CamVid export For export of images and videos:\nSupported annotations: Bounding Boxes, Polygons. Attributes: Not supported. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── label_colors.txt # optional, required for non-CamVid labels ├── \u003cany_subset_name\u003e/ | ├── image1.png | └── image2.png ├── \u003cany_subset_name\u003eannot/ | ├── image1.png | └── image2.png └── \u003cany_subset_name\u003e.txt # label_colors.txt (with color value type) # if you want to manually set the color for labels, configure label_colors.txt as follows: # color (RGB) label 0 0 0 Void 64 128 64 Animal 192 0 128 Archway 0 128 192 Bicyclist 0 128 64 Bridge # label_colors.txt (without color value type) # if you do not manually set the color for labels, it will be set automatically: # label Void Animal Archway Bicyclist Bridge A mask in the CamVid dataset is typically a .png image with either one or three channels.\nIn this image, each pixel is assigned a specific color that corresponds to a particular label.\nBy default, the color (0, 0, 0)—or black—is used to represent the background.\nCamVid import For import of images:\nUploaded file: a .zip archive of the structure above supported annotations: Polygons ","categories":"","description":"How to export and import data in CamVid format","excerpt":"How to export and import data in CamVid format","ref":"/v2.43.0/docs/manual/advanced/formats/format-camvid/","tags":"","title":"CamVid"},{"body":" `video` - VIDEO * `imageset` - IMAGESET * `list` - LIST Properties Name Type Description Notes value str * video - VIDEO * imageset - IMAGESET * list - LIST must be one of [“video”, “imageset”, “list”, ] ","categories":"","description":"","excerpt":" `video` - VIDEO * `imageset` - IMAGESET * `list` - LIST Properties …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/chunk-type/","tags":"","title":"ChunkType class reference"},{"body":"Properties Name Type Description Notes timestamp datetime events [Event] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes timestamp datetime events …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/client-events/","tags":"","title":"ClientEvents class reference"},{"body":"Properties Name Type Description Notes timestamp datetime events [EventRequest] [optional] if omitted the server will use the default value of [] previous_event ClientEventsRequestPreviousEvent [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes timestamp datetime events …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/client-events-request/","tags":"","title":"ClientEventsRequest class reference"},{"body":"Properties Name Type Description Notes scope str timestamp datetime obj_name str, none_type [optional] obj_id int, none_type [optional] obj_val str, none_type [optional] source str, none_type [optional] count int, none_type [optional] duration int [optional] if omitted the server will use the default value of 0 project_id int, none_type [optional] task_id int, none_type [optional] job_id int, none_type [optional] user_id int, none_type [optional] user_name str, none_type [optional] user_email str, none_type [optional] org_id int, none_type [optional] org_slug str, none_type [optional] payload str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes scope str timestamp datetime …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/client-events-request-previous-event/","tags":"","title":"ClientEventsRequestPreviousEvent class reference"},{"body":"Properties Name Type Description Notes content [FileInfo] next str, none_type This token is used to continue listing files in the bucket. [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes content [FileInfo] next str, …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/cloud-storage-content/","tags":"","title":"CloudStorageContent class reference"},{"body":"Properties Name Type Description Notes provider_type ProviderTypeEnum resource str display_name str credentials_type CredentialsTypeEnum id int [optional] [readonly] owner CloudStorageReadOwner [optional] manifests [str] [optional] if omitted the server will use the default value of [] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] specific_attributes str [optional] description str [optional] organization int, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes provider_type ProviderTypeEnum …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/cloud-storage-read/","tags":"","title":"CloudStorageRead class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. url str [optional] [readonly] id int [optional] [readonly] first_name str [optional] last_name str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/cloud-storage-read-owner/","tags":"","title":"CloudStorageReadOwner class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/cloudstorages Create a cloud storage destroy DELETE /api/cloudstorages/{id} Delete a cloud storage list GET /api/cloudstorages List cloud storages partial_update PATCH /api/cloudstorages/{id} Update a cloud storage retrieve GET /api/cloudstorages/{id} Get cloud storage details retrieve_actions GET /api/cloudstorages/{id}/actions Get allowed actions for a cloud storage retrieve_content_v2 GET /api/cloudstorages/{id}/content-v2 Get cloud storage content retrieve_preview GET /api/cloudstorages/{id}/preview Get a preview image for a cloud storage retrieve_status GET /api/cloudstorages/{id}/status Get the status of a cloud storage create create( cloud_storage_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate a cloud storage\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: cloud_storage_write_request = CloudStorageWriteRequest( provider_type=ProviderTypeEnum(\"AWS_S3_BUCKET\"), resource=\"resource_example\", display_name=\"display_name_example\", owner=BasicUserRequest( username=\"A\", first_name=\"first_name_example\", last_name=\"last_name_example\", ), credentials_type=CredentialsTypeEnum(\"KEY_SECRET_KEY_PAIR\"), session_token=\"session_token_example\", account_name=\"account_name_example\", key=\"key_example\", secret_key=\"secret_key_example\", connection_string=\"connection_string_example\", key_file=open('/path/to/file', 'rb'), specific_attributes=\"specific_attributes_example\", description=\"description_example\", manifests=[], ) # CloudStorageWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.cloudstorages_api.create( cloud_storage_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.create(): %s\\n\" % e) Parameters Name Type Description Notes cloud_storage_write_request CloudStorageWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CloudStorageRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - destroy destroy( id, **kwargs )\nDelete a cloud storage\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. try: api_client.cloudstorages_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The cloud storage has been removed - list list( x_organization=None, credentials_type=None, filter=None, name=None, org=None, org_id=None, owner=None, page=None, page_size=None, provider_type=None, resource=None, search=None, sort=None, **kwargs )\nList cloud storages\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) credentials_type = \"KEY_SECRET_KEY_PAIR\" # str | A simple equality filter for the credentials_type field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['provider_type', 'name', 'resource', 'credentials_type', 'owner', 'description', 'id']. (optional) name = \"name_example\" # str | A simple equality filter for the name field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) provider_type = \"AWS_S3_BUCKET\" # str | A simple equality filter for the provider_type field (optional) resource = \"resource_example\" # str | A simple equality filter for the resource field (optional) search = \"search_example\" # str | A search term. Available search_fields: ('provider_type', 'name', 'resource', 'credentials_type', 'owner', 'description') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['provider_type', 'name', 'resource', 'credentials_type', 'owner', 'description', 'id'] (optional) try: (data, response) = api_client.cloudstorages_api.list( x_organization=x_organization, credentials_type=credentials_type, filter=filter, name=name, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, provider_type=provider_type, resource=resource, search=search, sort=sort, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] credentials_type str A simple equality filter for the credentials_type field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘provider_type’, ’name’, ‘resource’, ‘credentials_type’, ‘owner’, ‘description’, ‘id’]. [optional] name str A simple equality filter for the name field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] provider_type str A simple equality filter for the provider_type field [optional] resource str A simple equality filter for the resource field [optional] search str A search term. Available search_fields: (‘provider_type’, ’name’, ‘resource’, ‘credentials_type’, ‘owner’, ‘description’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘provider_type’, ’name’, ‘resource’, ‘credentials_type’, ‘owner’, ‘description’, ‘id’] [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedCloudStorageReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_cloud_storage_write_request=None, **kwargs )\nUpdate a cloud storage\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. patched_cloud_storage_write_request = PatchedCloudStorageWriteRequest( provider_type=ProviderTypeEnum(\"AWS_S3_BUCKET\"), resource=\"resource_example\", display_name=\"display_name_example\", owner=BasicUserRequest( username=\"A\", first_name=\"first_name_example\", last_name=\"last_name_example\", ), credentials_type=CredentialsTypeEnum(\"KEY_SECRET_KEY_PAIR\"), session_token=\"session_token_example\", account_name=\"account_name_example\", key=\"key_example\", secret_key=\"secret_key_example\", connection_string=\"connection_string_example\", key_file=open('/path/to/file', 'rb'), specific_attributes=\"specific_attributes_example\", description=\"description_example\", manifests=[], ) # PatchedCloudStorageWriteRequest | (optional) try: (data, response) = api_client.cloudstorages_api.partial_update( id, patched_cloud_storage_write_request=patched_cloud_storage_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. patched_cloud_storage_write_request PatchedCloudStorageWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CloudStorageRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet cloud storage details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. try: (data, response) = api_client.cloudstorages_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CloudStorageRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_actions retrieve_actions( id, **kwargs )\nGet allowed actions for a cloud storage\nMethod return allowed actions for cloud storage. It’s required for reading/writing\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. try: (data, response) = api_client.cloudstorages_api.retrieve_actions( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.retrieve_actions(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[str, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 Cloud Storage actions (GET PUT retrieve_content_v2 retrieve_content_v2( id, manifest_path=None, next_token=None, page_size=None, prefix=None, **kwargs )\nGet cloud storage content\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. manifest_path = \"manifest_path_example\" # str | Path to the manifest file in a cloud storage (optional) next_token = \"next_token_example\" # str | Used to continue listing files in the bucket (optional) page_size = 1 # int | (optional) prefix = \"prefix_example\" # str | Prefix to filter data (optional) try: (data, response) = api_client.cloudstorages_api.retrieve_content_v2( id, manifest_path=manifest_path, next_token=next_token, page_size=page_size, prefix=prefix, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.retrieve_content_v2(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. manifest_path str Path to the manifest file in a cloud storage [optional] next_token str Used to continue listing files in the bucket [optional] page_size int [optional] prefix str Prefix to filter data [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CloudStorageContent, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 A manifest content - retrieve_preview retrieve_preview( id, **kwargs )\nGet a preview image for a cloud storage\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. try: api_client.cloudstorages_api.retrieve_preview( id,) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.retrieve_preview(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Cloud Storage preview - 400 Failed to get cloud storage preview - 404 Cloud Storage preview not found - retrieve_status retrieve_status( id, **kwargs )\nGet the status of a cloud storage\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this cloud storage. try: (data, response) = api_client.cloudstorages_api.retrieve_status( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CloudstoragesApi.retrieve_status(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this cloud storage. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[str, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 Cloud Storage status (AVAILABLE NOT_FOUND ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/cloudstorages-api/","tags":"","title":"CloudstoragesApi class reference"},{"body":"Properties Name Type Description Notes provider_type ProviderTypeEnum resource str display_name str credentials_type CredentialsTypeEnum owner BasicUserRequest [optional] session_token str [optional] account_name str [optional] key str [optional] secret_key str [optional] connection_string str [optional] key_file file_type [optional] specific_attributes str [optional] description str [optional] manifests [str] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes provider_type ProviderTypeEnum …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/cloud-storage-write-request/","tags":"","title":"CloudStorageWriteRequest class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] issue int [optional] [readonly] owner CloudStorageReadOwner [optional] message str [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/comment-read/","tags":"","title":"CommentRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/comments Create a comment destroy DELETE /api/comments/{id} Delete a comment list GET /api/comments List comments partial_update PATCH /api/comments/{id} Update a comment retrieve GET /api/comments/{id} Get comment details create create( comment_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate a comment\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: comment_write_request = CommentWriteRequest( issue=1, message=\"message_example\", ) # CommentWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.comments_api.create( comment_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CommentsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes comment_write_request CommentWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CommentRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - destroy destroy( id, **kwargs )\nDelete a comment\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this comment. try: api_client.comments_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling CommentsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this comment. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The comment has been deleted - list list( x_organization=None, filter=None, frame_id=None, issue_id=None, job_id=None, org=None, org_id=None, owner=None, page=None, page_size=None, search=None, sort=None, **kwargs )\nList comments\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['owner', 'id', 'issue_id', 'frame_id', 'job_id']. (optional) frame_id = 1 # int | A simple equality filter for the frame_id field (optional) issue_id = 1 # int | A simple equality filter for the issue_id field (optional) job_id = 1 # int | A simple equality filter for the job_id field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) search = \"search_example\" # str | A search term. Available search_fields: ('owner',) (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['owner', 'id', 'issue_id', 'frame_id', 'job_id'] (optional) try: (data, response) = api_client.comments_api.list( x_organization=x_organization, filter=filter, frame_id=frame_id, issue_id=issue_id, job_id=job_id, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, search=search, sort=sort, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CommentsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘owner’, ‘id’, ‘issue_id’, ‘frame_id’, ‘job_id’]. [optional] frame_id int A simple equality filter for the frame_id field [optional] issue_id int A simple equality filter for the issue_id field [optional] job_id int A simple equality filter for the job_id field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] search str A search term. Available search_fields: (‘owner’,) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘owner’, ‘id’, ‘issue_id’, ‘frame_id’, ‘job_id’] [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedCommentReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_comment_write_request=None, **kwargs )\nUpdate a comment\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this comment. patched_comment_write_request = PatchedCommentWriteRequest( message=\"message_example\", ) # PatchedCommentWriteRequest | (optional) try: (data, response) = api_client.comments_api.partial_update( id, patched_comment_write_request=patched_comment_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CommentsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this comment. patched_comment_write_request PatchedCommentWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CommentRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet comment details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this comment. try: (data, response) = api_client.comments_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling CommentsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this comment. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[CommentRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/comments-api/","tags":"","title":"CommentsApi class reference"},{"body":"Properties Name Type Description Notes count int [optional] if omitted the server will use the default value of 0 url str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int [optional] if omitted …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/comments-summary/","tags":"","title":"CommentsSummary class reference"},{"body":"Properties Name Type Description Notes issue int message str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes issue int message str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/comment-write-request/","tags":"","title":"CommentWriteRequest class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create_merge POST /api/consensus/merges Create a consensus merge list_settings GET /api/consensus/settings List consensus settings instances partial_update_settings PATCH /api/consensus/settings/{id} Update a consensus settings instance retrieve_settings GET /api/consensus/settings/{id} Get consensus settings instance details create_merge create_merge( consensus_merge_create_request=None, **kwargs )\nCreate a consensus merge\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: consensus_merge_create_request = ConsensusMergeCreateRequest( task_id=1, job_id=1, ) # ConsensusMergeCreateRequest | (optional) try: (data, response) = api_client.consensus_api.create_merge( consensus_merge_create_request=consensus_merge_create_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ConsensusApi.create_merge(): %s\\n\" % e) Parameters Name Type Description Notes consensus_merge_create_request ConsensusMergeCreateRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 A consensus merge request has been enqueued, the request id is returned. The request status can be checked by using common requests API: GET /api/requests/\u003crq_id\u003e - 400 Invalid or failed request, check the response data for details - list_settings list_settings( x_organization=None, filter=None, org=None, org_id=None, page=None, page_size=None, sort=None, task_id=None, **kwargs )\nList consensus settings instances\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['id', 'task_id']. (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['id'] (optional) task_id = 1 # int | A simple equality filter for the task_id field (optional) try: (data, response) = api_client.consensus_api.list_settings( x_organization=x_organization, filter=filter, org=org, org_id=org_id, page=page, page_size=page_size, sort=sort, task_id=task_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ConsensusApi.list_settings(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘id’, ’task_id’]. [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘id’] [optional] task_id int A simple equality filter for the task_id field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedConsensusSettingsList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_settings partial_update_settings( id, patched_consensus_settings_request=None, **kwargs )\nUpdate a consensus settings instance\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | An id of a consensus settings instance patched_consensus_settings_request = PatchedConsensusSettingsRequest( iou_threshold=0, quorum=0, ) # PatchedConsensusSettingsRequest | (optional) try: (data, response) = api_client.consensus_api.partial_update_settings( id, patched_consensus_settings_request=patched_consensus_settings_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ConsensusApi.partial_update_settings(): %s\\n\" % e) Parameters Name Type Description Notes id int An id of a consensus settings instance patched_consensus_settings_request PatchedConsensusSettingsRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[ConsensusSettings, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_settings retrieve_settings( id, **kwargs )\nGet consensus settings instance details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | An id of a consensus settings instance try: (data, response) = api_client.consensus_api.retrieve_settings( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ConsensusApi.retrieve_settings(): %s\\n\" % e) Parameters Name Type Description Notes id int An id of a consensus settings instance There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[ConsensusSettings, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/consensus-api/","tags":"","title":"ConsensusApi class reference"},{"body":"Properties Name Type Description Notes task_id int [optional] job_id int [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes task_id int [optional] job_id …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/consensus-merge-create-request/","tags":"","title":"ConsensusMergeCreateRequest class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] task_id int [optional] [readonly] iou_threshold float Pairwise annotation matching IoU threshold [optional] quorum float Minimum required share of sources having an annotation for it to be accepted [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/consensus-settings/","tags":"","title":"ConsensusSettings class reference"},{"body":" `KEY_SECRET_KEY_PAIR` - KEY_SECRET_KEY_PAIR * `ACCOUNT_NAME_TOKEN_PAIR` - ACCOUNT_NAME_TOKEN_PAIR * `KEY_FILE_PATH` - KEY_FILE_PATH * `ANONYMOUS_ACCESS` - ANONYMOUS_ACCESS * `CONNECTION_STRING` - CONNECTION_STRING Properties Name Type Description Notes value str * KEY_SECRET_KEY_PAIR - KEY_SECRET_KEY_PAIR * ACCOUNT_NAME_TOKEN_PAIR - ACCOUNT_NAME_TOKEN_PAIR * KEY_FILE_PATH - KEY_FILE_PATH * ANONYMOUS_ACCESS - ANONYMOUS_ACCESS * CONNECTION_STRING - CONNECTION_STRING must be one of [“KEY_SECRET_KEY_PAIR”, “ACCOUNT_NAME_TOKEN_PAIR”, “KEY_FILE_PATH”, “ANONYMOUS_ACCESS”, “CONNECTION_STRING”, ] ","categories":"","description":"","excerpt":" `KEY_SECRET_KEY_PAIR` - KEY_SECRET_KEY_PAIR * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/credentials-type-enum/","tags":"","title":"CredentialsTypeEnum class reference"},{"body":"Properties Name Type Description Notes chunks_updated_date datetime image_quality int frames [FrameMeta], none_type deleted_frames [int] chunk_size int, none_type [optional] [readonly] size int The number of frames included. Deleted frames do not affect this value. [optional] [readonly] start_frame int [optional] [readonly] stop_frame int [optional] [readonly] frame_filter str [optional] [readonly] included_frames [int], none_type A list of valid frame ids. The None value means all frames are included. [optional] storage bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] cloud_storage_id int, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes chunks_updated_date datetime …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/data-meta-read/","tags":"","title":"DataMetaRead class reference"},{"body":"Read more about parameters here: https://docs.cvat.ai/docs/manual/basics/create-annotation-task/#advanced-configuration\nProperties Name Type Description Notes image_quality int Image quality to use during annotation chunk_size int, none_type Maximum number of frames per chunk [optional] start_frame int First frame index [optional] stop_frame int Last frame index [optional] frame_filter str Frame filter. The only supported syntax is: ‘step=N’ [optional] client_files [file_type] Uploaded files. Must contain all files from job_file_mapping if job_file_mapping is not empty. [optional] if omitted the server will use the default value of [] server_files [str] Paths to files from a file share mounted on the server, or from a cloud storage. Must contain all files from job_file_mapping if job_file_mapping is not empty. [optional] if omitted the server will use the default value of [] remote_files [str] Direct download URLs for files. Must contain all files from job_file_mapping if job_file_mapping is not empty. [optional] if omitted the server will use the default value of [] use_zip_chunks bool When true, video chunks will be represented as zip archives with decoded video frames. When false, video chunks are represented as video segments [optional] if omitted the server will use the default value of False server_files_exclude [str] Paths to files and directories from a file share mounted on the server, or from a cloud storage that should be excluded from the directories specified in server_files. This option cannot be used together with filename_pattern. The server_files_exclude parameter cannot be used to exclude a part of dataset from an archive. Examples: Exclude all files from subfolder ‘sub/sub_1/sub_2’and single file ‘sub/image.jpg’ from specified folder: server_files = [‘sub/’], server_files_exclude = [‘sub/sub_1/sub_2/’, ‘sub/image.jpg’] Exclude all cloud storage files with prefix ‘sub’ from the content of manifest file: server_files = [‘manifest.jsonl’], server_files_exclude = [‘sub/’] [optional] if omitted the server will use the default value of [] cloud_storage_id int, none_type If not null, the files referenced by server_files will be retrieved from the cloud storage with the specified ID. The cloud storages applicable depend on the context. In the user sandbox, only the user sandbox cloud storages can be used. In an organization, only the organization cloud storages can be used. [optional] use_cache bool Enable or disable task data chunk caching for the task. Read more: https://docs.cvat.ai/docs/manual/advanced/data_on_fly/ [optional] if omitted the server will use the default value of False copy_data bool Copy data from the server file share to CVAT during the task creation. This will create a copy of the data, making the server independent from the file share availability [optional] if omitted the server will use the default value of False storage_method StorageMethod [optional] storage StorageType [optional] sorting_method SortingMethod [optional] filename_pattern str, none_type A filename filter for cloud storage files listed in the manifest. Supports fnmatch wildcards. Read more: https://docs.python.org/3/library/fnmatch.html [optional] job_file_mapping [[str]] Represents a file-to-job mapping. Useful to specify a custom job configuration during task creation. This option is not compatible with most other job split-related options. Files in the jobs must not overlap or repeat. Job file mapping files must be a subset of the input files. If directories are specified in server_files, all files obtained by recursive search in the specified directories will be used as input files. In case of missing items in the input files, an error will be raised. Example: [ [\"file1.jpg\", \"file2.jpg\"], # job #1 files [\"file3.png\"], # job #2 files [\"file4.jpg\", \"file5.png\", \"file6.bmp\"], # job #3 files ] [optional] upload_file_order [str] Allows to specify file order for client_file uploads. Only valid with the \"predefined\" sorting method selected. To state that the input files are sent in the correct order, pass an empty list. If you want to send files in an arbitrary order and reorder them afterwards on the server, pass the list of file names in the required order. [optional] validation_params DataRequestValidationParams [optional] ","categories":"","description":"","excerpt":"Read more about parameters here: …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/data-request/","tags":"","title":"DataRequest class reference"},{"body":"Properties Name Type Description Notes mode ValidationMode frame_selection_method FrameSelectionMethod random_seed int The seed value for the random number generator. The same value will produce the same frame sets. Applicable only to random frame selection methods. By default, a random value is used. [optional] frames [str] The list of file names to be included in the validation set. Applicable only to the \"manual\" frame selection method. Can only be used for images. [optional] frame_count int The number of frames to be included in the validation set. Applicable only to the \"random_uniform\" frame selection method [optional] frame_share float The share of frames to be included in the validation set. Applicable only to the \"random_uniform\" frame selection method [optional] frames_per_job_count int The number of frames to be included in the validation set from each annotation job. Applicable only to the \"random_per_job\" frame selection method [optional] frames_per_job_share float The share of frames to be included in the validation set from each annotation job. Applicable only to the \"random_per_job\" frame selection method [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes mode ValidationMode …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/data-request-validation-params/","tags":"","title":"DataRequestValidationParams class reference"},{"body":"Properties Name Type Description Notes rq_id str Request id [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes rq_id str Request id [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/data-response/","tags":"","title":"DataResponse class reference"},{"body":"Properties Name Type Description Notes dataset_file file_type ","categories":"","description":"","excerpt":"Properties Name Type Description Notes dataset_file file_type ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/dataset-file-request/","tags":"","title":"DatasetFileRequest class reference"},{"body":"Properties Name Type Description Notes name str ext str version str enabled bool dimension str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str ext str version str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/dataset-format/","tags":"","title":"DatasetFormat class reference"},{"body":"Properties Name Type Description Notes importers [DatasetFormat] exporters [DatasetFormat] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes importers [DatasetFormat] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/dataset-formats/","tags":"","title":"DatasetFormats class reference"},{"body":"Overview This package contains manually written and autogenerated files. We store only sources in the repository. To get the full package, one need to generate missing package files.\nLayout of the cvat-sdk directory gen/ - generator files cvat_sdk/ - Python package root cvat_sdk/api_client - autogenerated low-level package code cvat_sdk/core - high-level package code How to generate package code Install generator dependencies:\npip install -r cvat-sdk/gen/requirements.txt Generate package code (call from the package root directory!):\n./cvat-sdk/gen/generate.sh Install the packages:\npip install ./cvat-sdk ./cvat-cli If you want to edit package files, install them with -e:\npip install -e ./cvat-sdk -e ./cvat-cli How to edit templates If you want to edit templates, obtain them from the generator first:\ndocker run --rm -v $PWD:/local \\ openapitools/openapi-generator-cli author template \\ -o /local/generator_templates -g python Then, you can copy the modified version of the template you need into the gen/templates/openapi-generator/ directory.\nRelevant links:\nGenerator implementation, available variables in templates Mustache syntax in the generator How to test API client tests are integrated into REST API tests in /tests/python/rest_api and SDK tests are placed next to them in /tests/python/sdk. To execute, run:\npytest tests/python/rest_api tests/python/sdk SDK API design decisions The generated ApiClient code is modified from what openapi-generator does by default. Changes are mostly focused on better user experience - including better usage patterns and simpler/faster ways to achieve results.\nModifications Added Python type annotations for return types and class members. This change required us to implement a custom post-processing script, which converts generated types into correct type annotations. The types generated by default are supposed to work with the API implementation (parameter validation and parsing), but they are not applicable as type annotations (they have incorrect syntax). Custom post-processing allowed us to make these types correct type annotations. Other possible solutions:\nThere is the python-experimental API generator, which may solve some issues, but it is unstable and requires python 3.9. Our API works with 3.7, which is the lowest supported version now. Custom templates - partially works, but only in limited cases (model fields). It’s very hard to maintain the template code and logic for this. Only if checks and for loops are available in mustache templates, which is not enough for annotation generation. Separate APIs are embedded into the general APIClient class. Now we have:\nwith ApiClient(config) as api_client: result1 = api_client.foo_api.operation1() result2 = api_client.bar_api.operation2() This showed to be more convenient than the default:\nwith ApiClient(config) as api_client: foo_api = FooApi(api_client) result1 = foo_api.operation1() result2 = foo_api.operation2() bar_api = BarApi(api_client) result3 = bar_api.operation3() result4 = bar_api.operation4() This also required custom post-processing. Operation Ids are supposed to be unique in the OpenAPI / Swagger specification. Therefore, we can’t generate such schema on the server, nor we can’t expect it to be supported in the API generator.\nOperations have IDs like \u003capi\u003e/\u003cmethod\u003e_\u003cobject\u003e. This also showed to be more readable and more natural than DRF-spectacular’s default \u003capi\u003e/\u003cobject\u003e_\u003cmethod\u003e.\nServer operations have different types for input and output values. While it can be expected that an endpoint with POST/PUT methods available (like create or partial_update) has the same type for input and output (because it looks natural), it also leads to the situation, in which there are lots of read-/write-only fields, and it becomes hard for understanding. This clear type separation is supposed to make it simpler for users.\nAdded cookie management in the ApiClient class.\nAdded interface classes for models to simplify class member usage and lookup.\nDicts can be passed into API methods and model constructors instead of models. They are automatically parsed as models. In the original implementation, the user is required to pass a Configuration object each time, which is clumsy and adds little sense.\n","categories":"","description":"","excerpt":"Overview This package contains manually written and autogenerated …","ref":"/v2.43.0/docs/api_sdk/sdk/developer-guide/","tags":"","title":"Developer guide"},{"body":"Properties Name Type Description Notes scope str timestamp datetime obj_name str, none_type [optional] obj_id int, none_type [optional] obj_val str, none_type [optional] source str, none_type [optional] count int, none_type [optional] duration int [optional] if omitted the server will use the default value of 0 project_id int, none_type [optional] task_id int, none_type [optional] job_id int, none_type [optional] user_id int, none_type [optional] user_name str, none_type [optional] user_email str, none_type [optional] org_id int, none_type [optional] org_slug str, none_type [optional] payload str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes scope str timestamp datetime …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/event/","tags":"","title":"Event class reference"},{"body":"Properties Name Type Description Notes scope str timestamp datetime obj_name str, none_type [optional] obj_id int, none_type [optional] obj_val str, none_type [optional] source str, none_type [optional] count int, none_type [optional] duration int [optional] if omitted the server will use the default value of 0 project_id int, none_type [optional] task_id int, none_type [optional] job_id int, none_type [optional] user_id int, none_type [optional] user_name str, none_type [optional] user_email str, none_type [optional] org_id int, none_type [optional] org_slug str, none_type [optional] payload str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes scope str timestamp datetime …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/event-request/","tags":"","title":"EventRequest class reference"},{"body":"Properties Name Type Description Notes webhook_type WebhookType events [EventsEnum] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes webhook_type WebhookType events …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/events/","tags":"","title":"Events class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/events Log client events create_export POST /api/events/export Initiate a process to export events list GET /api/events Get an event log create create( client_events_request, x_organization=None, org=None, org_id=None, **kwargs )\nLog client events\nSends logs to the Clickhouse if it is connected\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: client_events_request = ClientEventsRequest( events=[ EventRequest( scope=\"scope_example\", obj_name=\"obj_name_example\", obj_id=1, obj_val=\"obj_val_example\", source=\"source_example\", timestamp=dateutil_parser('1970-01-01T00:00:00.00Z'), count=1, duration=0, project_id=1, task_id=1, job_id=1, user_id=1, user_name=\"user_name_example\", user_email=\"user_email_example\", org_id=1, org_slug=\"org_slug_example\", payload=\"payload_example\", ), ], previous_event=ClientEventsRequestPreviousEvent(None), timestamp=dateutil_parser('1970-01-01T00:00:00.00Z'), ) # ClientEventsRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.events_api.create( client_events_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling EventsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes client_events_request ClientEventsRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[ClientEvents, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - create_export create_export( cloud_storage_id=None, filename=None, _from=None, job_id=None, location=None, org_id=None, project_id=None, task_id=None, to=None, user_id=None, **kwargs )\nInitiate a process to export events\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Desired output file name (optional) _from = dateutil_parser('1970-01-01T00:00:00.00Z') # datetime | UTC start date for events filtration. Default is the minimal time. (optional) job_id = 1 # int | Filter events by job ID (optional) location = \"cloud_storage\" # str | Where need to save events file (optional) org_id = 1 # int | Filter events by organization ID (optional) project_id = 1 # int | Filter events by project ID (optional) task_id = 1 # int | Filter events by task ID (optional) to = dateutil_parser('1970-01-01T00:00:00.00Z') # datetime | UTC end date for events filtration. Default is the current time. (optional) user_id = 1 # int | Filter events by user ID (optional) try: (data, response) = api_client.events_api.create_export( cloud_storage_id=cloud_storage_id, filename=filename, _from=_from, job_id=job_id, location=location, org_id=org_id, project_id=project_id, task_id=task_id, to=to, user_id=user_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling EventsApi.create_export(): %s\\n\" % e) Parameters Name Type Description Notes cloud_storage_id int Storage id [optional] filename str Desired output file name [optional] _from datetime UTC start date for events filtration. Default is the minimal time. [optional] job_id int Filter events by job ID [optional] location str Where need to save events file [optional] org_id int Filter events by organization ID [optional] project_id int Filter events by project ID [optional] task_id int Filter events by task ID [optional] to datetime UTC end date for events filtration. Default is the current time. [optional] user_id int Filter events by user ID [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 - list list( action=None, filename=None, _from=None, job_id=None, org_id=None, project_id=None, query_id=None, task_id=None, to=None, user_id=None, **kwargs )\nGet an event log\nThe log is returned in the CSV format.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: action = \"download\" # str | Used to start downloading process after annotation file had been created (optional) if omitted the server will use the default value of \"download\" filename = \"filename_example\" # str | Desired output file name (optional) _from = dateutil_parser('1970-01-01T00:00:00.00Z') # datetime | UTC start date for events filtration. Default is the minimal time. (optional) job_id = 1 # int | Filter events by job ID (optional) org_id = 1 # int | Filter events by organization ID (optional) project_id = 1 # int | Filter events by project ID (optional) query_id = \"query_id_example\" # str | ID of query request that need to check or download (optional) task_id = 1 # int | Filter events by task ID (optional) to = dateutil_parser('1970-01-01T00:00:00.00Z') # datetime | UTC end date for events filtration. Default is the current time. (optional) user_id = 1 # int | Filter events by user ID (optional) try: api_client.events_api.list( action=action, filename=filename, _from=_from, job_id=job_id, org_id=org_id, project_id=project_id, query_id=query_id, task_id=task_id, to=to, user_id=user_id, ) except exceptions.ApiException as e: print(\"Exception when calling EventsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes action str Used to start downloading process after annotation file had been created [optional] if omitted the server will use the default value of “download” filename str Desired output file name [optional] _from datetime UTC start date for events filtration. Default is the minimal time. [optional] job_id int Filter events by job ID [optional] org_id int Filter events by organization ID [optional] project_id int Filter events by project ID [optional] query_id str ID of query request that need to check or download [optional] task_id int Filter events by task ID [optional] to datetime UTC end date for events filtration. Default is the current time. [optional] user_id int Filter events by user ID [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Download of file started - 201 CSV log file is ready for downloading - 202 Creating a CSV log file has been started - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/events-api/","tags":"","title":"EventsApi class reference"},{"body":" `create:comment` - CREATE:COMMENT * `create:invitation` - CREATE:INVITATION * `create:issue` - CREATE:ISSUE * `create:job` - CREATE:JOB * `create:membership` - CREATE:MEMBERSHIP * `create:project` - CREATE:PROJECT * `create:task` - CREATE:TASK * `delete:comment` - DELETE:COMMENT * `delete:invitation` - DELETE:INVITATION * `delete:issue` - DELETE:ISSUE * `delete:job` - DELETE:JOB * `delete:membership` - DELETE:MEMBERSHIP * `delete:organization` - DELETE:ORGANIZATION * `delete:project` - DELETE:PROJECT * `delete:task` - DELETE:TASK * `update:comment` - UPDATE:COMMENT * `update:issue` - UPDATE:ISSUE * `update:job` - UPDATE:JOB * `update:membership` - UPDATE:MEMBERSHIP * `update:organization` - UPDATE:ORGANIZATION * `update:project` - UPDATE:PROJECT * `update:task` - UPDATE:TASK Properties Name Type Description Notes value str * create:comment - CREATE:COMMENT * create:invitation - CREATE:INVITATION * create:issue - CREATE:ISSUE * create:job - CREATE:JOB * create:membership - CREATE:MEMBERSHIP * create:project - CREATE:PROJECT * create:task - CREATE:TASK * delete:comment - DELETE:COMMENT * delete:invitation - DELETE:INVITATION * delete:issue - DELETE:ISSUE * delete:job - DELETE:JOB * delete:membership - DELETE:MEMBERSHIP * delete:organization - DELETE:ORGANIZATION * delete:project - DELETE:PROJECT * delete:task - DELETE:TASK * update:comment - UPDATE:COMMENT * update:issue - UPDATE:ISSUE * update:job - UPDATE:JOB * update:membership - UPDATE:MEMBERSHIP * update:organization - UPDATE:ORGANIZATION * update:project - UPDATE:PROJECT * update:task - UPDATE:TASK must be one of [“create:comment”, “create:invitation”, “create:issue”, “create:job”, “create:membership”, “create:project”, “create:task”, “delete:comment”, “delete:invitation”, “delete:issue”, “delete:job”, “delete:membership”, “delete:organization”, “delete:project”, “delete:task”, “update:comment”, “update:issue”, “update:job”, “update:membership”, “update:organization”, “update:project”, “update:task”, ] ","categories":"","description":"","excerpt":" `create:comment` - CREATE:COMMENT * `create:invitation` - …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/events-enum/","tags":"","title":"EventsEnum class reference"},{"body":"Properties Name Type Description Notes name str type FileInfoTypeEnum mime_type str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str type FileInfoTypeEnum …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/file-info/","tags":"","title":"FileInfo class reference"},{"body":" `REG` - REG * `DIR` - DIR Properties Name Type Description Notes value str * REG - REG * DIR - DIR must be one of [“REG”, “DIR”, ] ","categories":"","description":"","excerpt":" `REG` - REG * `DIR` - DIR Properties Name Type Description Notes …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/file-info-type-enum/","tags":"","title":"FileInfoTypeEnum class reference"},{"body":"Properties Name Type Description Notes width int height int name str related_files int has_related_context bool [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes width int height int name str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/frame-meta/","tags":"","title":"FrameMeta class reference"},{"body":" `random_uniform` - RANDOM_UNIFORM * `random_per_job` - RANDOM_PER_JOB * `manual` - MANUAL Properties Name Type Description Notes value str * random_uniform - RANDOM_UNIFORM * random_per_job - RANDOM_PER_JOB * manual - MANUAL must be one of [“random_uniform”, “random_per_job”, “manual”, ] ","categories":"","description":"","excerpt":" `random_uniform` - RANDOM_UNIFORM * `random_per_job` - RANDOM_PER_JOB …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/frame-selection-method/","tags":"","title":"FrameSelectionMethod class reference"},{"body":"Properties Name Type Description Notes id str Request id function FunctionCallParams status str, none_type enqueued datetime, none_type started datetime, none_type ended datetime, none_type progress int, none_type [optional] if omitted the server will use the default value of 0 exc_info str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id str Request id function …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/function-call/","tags":"","title":"FunctionCall class reference"},{"body":"Properties Name Type Description Notes id str, none_type The name of the function task int, none_type The id of the task threshold float, none_type job int The id of the job [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id str, none_type The name of …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/function-call-params/","tags":"","title":"FunctionCallParams class reference"},{"body":"Properties Name Type Description Notes function str The name of the function to execute task int The id of the task to be annotated job int The id of the job to be annotated [optional] max_distance int [optional] threshold float [optional] cleanup bool Whether existing annotations should be removed [optional] if omitted the server will use the default value of False conv_mask_to_poly bool Deprecated; use conv_mask_to_poly instead [optional] conv_mask_to_poly bool Convert mask shapes to polygons [optional] mapping {str: (LabelMappingEntryRequest,)} Label mapping from the model to the task labels [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes function str The name of the …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/function-call-request/","tags":"","title":"FunctionCallRequest class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/guides Create an annotation guide destroy DELETE /api/guides/{id} Delete an annotation guide partial_update PATCH /api/guides/{id} Update an annotation guide retrieve GET /api/guides/{id} Get annotation guide details create create( annotation_guide_write_request=None, **kwargs )\nCreate an annotation guide\nThe new guide will be bound either to a project or a task, depending on parameters.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: annotation_guide_write_request = AnnotationGuideWriteRequest( task_id=1, project_id=1, markdown=\"markdown_example\", ) # AnnotationGuideWriteRequest | (optional) try: (data, response) = api_client.guides_api.create( annotation_guide_write_request=annotation_guide_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling GuidesApi.create(): %s\\n\" % e) Parameters Name Type Description Notes annotation_guide_write_request AnnotationGuideWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[AnnotationGuideRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - destroy destroy( id, **kwargs )\nDelete an annotation guide\nThis also deletes all assets attached to the guide.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this annotation guide. try: api_client.guides_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling GuidesApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this annotation guide. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The annotation guide has been deleted - partial_update partial_update( id, patched_annotation_guide_write_request=None, **kwargs )\nUpdate an annotation guide\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this annotation guide. patched_annotation_guide_write_request = PatchedAnnotationGuideWriteRequest( task_id=1, project_id=1, markdown=\"markdown_example\", ) # PatchedAnnotationGuideWriteRequest | (optional) try: (data, response) = api_client.guides_api.partial_update( id, patched_annotation_guide_write_request=patched_annotation_guide_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling GuidesApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this annotation guide. patched_annotation_guide_write_request PatchedAnnotationGuideWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[AnnotationGuideRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet annotation guide details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this annotation guide. try: (data, response) = api_client.guides_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling GuidesApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this annotation guide. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[AnnotationGuideRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/guides-api/","tags":"","title":"GuidesApi class reference"},{"body":" `checkbox` - CHECKBOX * `radio` - RADIO * `number` - NUMBER * `text` - TEXT * `select` - SELECT Properties Name Type Description Notes value str * checkbox - CHECKBOX * radio - RADIO * number - NUMBER * text - TEXT * select - SELECT must be one of [“checkbox”, “radio”, “number”, “text”, “select”, ] ","categories":"","description":"","excerpt":" `checkbox` - CHECKBOX * `radio` - RADIO * `number` - NUMBER * `text` …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/input-type-enum/","tags":"","title":"InputTypeEnum class reference"},{"body":" Warning Do not use docker compose up. If you did, make sure all containers are stopped by docker compose down. To bring up cvat with auto annotation tool, from cvat root directory, you need to run:\ndocker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml up -d If you did any changes to the Docker Compose files, make sure to add --build at the end.\nTo stop the containers, simply run:\ndocker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml down You have to install nuctl command line tool to build and deploy serverless functions. Download version 1.13.0. It is important that the version you download matches the version in docker-compose.serverless.yml. For example, using wget.\nwget https://github.com/nuclio/nuclio/releases/download/\u003cversion\u003e/nuctl-\u003cversion\u003e-linux-amd64 After downloading the nuclio, give it a proper permission and do a softlink.\nsudo chmod +x nuctl-\u003cversion\u003e-linux-amd64 sudo ln -sf $(pwd)/nuctl-\u003cversion\u003e-linux-amd64 /usr/local/bin/nuctl Deploy a couple of functions. This will automatically create a cvat Nuclio project to contain the functions. Commands below should be run only after CVAT has been installed using docker compose because it runs nuclio dashboard which manages all serverless functions.\n./serverless/deploy_cpu.sh serverless/openvino/dextr ./serverless/deploy_cpu.sh serverless/openvino/omz/public/yolo-v3-tf GPU Support You will need to install Nvidia Container Toolkit. Also you will need to add --resource-limit nvidia.com/gpu=1 --triggers '{\"myHttpTrigger\": {\"maxWorkers\": 1}}' to the nuclio deployment command. You can increase the maxWorker if you have enough GPU memory. As an example, below will run on the GPU:\nnuctl deploy --project-name cvat \\ --path serverless/tensorflow/matterport/mask_rcnn/nuclio \\ --platform local --base-image tensorflow/tensorflow:1.15.5-gpu-py3 \\ --desc \"GPU based implementation of Mask RCNN on Python 3, Keras, and TensorFlow.\" \\ --image cvat/tf.matterport.mask_rcnn_gpu \\ --triggers '{\"myHttpTrigger\": {\"maxWorkers\": 1}}' \\ --resource-limit nvidia.com/gpu=1 Note:\nThe number of GPU deployed functions will be limited to your GPU memory. See deploy_gpu.sh script for more examples. For some models (namely SiamMask) you need an Nvidia driver version greater than or equal to 450.80.02. Note for Windows users:\nIf you want to use nuclio under Windows CVAT installation you should install Nvidia drivers for WSL according to this instruction and follow the steps up to “2.3 Installing Nvidia drivers”. Important requirement: you should have the latest versions of Docker Desktop, Nvidia drivers for WSL, and the latest updates from the Windows Insider Preview Dev channel.\nTroubleshooting Nuclio Functions:\nYou can open nuclio dashboard at localhost:8070. Make sure status of your functions are up and running without any error.\nTest your deployed DL model as a serverless function. The command below should work on Linux and Mac OS.\nimage=$(curl https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png --output - | base64 | tr -d '\\n') cat \u003c\u003c EOF \u003e /tmp/input.json {\"image\": \"$image\"} EOF cat /tmp/input.json | nuctl invoke openvino-omz-public-yolo-v3-tf -c 'application/json' 20.07.17 12:07:44.519 nuctl.platform.invoker (I) Executing function {\"method\": \"POST\", \"url\": \"http://:57308\", \"headers\": {\"Content-Type\":[\"application/json\"],\"X-Nuclio-Log-Level\":[\"info\"],\"X-Nuclio-Target\":[\"openvino-omz-public-yolo-v3-tf\"]}} 20.07.17 12:07:45.275 nuctl.platform.invoker (I) Got response {\"status\": \"200 OK\"} 20.07.17 12:07:45.275 nuctl (I) \u003e\u003e\u003e Start of function logs 20.07.17 12:07:45.275 ino-omz-public-yolo-v3-tf (I) Run yolo-v3-tf model {\"worker_id\": \"0\", \"time\": 1594976864570.9353} 20.07.17 12:07:45.275 nuctl (I) \u003c\u003c\u003c End of function logs \u003e Response headers: Date = Fri, 17 Jul 2020 09:07:45 GMT Content-Type = application/json Content-Length = 100 Server = nuclio \u003e Response body: [ { \"confidence\": \"0.9992254\", \"label\": \"person\", \"points\": [ 39, 124, 408, 512 ], \"type\": \"rectangle\" } ] To check for internal server errors, run docker ps -a to see the list of containers. Find the container that you are interested, e.g., nuclio-nuclio-tf-faster-rcnn-inception-v2-coco-gpu. Then check its logs by docker logs \u003cname of your container\u003e e.g.,\ndocker logs nuclio-nuclio-tf-faster-rcnn-inception-v2-coco-gpu To debug a code inside a container, you can use vscode to attach to a container instructions. To apply your changes, make sure to restart the container.\ndocker restart \u003cname_of_the_container\u003e ","categories":"","description":"Information about the installation of components needed for semi-automatic and automatic annotation.","excerpt":"Information about the installation of components needed for …","ref":"/v2.43.0/docs/administration/advanced/installation_automatic_annotation/","tags":"","title":"Semi-automatic and Automatic Annotation"},{"body":"Properties Name Type Description Notes owner CloudStorageReadOwner role RoleEnum user BasicUser organization int organization_info BasicOrganization key str [optional] [readonly] created_date datetime [optional] [readonly] expired bool, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes owner CloudStorageReadOwner …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/invitation-read/","tags":"","title":"InvitationRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description accept POST /api/invitations/{key}/accept Accept an invitation create POST /api/invitations Create an invitation decline POST /api/invitations/{key}/decline Decline an invitation destroy DELETE /api/invitations/{key} Delete an invitation list GET /api/invitations List invitations partial_update PATCH /api/invitations/{key} Update an invitation resend POST /api/invitations/{key}/resend Resend an invitation retrieve GET /api/invitations/{key} Get invitation details accept accept( key, **kwargs )\nAccept an invitation\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: key = \"key_example\" # str | A unique value identifying this invitation. try: (data, response) = api_client.invitations_api.accept( key,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.accept(): %s\\n\" % e) Parameters Name Type Description Notes key str A unique value identifying this invitation. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[AcceptInvitationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 The invitation is accepted - 400 The invitation is expired or already accepted - create create( invitation_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate an invitation\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: invitation_write_request = InvitationWriteRequest( role=RoleEnum(\"worker\"), email=\"email_example\", ) # InvitationWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.invitations_api.create( invitation_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes invitation_write_request InvitationWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[InvitationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - decline decline( key, **kwargs )\nDecline an invitation\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: key = \"key_example\" # str | A unique value identifying this invitation. try: api_client.invitations_api.decline( key,) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.decline(): %s\\n\" % e) Parameters Name Type Description Notes key str A unique value identifying this invitation. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The invitation has been declined - destroy destroy( key, **kwargs )\nDelete an invitation\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: key = \"key_example\" # str | A unique value identifying this invitation. try: api_client.invitations_api.destroy( key,) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes key str A unique value identifying this invitation. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The invitation has been deleted - list list( x_organization=None, filter=None, org=None, org_id=None, owner=None, page=None, page_size=None, search=None, sort=None, **kwargs )\nList invitations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['owner', 'user_id', 'accepted']. (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) search = \"search_example\" # str | A search term. Available search_fields: ('owner',) (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['owner', 'created_date'] (optional) try: (data, response) = api_client.invitations_api.list( x_organization=x_organization, filter=filter, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, search=search, sort=sort, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘owner’, ‘user_id’, ‘accepted’]. [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] search str A search term. Available search_fields: (‘owner’,) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘owner’, ‘created_date’] [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedInvitationReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( key, patched_invitation_write_request=None, **kwargs )\nUpdate an invitation\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: key = \"key_example\" # str | A unique value identifying this invitation. patched_invitation_write_request = PatchedInvitationWriteRequest( role=RoleEnum(\"worker\"), email=\"email_example\", ) # PatchedInvitationWriteRequest | (optional) try: (data, response) = api_client.invitations_api.partial_update( key, patched_invitation_write_request=patched_invitation_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes key str A unique value identifying this invitation. patched_invitation_write_request PatchedInvitationWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[InvitationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - resend resend( key, **kwargs )\nResend an invitation\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: key = \"key_example\" # str | A unique value identifying this invitation. try: api_client.invitations_api.resend( key,) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.resend(): %s\\n\" % e) Parameters Name Type Description Notes key str A unique value identifying this invitation. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 Invitation has been sent - 400 The invitation is already accepted - retrieve retrieve( key, **kwargs )\nGet invitation details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: key = \"key_example\" # str | A unique value identifying this invitation. try: (data, response) = api_client.invitations_api.retrieve( key,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling InvitationsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes key str A unique value identifying this invitation. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[InvitationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/invitations-api/","tags":"","title":"InvitationsApi class reference"},{"body":"Properties Name Type Description Notes role RoleEnum email str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes role RoleEnum email str ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/invitation-write-request/","tags":"","title":"InvitationWriteRequest class reference"},{"body":"Properties Name Type Description Notes position [float] comments CommentsSummary id int [optional] [readonly] frame int [optional] [readonly] job int [optional] [readonly] owner CloudStorageReadOwner [optional] assignee CloudStorageReadOwner [optional] created_date datetime, none_type [optional] [readonly] updated_date datetime, none_type [optional] [readonly] resolved bool [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes position [float] comments …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/issue-read/","tags":"","title":"IssueRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/issues Create an issue destroy DELETE /api/issues/{id} Delete an issue list GET /api/issues List issues partial_update PATCH /api/issues/{id} Update an issue retrieve GET /api/issues/{id} Get issue details create create( issue_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate an issue\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: issue_write_request = IssueWriteRequest( frame=0, position=[ 3.14, ], job=1, assignee=1, message=\"message_example\", resolved=True, ) # IssueWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.issues_api.create( issue_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling IssuesApi.create(): %s\\n\" % e) Parameters Name Type Description Notes issue_write_request IssueWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[IssueRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - destroy destroy( id, **kwargs )\nDelete an issue\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this issue. try: api_client.issues_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling IssuesApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this issue. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The issue has been deleted - list list( x_organization=None, assignee=None, filter=None, frame_id=None, job_id=None, org=None, org_id=None, owner=None, page=None, page_size=None, resolved=None, search=None, sort=None, task_id=None, **kwargs )\nList issues\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) assignee = \"assignee_example\" # str | A simple equality filter for the assignee field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['owner', 'assignee', 'id', 'job_id', 'task_id', 'resolved', 'frame_id']. (optional) frame_id = 1 # int | A simple equality filter for the frame_id field (optional) job_id = 1 # int | A simple equality filter for the job_id field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) resolved = True # bool | A simple equality filter for the resolved field (optional) search = \"search_example\" # str | A search term. Available search_fields: ('owner', 'assignee') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['owner', 'assignee', 'id', 'job_id', 'task_id', 'resolved', 'frame_id'] (optional) task_id = 1 # int | A simple equality filter for the task_id field (optional) try: (data, response) = api_client.issues_api.list( x_organization=x_organization, assignee=assignee, filter=filter, frame_id=frame_id, job_id=job_id, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, resolved=resolved, search=search, sort=sort, task_id=task_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling IssuesApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] assignee str A simple equality filter for the assignee field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘owner’, ‘assignee’, ‘id’, ‘job_id’, ’task_id’, ‘resolved’, ‘frame_id’]. [optional] frame_id int A simple equality filter for the frame_id field [optional] job_id int A simple equality filter for the job_id field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] resolved bool A simple equality filter for the resolved field [optional] search str A search term. Available search_fields: (‘owner’, ‘assignee’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘owner’, ‘assignee’, ‘id’, ‘job_id’, ’task_id’, ‘resolved’, ‘frame_id’] [optional] task_id int A simple equality filter for the task_id field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedIssueReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_issue_write_request=None, **kwargs )\nUpdate an issue\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this issue. patched_issue_write_request = PatchedIssueWriteRequest( position=[ 3.14, ], assignee=1, resolved=True, ) # PatchedIssueWriteRequest | (optional) try: (data, response) = api_client.issues_api.partial_update( id, patched_issue_write_request=patched_issue_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling IssuesApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this issue. patched_issue_write_request PatchedIssueWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[IssueRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet issue details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this issue. try: (data, response) = api_client.issues_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling IssuesApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this issue. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[IssueRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/issues-api/","tags":"","title":"IssuesApi class reference"},{"body":"Properties Name Type Description Notes url str [optional] [readonly] count int [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes url str [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/issues-summary/","tags":"","title":"IssuesSummary class reference"},{"body":"Properties Name Type Description Notes frame int position [float] job int message str assignee int, none_type [optional] resolved bool [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int position [float] job …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/issue-write-request/","tags":"","title":"IssueWriteRequest class reference"},{"body":"Properties Name Type Description Notes issues IssuesSummary labels LabelsSummary url str [optional] [readonly] id int [optional] [readonly] task_id int [optional] [readonly] project_id int, none_type [optional] [readonly] assignee JobReadAssignee [optional] guide_id int, none_type [optional] [readonly] dimension str [optional] [readonly] bug_tracker str, none_type [optional] [readonly] status bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] stage bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] state bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] mode str [optional] [readonly] frame_count int [optional] [readonly] start_frame int [optional] [readonly] stop_frame int [optional] [readonly] data_chunk_size int, none_type [optional] [readonly] data_compressed_chunk_type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] data_original_chunk_type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] organization int, none_type [optional] [readonly] target_storage JobReadTargetStorage [optional] source_storage JobReadTargetStorage [optional] assignee_updated_date datetime, none_type [optional] [readonly] parent_job_id int, none_type [optional] [readonly] consensus_replicas int [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes issues IssuesSummary labels …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-read/","tags":"","title":"JobRead class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. url str [optional] [readonly] id int [optional] [readonly] first_name str [optional] last_name str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-read-assignee/","tags":"","title":"JobReadAssignee class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] location LocationEnum [optional] cloud_storage_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-read-target-storage/","tags":"","title":"JobReadTargetStorage class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/jobs Create a job create_annotations POST /api/jobs/{id}/annotations/ Import annotations into a job create_dataset_export POST /api/jobs/{id}/dataset/export Initialize process to export resource as a dataset in a specific format destroy DELETE /api/jobs/{id} Delete a job destroy_annotations DELETE /api/jobs/{id}/annotations/ Delete job annotations list GET /api/jobs List jobs partial_update PATCH /api/jobs/{id} Update a job partial_update_annotations PATCH /api/jobs/{id}/annotations/ Update job annotations partial_update_data_meta PATCH /api/jobs/{id}/data/meta Update metainformation for media files in a job partial_update_validation_layout PATCH /api/jobs/{id}/validation_layout Allows updating current validation configuration retrieve GET /api/jobs/{id} Get job details retrieve_annotations GET /api/jobs/{id}/annotations/ Get job annotations retrieve_data GET /api/jobs/{id}/data Get data of a job retrieve_data_meta GET /api/jobs/{id}/data/meta Get metainformation for media files in a job retrieve_preview GET /api/jobs/{id}/preview Get a preview image for a job retrieve_validation_layout GET /api/jobs/{id}/validation_layout Allows getting current validation configuration update_annotations PUT /api/jobs/{id}/annotations/ Replace job annotations create create( job_write_request, **kwargs )\nCreate a job\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: job_write_request = JobWriteRequest( assignee=1, stage=JobStage(\"annotation\"), state=OperationStatus(\"new\"), type=JobType(\"annotation\"), task_id=1, frame_selection_method=FrameSelectionMethod(\"random_uniform\"), frame_count=1, frame_share=3.14, frames_per_job_count=1, frames_per_job_share=3.14, random_seed=0, frames=[ 0, ], ) # JobWriteRequest | try: (data, response) = api_client.jobs_api.create( job_write_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes job_write_request JobWriteRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[JobRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - create_annotations create_annotations( id, cloud_storage_id=None, filename=None, format=None, location=None, use_default_location=None, annotation_file_request=None, **kwargs )\nImport annotations into a job\nThe request POST /api/jobs/id/annotations initiates a background process to import annotations into a job. Please, use the GET /api/requests/\u003crq_id\u003e endpoint for checking status of the process. The rq_id parameter can be found in the response on initiating request.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Annotation file name (optional) format = \"format_example\" # str | Input format name You can get the list of supported formats at: /server/annotation/formats (optional) location = \"cloud_storage\" # str | where to import the annotation from (optional) use_default_location = True # bool | Use the location that was configured in the task to import annotation (optional) if omitted the server will use the default value of True annotation_file_request = AnnotationFileRequest( annotation_file=open('/path/to/file', 'rb'), ) # AnnotationFileRequest | (optional) try: api_client.jobs_api.create_annotations( id, cloud_storage_id=cloud_storage_id, filename=filename, format=format, location=location, use_default_location=use_default_location, annotation_file_request=annotation_file_request, ) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.create_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. cloud_storage_id int Storage id [optional] filename str Annotation file name [optional] format str Input format name You can get the list of supported formats at: /server/annotation/formats [optional] location str where to import the annotation from [optional] use_default_location bool Use the location that was configured in the task to import annotation [optional] if omitted the server will use the default value of True annotation_file_request AnnotationFileRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 Uploading has finished - 202 Uploading has been started - 405 Format is not available - create_dataset_export create_dataset_export( format, id, cloud_storage_id=None, filename=None, location=None, save_images=None, **kwargs )\nInitialize process to export resource as a dataset in a specific format\nThe request POST /api/\u003cprojects|tasks|jobs\u003e/id/dataset/export will initialize a background process to export a dataset. To check status of the process please, use GET /api/requests/\u003crq_id\u003e where rq_id is request ID returned in the response for this endpoint.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: format = \"format_example\" # str | Desired output format name You can get the list of supported formats at: /server/annotation/formats id = 1 # int | A unique integer value identifying this job. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Desired output file name (optional) location = \"cloud_storage\" # str | Where need to save downloaded dataset (optional) save_images = False # bool | Include images or not (optional) if omitted the server will use the default value of False try: (data, response) = api_client.jobs_api.create_dataset_export( format, id, cloud_storage_id=cloud_storage_id, filename=filename, location=location, save_images=save_images, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.create_dataset_export(): %s\\n\" % e) Parameters Name Type Description Notes format str Desired output format name You can get the list of supported formats at: /server/annotation/formats id int A unique integer value identifying this job. cloud_storage_id int Storage id [optional] filename str Desired output file name [optional] location str Where need to save downloaded dataset [optional] save_images bool Include images or not [optional] if omitted the server will use the default value of False There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Exporting has been started - 405 Format is not available - 409 Exporting is already in progress - destroy destroy( id, **kwargs )\nDelete a job\nRelated annotations will be deleted as well. Please note, that not every job can be removed. Currently, it is only available for Ground Truth jobs.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. try: api_client.jobs_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The job has been deleted - destroy_annotations destroy_annotations( id, **kwargs )\nDelete job annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. try: api_client.jobs_api.destroy_annotations( id,) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.destroy_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The annotation has been deleted - list list( x_organization=None, assignee=None, dimension=None, filter=None, org=None, org_id=None, page=None, page_size=None, parent_job_id=None, project_id=None, project_name=None, search=None, sort=None, stage=None, state=None, task_id=None, task_name=None, type=None, **kwargs )\nList jobs\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) assignee = \"assignee_example\" # str | A simple equality filter for the assignee field (optional) dimension = \"3d\" # str | A simple equality filter for the dimension field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['task_name', 'project_name', 'assignee', 'state', 'stage', 'id', 'task_id', 'project_id', 'updated_date', 'dimension', 'type', 'parent_job_id']. (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) parent_job_id = 1 # int | A simple equality filter for the parent_job_id field (optional) project_id = 1 # int | A simple equality filter for the project_id field (optional) project_name = \"project_name_example\" # str | A simple equality filter for the project_name field (optional) search = \"search_example\" # str | A search term. Available search_fields: ('task_name', 'project_name', 'assignee', 'state', 'stage') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['task_name', 'project_name', 'assignee', 'state', 'stage', 'id', 'task_id', 'project_id', 'updated_date', 'dimension', 'type', 'parent_job_id'] (optional) stage = \"annotation\" # str | A simple equality filter for the stage field (optional) state = \"new\" # str | A simple equality filter for the state field (optional) task_id = 1 # int | A simple equality filter for the task_id field (optional) task_name = \"task_name_example\" # str | A simple equality filter for the task_name field (optional) type = \"annotation\" # str | A simple equality filter for the type field (optional) try: (data, response) = api_client.jobs_api.list( x_organization=x_organization, assignee=assignee, dimension=dimension, filter=filter, org=org, org_id=org_id, page=page, page_size=page_size, parent_job_id=parent_job_id, project_id=project_id, project_name=project_name, search=search, sort=sort, stage=stage, state=state, task_id=task_id, task_name=task_name, type=type, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] assignee str A simple equality filter for the assignee field [optional] dimension str A simple equality filter for the dimension field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [’task_name’, ‘project_name’, ‘assignee’, ‘state’, ‘stage’, ‘id’, ’task_id’, ‘project_id’, ‘updated_date’, ‘dimension’, ’type’, ‘parent_job_id’]. [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] parent_job_id int A simple equality filter for the parent_job_id field [optional] project_id int A simple equality filter for the project_id field [optional] project_name str A simple equality filter for the project_name field [optional] search str A search term. Available search_fields: (’task_name’, ‘project_name’, ‘assignee’, ‘state’, ‘stage’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [’task_name’, ‘project_name’, ‘assignee’, ‘state’, ‘stage’, ‘id’, ’task_id’, ‘project_id’, ‘updated_date’, ‘dimension’, ’type’, ‘parent_job_id’] [optional] stage str A simple equality filter for the stage field [optional] state str A simple equality filter for the state field [optional] task_id int A simple equality filter for the task_id field [optional] task_name str A simple equality filter for the task_name field [optional] type str A simple equality filter for the type field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedJobReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_job_write_request=None, **kwargs )\nUpdate a job\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. patched_job_write_request = PatchedJobWriteRequest( assignee=1, stage=JobStage(\"annotation\"), state=OperationStatus(\"new\"), ) # PatchedJobWriteRequest | (optional) try: (data, response) = api_client.jobs_api.partial_update( id, patched_job_write_request=patched_job_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. patched_job_write_request PatchedJobWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[JobRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_annotations partial_update_annotations( action, id, patched_labeled_data_request=None, **kwargs )\nUpdate job annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: action = \"create\" # str | id = 1 # int | A unique integer value identifying this job. patched_labeled_data_request = PatchedLabeledDataRequest( version=0, tags=[ LabeledImageRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], shapes=[ LabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], tracks=[ LabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], ) # PatchedLabeledDataRequest | (optional) try: api_client.jobs_api.partial_update_annotations( action, id, patched_labeled_data_request=patched_labeled_data_request, ) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.partial_update_annotations(): %s\\n\" % e) Parameters Name Type Description Notes action str id int A unique integer value identifying this job. patched_labeled_data_request PatchedLabeledDataRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: Not defined HTTP response details Status code Description Response headers 200 Annotations successfully uploaded - partial_update_data_meta partial_update_data_meta( id, patched_job_data_meta_write_request=None, **kwargs )\nUpdate metainformation for media files in a job\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. patched_job_data_meta_write_request = PatchedJobDataMetaWriteRequest( deleted_frames=[ 0, ], ) # PatchedJobDataMetaWriteRequest | (optional) try: (data, response) = api_client.jobs_api.partial_update_data_meta( id, patched_job_data_meta_write_request=patched_job_data_meta_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.partial_update_data_meta(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. patched_job_data_meta_write_request PatchedJobDataMetaWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[DataMetaRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_validation_layout partial_update_validation_layout( id, patched_job_validation_layout_write_request=None, **kwargs )\nAllows updating current validation configuration\nWARNING: this operation is not protected from race conditions. It’s up to the user to ensure no parallel calls to this operation happen. It affects image access, including exports with images, backups, chunk downloading etc.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. patched_job_validation_layout_write_request = PatchedJobValidationLayoutWriteRequest( frame_selection_method=None, honeypot_real_frames=[ 0, ], ) # PatchedJobValidationLayoutWriteRequest | (optional) try: (data, response) = api_client.jobs_api.partial_update_validation_layout( id, patched_job_validation_layout_write_request=patched_job_validation_layout_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.partial_update_validation_layout(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. patched_job_validation_layout_write_request PatchedJobValidationLayoutWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[JobValidationLayoutRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet job details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. try: (data, response) = api_client.jobs_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[JobRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_annotations retrieve_annotations( id, action=None, cloud_storage_id=None, filename=None, format=None, location=None, **kwargs )\nGet job annotations\nDeprecation warning: Utilizing this endpoint to export job dataset in a specific format is no longer possible. Consider using new API: - POST /api/jobs/\u003cjob_id\u003e/dataset/export?save_images=True to initiate export process - GET /api/requests/\u003crq_id\u003e to check process status, where rq_id is request id returned on initializing request - GET result_url to download a prepared file, where result_url can be found in the response on checking status request\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. action = \"action_example\" # str | This parameter is no longer supported (optional) cloud_storage_id = 1 # int | This parameter is no longer supported (optional) filename = \"filename_example\" # str | This parameter is no longer supported (optional) format = \"format_example\" # str | This parameter is no longer supported (optional) location = \"cloud_storage\" # str | This parameter is no longer supported (optional) try: (data, response) = api_client.jobs_api.retrieve_annotations( id, action=action, cloud_storage_id=cloud_storage_id, filename=filename, format=format, location=location, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.retrieve_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. action str This parameter is no longer supported [optional] cloud_storage_id int This parameter is no longer supported [optional] filename str This parameter is no longer supported [optional] format str This parameter is no longer supported [optional] location str This parameter is no longer supported [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[LabeledData, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - 410 API endpoint no longer handles dataset exporting process - retrieve_data retrieve_data( id, index=None, number=None, quality=None, type=None, **kwargs )\nGet data of a job\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. index = 1 # int | A unique number value identifying chunk, starts from 0 for each job (optional) number = 1 # int | A unique number value identifying chunk or frame. The numbers are the same as for the task. Deprecated for chunks in favor of 'index' (optional) quality = \"compressed\" # str | Specifies the quality level of the requested data (optional) type = \"chunk\" # str | Specifies the type of the requested data (optional) try: (data, response) = api_client.jobs_api.retrieve_data( id, index=index, number=number, quality=quality, type=type, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.retrieve_data(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. index int A unique number value identifying chunk, starts from 0 for each job [optional] number int A unique number value identifying chunk or frame. The numbers are the same as for the task. Deprecated for chunks in favor of ‘index’ [optional] quality str Specifies the quality level of the requested data [optional] type str Specifies the type of the requested data [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[file_type, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 Data of a specific type - retrieve_data_meta retrieve_data_meta( id, **kwargs )\nGet metainformation for media files in a job\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. try: (data, response) = api_client.jobs_api.retrieve_data_meta( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.retrieve_data_meta(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[DataMetaRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_preview retrieve_preview( id, **kwargs )\nGet a preview image for a job\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. try: api_client.jobs_api.retrieve_preview( id,) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.retrieve_preview(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Job image preview - retrieve_validation_layout retrieve_validation_layout( id, **kwargs )\nAllows getting current validation configuration\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. try: (data, response) = api_client.jobs_api.retrieve_validation_layout( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.retrieve_validation_layout(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[JobValidationLayoutRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - update_annotations update_annotations( id, labeled_data_request=None, **kwargs )\nReplace job annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this job. labeled_data_request = LabeledDataRequest( version=0, tags=[ LabeledImageRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], shapes=[ LabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], tracks=[ LabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], ) # LabeledDataRequest | (optional) try: api_client.jobs_api.update_annotations( id, labeled_data_request=labeled_data_request, ) except exceptions.ApiException as e: print(\"Exception when calling JobsApi.update_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this job. labeled_data_request LabeledDataRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: Not defined HTTP response details Status code Description Response headers 200 Annotations have been replaced - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/jobs-api/","tags":"","title":"JobsApi class reference"},{"body":"Properties Name Type Description Notes completed int, none_type validation int, none_type count int [optional] if omitted the server will use the default value of 0 url str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes completed int, none_type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/jobs-summary/","tags":"","title":"JobsSummary class reference"},{"body":" `annotation` - ANNOTATION * `validation` - VALIDATION * `acceptance` - ACCEPTANCE Properties Name Type Description Notes value str * annotation - ANNOTATION * validation - VALIDATION * acceptance - ACCEPTANCE must be one of [“annotation”, “validation”, “acceptance”, ] ","categories":"","description":"","excerpt":" `annotation` - ANNOTATION * `validation` - VALIDATION * `acceptance` …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-stage/","tags":"","title":"JobStage class reference"},{"body":" `annotation` - ANNOTATION * `validation` - VALIDATION * `completed` - COMPLETED Properties Name Type Description Notes value str * annotation - ANNOTATION * validation - VALIDATION * completed - COMPLETED must be one of [“annotation”, “validation”, “completed”, ] ","categories":"","description":"","excerpt":" `annotation` - ANNOTATION * `validation` - VALIDATION * `completed` - …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-status/","tags":"","title":"JobStatus class reference"},{"body":" `annotation` - ANNOTATION * `ground_truth` - GROUND_TRUTH * `consensus_replica` - CONSENSUS_REPLICA Properties Name Type Description Notes value str * annotation - ANNOTATION * ground_truth - GROUND_TRUTH * consensus_replica - CONSENSUS_REPLICA must be one of [“annotation”, “ground_truth”, “consensus_replica”, ] ","categories":"","description":"","excerpt":" `annotation` - ANNOTATION * `ground_truth` - GROUND_TRUTH * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-type/","tags":"","title":"JobType class reference"},{"body":"Properties Name Type Description Notes honeypot_count int [optional] honeypot_frames [int] The list of frame ids for honeypots in the job [optional] honeypot_real_frames [int] The list of real (validation) frame ids for honeypots in the job [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes honeypot_count int [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-validation-layout-read/","tags":"","title":"JobValidationLayoutRead class reference"},{"body":"Properties Name Type Description Notes type JobType task_id int assignee int, none_type [optional] stage JobStage [optional] state OperationStatus [optional] frame_selection_method FrameSelectionMethod [optional] frame_count int The number of frames included in the GT job. Applicable only to the \"random_uniform\" frame selection method [optional] frame_share float The share of frames included in the GT job. Applicable only to the \"random_uniform\" frame selection method [optional] frames_per_job_count int The number of frames included in the GT job from each annotation job. Applicable only to the \"random_per_job\" frame selection method [optional] frames_per_job_share float The share of frames included in the GT job from each annotation job. Applicable only to the \"random_per_job\" frame selection method [optional] random_seed int The seed value for the random number generator. The same value will produce the same frame sets. Applicable only to random frame selection methods. By default, a random value is used. [optional] frames [int] The list of frame ids. Applicable only to the \"manual\" frame selection method [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type JobType task_id int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/job-write-request/","tags":"","title":"JobWriteRequest class reference"},{"body":"Properties Name Type Description Notes name str id int [optional] color str The hex value for the RGB color. Will be generated automatically, unless specified explicitly. [optional] attributes [Attribute] The list of attributes. If you want to remove an attribute, you need to recreate the label and specify the remaining attributes. [optional] if omitted the server will use the default value of [] type bool, date, datetime, dict, float, int, list, str, none_type Associated annotation type for this label * any - ANY * cuboid - CUBOID * ellipse - ELLIPSE * mask - MASK * points - POINTS * polygon - POLYGON * polyline - POLYLINE * rectangle - RECTANGLE * skeleton - SKELETON * tag - TAG [optional] svg str [optional] sublabels **[Sublabel]** [optional] project_id int, none_type [optional] [readonly] task_id int, none_type [optional] [readonly] parent_id int, none_type [optional] [readonly] has_parent bool [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str id int [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/label/","tags":"","title":"Label class reference"},{"body":"Properties Name Type Description Notes version int [optional] if omitted the server will use the default value of 0 tags [LabeledImage] [optional] if omitted the server will use the default value of [] shapes [LabeledShape] [optional] if omitted the server will use the default value of [] tracks [LabeledTrack] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes version int [optional] if …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-data/","tags":"","title":"LabeledData class reference"},{"body":"Properties Name Type Description Notes version int [optional] if omitted the server will use the default value of 0 tags [LabeledImageRequest] [optional] if omitted the server will use the default value of [] shapes [LabeledShapeRequest] [optional] if omitted the server will use the default value of [] tracks [LabeledTrackRequest] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes version int [optional] if …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-data-request/","tags":"","title":"LabeledDataRequest class reference"},{"body":"Properties Name Type Description Notes frame int label_id int id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeVal] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int label_id int id int, …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-image/","tags":"","title":"LabeledImage class reference"},{"body":"Properties Name Type Description Notes frame int label_id int id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeValRequest] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int label_id int id int, …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-image-request/","tags":"","title":"LabeledImageRequest class reference"},{"body":"Properties Name Type Description Notes type ShapeType frame int label_id int occluded bool [optional] if omitted the server will use the default value of False outside bool [optional] if omitted the server will use the default value of False z_order int [optional] if omitted the server will use the default value of 0 rotation float [optional] if omitted the server will use the default value of 0.0 points [float] [optional] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeVal] [optional] if omitted the server will use the default value of [] elements [SubLabeledShape] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type ShapeType frame int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-shape/","tags":"","title":"LabeledShape class reference"},{"body":"Properties Name Type Description Notes type ShapeType frame int label_id int occluded bool [optional] if omitted the server will use the default value of False outside bool [optional] if omitted the server will use the default value of False z_order int [optional] if omitted the server will use the default value of 0 rotation float [optional] if omitted the server will use the default value of 0.0 points [float] [optional] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeValRequest] [optional] if omitted the server will use the default value of [] elements [SubLabeledShapeRequest] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type ShapeType frame int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-shape-request/","tags":"","title":"LabeledShapeRequest class reference"},{"body":"Properties Name Type Description Notes frame int label_id int shapes [TrackedShape] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeVal] [optional] if omitted the server will use the default value of [] elements [SubLabeledTrack] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int label_id int shapes …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-track/","tags":"","title":"LabeledTrack class reference"},{"body":"Properties Name Type Description Notes frame int label_id int shapes [TrackedShapeRequest] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeValRequest] [optional] if omitted the server will use the default value of [] elements [SubLabeledTrackRequest] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int label_id int shapes …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labeled-track-request/","tags":"","title":"LabeledTrackRequest class reference"},{"body":"Properties Name Type Description Notes name str attributes {str: (str,)} [optional] sublabels {str: (SublabelMappingEntryRequest,)} Label mapping for from the model to the task sublabels within a parent label [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str attributes {str: …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/label-mapping-entry-request/","tags":"","title":"LabelMappingEntryRequest class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description destroy DELETE /api/labels/{id} Delete a label list GET /api/labels List labels partial_update PATCH /api/labels/{id} Update a label retrieve GET /api/labels/{id} Get label details destroy destroy( id, **kwargs )\nDelete a label\nTo delete a sublabel, please use the PATCH method of the parent label.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this label. try: api_client.labels_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling LabelsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this label. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The label has been deleted - list list( x_organization=None, color=None, filter=None, job_id=None, name=None, org=None, org_id=None, page=None, page_size=None, parent=None, parent_id=None, project_id=None, search=None, sort=None, task_id=None, type=None, **kwargs )\nList labels\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) color = \"color_example\" # str | A simple equality filter for the color field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['name', 'parent', 'id', 'type', 'color', 'parent_id']. (optional) job_id = 1 # int | A simple equality filter for job id (optional) name = \"name_example\" # str | A simple equality filter for the name field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) parent = \"parent_example\" # str | A simple equality filter for the parent field (optional) parent_id = 1 # int | A simple equality filter for the parent_id field (optional) project_id = 1 # int | A simple equality filter for project id (optional) search = \"search_example\" # str | A search term. Available search_fields: ('name', 'parent') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['name', 'parent', 'id', 'type', 'color', 'parent_id'] (optional) task_id = 1 # int | A simple equality filter for task id (optional) type = \"any\" # str | A simple equality filter for the type field (optional) try: (data, response) = api_client.labels_api.list( x_organization=x_organization, color=color, filter=filter, job_id=job_id, name=name, org=org, org_id=org_id, page=page, page_size=page_size, parent=parent, parent_id=parent_id, project_id=project_id, search=search, sort=sort, task_id=task_id, type=type, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LabelsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] color str A simple equality filter for the color field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [’name’, ‘parent’, ‘id’, ’type’, ‘color’, ‘parent_id’]. [optional] job_id int A simple equality filter for job id [optional] name str A simple equality filter for the name field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] parent str A simple equality filter for the parent field [optional] parent_id int A simple equality filter for the parent_id field [optional] project_id int A simple equality filter for project id [optional] search str A search term. Available search_fields: (’name’, ‘parent’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [’name’, ‘parent’, ‘id’, ’type’, ‘color’, ‘parent_id’] [optional] task_id int A simple equality filter for task id [optional] type str A simple equality filter for the type field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedLabelList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_label_request=None, **kwargs )\nUpdate a label\nTo modify a sublabel, please use the PATCH method of the parent label.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this label. patched_label_request = PatchedLabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], deleted=True, type=None, svg=\"svg_example\", sublabels=[ SublabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], type=None, has_parent=True, ), ], ) # PatchedLabelRequest | (optional) try: (data, response) = api_client.labels_api.partial_update( id, patched_label_request=patched_label_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LabelsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this label. patched_label_request PatchedLabelRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[Label, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet label details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this label. try: (data, response) = api_client.labels_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LabelsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this label. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[Label, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/labels-api/","tags":"","title":"LabelsApi class reference"},{"body":"Properties Name Type Description Notes url str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes url str [optional] [readonly] ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/labels-summary/","tags":"","title":"LabelsSummary class reference"},{"body":" `any` - ANY * `cuboid` - CUBOID * `ellipse` - ELLIPSE * `mask` - MASK * `points` - POINTS * `polygon` - POLYGON * `polyline` - POLYLINE * `rectangle` - RECTANGLE * `skeleton` - SKELETON * `tag` - TAG Properties Name Type Description Notes value str * any - ANY * cuboid - CUBOID * ellipse - ELLIPSE * mask - MASK * points - POINTS * polygon - POLYGON * polyline - POLYLINE * rectangle - RECTANGLE * skeleton - SKELETON * tag - TAG must be one of [“any”, “cuboid”, “ellipse”, “mask”, “points”, “polygon”, “polyline”, “rectangle”, “skeleton”, “tag”, ] ","categories":"","description":"","excerpt":" `any` - ANY * `cuboid` - CUBOID * `ellipse` - ELLIPSE * `mask` - MASK …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/label-type/","tags":"","title":"LabelType class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create_functions POST /api/lambda/functions/{func_id} create_requests POST /api/lambda/requests Method calls the function delete_requests DELETE /api/lambda/requests/{id} Method cancels the request list_functions GET /api/lambda/functions Method returns a list of functions list_requests GET /api/lambda/requests Method returns a list of requests retrieve_functions GET /api/lambda/functions/{func_id} Method returns the information about the function retrieve_requests GET /api/lambda/requests/{id} Method returns the status of the request create_functions create_functions( func_id, online_function_call_request=None, **kwargs )\nAllows to execute a function for immediate computation. Intended for short-lived executions, useful for interactive calls. When executed for interactive annotation, the job id must be specified in the ‘job’ input field. The task id is not required in this case, but if it is specified, it must match the job task id.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: func_id = \"2\" # str | online_function_call_request = OnlineFunctionCallRequest( job=1, task=1, ) # OnlineFunctionCallRequest | (optional) try: api_client.lambda_api.create_functions( func_id, online_function_call_request=online_function_call_request, ) except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.create_functions(): %s\\n\" % e) Parameters Name Type Description Notes func_id str online_function_call_request OnlineFunctionCallRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: Not defined HTTP response details Status code Description Response headers 200 Returns function invocation results - create_requests create_requests( function_call_request, x_organization=None, org=None, org_id=None, **kwargs )\nMethod calls the function\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: function_call_request = FunctionCallRequest( function=\"function_example\", task=1, job=1, max_distance=1, threshold=3.14, cleanup=False, conv_mask_to_poly=True, conv_mask_to_poly=True, mapping={ \"key\": LabelMappingEntryRequest( name=\"name_example\", attributes={ \"key\": \"key_example\", }, sublabels={ \"key\": SublabelMappingEntryRequest( name=\"name_example\", attributes={ \"key\": \"key_example\", }, ), }, ), }, ) # FunctionCallRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.lambda_api.create_requests( function_call_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.create_requests(): %s\\n\" % e) Parameters Name Type Description Notes function_call_request FunctionCallRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[FunctionCall, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - delete_requests delete_requests( id, **kwargs )\nMethod cancels the request\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = \"id_example\" # str | Request id try: api_client.lambda_api.delete_requests( id,) except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.delete_requests(): %s\\n\" % e) Parameters Name Type Description Notes id str Request id There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 No response body - list_functions list_functions( **kwargs )\nMethod returns a list of functions\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: api_client.lambda_api.list_functions() except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.list_functions(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 No response body - list_requests list_requests( **kwargs )\nMethod returns a list of requests\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: (data, response) = api_client.lambda_api.list_requests() pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.list_requests(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[list[FunctionCall], urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_functions retrieve_functions( func_id, **kwargs )\nMethod returns the information about the function\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: func_id = \"2\" # str | try: (data, response) = api_client.lambda_api.retrieve_functions( func_id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.retrieve_functions(): %s\\n\" % e) Parameters Name Type Description Notes func_id str There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[dict[str, typing.Union[typing.Any, none_type]], urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 Information about the function - retrieve_requests retrieve_requests( id, **kwargs )\nMethod returns the status of the request\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = \"id_example\" # str | Request id try: (data, response) = api_client.lambda_api.retrieve_requests( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling LambdaApi.retrieve_requests(): %s\\n\" % e) Parameters Name Type Description Notes id str Request id There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[FunctionCall, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/lambda-api/","tags":"","title":"LambdaApi class reference"},{"body":" `cloud_storage` - CLOUD_STORAGE * `local` - LOCAL Properties Name Type Description Notes value str * cloud_storage - CLOUD_STORAGE * local - LOCAL must be one of [“cloud_storage”, “local”, ] ","categories":"","description":"","excerpt":" `cloud_storage` - CLOUD_STORAGE * `local` - LOCAL Properties Name …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/location-enum/","tags":"","title":"LocationEnum class reference"},{"body":"Properties Name Type Description Notes password str username str [optional] email str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes password str username str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/login-serializer-ex-request/","tags":"","title":"LoginSerializerExRequest class reference"},{"body":"Properties Name Type Description Notes user BasicUser id int [optional] [readonly] organization int [optional] [readonly] is_active bool [optional] [readonly] joined_date datetime, none_type [optional] [readonly] role bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] invitation str, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes user BasicUser id int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/membership-read/","tags":"","title":"MembershipRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description destroy DELETE /api/memberships/{id} Delete a membership list GET /api/memberships List memberships partial_update PATCH /api/memberships/{id} Update a membership retrieve GET /api/memberships/{id} Get membership details destroy destroy( id, **kwargs )\nDelete a membership\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this membership. try: api_client.memberships_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling MembershipsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this membership. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The membership has been deleted - list list( x_organization=None, filter=None, org=None, org_id=None, page=None, page_size=None, role=None, search=None, sort=None, user=None, **kwargs )\nList memberships\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['user', 'role', 'id']. (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) role = \"worker\" # str | A simple equality filter for the role field (optional) search = \"search_example\" # str | A search term. Available search_fields: ('user', 'role') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['user', 'role', 'id'] (optional) user = \"user_example\" # str | A simple equality filter for the user field (optional) try: (data, response) = api_client.memberships_api.list( x_organization=x_organization, filter=filter, org=org, org_id=org_id, page=page, page_size=page_size, role=role, search=search, sort=sort, user=user, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling MembershipsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘user’, ‘role’, ‘id’]. [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] role str A simple equality filter for the role field [optional] search str A search term. Available search_fields: (‘user’, ‘role’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘user’, ‘role’, ‘id’] [optional] user str A simple equality filter for the user field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedMembershipReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_membership_write_request=None, **kwargs )\nUpdate a membership\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this membership. patched_membership_write_request = PatchedMembershipWriteRequest( role=RoleEnum(\"worker\"), ) # PatchedMembershipWriteRequest | (optional) try: (data, response) = api_client.memberships_api.partial_update( id, patched_membership_write_request=patched_membership_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling MembershipsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this membership. patched_membership_write_request PatchedMembershipWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[MembershipRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet membership details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this membership. try: (data, response) = api_client.memberships_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling MembershipsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this membership. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[MembershipRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/memberships-api/","tags":"","title":"MembershipsApi class reference"},{"body":"Properties Name Type Description Notes url str [optional] [readonly] id int [optional] [readonly] first_name str [optional] last_name str [optional] email str [optional] is_staff bool Designates whether the user can log into this admin site. [optional] is_superuser bool Designates that this user has all permissions without explicitly assigning them. [optional] is_active bool Designates whether this user should be treated as active. Unselect this instead of deleting accounts. [optional] last_login datetime, none_type [optional] [readonly] date_joined datetime [optional] [readonly] has_analytics_access bool [optional] [readonly] username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. [optional] groups [str] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes url str [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/meta-user/","tags":"","title":"MetaUser class reference"},{"body":" Add a python script to dataset_manager/formats Add an import statement to registry.py. Implement some importers and exporters as the format requires. Each format is supported by an importer and exporter.\nIt can be a function or a class decorated with importer or exporter from registry.py. Examples:\n@importer(name=\"MyFormat\", version=\"1.0\", ext=\"ZIP\") def my_importer(file_object, task_data, **options): ... @importer(name=\"MyFormat\", version=\"2.0\", ext=\"XML\") class my_importer(file_object, task_data, **options): def __call__(self, file_object, task_data, **options): ... @exporter(name=\"MyFormat\", version=\"1.0\", ext=\"ZIP\"): def my_exporter(file_object, task_data, **options): ... Each decorator defines format parameters such as:\nname\nversion\nfile extension. For the importer it can be a comma-separated list. These parameters are combined to produce a visible name. It can be set explicitly by the display_name argument.\nImporter arguments:\nfile_object - a file with annotations or dataset task_data - an instance of TaskData class. Exporter arguments:\nfile_object - a file for annotations or dataset\ntask_data - an instance of TaskData class.\noptions - format-specific options. save_images is the option to distinguish if dataset or just annotations are requested.\nTaskData provides many task properties and interfaces to add and read task annotations.\nPublic members:\nTaskData. Attribute - class, namedtuple('Attribute', 'name, value')\nTaskData. LabeledShape - class, namedtuple('LabeledShape', 'type, frame, label, points, occluded, attributes, group, z_order')\nTrackedShape - namedtuple('TrackedShape', 'type, points, occluded, frame, attributes, outside, keyframe, z_order')\nTrack - class, namedtuple('Track', 'label, group, shapes')\nTag - class, namedtuple('Tag', 'frame, label, attributes, group')\nFrame - class, namedtuple('Frame', 'frame, name, width, height, labeled_shapes, tags')\nTaskData. shapes - property, an iterator over LabeledShape objects\nTaskData. tracks - property, an iterator over Track objects\nTaskData. tags - property, an iterator over Tag objects\nTaskData. meta - property, a dictionary with task information\nTaskData. group_by_frame() - method, returns an iterator over Frame objects, which groups annotation objects by frame. Note that TrackedShape s will be represented as LabeledShape s.\nTaskData. add_tag(tag) - method, tag should be an instance of the Tag class\nTaskData. add_shape(shape) - method, shape should be an instance of the Shape class\nTaskData. add_track(track) - method, track should be an instance of the Track class\nSample exporter code:\n... # dump meta info if necessary ... # iterate over all frames for frame_annotation in task_data.group_by_frame(): # get frame info image_name = frame_annotation.name image_width = frame_annotation.width image_height = frame_annotation.height # iterate over all shapes on the frame for shape in frame_annotation.labeled_shapes: label = shape.label xtl = shape.points[0] ytl = shape.points[1] xbr = shape.points[2] ybr = shape.points[3] # iterate over shape attributes for attr in shape.attributes: attr_name = attr.name attr_value = attr.value ... # dump annotation code file_object.write(...) ... Sample importer code:\n... #read file_object ... for parsed_shape in parsed_shapes: shape = task_data.LabeledShape( type=\"rectangle\", points=[0, 0, 100, 100], occluded=False, attributes=[], label=\"car\", outside=False, frame=99, ) task_data.add_shape(shape) Format specifications CVAT Datumaro LabelMe MOT MOTS COCO PASCAL VOC and mask YOLO ImageNet CamVid WIDER Face VGGFace2 Market-1501 ICDAR13/15 ","categories":"","description":"Instructions on adding support for new annotation formats. This section on [GitHub](https://github.com/cvat-ai/cvat/tree/develop/cvat/apps/dataset_manager/formats).","excerpt":"Instructions on adding support for new annotation formats. This …","ref":"/v2.43.0/docs/contributing/new-annotation-format/","tags":"","title":"How to add a new annotation format support"},{"body":"Properties Name Type Description Notes value str must be one of [“null”, ] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes value str must be one of …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/null-enum/","tags":"","title":"NullEnum class reference"},{"body":"Properties Name Type Description Notes job int [optional] task int [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes job int [optional] task int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/online-function-call-request/","tags":"","title":"OnlineFunctionCallRequest class reference"},{"body":" `new` - NEW * `in progress` - IN_PROGRESS * `completed` - COMPLETED * `rejected` - REJECTED Properties Name Type Description Notes value str * new - NEW * in progress - IN_PROGRESS * completed - COMPLETED * rejected - REJECTED must be one of [“new”, “in progress”, “completed”, “rejected”, ] ","categories":"","description":"","excerpt":" `new` - NEW * `in progress` - IN_PROGRESS * `completed` - COMPLETED * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/operation-status/","tags":"","title":"OperationStatus class reference"},{"body":"Properties Name Type Description Notes owner CloudStorageReadOwner id int [optional] [readonly] slug str [optional] [readonly] name str [optional] [readonly] description str [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] contact {str: (bool, date, datetime, dict, float, int, list, str, none_type)} [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes owner CloudStorageReadOwner id …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/organization-read/","tags":"","title":"OrganizationRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/organizations Create an organization destroy DELETE /api/organizations/{id} Delete an organization list GET /api/organizations List organizations partial_update PATCH /api/organizations/{id} Update an organization retrieve GET /api/organizations/{id} Get organization details create create( organization_write_request, **kwargs )\nCreate an organization\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: organization_write_request = OrganizationWriteRequest( slug=\"z\", name=\"name_example\", description=\"description_example\", contact={}, ) # OrganizationWriteRequest | try: (data, response) = api_client.organizations_api.create( organization_write_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling OrganizationsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes organization_write_request OrganizationWriteRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[OrganizationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - destroy destroy( id, **kwargs )\nDelete an organization\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this organization. try: api_client.organizations_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling OrganizationsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this organization. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The organization has been deleted - list list( filter=None, name=None, owner=None, page=None, page_size=None, search=None, slug=None, sort=None, **kwargs )\nList organizations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['name', 'owner', 'slug', 'id']. (optional) name = \"name_example\" # str | A simple equality filter for the name field (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) search = \"search_example\" # str | A search term. Available search_fields: ('name', 'owner', 'slug') (optional) slug = \"slug_example\" # str | A simple equality filter for the slug field (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['name', 'owner', 'slug', 'id'] (optional) try: (data, response) = api_client.organizations_api.list( filter=filter, name=name, owner=owner, page=page, page_size=page_size, search=search, slug=slug, sort=sort, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling OrganizationsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [’name’, ‘owner’, ‘slug’, ‘id’]. [optional] name str A simple equality filter for the name field [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] search str A search term. Available search_fields: (’name’, ‘owner’, ‘slug’) [optional] slug str A simple equality filter for the slug field [optional] sort str Which field to use when ordering the results. Available ordering_fields: [’name’, ‘owner’, ‘slug’, ‘id’] [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedOrganizationReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_organization_write_request=None, **kwargs )\nUpdate an organization\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this organization. patched_organization_write_request = PatchedOrganizationWriteRequest( slug=\"z\", name=\"name_example\", description=\"description_example\", contact={}, ) # PatchedOrganizationWriteRequest | (optional) try: (data, response) = api_client.organizations_api.partial_update( id, patched_organization_write_request=patched_organization_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling OrganizationsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this organization. patched_organization_write_request PatchedOrganizationWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[OrganizationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet organization details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this organization. try: (data, response) = api_client.organizations_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling OrganizationsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this organization. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[OrganizationRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/organizations-api/","tags":"","title":"OrganizationsApi class reference"},{"body":"Properties Name Type Description Notes slug str name str [optional] description str [optional] contact {str: (bool, date, datetime, dict, float, int, list, str, none_type)} [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes slug str name str [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/organization-write-request/","tags":"","title":"OrganizationWriteRequest class reference"},{"body":"Properties Name Type Description Notes count int results [AnnotationConflict] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-annotation-conflict-list/","tags":"","title":"PaginatedAnnotationConflictList class reference"},{"body":"Properties Name Type Description Notes count int results [CloudStorageRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-cloud-storage-read-list/","tags":"","title":"PaginatedCloudStorageReadList class reference"},{"body":"Properties Name Type Description Notes count int results [CommentRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [CommentRead] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-comment-read-list/","tags":"","title":"PaginatedCommentReadList class reference"},{"body":"Properties Name Type Description Notes count int results [ConsensusSettings] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-consensus-settings-list/","tags":"","title":"PaginatedConsensusSettingsList class reference"},{"body":"Properties Name Type Description Notes count int results [InvitationRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-invitation-read-list/","tags":"","title":"PaginatedInvitationReadList class reference"},{"body":"Properties Name Type Description Notes count int results [IssueRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [IssueRead] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-issue-read-list/","tags":"","title":"PaginatedIssueReadList class reference"},{"body":"Properties Name Type Description Notes count int results [JobRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [JobRead] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-job-read-list/","tags":"","title":"PaginatedJobReadList class reference"},{"body":"Properties Name Type Description Notes count int results [Label] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [Label] next …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-label-list/","tags":"","title":"PaginatedLabelList class reference"},{"body":"Properties Name Type Description Notes count int results [MembershipRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-membership-read-list/","tags":"","title":"PaginatedMembershipReadList class reference"},{"body":"Properties Name Type Description Notes count int results [MetaUser] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [MetaUser] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-meta-user-list/","tags":"","title":"PaginatedMetaUserList class reference"},{"body":"Properties Name Type Description Notes count int results [OrganizationRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-organization-read-list/","tags":"","title":"PaginatedOrganizationReadList class reference"},{"body":"Properties Name Type Description Notes count int results [ProjectRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [ProjectRead] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-project-read-list/","tags":"","title":"PaginatedProjectReadList class reference"},{"body":"Properties Name Type Description Notes count int results [QualityReport] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-quality-report-list/","tags":"","title":"PaginatedQualityReportList class reference"},{"body":"Properties Name Type Description Notes count int results [QualitySettings] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-quality-settings-list/","tags":"","title":"PaginatedQualitySettingsList class reference"},{"body":"Properties Name Type Description Notes count int results [Request] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [Request] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-request-list/","tags":"","title":"PaginatedRequestList class reference"},{"body":"Properties Name Type Description Notes count int results [TaskRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [TaskRead] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-task-read-list/","tags":"","title":"PaginatedTaskReadList class reference"},{"body":"Properties Name Type Description Notes count int results [WebhookDeliveryRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-webhook-delivery-read-list/","tags":"","title":"PaginatedWebhookDeliveryReadList class reference"},{"body":"Properties Name Type Description Notes count int results [WebhookRead] next str, none_type [optional] previous str, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int results [WebhookRead] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/paginated-webhook-read-list/","tags":"","title":"PaginatedWebhookReadList class reference"},{"body":"Properties Name Type Description Notes old_password str new_password1 str new_password2 str ","categories":"","description":"","excerpt":"Properties Name Type Description Notes old_password str new_password1 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/password-change-request/","tags":"","title":"PasswordChangeRequest class reference"},{"body":"Serializer for confirming a password reset attempt.\nProperties Name Type Description Notes new_password1 str new_password2 str uid str token str ","categories":"","description":"","excerpt":"Serializer for confirming a password reset attempt.\nProperties Name …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/password-reset-confirm-request/","tags":"","title":"PasswordResetConfirmRequest class reference"},{"body":"Serializer for requesting a password reset e-mail.\nProperties Name Type Description Notes email str ","categories":"","description":"","excerpt":"Serializer for requesting a password reset e-mail.\nProperties Name …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/password-reset-serializer-ex-request/","tags":"","title":"PasswordResetSerializerExRequest class reference"},{"body":"Properties Name Type Description Notes task_id int, none_type [optional] project_id int, none_type [optional] markdown str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes task_id int, none_type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-annotation-guide-write-request/","tags":"","title":"PatchedAnnotationGuideWriteRequest class reference"},{"body":"Properties Name Type Description Notes provider_type ProviderTypeEnum [optional] resource str [optional] display_name str [optional] owner BasicUserRequest [optional] credentials_type CredentialsTypeEnum [optional] session_token str [optional] account_name str [optional] key str [optional] secret_key str [optional] connection_string str [optional] key_file file_type [optional] specific_attributes str [optional] description str [optional] manifests [str] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes provider_type ProviderTypeEnum …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-cloud-storage-write-request/","tags":"","title":"PatchedCloudStorageWriteRequest class reference"},{"body":"Properties Name Type Description Notes message str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes message str [optional] ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-comment-write-request/","tags":"","title":"PatchedCommentWriteRequest class reference"},{"body":"Properties Name Type Description Notes iou_threshold float Pairwise annotation matching IoU threshold [optional] quorum float Minimum required share of sources having an annotation for it to be accepted [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes iou_threshold float Pairwise …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-consensus-settings-request/","tags":"","title":"PatchedConsensusSettingsRequest class reference"},{"body":"Properties Name Type Description Notes deleted_frames [int] [optional] cloud_storage_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes deleted_frames [int] [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-data-meta-write-request/","tags":"","title":"PatchedDataMetaWriteRequest class reference"},{"body":"Properties Name Type Description Notes role RoleEnum [optional] email str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes role RoleEnum [optional] email …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-invitation-write-request/","tags":"","title":"PatchedInvitationWriteRequest class reference"},{"body":"Properties Name Type Description Notes position [float] [optional] assignee int, none_type [optional] resolved bool [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes position [float] [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-issue-write-request/","tags":"","title":"PatchedIssueWriteRequest class reference"},{"body":"Properties Name Type Description Notes deleted_frames [int] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes deleted_frames [int] [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-job-data-meta-write-request/","tags":"","title":"PatchedJobDataMetaWriteRequest class reference"},{"body":"Properties Name Type Description Notes frame_selection_method bool, date, datetime, dict, float, int, list, str, none_type The method to use for frame selection of new real frames for honeypots in the job * random_uniform - RANDOM_UNIFORM * random_per_job - RANDOM_PER_JOB * manual - MANUAL [optional] honeypot_real_frames [int] The list of frame ids. Applicable only to the \"manual\" frame selection method [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame_selection_method bool, …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-job-validation-layout-write-request/","tags":"","title":"PatchedJobValidationLayoutWriteRequest class reference"},{"body":"Properties Name Type Description Notes assignee int, none_type [optional] stage JobStage [optional] state OperationStatus [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes assignee int, none_type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-job-write-request/","tags":"","title":"PatchedJobWriteRequest class reference"},{"body":"Properties Name Type Description Notes version int [optional] if omitted the server will use the default value of 0 tags [LabeledImageRequest] [optional] if omitted the server will use the default value of [] shapes [LabeledShapeRequest] [optional] if omitted the server will use the default value of [] tracks [LabeledTrackRequest] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes version int [optional] if …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-labeled-data-request/","tags":"","title":"PatchedLabeledDataRequest class reference"},{"body":"Properties Name Type Description Notes id int [optional] name str [optional] color str The hex value for the RGB color. Will be generated automatically, unless specified explicitly. [optional] attributes [AttributeRequest] The list of attributes. If you want to remove an attribute, you need to recreate the label and specify the remaining attributes. [optional] if omitted the server will use the default value of [] deleted bool Delete the label. Only applicable in the PATCH methods of a project or a task. [optional] type bool, date, datetime, dict, float, int, list, str, none_type Associated annotation type for this label * any - ANY * cuboid - CUBOID * ellipse - ELLIPSE * mask - MASK * points - POINTS * polygon - POLYGON * polyline - POLYLINE * rectangle - RECTANGLE * skeleton - SKELETON * tag - TAG [optional] svg str [optional] sublabels **[SublabelRequest]** [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] name str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-label-request/","tags":"","title":"PatchedLabelRequest class reference"},{"body":"Properties Name Type Description Notes role RoleEnum [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes role RoleEnum [optional] ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-membership-write-request/","tags":"","title":"PatchedMembershipWriteRequest class reference"},{"body":"Properties Name Type Description Notes slug str [optional] name str [optional] description str [optional] contact {str: (bool, date, datetime, dict, float, int, list, str, none_type)} [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes slug str [optional] name str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-organization-write-request/","tags":"","title":"PatchedOrganizationWriteRequest class reference"},{"body":"Properties Name Type Description Notes name str [optional] labels [PatchedLabelRequest] [optional] if omitted the server will use the default value of [] owner_id int, none_type [optional] assignee_id int, none_type [optional] bug_tracker str [optional] target_storage PatchedProjectWriteRequestTargetStorage [optional] source_storage PatchedProjectWriteRequestTargetStorage [optional] organization_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str [optional] labels …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-project-write-request/","tags":"","title":"PatchedProjectWriteRequest class reference"},{"body":"Properties Name Type Description Notes location LocationEnum [optional] cloud_storage_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes location LocationEnum …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-project-write-request-target-storage/","tags":"","title":"PatchedProjectWriteRequestTargetStorage class reference"},{"body":"Properties Name Type Description Notes job_filter str A JSON-based logic expression used to filter jobs for quality validation. The filter supports various terms to specify conditions on job: [‘assignee’, ‘id’, ‘stage’, ‘state’, ’task_id’, ’task_name’, ’type’] [optional] inherit bool Allow using project settings when computing task quality. Only applicable to task quality settings inside projects [optional] target_metric bool, date, datetime, dict, float, int, list, str, none_type The primary metric used for quality estimation * accuracy - ACCURACY * precision - PRECISION * recall - RECALL [optional] target_metric_threshold float Defines the minimal quality requirements in terms of the selected target metric. [optional] max_validations_per_job int The maximum number of job validation attempts for the job assignee. The job can be automatically accepted if the job quality is above the required threshold, defined by the target threshold parameter. [optional] iou_threshold float Used for distinction between matched / unmatched shapes [optional] if omitted the server will use the default value of 0.4 oks_sigma float Like IoU threshold, but for points. The percent of the bbox side, used as the radius of the circle around the GT point, where the checked point is expected to be. For boxes with different width and height, the \"side\" is computed as a geometric mean of the width and height. Read more: https://cocodataset.org/#keypoints-eval [optional] if omitted the server will use the default value of 0.09 point_size_base bool, date, datetime, dict, float, int, list, str, none_type When comparing point annotations (including both separate points and point groups), the OKS sigma parameter defines matching area for each GT point based to the object size. The point size base parameter allows to configure how to determine the object size. If image_size, the image size is used. Useful if each point annotation represents a separate object or boxes grouped with points do not represent object boundaries. If group_bbox_size, the object size is based on the point group bbox size. Useful if each point group represents an object or there is a bbox grouped with points, representing the object size. * image_size - IMAGE_SIZE * group_bbox_size - GROUP_BBOX_SIZE [optional] line_thickness float Thickness of polylines, relatively to the (image area) ^ 0.5. The distance to the boundary around the GT line, inside of which the checked line points should be [optional] if omitted the server will use the default value of 0.01 low_overlap_threshold float Used for distinction between strong / weak (low_overlap) matches [optional] if omitted the server will use the default value of 0.8 compare_line_orientation bool Enables or disables polyline orientation comparison [optional] if omitted the server will use the default value of True line_orientation_threshold float The minimal gain in the GT IoU between the given and reversed line directions to consider the line inverted. Only used when the ‘compare_line_orientation’ parameter is true [optional] if omitted the server will use the default value of 0.1 compare_groups bool Enables or disables annotation group checks [optional] if omitted the server will use the default value of True group_match_threshold float Minimal IoU for groups to be considered matching. Only used when the ‘compare_groups’ parameter is true [optional] if omitted the server will use the default value of 0.5 check_covered_annotations bool Check for partially-covered annotations, useful in segmentation tasks [optional] if omitted the server will use the default value of True object_visibility_threshold float Minimal visible area percent of the spatial annotations (polygons, masks) for reporting covered annotations. Only used when the ‘object_visibility_threshold’ parameter is true [optional] if omitted the server will use the default value of 0.05 panoptic_comparison bool Use only the visible part of the masks and polygons in comparisons [optional] if omitted the server will use the default value of True compare_attributes bool Enables or disables annotation attribute comparison [optional] if omitted the server will use the default value of True empty_is_annotated bool Consider empty frames annotated as \"empty\". This affects target metrics like accuracy in cases there are no annotations. If disabled, frames without annotations are counted as not matching (accuracy is 0). If enabled, accuracy will be 1 instead. This will also add virtual annotations to empty frames in the comparison results. [optional] if omitted the server will use the default value of False ","categories":"","description":"","excerpt":"Properties Name Type Description Notes job_filter str A JSON-based …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-quality-settings-request/","tags":"","title":"PatchedQualitySettingsRequest class reference"},{"body":"Properties Name Type Description Notes disabled_frames [int] The list of frame ids to be excluded from validation [optional] frame_selection_method bool, date, datetime, dict, float, int, list, str, none_type The method to use for frame selection of new real frames for honeypots in the task * random_uniform - RANDOM_UNIFORM * random_per_job - RANDOM_PER_JOB * manual - MANUAL [optional] honeypot_real_frames [int] The list of frame ids. Applicable only to the \"manual\" frame selection method [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes disabled_frames [int] The list …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-task-validation-layout-write-request/","tags":"","title":"PatchedTaskValidationLayoutWriteRequest class reference"},{"body":"Properties Name Type Description Notes name str [optional] project_id int, none_type [optional] owner_id int, none_type [optional] assignee_id int, none_type [optional] bug_tracker str [optional] labels [PatchedLabelRequest] [optional] subset str [optional] target_storage StorageRequest [optional] source_storage StorageRequest [optional] organization_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str [optional] project_id …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-task-write-request/","tags":"","title":"PatchedTaskWriteRequest class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. [optional] first_name str [optional] last_name str [optional] email str [optional] groups [str] [optional] is_staff bool Designates whether the user can log into this admin site. [optional] is_superuser bool Designates that this user has all permissions without explicitly assigning them. [optional] is_active bool Designates whether this user should be treated as active. Unselect this instead of deleting accounts. [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-user-request/","tags":"","title":"PatchedUserRequest class reference"},{"body":"Properties Name Type Description Notes target_url str [optional] description str [optional] content_type WebhookContentType [optional] secret str [optional] is_active bool [optional] enable_ssl bool [optional] events [EventsEnum] [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes target_url str [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/patched-webhook-write-request/","tags":"","title":"PatchedWebhookWriteRequest class reference"},{"body":"Properties Name Type Description Notes git_integration bool analytics bool models bool predict bool ","categories":"","description":"","excerpt":"Properties Name Type Description Notes git_integration bool analytics …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/plugins/","tags":"","title":"Plugins class reference"},{"body":"Properties Name Type Description Notes project_file file_type ","categories":"","description":"","excerpt":"Properties Name Type Description Notes project_file file_type ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/project-file-request/","tags":"","title":"ProjectFileRequest class reference"},{"body":"Properties Name Type Description Notes tasks TasksSummary labels LabelsSummary url str [optional] [readonly] id int [optional] [readonly] name str [optional] [readonly] owner JobReadAssignee [optional] assignee JobReadAssignee [optional] guide_id int, none_type [optional] bug_tracker str [optional] [readonly] task_subsets [str] [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] status bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] dimension str, none_type [optional] [readonly] organization int, none_type [optional] [readonly] organization_id int, none_type [optional] [readonly] target_storage ProjectReadTargetStorage [optional] source_storage ProjectReadTargetStorage [optional] assignee_updated_date datetime, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes tasks TasksSummary labels …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/project-read/","tags":"","title":"ProjectRead class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] location LocationEnum [optional] cloud_storage_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/project-read-target-storage/","tags":"","title":"ProjectReadTargetStorage class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/projects Create a project create_backup POST /api/projects/backup/ Recreate a project from a backup create_backup_export POST /api/projects/{id}/backup/export Initiate process to backup resource create_dataset POST /api/projects/{id}/dataset/ Import a dataset into a project create_dataset_export POST /api/projects/{id}/dataset/export Initialize process to export resource as a dataset in a specific format destroy DELETE /api/projects/{id} Delete a project list GET /api/projects List projects partial_update PATCH /api/projects/{id} Update a project retrieve GET /api/projects/{id} Get project details retrieve_preview GET /api/projects/{id}/preview Get a preview image for a project create create( project_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate a project\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: project_write_request = ProjectWriteRequest( name=\"name_example\", labels=[ PatchedLabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], deleted=True, type=None, svg=\"svg_example\", sublabels=[ SublabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], type=None, has_parent=True, ), ], ), ], owner_id=1, assignee_id=1, bug_tracker=\"bug_tracker_example\", target_storage=PatchedProjectWriteRequestTargetStorage(None), source_storage=PatchedProjectWriteRequestTargetStorage(None), ) # ProjectWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.projects_api.create( project_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.create(): %s\\n\" % e) Parameters Name Type Description Notes project_write_request ProjectWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[ProjectRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - create_backup create_backup( x_organization=None, cloud_storage_id=None, filename=None, location=None, org=None, org_id=None, project_file_request=None, **kwargs )\nRecreate a project from a backup\nThe backup import process is as follows: The first request POST /api/projects/backup schedules a background job on the server in which the process of creating a project from the uploaded backup is carried out. To check the status of the import process, use GET /api/requests/rq_id, where rq_id is the request ID obtained from the response to the previous request. Once the import completes successfully, the response will contain the ID of the newly created project in the result_id field.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Backup file name (optional) location = \"local\" # str | Where to import the backup file from (optional) if omitted the server will use the default value of \"local\" org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) project_file_request = ProjectFileRequest( project_file=open('/path/to/file', 'rb'), ) # ProjectFileRequest | (optional) try: (data, response) = api_client.projects_api.create_backup( x_organization=x_organization, cloud_storage_id=cloud_storage_id, filename=filename, location=location, org=org, org_id=org_id, project_file_request=project_file_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.create_backup(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] cloud_storage_id int Storage id [optional] filename str Backup file name [optional] location str Where to import the backup file from [optional] if omitted the server will use the default value of “local” org str Organization unique slug [optional] org_id int Organization identifier [optional] project_file_request ProjectFileRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Import of the backup file has started - create_backup_export create_backup_export( id, cloud_storage_id=None, filename=None, lightweight=None, location=None, **kwargs )\nInitiate process to backup resource\nThe request POST /api/\u003cprojects|tasks\u003e/id/backup/export will initialize a background process to backup a resource. To check status of the process please, use GET /api/requests/\u003crq_id\u003e where rq_id is request ID returned in the response for this endpoint.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this project. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Backup file name (optional) lightweight = True # bool | Makes a lightweight backup (without media files) for tasks whose media is located in cloud storage (optional) if omitted the server will use the default value of True location = \"cloud_storage\" # str | Where need to save downloaded backup (optional) try: (data, response) = api_client.projects_api.create_backup_export( id, cloud_storage_id=cloud_storage_id, filename=filename, lightweight=lightweight, location=location, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.create_backup_export(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this project. cloud_storage_id int Storage id [optional] filename str Backup file name [optional] lightweight bool Makes a lightweight backup (without media files) for tasks whose media is located in cloud storage [optional] if omitted the server will use the default value of True location str Where need to save downloaded backup [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Creating a backup file has been started - 400 Wrong query parameters were passed - 409 The backup process has already been initiated and is not yet finished - create_dataset create_dataset( id, cloud_storage_id=None, filename=None, format=None, location=None, dataset_file_request=None, **kwargs )\nImport a dataset into a project\nThe request POST /api/projects/id/dataset initiates a background process to import dataset into a project. Please, use the GET /api/requests/\u003crq_id\u003e endpoint for checking status of the process. The rq_id parameter can be found in the response on initiating request.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this project. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Dataset file name (optional) format = \"format_example\" # str | Desired dataset format name You can get the list of supported formats at: /server/annotation/formats (optional) location = \"cloud_storage\" # str | Where to import the dataset from (optional) dataset_file_request = DatasetFileRequest( dataset_file=open('/path/to/file', 'rb'), ) # DatasetFileRequest | (optional) try: (data, response) = api_client.projects_api.create_dataset( id, cloud_storage_id=cloud_storage_id, filename=filename, format=format, location=location, dataset_file_request=dataset_file_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.create_dataset(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this project. cloud_storage_id int Storage id [optional] filename str Dataset file name [optional] format str Desired dataset format name You can get the list of supported formats at: /server/annotation/formats [optional] location str Where to import the dataset from [optional] dataset_file_request DatasetFileRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Importing has been started - 400 Failed to import dataset - 405 Format is not available - create_dataset_export create_dataset_export( format, id, cloud_storage_id=None, filename=None, location=None, save_images=None, **kwargs )\nInitialize process to export resource as a dataset in a specific format\nThe request POST /api/\u003cprojects|tasks|jobs\u003e/id/dataset/export will initialize a background process to export a dataset. To check status of the process please, use GET /api/requests/\u003crq_id\u003e where rq_id is request ID returned in the response for this endpoint.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: format = \"format_example\" # str | Desired output format name You can get the list of supported formats at: /server/annotation/formats id = 1 # int | A unique integer value identifying this project. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Desired output file name (optional) location = \"cloud_storage\" # str | Where need to save downloaded dataset (optional) save_images = False # bool | Include images or not (optional) if omitted the server will use the default value of False try: (data, response) = api_client.projects_api.create_dataset_export( format, id, cloud_storage_id=cloud_storage_id, filename=filename, location=location, save_images=save_images, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.create_dataset_export(): %s\\n\" % e) Parameters Name Type Description Notes format str Desired output format name You can get the list of supported formats at: /server/annotation/formats id int A unique integer value identifying this project. cloud_storage_id int Storage id [optional] filename str Desired output file name [optional] location str Where need to save downloaded dataset [optional] save_images bool Include images or not [optional] if omitted the server will use the default value of False There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Exporting has been started - 405 Format is not available - 409 Exporting is already in progress - destroy destroy( id, **kwargs )\nDelete a project\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this project. try: api_client.projects_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this project. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The project has been deleted - list list( x_organization=None, assignee=None, filter=None, name=None, org=None, org_id=None, owner=None, page=None, page_size=None, search=None, sort=None, status=None, **kwargs )\nList projects\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) assignee = \"assignee_example\" # str | A simple equality filter for the assignee field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['name', 'owner', 'assignee', 'status', 'id', 'updated_date']. (optional) name = \"name_example\" # str | A simple equality filter for the name field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) search = \"search_example\" # str | A search term. Available search_fields: ('name', 'owner', 'assignee', 'status') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['name', 'owner', 'assignee', 'status', 'id', 'updated_date'] (optional) status = \"annotation\" # str | A simple equality filter for the status field (optional) try: (data, response) = api_client.projects_api.list( x_organization=x_organization, assignee=assignee, filter=filter, name=name, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, search=search, sort=sort, status=status, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] assignee str A simple equality filter for the assignee field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [’name’, ‘owner’, ‘assignee’, ‘status’, ‘id’, ‘updated_date’]. [optional] name str A simple equality filter for the name field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] search str A search term. Available search_fields: (’name’, ‘owner’, ‘assignee’, ‘status’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [’name’, ‘owner’, ‘assignee’, ‘status’, ‘id’, ‘updated_date’] [optional] status str A simple equality filter for the status field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedProjectReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_project_write_request=None, **kwargs )\nUpdate a project\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this project. patched_project_write_request = PatchedProjectWriteRequest( name=\"name_example\", labels=[ PatchedLabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], deleted=True, type=None, svg=\"svg_example\", sublabels=[ SublabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], type=None, has_parent=True, ), ], ), ], owner_id=1, assignee_id=1, bug_tracker=\"bug_tracker_example\", target_storage=PatchedProjectWriteRequestTargetStorage(None), source_storage=PatchedProjectWriteRequestTargetStorage(None), organization_id=1, ) # PatchedProjectWriteRequest | (optional) try: (data, response) = api_client.projects_api.partial_update( id, patched_project_write_request=patched_project_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this project. patched_project_write_request PatchedProjectWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[ProjectRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet project details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this project. try: (data, response) = api_client.projects_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this project. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[ProjectRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_preview retrieve_preview( id, **kwargs )\nGet a preview image for a project\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this project. try: api_client.projects_api.retrieve_preview( id,) except exceptions.ApiException as e: print(\"Exception when calling ProjectsApi.retrieve_preview(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this project. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Project image preview - 404 Project image preview not found - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/projects-api/","tags":"","title":"ProjectsApi class reference"},{"body":"Properties Name Type Description Notes name str labels [PatchedLabelRequest] [optional] if omitted the server will use the default value of [] owner_id int, none_type [optional] assignee_id int, none_type [optional] bug_tracker str [optional] target_storage PatchedProjectWriteRequestTargetStorage [optional] source_storage PatchedProjectWriteRequestTargetStorage [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str labels …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/project-write-request/","tags":"","title":"ProjectWriteRequest class reference"},{"body":" `AWS_S3_BUCKET` - AWS_S3 * `AZURE_CONTAINER` - AZURE_CONTAINER * `GOOGLE_DRIVE` - GOOGLE_DRIVE * `GOOGLE_CLOUD_STORAGE` - GOOGLE_CLOUD_STORAGE Properties Name Type Description Notes value str * AWS_S3_BUCKET - AWS_S3 * AZURE_CONTAINER - AZURE_CONTAINER * GOOGLE_DRIVE - GOOGLE_DRIVE * GOOGLE_CLOUD_STORAGE - GOOGLE_CLOUD_STORAGE must be one of [“AWS_S3_BUCKET”, “AZURE_CONTAINER”, “GOOGLE_DRIVE”, “GOOGLE_CLOUD_STORAGE”, ] ","categories":"","description":"","excerpt":" `AWS_S3_BUCKET` - AWS_S3 * `AZURE_CONTAINER` - AZURE_CONTAINER * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/provider-type-enum/","tags":"","title":"ProviderTypeEnum class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create_report POST /api/quality/reports Create a quality report list_conflicts GET /api/quality/conflicts List annotation conflicts in a quality report list_reports GET /api/quality/reports Method returns a paginated list of quality reports. list_settings GET /api/quality/settings List quality settings instances partial_update_settings PATCH /api/quality/settings/{id} Update a quality settings instance retrieve_report GET /api/quality/reports/{id} Get quality report details retrieve_report_data GET /api/quality/reports/{id}/data Get quality report contents retrieve_settings GET /api/quality/settings/{id} Get quality settings instance details create_report create_report( rq_id=None, quality_report_create_request=None, **kwargs )\nCreate a quality report\nDeprecation warning: Utilizing this endpoint to check the computation status is no longer possible. Consider using common requests API: GET /api/requests/\u003crq_id\u003e\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: rq_id = \"rq_id_example\" # str | The report creation request id. Can be specified to check the report creation status. (optional) quality_report_create_request = QualityReportCreateRequest( task_id=1, project_id=1, ) # QualityReportCreateRequest | (optional) try: (data, response) = api_client.quality_api.create_report( rq_id=rq_id, quality_report_create_request=quality_report_create_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.create_report(): %s\\n\" % e) Parameters Name Type Description Notes rq_id str The report creation request id. Can be specified to check the report creation status. [optional] quality_report_create_request QualityReportCreateRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[QualityReport, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - 202 A quality report request has been enqueued, the request id is returned. The request status can be checked at this endpoint by passing the rq_id as the query parameter. If the request id is specified, this response means the quality report request is queued or is being processed. - 400 Invalid or failed request, check the response data for details - list_conflicts list_conflicts( x_organization=None, filter=None, frame=None, job_id=None, org=None, org_id=None, page=None, page_size=None, project_id=None, report_id=None, severity=None, sort=None, task_id=None, type=None, **kwargs )\nList annotation conflicts in a quality report\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['id', 'frame', 'type', 'job_id', 'task_id', 'project_id', 'severity']. (optional) frame = 1 # int | A simple equality filter for the frame field (optional) job_id = 1 # int | A simple equality filter for the job_id field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) project_id = 1 # int | A simple equality filter for the project_id field (optional) report_id = 1 # int | A simple equality filter for report id (optional) severity = \"warning\" # str | A simple equality filter for the severity field (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['id', 'frame', 'type', 'job_id', 'task_id', 'project_id', 'severity'] (optional) task_id = 1 # int | A simple equality filter for the task_id field (optional) type = \"missing_annotation\" # str | A simple equality filter for the type field (optional) try: (data, response) = api_client.quality_api.list_conflicts( x_organization=x_organization, filter=filter, frame=frame, job_id=job_id, org=org, org_id=org_id, page=page, page_size=page_size, project_id=project_id, report_id=report_id, severity=severity, sort=sort, task_id=task_id, type=type, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.list_conflicts(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘id’, ‘frame’, ’type’, ‘job_id’, ’task_id’, ‘project_id’, ‘severity’]. [optional] frame int A simple equality filter for the frame field [optional] job_id int A simple equality filter for the job_id field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] project_id int A simple equality filter for the project_id field [optional] report_id int A simple equality filter for report id [optional] severity str A simple equality filter for the severity field [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘id’, ‘frame’, ’type’, ‘job_id’, ’task_id’, ‘project_id’, ‘severity’] [optional] task_id int A simple equality filter for the task_id field [optional] type str A simple equality filter for the type field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedAnnotationConflictList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - list_reports list_reports( x_organization=None, filter=None, job_id=None, org=None, org_id=None, page=None, page_size=None, parent_id=None, project_id=None, sort=None, target=None, task_id=None, **kwargs )\nMethod returns a paginated list of quality reports.\nPlease note that children reports are included by default if the \"task_id\", \"project_id\" filters are used. If you want to restrict the list of results to a specific report type, use the \"target\" parameter. The \"parent_id\" filter includes all the nested reports recursively. For instance, if the \"parent_id\" is a project report, all the related task and job reports will be returned. Please note that a report can be reused in several parent reports, but the \"parent_id\" field in responses will include only the first parent report id. The \"parent_id\" filter still returns all the relevant nested reports, even though the response \"parent_id\" values may be different from the requested one.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['id', 'job_id', 'task_id', 'project_id', 'created_date', 'gt_last_updated', 'target_last_updated']. (optional) job_id = 1 # int | A simple equality filter for the job_id field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) parent_id = 1 # int | A simple equality filter for parent id (optional) project_id = 1 # int | A simple equality filter for project id (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['id', 'job_id', 'task_id', 'project_id', 'created_date', 'gt_last_updated', 'target_last_updated'] (optional) target = \"job\" # str | A simple equality filter for target (optional) task_id = 1 # int | A simple equality filter for task id (optional) try: (data, response) = api_client.quality_api.list_reports( x_organization=x_organization, filter=filter, job_id=job_id, org=org, org_id=org_id, page=page, page_size=page_size, parent_id=parent_id, project_id=project_id, sort=sort, target=target, task_id=task_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.list_reports(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘id’, ‘job_id’, ’task_id’, ‘project_id’, ‘created_date’, ‘gt_last_updated’, ’target_last_updated’]. [optional] job_id int A simple equality filter for the job_id field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] parent_id int A simple equality filter for parent id [optional] project_id int A simple equality filter for project id [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘id’, ‘job_id’, ’task_id’, ‘project_id’, ‘created_date’, ‘gt_last_updated’, ’target_last_updated’] [optional] target str A simple equality filter for target [optional] task_id int A simple equality filter for task id [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedQualityReportList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - list_settings list_settings( x_organization=None, filter=None, inherit=None, org=None, org_id=None, page=None, page_size=None, parent_type=None, project_id=None, sort=None, task_id=None, **kwargs )\nList quality settings instances\nPlease note that child task settings are included by default if the \"project_id\" filter is used. If you want to restrict results only to a specific parent type, use the \"parent_type\" parameter.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['id', 'task_id', 'project_id', 'inherit', 'created_date', 'updated_date']. (optional) inherit = True # bool | A simple equality filter for the inherit field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) parent_type = \"project\" # str | A simple equality filter for parent instance type (optional) project_id = 1 # int | A simple equality filter for project id (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['id', 'task_id', 'project_id', 'inherit', 'created_date', 'updated_date'] (optional) task_id = 1 # int | A simple equality filter for the task_id field (optional) try: (data, response) = api_client.quality_api.list_settings( x_organization=x_organization, filter=filter, inherit=inherit, org=org, org_id=org_id, page=page, page_size=page_size, parent_type=parent_type, project_id=project_id, sort=sort, task_id=task_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.list_settings(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘id’, ’task_id’, ‘project_id’, ‘inherit’, ‘created_date’, ‘updated_date’]. [optional] inherit bool A simple equality filter for the inherit field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] parent_type str A simple equality filter for parent instance type [optional] project_id int A simple equality filter for project id [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘id’, ’task_id’, ‘project_id’, ‘inherit’, ‘created_date’, ‘updated_date’] [optional] task_id int A simple equality filter for the task_id field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedQualitySettingsList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_settings partial_update_settings( id, patched_quality_settings_request=None, **kwargs )\nUpdate a quality settings instance\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | An id of a quality settings instance patched_quality_settings_request = PatchedQualitySettingsRequest( job_filter=\"job_filter_example\", inherit=True, target_metric=None, target_metric_threshold=0, max_validations_per_job=0, iou_threshold=0.4, oks_sigma=0.09, point_size_base=None, line_thickness=0.01, low_overlap_threshold=0.8, compare_line_orientation=True, line_orientation_threshold=0.1, compare_groups=True, group_match_threshold=0.5, check_covered_annotations=True, object_visibility_threshold=0.05, panoptic_comparison=True, compare_attributes=True, empty_is_annotated=False, ) # PatchedQualitySettingsRequest | (optional) try: (data, response) = api_client.quality_api.partial_update_settings( id, patched_quality_settings_request=patched_quality_settings_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.partial_update_settings(): %s\\n\" % e) Parameters Name Type Description Notes id int An id of a quality settings instance patched_quality_settings_request PatchedQualitySettingsRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[QualitySettings, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_report retrieve_report( id, **kwargs )\nGet quality report details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this quality report. try: (data, response) = api_client.quality_api.retrieve_report( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.retrieve_report(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this quality report. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[QualityReport, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_report_data retrieve_report_data( id, **kwargs )\nGet quality report contents\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this quality report. try: (data, response) = api_client.quality_api.retrieve_report_data( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.retrieve_report_data(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this quality report. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[dict[str, typing.Union[typing.Any, none_type]], urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_settings retrieve_settings( id, **kwargs )\nGet quality settings instance details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | An id of a quality settings instance try: (data, response) = api_client.quality_api.retrieve_settings( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling QualityApi.retrieve_settings(): %s\\n\" % e) Parameters Name Type Description Notes id int An id of a quality settings instance There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[QualitySettings, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/quality-api/","tags":"","title":"QualityApi class reference"},{"body":" `image_size` - IMAGE_SIZE * `group_bbox_size` - GROUP_BBOX_SIZE Properties Name Type Description Notes value str * image_size - IMAGE_SIZE * group_bbox_size - GROUP_BBOX_SIZE must be one of [“image_size”, “group_bbox_size”, ] ","categories":"","description":"","excerpt":" `image_size` - IMAGE_SIZE * `group_bbox_size` - GROUP_BBOX_SIZE …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-point-size-base/","tags":"","title":"QualityPointSizeBase class reference"},{"body":"Properties Name Type Description Notes target QualityReportTarget summary QualityReportSummary id int [optional] [readonly] job_id int, none_type [optional] [readonly] task_id int, none_type [optional] [readonly] project_id int, none_type [optional] [readonly] parent_id int, none_type [optional] [readonly] created_date datetime [optional] [readonly] target_last_updated datetime [optional] [readonly] gt_last_updated datetime, none_type [optional] [readonly] assignee JobReadAssignee [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes target QualityReportTarget …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report/","tags":"","title":"QualityReport class reference"},{"body":"Properties Name Type Description Notes task_id int [optional] project_id int [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes task_id int [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-create-request/","tags":"","title":"QualityReportCreateRequest class reference"},{"body":"Properties Name Type Description Notes total int Non-GT jobs in included tasks excluded int Jobs excluded by filters not_checkable int Included jobs without validation frames included int Included job count = total - excluded ","categories":"","description":"","excerpt":"Properties Name Type Description Notes total int Non-GT jobs in …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-jobs-summary/","tags":"","title":"QualityReportJobsSummary class reference"},{"body":"Properties Name Type Description Notes total_frames int validation_frames int validation_frame_share float conflict_count int warning_count int error_count int conflicts_by_type {str: (int,)} valid_count int ds_count int gt_count int total_count int accuracy float precision float recall float frame_count int Deprecated. Use ‘validation_frames’ instead [optional] frame_share float Deprecated. Use ‘validation_frame_share’ instead [optional] tasks QualityReportSummaryTasks [optional] jobs QualityReportSummaryJobs [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes total_frames int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-summary/","tags":"","title":"QualityReportSummary class reference"},{"body":"Included only in task and project reports\nProperties Name Type Description Notes total int Non-GT jobs in included tasks excluded int Jobs excluded by filters not_checkable int Included jobs without validation frames included int Included job count = total - excluded ","categories":"","description":"","excerpt":"Included only in task and project reports\nProperties Name Type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-summary-jobs/","tags":"","title":"QualityReportSummaryJobs class reference"},{"body":"Included only in project reports\nProperties Name Type Description Notes total int Total task count custom int Tasks with individual settings not_configured int Tasks with validation not configured excluded int Tasks excluded by filters included int Included task count = total - custom - non_configured - excluded ","categories":"","description":"","excerpt":"Included only in project reports\nProperties Name Type Description …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-summary-tasks/","tags":"","title":"QualityReportSummaryTasks class reference"},{"body":" `job` - JOB * `task` - TASK * `project` - PROJECT Properties Name Type Description Notes value str * job - JOB * task - TASK * project - PROJECT must be one of [“job”, “task”, “project”, ] ","categories":"","description":"","excerpt":" `job` - JOB * `task` - TASK * `project` - PROJECT Properties Name …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-target/","tags":"","title":"QualityReportTarget class reference"},{"body":"Properties Name Type Description Notes total int Total task count custom int Tasks with individual settings not_configured int Tasks with validation not configured excluded int Tasks excluded by filters included int Included task count = total - custom - non_configured - excluded ","categories":"","description":"","excerpt":"Properties Name Type Description Notes total int Total task count …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-report-tasks-summary/","tags":"","title":"QualityReportTasksSummary class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] task_id int, none_type [optional] project_id int, none_type [optional] job_filter str A JSON-based logic expression used to filter jobs for quality validation. The filter supports various terms to specify conditions on job: [‘assignee’, ‘id’, ‘stage’, ‘state’, ’task_id’, ’task_name’, ’type’] [optional] inherit bool Allow using project settings when computing task quality. Only applicable to task quality settings inside projects [optional] target_metric bool, date, datetime, dict, float, int, list, str, none_type The primary metric used for quality estimation * accuracy - ACCURACY * precision - PRECISION * recall - RECALL [optional] target_metric_threshold float Defines the minimal quality requirements in terms of the selected target metric. [optional] max_validations_per_job int The maximum number of job validation attempts for the job assignee. The job can be automatically accepted if the job quality is above the required threshold, defined by the target threshold parameter. [optional] iou_threshold float Used for distinction between matched / unmatched shapes [optional] if omitted the server will use the default value of 0.4 oks_sigma float Like IoU threshold, but for points. The percent of the bbox side, used as the radius of the circle around the GT point, where the checked point is expected to be. For boxes with different width and height, the \"side\" is computed as a geometric mean of the width and height. Read more: https://cocodataset.org/#keypoints-eval [optional] if omitted the server will use the default value of 0.09 point_size_base bool, date, datetime, dict, float, int, list, str, none_type When comparing point annotations (including both separate points and point groups), the OKS sigma parameter defines matching area for each GT point based to the object size. The point size base parameter allows to configure how to determine the object size. If image_size, the image size is used. Useful if each point annotation represents a separate object or boxes grouped with points do not represent object boundaries. If group_bbox_size, the object size is based on the point group bbox size. Useful if each point group represents an object or there is a bbox grouped with points, representing the object size. * image_size - IMAGE_SIZE * group_bbox_size - GROUP_BBOX_SIZE [optional] line_thickness float Thickness of polylines, relatively to the (image area) ^ 0.5. The distance to the boundary around the GT line, inside of which the checked line points should be [optional] if omitted the server will use the default value of 0.01 low_overlap_threshold float Used for distinction between strong / weak (low_overlap) matches [optional] if omitted the server will use the default value of 0.8 compare_line_orientation bool Enables or disables polyline orientation comparison [optional] if omitted the server will use the default value of True line_orientation_threshold float The minimal gain in the GT IoU between the given and reversed line directions to consider the line inverted. Only used when the ‘compare_line_orientation’ parameter is true [optional] if omitted the server will use the default value of 0.1 compare_groups bool Enables or disables annotation group checks [optional] if omitted the server will use the default value of True group_match_threshold float Minimal IoU for groups to be considered matching. Only used when the ‘compare_groups’ parameter is true [optional] if omitted the server will use the default value of 0.5 check_covered_annotations bool Check for partially-covered annotations, useful in segmentation tasks [optional] if omitted the server will use the default value of True object_visibility_threshold float Minimal visible area percent of the spatial annotations (polygons, masks) for reporting covered annotations. Only used when the ‘object_visibility_threshold’ parameter is true [optional] if omitted the server will use the default value of 0.05 panoptic_comparison bool Use only the visible part of the masks and polygons in comparisons [optional] if omitted the server will use the default value of True compare_attributes bool Enables or disables annotation attribute comparison [optional] if omitted the server will use the default value of True empty_is_annotated bool Consider empty frames annotated as \"empty\". This affects target metrics like accuracy in cases there are no annotations. If disabled, frames without annotations are counted as not matching (accuracy is 0). If enabled, accuracy will be 1 instead. This will also add virtual annotations to empty frames in the comparison results. [optional] if omitted the server will use the default value of False created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-settings/","tags":"","title":"QualitySettings class reference"},{"body":" `accuracy` - ACCURACY * `precision` - PRECISION * `recall` - RECALL Properties Name Type Description Notes value str * accuracy - ACCURACY * precision - PRECISION * recall - RECALL must be one of [“accuracy”, “precision”, “recall”, ] ","categories":"","description":"","excerpt":" `accuracy` - ACCURACY * `precision` - PRECISION * `recall` - RECALL …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/quality-target-metric/","tags":"","title":"QualityTargetMetric class reference"},{"body":"Properties Name Type Description Notes username str email str [optional] first_name str [optional] last_name str [optional] email_verification_required bool [optional] [readonly] key str, none_type [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str email str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/register-serializer-ex/","tags":"","title":"RegisterSerializerEx class reference"},{"body":"Properties Name Type Description Notes username str password1 str password2 str email str [optional] first_name str [optional] last_name str [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str password1 str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/register-serializer-ex-request/","tags":"","title":"RegisterSerializerExRequest class reference"},{"body":"Properties Name Type Description Notes status RequestStatus id str operation RequestDataOperation created_date datetime message str [optional] [readonly] progress float, none_type [optional] [readonly] started_date datetime, none_type [optional] finished_date datetime, none_type [optional] expiry_date datetime, none_type [optional] [readonly] owner RequestOwner [optional] result_url str, none_type [optional] result_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes status RequestStatus id str …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/request/","tags":"","title":"Request class reference"},{"body":"Properties Name Type Description Notes type str target str project_id int, none_type [optional] task_id int, none_type [optional] job_id int, none_type [optional] format str, none_type [optional] function_id str, none_type [optional] lightweight bool, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type str target str project_id …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/request-data-operation/","tags":"","title":"RequestDataOperation class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. id int [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/request-owner/","tags":"","title":"RequestOwner class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create_cancel POST /api/requests/{id}/cancel Cancel request list GET /api/requests List requests retrieve GET /api/requests/{id} Get request details create_cancel create_cancel( id, **kwargs )\nCancel request\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = \"id_example\" # str | try: api_client.requests_api.create_cancel( id,) except exceptions.ApiException as e: print(\"Exception when calling RequestsApi.create_cancel(): %s\\n\" % e) Parameters Name Type Description Notes id str There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 The request has been cancelled - list list( action=None, filter=None, format=None, job_id=None, org=None, page=None, page_size=None, project_id=None, sort=None, status=None, subresource=None, target=None, task_id=None, **kwargs )\nList requests\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: action = \"action_example\" # str | A simple equality filter for the action field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['status', 'project_id', 'task_id', 'job_id', 'action', 'target', 'subresource', 'format']. (optional) format = \"format_example\" # str | A simple equality filter for the format field (optional) job_id = 1 # int | A simple equality filter for the job_id field (optional) org = \"org_example\" # str | A simple equality filter for the org field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) project_id = 1 # int | A simple equality filter for the project_id field (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['created_date', 'status', 'action'] (optional) status = \"queued\" # str | A simple equality filter for the status field (optional) subresource = \"subresource_example\" # str | A simple equality filter for the subresource field (optional) target = \"target_example\" # str | A simple equality filter for the target field (optional) task_id = 1 # int | A simple equality filter for the task_id field (optional) try: (data, response) = api_client.requests_api.list( action=action, filter=filter, format=format, job_id=job_id, org=org, page=page, page_size=page_size, project_id=project_id, sort=sort, status=status, subresource=subresource, target=target, task_id=task_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling RequestsApi.list(): %s\\n\" % e) Parameters Name Type Description Notes action str A simple equality filter for the action field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘status’, ‘project_id’, ’task_id’, ‘job_id’, ‘action’, ’target’, ‘subresource’, ‘format’]. [optional] format str A simple equality filter for the format field [optional] job_id int A simple equality filter for the job_id field [optional] org str A simple equality filter for the org field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] project_id int A simple equality filter for the project_id field [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘created_date’, ‘status’, ‘action’] [optional] status str A simple equality filter for the status field [optional] subresource str A simple equality filter for the subresource field [optional] target str A simple equality filter for the target field [optional] task_id int A simple equality filter for the task_id field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedRequestList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet request details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = \"id_example\" # str | try: (data, response) = api_client.requests_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling RequestsApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id str There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[Request, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/requests-api/","tags":"","title":"RequestsApi class reference"},{"body":" `queued` - Queued * `started` - Started * `failed` - Failed * `finished` - Finished Properties Name Type Description Notes value str * queued - Queued * started - Started * failed - Failed * finished - Finished must be one of [“queued”, “started”, “failed”, “finished”, ] ","categories":"","description":"","excerpt":" `queued` - Queued * `started` - Started * `failed` - Failed * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/request-status/","tags":"","title":"RequestStatus class reference"},{"body":"Properties Name Type Description Notes detail str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes detail str [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/rest-auth-detail/","tags":"","title":"RestAuthDetail class reference"},{"body":" `worker` - Worker * `supervisor` - Supervisor * `maintainer` - Maintainer * `owner` - Owner Properties Name Type Description Notes value str * worker - Worker * supervisor - Supervisor * maintainer - Maintainer * owner - Owner must be one of [“worker”, “supervisor”, “maintainer”, “owner”, ] ","categories":"","description":"","excerpt":" `worker` - Worker * `supervisor` - Supervisor * `maintainer` - …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/role-enum/","tags":"","title":"RoleEnum class reference"},{"body":"Properties Name Type Description Notes rq_id str Request id ","categories":"","description":"","excerpt":"Properties Name Type Description Notes rq_id str Request id ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/rq-id/","tags":"","title":"RqId class reference"},{"body":"Properties Name Type Description Notes state RqStatusStateEnum message str [optional] if omitted the server will use the default value of \"\" progress float [optional] if omitted the server will use the default value of 0.0 ","categories":"","description":"","excerpt":"Properties Name Type Description Notes state RqStatusStateEnum message …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/rq-status/","tags":"","title":"RqStatus class reference"},{"body":" `Queued` - Queued * `Started` - Started * `Finished` - Finished * `Failed` - Failed Properties Name Type Description Notes value str * Queued - Queued * Started - Started * Finished - Finished * Failed - Failed must be one of [“Queued”, “Started”, “Finished”, “Failed”, ] ","categories":"","description":"","excerpt":" `Queued` - Queued * `Started` - Started * `Finished` - Finished * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/rq-status-state-enum/","tags":"","title":"RqStatusStateEnum class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description retrieve GET /api/schema/ retrieve retrieve( lang=None, scheme=None, **kwargs )\nOpenApi3 schema for this API. Format can be selected via content negotiation. - YAML: application/vnd.oai.openapi - JSON: application/vnd.oai.openapi+json\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: lang = \"af\" # str | (optional) scheme = \"json\" # str | (optional) try: (data, response) = api_client.schema_api.retrieve( lang=lang, scheme=scheme, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling SchemaApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes lang str [optional] scheme str [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[dict[str, typing.Union[typing.Any, none_type]], urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.oai.openapi, application/yaml, application/vnd.oai.openapi+json, application/json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/schema-api/","tags":"","title":"SchemaApi class reference"},{"body":"Below you can find just quick overview of the Django Silk profiler. Please read Silk documentation for more information about its features.\nSilk is a live profiling and inspection tool for the Django framework. Silk intercepts and stores HTTP requests and database queries before presenting them in a user interface for further inspection:\nPrimary features:\nRequest Inspection SQL Inspection Profiling of python code Silk is available in the development configuration of CVAT server for authenticated users: http://localhost:3000/profiler/.\n","categories":"","description":"Tutorial about how to profile the server","excerpt":"Tutorial about how to profile the server","ref":"/v2.43.0/docs/contributing/server-profiling/","tags":"","title":"Server Profiling"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description list_share GET /api/server/share List files/directories in the mounted share retrieve_about GET /api/server/about Get basic CVAT information retrieve_annotation_formats GET /api/server/annotation/formats Get supported annotation formats retrieve_plugins GET /api/server/plugins Get enabled plugins list_share list_share( directory=None, search=None, **kwargs )\nList files/directories in the mounted share\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: directory = \"directory_example\" # str | Directory to browse (optional) search = \"search_example\" # str | Search for specific files (optional) try: (data, response) = api_client.server_api.list_share( directory=directory, search=search, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ServerApi.list_share(): %s\\n\" % e) Parameters Name Type Description Notes directory str Directory to browse [optional] search str Search for specific files [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[list[FileInfo], urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_about retrieve_about( **kwargs )\nGet basic CVAT information\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: (data, response) = api_client.server_api.retrieve_about() pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ServerApi.retrieve_about(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[About, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_annotation_formats retrieve_annotation_formats( **kwargs )\nGet supported annotation formats\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: (data, response) = api_client.server_api.retrieve_annotation_formats() pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ServerApi.retrieve_annotation_formats(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[DatasetFormats, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_plugins retrieve_plugins( **kwargs )\nGet enabled plugins\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: (data, response) = api_client.server_api.retrieve_plugins() pprint(data) except exceptions.ApiException as e: print(\"Exception when calling ServerApi.retrieve_plugins(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[Plugins, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/server-api/","tags":"","title":"ServerApi class reference"},{"body":" `rectangle` - RECTANGLE * `polygon` - POLYGON * `polyline` - POLYLINE * `points` - POINTS * `ellipse` - ELLIPSE * `cuboid` - CUBOID * `mask` - MASK * `skeleton` - SKELETON Properties Name Type Description Notes value str * rectangle - RECTANGLE * polygon - POLYGON * polyline - POLYLINE * points - POINTS * ellipse - ELLIPSE * cuboid - CUBOID * mask - MASK * skeleton - SKELETON must be one of [“rectangle”, “polygon”, “polyline”, “points”, “ellipse”, “cuboid”, “mask”, “skeleton”, ] ","categories":"","description":"","excerpt":" `rectangle` - RECTANGLE * `polygon` - POLYGON * `polyline` - POLYLINE …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/shape-type/","tags":"","title":"ShapeType class reference"},{"body":" `lexicographical` - LEXICOGRAPHICAL * `natural` - NATURAL * `predefined` - PREDEFINED * `random` - RANDOM Properties Name Type Description Notes value str * lexicographical - LEXICOGRAPHICAL * natural - NATURAL * predefined - PREDEFINED * random - RANDOM must be one of [“lexicographical”, “natural”, “predefined”, “random”, ] ","categories":"","description":"","excerpt":" `lexicographical` - LEXICOGRAPHICAL * `natural` - NATURAL * …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sorting-method/","tags":"","title":"SortingMethod class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] location LocationEnum [optional] cloud_storage_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/storage/","tags":"","title":"Storage class reference"},{"body":" `cache` - CACHE * `file_system` - FILE_SYSTEM Properties Name Type Description Notes value str * cache - CACHE * file_system - FILE_SYSTEM must be one of [“cache”, “file_system”, ] ","categories":"","description":"","excerpt":" `cache` - CACHE * `file_system` - FILE_SYSTEM Properties Name Type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/storage-method/","tags":"","title":"StorageMethod class reference"},{"body":"Properties Name Type Description Notes location LocationEnum [optional] cloud_storage_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes location LocationEnum …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/storage-request/","tags":"","title":"StorageRequest class reference"},{"body":" `cloud_storage` - CLOUD_STORAGE * `local` - LOCAL * `share` - SHARE Properties Name Type Description Notes value str * cloud_storage - CLOUD_STORAGE * local - LOCAL * share - SHARE must be one of [“cloud_storage”, “local”, “share”, ] ","categories":"","description":"","excerpt":" `cloud_storage` - CLOUD_STORAGE * `local` - LOCAL * `share` - SHARE …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/storage-type/","tags":"","title":"StorageType class reference"},{"body":"Properties Name Type Description Notes name str id int [optional] color str The hex value for the RGB color. Will be generated automatically, unless specified explicitly. [optional] attributes [Attribute] The list of attributes. If you want to remove an attribute, you need to recreate the label and specify the remaining attributes. [optional] if omitted the server will use the default value of [] type bool, date, datetime, dict, float, int, list, str, none_type Associated annotation type for this label * any - ANY * cuboid - CUBOID * ellipse - ELLIPSE * mask - MASK * points - POINTS * polygon - POLYGON * polyline - POLYLINE * rectangle - RECTANGLE * skeleton - SKELETON * tag - TAG [optional] has_parent bool [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str id int [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sublabel/","tags":"","title":"Sublabel class reference"},{"body":"Properties Name Type Description Notes type ShapeType frame int label_id int occluded bool [optional] if omitted the server will use the default value of False outside bool [optional] if omitted the server will use the default value of False z_order int [optional] if omitted the server will use the default value of 0 rotation float [optional] if omitted the server will use the default value of 0.0 points [float] [optional] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeVal] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type ShapeType frame int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sub-labeled-shape/","tags":"","title":"SubLabeledShape class reference"},{"body":"Properties Name Type Description Notes type ShapeType frame int label_id int occluded bool [optional] if omitted the server will use the default value of False outside bool [optional] if omitted the server will use the default value of False z_order int [optional] if omitted the server will use the default value of 0 rotation float [optional] if omitted the server will use the default value of 0.0 points [float] [optional] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeValRequest] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type ShapeType frame int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sub-labeled-shape-request/","tags":"","title":"SubLabeledShapeRequest class reference"},{"body":"Properties Name Type Description Notes frame int label_id int shapes [TrackedShape] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeVal] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int label_id int shapes …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sub-labeled-track/","tags":"","title":"SubLabeledTrack class reference"},{"body":"Properties Name Type Description Notes frame int label_id int shapes [TrackedShapeRequest] id int, none_type [optional] group int, none_type [optional] source str [optional] if omitted the server will use the default value of “manual” attributes [AttributeValRequest] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes frame int label_id int shapes …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sub-labeled-track-request/","tags":"","title":"SubLabeledTrackRequest class reference"},{"body":"Properties Name Type Description Notes name str attributes {str: (str,)} [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str attributes {str: …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sublabel-mapping-entry-request/","tags":"","title":"SublabelMappingEntryRequest class reference"},{"body":"Properties Name Type Description Notes name str id int [optional] color str The hex value for the RGB color. Will be generated automatically, unless specified explicitly. [optional] attributes [AttributeRequest] The list of attributes. If you want to remove an attribute, you need to recreate the label and specify the remaining attributes. [optional] if omitted the server will use the default value of [] type bool, date, datetime, dict, float, int, list, str, none_type Associated annotation type for this label * any - ANY * cuboid - CUBOID * ellipse - ELLIPSE * mask - MASK * points - POINTS * polygon - POLYGON * polyline - POLYLINE * rectangle - RECTANGLE * skeleton - SKELETON * tag - TAG [optional] has_parent bool [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str id int [optional] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/sublabel-request/","tags":"","title":"SublabelRequest class reference"},{"body":"Properties Name Type Description Notes task_file file_type ","categories":"","description":"","excerpt":"Properties Name Type Description Notes task_file file_type ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/task-file-request/","tags":"","title":"TaskFileRequest class reference"},{"body":"Properties Name Type Description Notes jobs JobsSummary labels LabelsSummary url str [optional] [readonly] id int [optional] [readonly] name str [optional] [readonly] project_id int, none_type [optional] mode str [optional] [readonly] owner CloudStorageReadOwner [optional] assignee CloudStorageReadOwner [optional] bug_tracker str [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] overlap int, none_type [optional] [readonly] segment_size int [optional] [readonly] status bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] data_chunk_size int, none_type [optional] [readonly] data_original_chunk_type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] data_compressed_chunk_type bool, date, datetime, dict, float, int, list, str, none_type [optional] [readonly] data_cloud_storage_id int, none_type [optional] [readonly] guide_id int, none_type [optional] size int [optional] [readonly] image_quality int [optional] [readonly] data int [optional] [readonly] dimension str [optional] subset str [optional] [readonly] organization_id int, none_type [optional] [readonly] organization int, none_type [optional] [readonly] target_storage JobReadTargetStorage [optional] source_storage JobReadTargetStorage [optional] assignee_updated_date datetime, none_type [optional] [readonly] validation_mode str, none_type Describes how the task validation is performed. Configured at task creation [optional] consensus_enabled bool [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes jobs JobsSummary labels …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/task-read/","tags":"","title":"TaskRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/tasks Create a task create_annotations POST /api/tasks/{id}/annotations/ Import annotations into a task create_backup POST /api/tasks/backup/ Recreate a task from a backup create_backup_export POST /api/tasks/{id}/backup/export Initiate process to backup resource create_data POST /api/tasks/{id}/data/ Attach data to a task create_dataset_export POST /api/tasks/{id}/dataset/export Initialize process to export resource as a dataset in a specific format destroy DELETE /api/tasks/{id} Delete a task destroy_annotations DELETE /api/tasks/{id}/annotations/ Delete task annotations list GET /api/tasks List tasks partial_update PATCH /api/tasks/{id} Update a task partial_update_annotations PATCH /api/tasks/{id}/annotations/ Update task annotations partial_update_data_meta PATCH /api/tasks/{id}/data/meta Update metainformation for media files in a task partial_update_validation_layout PATCH /api/tasks/{id}/validation_layout Allows updating current validation configuration retrieve GET /api/tasks/{id} Get task details retrieve_annotations GET /api/tasks/{id}/annotations/ Get task annotations retrieve_data GET /api/tasks/{id}/data/ Get data of a task retrieve_data_meta GET /api/tasks/{id}/data/meta Get metainformation for media files in a task retrieve_preview GET /api/tasks/{id}/preview Get a preview image for a task retrieve_status GET /api/tasks/{id}/status Get the creation status of a task retrieve_validation_layout GET /api/tasks/{id}/validation_layout Allows getting current validation configuration update_annotations PUT /api/tasks/{id}/annotations/ Replace task annotations create create( task_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate a task\nThe new task will not have any attached images or videos. To attach them, use the /api/tasks//data endpoint.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: task_write_request = TaskWriteRequest( name=\"name_example\", project_id=1, owner_id=1, assignee_id=1, bug_tracker=\"bug_tracker_example\", overlap=0, segment_size=0, labels=[ PatchedLabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], deleted=True, type=None, svg=\"svg_example\", sublabels=[ SublabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], type=None, has_parent=True, ), ], ), ], subset=\"subset_example\", target_storage=StorageRequest( location=LocationEnum(\"cloud_storage\"), cloud_storage_id=1, ), source_storage=StorageRequest( location=LocationEnum(\"cloud_storage\"), cloud_storage_id=1, ), consensus_replicas=0, ) # TaskWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.tasks_api.create( task_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.create(): %s\\n\" % e) Parameters Name Type Description Notes task_write_request TaskWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[TaskRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - create_annotations create_annotations( id, cloud_storage_id=None, filename=None, format=None, location=None, use_default_location=None, annotation_file_request=None, **kwargs )\nImport annotations into a task\nThe request POST /api/tasks/id/annotations initiates a background process to import annotations into a task. Please, use the GET /api/requests/\u003crq_id\u003e endpoint for checking status of the process. The rq_id parameter can be found in the response on initiating request.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Annotation file name (optional) format = \"format_example\" # str | Input format name You can get the list of supported formats at: /server/annotation/formats (optional) location = \"cloud_storage\" # str | where to import the annotation from (optional) use_default_location = True # bool | Use the location that was configured in task to import annotations (optional) if omitted the server will use the default value of True annotation_file_request = AnnotationFileRequest( annotation_file=open('/path/to/file', 'rb'), ) # AnnotationFileRequest | (optional) try: api_client.tasks_api.create_annotations( id, cloud_storage_id=cloud_storage_id, filename=filename, format=format, location=location, use_default_location=use_default_location, annotation_file_request=annotation_file_request, ) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.create_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. cloud_storage_id int Storage id [optional] filename str Annotation file name [optional] format str Input format name You can get the list of supported formats at: /server/annotation/formats [optional] location str where to import the annotation from [optional] use_default_location bool Use the location that was configured in task to import annotations [optional] if omitted the server will use the default value of True annotation_file_request AnnotationFileRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 Uploading has finished - 202 Uploading has been started - 405 Format is not available - create_backup create_backup( x_organization=None, cloud_storage_id=None, filename=None, location=None, org=None, org_id=None, task_file_request=None, **kwargs )\nRecreate a task from a backup\nThe backup import process is as follows: The first request POST /api/tasks/backup creates a background job on the server in which the process of a task creating from an uploaded backup is carried out. To check the status of the import process, use GET /api/requests/rq_id, where rq_id is the request ID obtained from the response to the previous request. Once the import completes successfully, the response will contain the ID of the newly created task in the result_id field.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Backup file name (optional) location = \"local\" # str | Where to import the backup file from (optional) if omitted the server will use the default value of \"local\" org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) task_file_request = TaskFileRequest( task_file=open('/path/to/file', 'rb'), ) # TaskFileRequest | (optional) try: (data, response) = api_client.tasks_api.create_backup( x_organization=x_organization, cloud_storage_id=cloud_storage_id, filename=filename, location=location, org=org, org_id=org_id, task_file_request=task_file_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.create_backup(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] cloud_storage_id int Storage id [optional] filename str Backup file name [optional] location str Where to import the backup file from [optional] if omitted the server will use the default value of “local” org str Organization unique slug [optional] org_id int Organization identifier [optional] task_file_request TaskFileRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Import of the backup file has started - create_backup_export create_backup_export( id, cloud_storage_id=None, filename=None, lightweight=None, location=None, **kwargs )\nInitiate process to backup resource\nThe request POST /api/\u003cprojects|tasks\u003e/id/backup/export will initialize a background process to backup a resource. To check status of the process please, use GET /api/requests/\u003crq_id\u003e where rq_id is request ID returned in the response for this endpoint.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Backup file name (optional) lightweight = True # bool | Makes a lightweight backup (without media files) for tasks whose media is located in cloud storage (optional) if omitted the server will use the default value of True location = \"cloud_storage\" # str | Where need to save downloaded backup (optional) try: (data, response) = api_client.tasks_api.create_backup_export( id, cloud_storage_id=cloud_storage_id, filename=filename, lightweight=lightweight, location=location, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.create_backup_export(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. cloud_storage_id int Storage id [optional] filename str Backup file name [optional] lightweight bool Makes a lightweight backup (without media files) for tasks whose media is located in cloud storage [optional] if omitted the server will use the default value of True location str Where need to save downloaded backup [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Creating a backup file has been started - 400 Wrong query parameters were passed - 409 The backup process has already been initiated and is not yet finished - create_data create_data( id, upload_finish=None, upload_multiple=None, upload_start=None, data_request=None, **kwargs )\nAttach data to a task\nAllows to upload data (images, video, etc.) to a task. Supports the TUS open file uploading protocol (https://tus.io/). Supports the following protocols: 1. A single Data request and 2.1. An Upload-Start request 2.2.a. Regular TUS protocol requests (Upload-Length + Chunks) 2.2.b. Upload-Multiple requests 2.3. An Upload-Finish request Requests: - Data - POST, no extra headers or ‘Upload-Start’ + ‘Upload-Finish’ headers. Contains data in the body. - Upload-Start - POST, has an ‘Upload-Start’ header. No body is expected. - Upload-Length - POST, has an ‘Upload-Length’ header (see the TUS specification) - Chunk - HEAD/PATCH (see the TUS specification). Sent to /data/ endpoints. - Upload-Finish - POST, has an ‘Upload-Finish’ header. Can contain data in the body. - Upload-Multiple - POST, has an ‘Upload-Multiple’ header. Contains data in the body. The ‘Upload-Finish’ request allows to specify the uploaded files should be ordered. This may be needed if the files can be sent unordered. To state that the input files are sent ordered, pass an empty list of files in the ‘upload_file_order’ field. If the files are sent unordered, the ordered file list is expected in the ‘upload_file_order’ field. It must be a list of string file paths, relative to the dataset root. Example: files = [ \"cats/cat_1.jpg\", \"dogs/dog2.jpg\", \"image_3.png\", … ] Independently of the file declaration field used (‘client_files’, ‘server_files’, etc.), when the ‘predefined’ sorting method is selected, the uploaded files will be ordered according to the ‘.jsonl’ manifest file, if it is found in the list of files. For archives (e.g. ‘.zip’), a manifest file (’*.jsonl’) is required when using the ‘predefined’ file ordering. Such file must be provided next to the archive in the list of files. Read more about manifest files here: https://docs.cvat.ai/docs/manual/advanced/dataset_manifest/ After all data is sent, the operation status can be retrieved via the GET /api/requests/\u003crq_id\u003e, where rq_id is request ID returned for this request. Once data is attached to a task, it cannot be detached or replaced.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. upload_finish = True # bool | Finishes data upload. Can be combined with Upload-Start header to create task data with one request (optional) upload_multiple = True # bool | Indicates that data with this request are single or multiple files that should be attached to a task (optional) upload_start = True # bool | Initializes data upload. Optionally, can include upload metadata in the request body. (optional) data_request = DataRequest( chunk_size=0, image_quality=0, start_frame=0, stop_frame=0, frame_filter=\"frame_filter_example\", client_files=[], server_files=[], remote_files=[], use_zip_chunks=False, server_files_exclude=[], cloud_storage_id=1, use_cache=False, copy_data=False, storage_method=StorageMethod(\"cache\"), storage=StorageType(\"cloud_storage\"), sorting_method=SortingMethod(\"lexicographical\"), filename_pattern=\"filename_pattern_example\", job_file_mapping=[ [ \"a\", ], ], upload_file_order=[ \"upload_file_order_example\", ], validation_params=DataRequestValidationParams(None), ) # DataRequest | (optional) try: (data, response) = api_client.tasks_api.create_data( id, upload_finish=upload_finish, upload_multiple=upload_multiple, upload_start=upload_start, data_request=data_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.create_data(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. upload_finish bool Finishes data upload. Can be combined with Upload-Start header to create task data with one request [optional] upload_multiple bool Indicates that data with this request are single or multiple files that should be attached to a task [optional] upload_start bool Initializes data upload. Optionally, can include upload metadata in the request body. [optional] data_request DataRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[DataResponse, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Request to attach a data to a task has been accepted - create_dataset_export create_dataset_export( format, id, cloud_storage_id=None, filename=None, location=None, save_images=None, **kwargs )\nInitialize process to export resource as a dataset in a specific format\nThe request POST /api/\u003cprojects|tasks|jobs\u003e/id/dataset/export will initialize a background process to export a dataset. To check status of the process please, use GET /api/requests/\u003crq_id\u003e where rq_id is request ID returned in the response for this endpoint.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: format = \"format_example\" # str | Desired output format name You can get the list of supported formats at: /server/annotation/formats id = 1 # int | A unique integer value identifying this task. cloud_storage_id = 1 # int | Storage id (optional) filename = \"filename_example\" # str | Desired output file name (optional) location = \"cloud_storage\" # str | Where need to save downloaded dataset (optional) save_images = False # bool | Include images or not (optional) if omitted the server will use the default value of False try: (data, response) = api_client.tasks_api.create_dataset_export( format, id, cloud_storage_id=cloud_storage_id, filename=filename, location=location, save_images=save_images, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.create_dataset_export(): %s\\n\" % e) Parameters Name Type Description Notes format str Desired output format name You can get the list of supported formats at: /server/annotation/formats id int A unique integer value identifying this task. cloud_storage_id int Storage id [optional] filename str Desired output file name [optional] location str Where need to save downloaded dataset [optional] save_images bool Include images or not [optional] if omitted the server will use the default value of False There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqId, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 202 Exporting has been started - 405 Format is not available - 409 Exporting is already in progress - destroy destroy( id, **kwargs )\nDelete a task\nAll attached jobs, annotations and data will be deleted as well.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: api_client.tasks_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The task has been deleted - destroy_annotations destroy_annotations( id, **kwargs )\nDelete task annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: api_client.tasks_api.destroy_annotations( id,) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.destroy_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The annotation has been deleted - list list( x_organization=None, assignee=None, dimension=None, filter=None, mode=None, name=None, org=None, org_id=None, owner=None, page=None, page_size=None, project_id=None, project_name=None, search=None, sort=None, status=None, subset=None, tracker_link=None, validation_mode=None, **kwargs )\nList tasks\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) assignee = \"assignee_example\" # str | A simple equality filter for the assignee field (optional) dimension = \"3d\" # str | A simple equality filter for the dimension field (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['project_name', 'name', 'owner', 'status', 'assignee', 'subset', 'mode', 'dimension', 'tracker_link', 'validation_mode', 'id', 'project_id', 'updated_date']. There are few examples for complex filtering tasks: - Get all tasks from 1,2,3 projects - { \\\"and\\\" : [{ \\\"in\\\" : [{ \\\"var\\\" : \\\"project_id\\\" }, [1, 2, 3]]}]} - Get all completed tasks from 1 project - { \\\"and\\\": [{ \\\"==\\\": [{ \\\"var\\\" : \\\"status\\\" }, \\\"completed\\\"]}, { \\\"==\\\" : [{ \\\"var\\\" : \\\"project_id\\\"}, 1]}]} (optional) mode = \"mode_example\" # str | A simple equality filter for the mode field (optional) name = \"name_example\" # str | A simple equality filter for the name field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) project_id = 1 # int | A simple equality filter for the project_id field (optional) project_name = \"project_name_example\" # str | A simple equality filter for the project_name field (optional) search = \"search_example\" # str | A search term. Available search_fields: ('project_name', 'name', 'owner', 'status', 'assignee', 'subset', 'mode', 'dimension', 'tracker_link', 'validation_mode') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['project_name', 'name', 'owner', 'status', 'assignee', 'subset', 'mode', 'dimension', 'tracker_link', 'validation_mode', 'id', 'project_id', 'updated_date'] (optional) status = \"annotation\" # str | A simple equality filter for the status field (optional) subset = \"subset_example\" # str | A simple equality filter for the subset field (optional) tracker_link = \"tracker_link_example\" # str | A simple equality filter for the tracker_link field (optional) validation_mode = \"gt\" # str | A simple equality filter for the validation_mode field (optional) try: (data, response) = api_client.tasks_api.list( x_organization=x_organization, assignee=assignee, dimension=dimension, filter=filter, mode=mode, name=name, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, project_id=project_id, project_name=project_name, search=search, sort=sort, status=status, subset=subset, tracker_link=tracker_link, validation_mode=validation_mode, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] assignee str A simple equality filter for the assignee field [optional] dimension str A simple equality filter for the dimension field [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘project_name’, ’name’, ‘owner’, ‘status’, ‘assignee’, ‘subset’, ‘mode’, ‘dimension’, ’tracker_link’, ‘validation_mode’, ‘id’, ‘project_id’, ‘updated_date’]. There are few examples for complex filtering tasks: - Get all tasks from 1,2,3 projects - { \"and\" : [{ \"in\" : [{ \"var\" : \"project_id\" }, [1, 2, 3]]}]} - Get all completed tasks from 1 project - { \"and\": [{ \"==\": [{ \"var\" : \"status\" }, \"completed\"]}, { \"==\" : [{ \"var\" : \"project_id\"}, 1]}]} [optional] mode str A simple equality filter for the mode field [optional] name str A simple equality filter for the name field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] project_id int A simple equality filter for the project_id field [optional] project_name str A simple equality filter for the project_name field [optional] search str A search term. Available search_fields: (‘project_name’, ’name’, ‘owner’, ‘status’, ‘assignee’, ‘subset’, ‘mode’, ‘dimension’, ’tracker_link’, ‘validation_mode’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘project_name’, ’name’, ‘owner’, ‘status’, ‘assignee’, ‘subset’, ‘mode’, ‘dimension’, ’tracker_link’, ‘validation_mode’, ‘id’, ‘project_id’, ‘updated_date’] [optional] status str A simple equality filter for the status field [optional] subset str A simple equality filter for the subset field [optional] tracker_link str A simple equality filter for the tracker_link field [optional] validation_mode str A simple equality filter for the validation_mode field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedTaskReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_task_write_request=None, **kwargs )\nUpdate a task\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. patched_task_write_request = PatchedTaskWriteRequest( name=\"name_example\", project_id=1, owner_id=1, assignee_id=1, bug_tracker=\"bug_tracker_example\", labels=[ PatchedLabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], deleted=True, type=None, svg=\"svg_example\", sublabels=[ SublabelRequest( id=1, name=\"name_example\", color=\"color_example\", attributes=[ AttributeRequest( id=1, name=\"name_example\", mutable=True, input_type=InputTypeEnum(\"checkbox\"), default_value=\"default_value_example\", values=[ \"values_example\", ], ), ], type=None, has_parent=True, ), ], ), ], subset=\"subset_example\", target_storage=StorageRequest( location=LocationEnum(\"cloud_storage\"), cloud_storage_id=1, ), source_storage=StorageRequest( location=LocationEnum(\"cloud_storage\"), cloud_storage_id=1, ), organization_id=1, ) # PatchedTaskWriteRequest | (optional) try: (data, response) = api_client.tasks_api.partial_update( id, patched_task_write_request=patched_task_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. patched_task_write_request PatchedTaskWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[TaskRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_annotations partial_update_annotations( action, id, patched_labeled_data_request=None, **kwargs )\nUpdate task annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: action = \"create\" # str | id = 1 # int | A unique integer value identifying this task. patched_labeled_data_request = PatchedLabeledDataRequest( version=0, tags=[ LabeledImageRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], shapes=[ LabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], tracks=[ LabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], ) # PatchedLabeledDataRequest | (optional) try: (data, response) = api_client.tasks_api.partial_update_annotations( action, id, patched_labeled_data_request=patched_labeled_data_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.partial_update_annotations(): %s\\n\" % e) Parameters Name Type Description Notes action str id int A unique integer value identifying this task. patched_labeled_data_request PatchedLabeledDataRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[LabeledData, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_data_meta partial_update_data_meta( id, patched_data_meta_write_request=None, **kwargs )\nUpdate metainformation for media files in a task\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. patched_data_meta_write_request = PatchedDataMetaWriteRequest( deleted_frames=[ 0, ], cloud_storage_id=1, ) # PatchedDataMetaWriteRequest | (optional) try: (data, response) = api_client.tasks_api.partial_update_data_meta( id, patched_data_meta_write_request=patched_data_meta_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.partial_update_data_meta(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. patched_data_meta_write_request PatchedDataMetaWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[DataMetaRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update_validation_layout partial_update_validation_layout( id, patched_task_validation_layout_write_request=None, **kwargs )\nAllows updating current validation configuration\nWARNING: this operation is not protected from race conditions. It’s up to the user to ensure no parallel calls to this operation happen. It affects image access, including exports with images, backups, chunk downloading etc.\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. patched_task_validation_layout_write_request = PatchedTaskValidationLayoutWriteRequest( disabled_frames=[ 0, ], frame_selection_method=None, honeypot_real_frames=[ 0, ], ) # PatchedTaskValidationLayoutWriteRequest | (optional) try: (data, response) = api_client.tasks_api.partial_update_validation_layout( id, patched_task_validation_layout_write_request=patched_task_validation_layout_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.partial_update_validation_layout(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. patched_task_validation_layout_write_request PatchedTaskValidationLayoutWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[TaskValidationLayoutRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet task details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: (data, response) = api_client.tasks_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[TaskRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_annotations retrieve_annotations( id, **kwargs )\nGet task annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: (data, response) = api_client.tasks_api.retrieve_annotations( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[LabeledData, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - 400 Exporting without data is not allowed - 410 API endpoint no longer handles exporting process - retrieve_data retrieve_data( id, number=None, quality=None, type=None, **kwargs )\nGet data of a task\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. number = 1 # int | A unique number value identifying chunk or frame (optional) quality = \"compressed\" # str | Specifies the quality level of the requested data (optional) type = \"chunk\" # str | Specifies the type of the requested data (optional) try: api_client.tasks_api.retrieve_data( id, number=number, quality=quality, type=type, ) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve_data(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. number int A unique number value identifying chunk or frame [optional] quality str Specifies the quality level of the requested data [optional] type str Specifies the type of the requested data [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Data of a specific type * X-Checksum - Data checksum, applicable for chunks only * X-Updated-Date - Data update date, applicable for chunks only retrieve_data_meta retrieve_data_meta( id, **kwargs )\nGet metainformation for media files in a task\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: (data, response) = api_client.tasks_api.retrieve_data_meta( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve_data_meta(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[DataMetaRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_preview retrieve_preview( id, **kwargs )\nGet a preview image for a task\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: api_client.tasks_api.retrieve_preview( id,) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve_preview(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 Task image preview - 404 Task image preview not found - retrieve_status retrieve_status( id, **kwargs )\nGet the creation status of a task\nThis method is deprecated and will be removed in one of the next releases. To check status of task creation, use new common API for managing background operations: GET /api/requests/?action=create\u0026task_id=\u003ctask_id\u003e\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: (data, response) = api_client.tasks_api.retrieve_status( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve_status(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[RqStatus, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_validation_layout retrieve_validation_layout( id, **kwargs )\nAllows getting current validation configuration\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. try: (data, response) = api_client.tasks_api.retrieve_validation_layout( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.retrieve_validation_layout(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[TaskValidationLayoutRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - update_annotations update_annotations( id, labeled_data_request=None, **kwargs )\nReplace task annotations\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this task. labeled_data_request = LabeledDataRequest( version=0, tags=[ LabeledImageRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], shapes=[ LabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, label_id=0, group=0, source=\"manual\", attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], tracks=[ LabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], elements=[ SubLabeledTrackRequest( id=1, frame=0, label_id=0, group=0, source=\"manual\", shapes=[ TrackedShapeRequest( type=ShapeType(\"rectangle\"), occluded=False, outside=False, z_order=0, rotation=0.0, points=[ 3.14, ], id=1, frame=0, attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], attributes=[ AttributeValRequest( spec_id=1, value=\"value_example\", ), ], ), ], ), ], ) # LabeledDataRequest | (optional) try: api_client.tasks_api.update_annotations( id, labeled_data_request=labeled_data_request, ) except exceptions.ApiException as e: print(\"Exception when calling TasksApi.update_annotations(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this task. labeled_data_request LabeledDataRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json, multipart/form-data Accept: Not defined HTTP response details Status code Description Response headers 200 Annotations have been replaced - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/tasks-api/","tags":"","title":"TasksApi class reference"},{"body":"Properties Name Type Description Notes count int [optional] if omitted the server will use the default value of 0 url str [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes count int [optional] if omitted …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/tasks-summary/","tags":"","title":"TasksSummary class reference"},{"body":"Properties Name Type Description Notes mode TaskValidationLayoutReadMode [optional] frames_per_job_count int, none_type [optional] [readonly] validation_frames [int] The list of frame ids to be used for validation [optional] disabled_frames [int] The list of frame ids excluded from validation [optional] honeypot_count int [optional] honeypot_frames [int] The list of frame ids for all honeypots in the task [optional] honeypot_real_frames [int] The list of real (validation) frame ids for all honeypots in the task [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes mode …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/task-validation-layout-read/","tags":"","title":"TaskValidationLayoutRead class reference"},{"body":"Properties Name Type Description Notes ","categories":"","description":"","excerpt":"Properties Name Type Description Notes ","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/task-validation-layout-read-mode/","tags":"","title":"TaskValidationLayoutReadMode class reference"},{"body":"Properties Name Type Description Notes name str project_id int, none_type [optional] owner_id int, none_type [optional] assignee_id int, none_type [optional] bug_tracker str [optional] overlap int, none_type [optional] segment_size int [optional] labels [PatchedLabelRequest] [optional] subset str [optional] target_storage StorageRequest [optional] source_storage StorageRequest [optional] consensus_replicas int The number of consensus replica jobs for each annotation job. Configured at task creation [optional] if omitted the server will use the default value of 0 ","categories":"","description":"","excerpt":"Properties Name Type Description Notes name str project_id int, …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/task-write-request/","tags":"","title":"TaskWriteRequest class reference"},{"body":"Serializer for Token model.\nProperties Name Type Description Notes key str ","categories":"","description":"","excerpt":"Serializer for Token model.\nProperties Name Type Description Notes key …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/token/","tags":"","title":"Token class reference"},{"body":"Properties Name Type Description Notes type ShapeType frame int occluded bool [optional] if omitted the server will use the default value of False outside bool [optional] if omitted the server will use the default value of False z_order int [optional] if omitted the server will use the default value of 0 rotation float [optional] if omitted the server will use the default value of 0.0 points [float] [optional] id int, none_type [optional] attributes [AttributeVal] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type ShapeType frame int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/tracked-shape/","tags":"","title":"TrackedShape class reference"},{"body":"Properties Name Type Description Notes type ShapeType frame int occluded bool [optional] if omitted the server will use the default value of False outside bool [optional] if omitted the server will use the default value of False z_order int [optional] if omitted the server will use the default value of 0 rotation float [optional] if omitted the server will use the default value of 0.0 points [float] [optional] id int, none_type [optional] attributes [AttributeValRequest] [optional] if omitted the server will use the default value of [] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type ShapeType frame int …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/tracked-shape-request/","tags":"","title":"TrackedShapeRequest class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. groups [str] url str [optional] [readonly] id int [optional] [readonly] first_name str [optional] last_name str [optional] email str [optional] is_staff bool Designates whether the user can log into this admin site. [optional] is_superuser bool Designates that this user has all permissions without explicitly assigning them. [optional] is_active bool Designates whether this user should be treated as active. Unselect this instead of deleting accounts. [optional] last_login datetime, none_type [optional] [readonly] date_joined datetime [optional] [readonly] has_analytics_access bool [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/user/","tags":"","title":"User class reference"},{"body":"Properties Name Type Description Notes username str Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only. id int [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes username str Required. 150 …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/user-identifiers/","tags":"","title":"UserIdentifiers class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description destroy DELETE /api/users/{id} Delete a user list GET /api/users List users partial_update PATCH /api/users/{id} Update a user retrieve GET /api/users/{id} Get user details retrieve_self GET /api/users/self Get details of the current user destroy destroy( id, **kwargs )\nDelete a user\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this user. try: api_client.users_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling UsersApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this user. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The user has been deleted - list list( x_organization=None, filter=None, first_name=None, is_active=None, last_name=None, org=None, org_id=None, page=None, page_size=None, search=None, sort=None, username=None, **kwargs )\nList users\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['username', 'first_name', 'last_name', 'id', 'is_active']. (optional) first_name = \"first_name_example\" # str | A simple equality filter for the first_name field (optional) is_active = True # bool | A simple equality filter for the is_active field (optional) last_name = \"last_name_example\" # str | A simple equality filter for the last_name field (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) search = \"search_example\" # str | A search term. Available search_fields: ('username', 'first_name', 'last_name') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['username', 'first_name', 'last_name', 'id', 'is_active'] (optional) username = \"username_example\" # str | A simple equality filter for the username field (optional) try: (data, response) = api_client.users_api.list( x_organization=x_organization, filter=filter, first_name=first_name, is_active=is_active, last_name=last_name, org=org, org_id=org_id, page=page, page_size=page_size, search=search, sort=sort, username=username, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling UsersApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [‘username’, ‘first_name’, ’last_name’, ‘id’, ‘is_active’]. [optional] first_name str A simple equality filter for the first_name field [optional] is_active bool A simple equality filter for the is_active field [optional] last_name str A simple equality filter for the last_name field [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] search str A search term. Available search_fields: (‘username’, ‘first_name’, ’last_name’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [‘username’, ‘first_name’, ’last_name’, ‘id’, ‘is_active’] [optional] username str A simple equality filter for the username field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedMetaUserList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_user_request=None, **kwargs )\nUpdate a user\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this user. patched_user_request = PatchedUserRequest( username=\"A\", first_name=\"first_name_example\", last_name=\"last_name_example\", email=\"email_example\", groups=[ \"groups_example\", ], is_staff=True, is_superuser=True, is_active=True, ) # PatchedUserRequest | (optional) try: (data, response) = api_client.users_api.partial_update( id, patched_user_request=patched_user_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling UsersApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this user. patched_user_request PatchedUserRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[MetaUser, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet user details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this user. try: (data, response) = api_client.users_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling UsersApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this user. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[MetaUser, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_self retrieve_self( **kwargs )\nGet details of the current user\nMethod returns an instance of a user who is currently authenticated\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: try: (data, response) = api_client.users_api.retrieve_self() pprint(data) except exceptions.ApiException as e: print(\"Exception when calling UsersApi.retrieve_self(): %s\\n\" % e) Parameters This endpoint does not need any parameter.\nThere are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[MetaUser, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/users-api/","tags":"","title":"UsersApi class reference"},{"body":" `gt` - GT * `gt_pool` - GT_POOL Properties Name Type Description Notes value str * gt - GT * gt_pool - GT_POOL must be one of [“gt”, “gt_pool”, ] ","categories":"","description":"","excerpt":" `gt` - GT * `gt_pool` - GT_POOL Properties Name Type Description …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/validation-mode/","tags":"","title":"ValidationMode class reference"},{"body":"Properties Name Type Description Notes mode ValidationMode frame_selection_method FrameSelectionMethod random_seed int The seed value for the random number generator. The same value will produce the same frame sets. Applicable only to random frame selection methods. By default, a random value is used. [optional] frames [str] The list of file names to be included in the validation set. Applicable only to the \"manual\" frame selection method. Can only be used for images. [optional] frame_count int The number of frames to be included in the validation set. Applicable only to the \"random_uniform\" frame selection method [optional] frame_share float The share of frames to be included in the validation set. Applicable only to the \"random_uniform\" frame selection method [optional] frames_per_job_count int The number of frames to be included in the validation set from each annotation job. Applicable only to the \"random_per_job\" frame selection method [optional] frames_per_job_share float The share of frames to be included in the validation set from each annotation job. Applicable only to the \"random_per_job\" frame selection method [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes mode ValidationMode …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/validation-params-request/","tags":"","title":"ValidationParamsRequest class reference"},{"body":" `application/json` - JSON Properties Name Type Description Notes value str * application/json - JSON defaults to “application/json”, must be one of [“application/json”, ] ","categories":"","description":"","excerpt":" `application/json` - JSON Properties Name Type Description Notes …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/webhook-content-type/","tags":"","title":"WebhookContentType class reference"},{"body":"Properties Name Type Description Notes id int [optional] [readonly] webhook_id int [optional] [readonly] event str [optional] [readonly] status_code int, none_type [optional] [readonly] redelivery bool [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] changed_fields str [optional] [readonly] request {str: (bool, date, datetime, dict, float, int, list, str, none_type)} [optional] [readonly] response {str: (bool, date, datetime, dict, float, int, list, str, none_type)} [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes id int [optional] [readonly] …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/webhook-delivery-read/","tags":"","title":"WebhookDeliveryRead class reference"},{"body":"Properties Name Type Description Notes type WebhookType content_type WebhookContentType id int [optional] [readonly] url str [optional] [readonly] target_url str [optional] [readonly] description str [optional] [readonly] is_active bool [optional] [readonly] enable_ssl bool [optional] [readonly] created_date datetime [optional] [readonly] updated_date datetime [optional] [readonly] owner JobReadAssignee [optional] project_id int, none_type [optional] organization int, none_type [optional] [readonly] events [EventsEnum] [optional] [readonly] last_status int [optional] [readonly] last_delivery_date datetime [optional] [readonly] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes type WebhookType content_type …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/webhook-read/","tags":"","title":"WebhookRead class reference"},{"body":"All URIs are relative to http://localhost\nMethod HTTP request Description create POST /api/webhooks Create a webhook create_deliveries_redelivery POST /api/webhooks/{id}/deliveries/{delivery_id}/redelivery Redeliver a webhook delivery create_ping POST /api/webhooks/{id}/ping Send a ping webhook destroy DELETE /api/webhooks/{id} Delete a webhook list GET /api/webhooks List webhooks list_deliveries GET /api/webhooks/{id}/deliveries List deliveries for a webhook partial_update PATCH /api/webhooks/{id} Update a webhook retrieve GET /api/webhooks/{id} Get webhook details retrieve_deliveries GET /api/webhooks/{id}/deliveries/{delivery_id} Get details of a webhook delivery retrieve_events GET /api/webhooks/events List available webhook events update PUT /api/webhooks/{id} Replace a webhook create create( webhook_write_request, x_organization=None, org=None, org_id=None, **kwargs )\nCreate a webhook\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: webhook_write_request = WebhookWriteRequest( target_url=\"target_url_example\", description=\"description_example\", type=WebhookType(\"organization\"), content_type=WebhookContentType(\"application/json\"), secret=\"secret_example\", is_active=True, enable_ssl=True, project_id=1, events=[ EventsEnum(\"create:comment\"), ], ) # WebhookWriteRequest | x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) try: (data, response) = api_client.webhooks_api.create( webhook_write_request, x_organization=x_organization, org=org, org_id=org_id, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.create(): %s\\n\" % e) Parameters Name Type Description Notes webhook_write_request WebhookWriteRequest x_organization str Organization unique slug [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[WebhookRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 201 - create_deliveries_redelivery create_deliveries_redelivery( delivery_id, id, **kwargs )\nRedeliver a webhook delivery\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: delivery_id = \"4\" # str | id = 1 # int | A unique integer value identifying this webhook. try: api_client.webhooks_api.create_deliveries_redelivery( delivery_id, id,) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.create_deliveries_redelivery(): %s\\n\" % e) Parameters Name Type Description Notes delivery_id str id int A unique integer value identifying this webhook. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 200 No response body - create_ping create_ping( id, **kwargs )\nSend a ping webhook\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this webhook. try: (data, response) = api_client.webhooks_api.create_ping( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.create_ping(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this webhook. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[WebhookDeliveryRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - destroy destroy( id, **kwargs )\nDelete a webhook\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this webhook. try: api_client.webhooks_api.destroy( id,) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.destroy(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this webhook. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[None, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (None, raw_response).\nThis endpoint does not have any return value, so None is always returned as the first value. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: Not defined HTTP response details Status code Description Response headers 204 The webhook has been deleted - list list( x_organization=None, filter=None, org=None, org_id=None, owner=None, page=None, page_size=None, project_id=None, search=None, sort=None, target_url=None, type=None, **kwargs )\nList webhooks\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: x_organization = \"X-Organization_example\" # str | Organization unique slug (optional) filter = \"filter_example\" # str | JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\\\"and\\\":[{\\\"==\\\":[{\\\"var\\\":\\\"owner\\\"},\\\"\u003cuser\u003e\\\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: ['target_url', 'owner', 'type', 'description', 'id', 'project_id', 'updated_date']. (optional) org = \"org_example\" # str | Organization unique slug (optional) org_id = 1 # int | Organization identifier (optional) owner = \"owner_example\" # str | A simple equality filter for the owner field (optional) page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) project_id = 1 # int | A simple equality filter for the project_id field (optional) search = \"search_example\" # str | A search term. Available search_fields: ('target_url', 'owner', 'type', 'description') (optional) sort = \"sort_example\" # str | Which field to use when ordering the results. Available ordering_fields: ['target_url', 'owner', 'type', 'description', 'id', 'project_id', 'updated_date'] (optional) target_url = \"target_url_example\" # str | A simple equality filter for the target_url field (optional) type = \"organization\" # str | A simple equality filter for the type field (optional) try: (data, response) = api_client.webhooks_api.list( x_organization=x_organization, filter=filter, org=org, org_id=org_id, owner=owner, page=page, page_size=page_size, project_id=project_id, search=search, sort=sort, target_url=target_url, type=type, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.list(): %s\\n\" % e) Parameters Name Type Description Notes x_organization str Organization unique slug [optional] filter str JSON Logic filter. This filter can be used to perform complex filtering by grouping rules. For example, using such a filter you can get all resources created by you: - {\"and\":[{\"==\":[{\"var\":\"owner\"},\"\"]}]} Details about the syntax used can be found at the link: https://jsonlogic.com/ Available filter_fields: [’target_url’, ‘owner’, ’type’, ‘description’, ‘id’, ‘project_id’, ‘updated_date’]. [optional] org str Organization unique slug [optional] org_id int Organization identifier [optional] owner str A simple equality filter for the owner field [optional] page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] project_id int A simple equality filter for the project_id field [optional] search str A search term. Available search_fields: (’target_url’, ‘owner’, ’type’, ‘description’) [optional] sort str Which field to use when ordering the results. Available ordering_fields: [’target_url’, ‘owner’, ’type’, ‘description’, ‘id’, ‘project_id’, ‘updated_date’] [optional] target_url str A simple equality filter for the target_url field [optional] type str A simple equality filter for the type field [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedWebhookReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - list_deliveries list_deliveries( id, page=None, page_size=None, **kwargs )\nList deliveries for a webhook\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this webhook. page = 1 # int | A page number within the paginated result set. (optional) page_size = 1 # int | Number of results to return per page. (optional) try: (data, response) = api_client.webhooks_api.list_deliveries( id, page=page, page_size=page_size, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.list_deliveries(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this webhook. page int A page number within the paginated result set. [optional] page_size int Number of results to return per page. [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[PaginatedWebhookDeliveryReadList, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - partial_update partial_update( id, patched_webhook_write_request=None, **kwargs )\nUpdate a webhook\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this webhook. patched_webhook_write_request = PatchedWebhookWriteRequest( target_url=\"target_url_example\", description=\"description_example\", content_type=WebhookContentType(\"application/json\"), secret=\"secret_example\", is_active=True, enable_ssl=True, events=[ EventsEnum(\"create:comment\"), ], ) # PatchedWebhookWriteRequest | (optional) try: (data, response) = api_client.webhooks_api.partial_update( id, patched_webhook_write_request=patched_webhook_write_request, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.partial_update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this webhook. patched_webhook_write_request PatchedWebhookWriteRequest [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[WebhookRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve retrieve( id, **kwargs )\nGet webhook details\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this webhook. try: (data, response) = api_client.webhooks_api.retrieve( id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.retrieve(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this webhook. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[WebhookRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_deliveries retrieve_deliveries( delivery_id, id, **kwargs )\nGet details of a webhook delivery\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: delivery_id = \"4\" # str | id = 1 # int | A unique integer value identifying this webhook. try: (data, response) = api_client.webhooks_api.retrieve_deliveries( delivery_id, id,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.retrieve_deliveries(): %s\\n\" % e) Parameters Name Type Description Notes delivery_id str id int A unique integer value identifying this webhook. There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[WebhookDeliveryRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - retrieve_events retrieve_events( type=None, **kwargs )\nList available webhook events\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: type = \"type_example\" # str | Type of webhook (optional) try: (data, response) = api_client.webhooks_api.retrieve_events( type=type, ) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.retrieve_events(): %s\\n\" % e) Parameters Name Type Description Notes type str Type of webhook [optional] There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[Events, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: Not defined Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - update update( id, webhook_write_request, **kwargs )\nReplace a webhook\nExample from pprint import pprint from cvat_sdk.api_client import Configuration, ApiClient, exceptions from cvat_sdk.api_client.models import * # Set up an API client # Read Configuration class docs for more info about parameters and authentication methods configuration = Configuration( host = \"http://localhost\", username = 'YOUR_USERNAME', password = 'YOUR_PASSWORD', ) with ApiClient(configuration) as api_client: id = 1 # int | A unique integer value identifying this webhook. webhook_write_request = WebhookWriteRequest( target_url=\"target_url_example\", description=\"description_example\", type=WebhookType(\"organization\"), content_type=WebhookContentType(\"application/json\"), secret=\"secret_example\", is_active=True, enable_ssl=True, project_id=1, events=[ EventsEnum(\"create:comment\"), ], ) # WebhookWriteRequest | try: (data, response) = api_client.webhooks_api.update( id, webhook_write_request,) pprint(data) except exceptions.ApiException as e: print(\"Exception when calling WebhooksApi.update(): %s\\n\" % e) Parameters Name Type Description Notes id int A unique integer value identifying this webhook. webhook_write_request WebhookWriteRequest There are also optional kwargs that control the function invocation behavior. Read more here.\nReturned values Returned type: Tuple[WebhookRead, urllib3.HTTPResponse].\nReturns a tuple with 2 values: (parsed_response, raw_response).\nThe first value is a model parsed from the response data. The second value is the raw response, which can be useful to get response parameters, such as status code, headers, or raw response data. Read more about invocation parameters and returned values here.\nAuthentication basicAuth, csrfAuth, csrfHeaderAuth, sessionAuth, tokenAuth\nHTTP request headers Content-Type: application/json Accept: application/vnd.cvat+json HTTP response details Status code Description Response headers 200 - ","categories":"","description":"","excerpt":"All URIs are relative to http://localhost\nMethod HTTP request …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/apis/webhooks-api/","tags":"","title":"WebhooksApi class reference"},{"body":" `organization` - ORGANIZATION * `project` - PROJECT Properties Name Type Description Notes value str * organization - ORGANIZATION * project - PROJECT must be one of [“organization”, “project”, ] ","categories":"","description":"","excerpt":" `organization` - ORGANIZATION * `project` - PROJECT Properties Name …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/webhook-type/","tags":"","title":"WebhookType class reference"},{"body":"Properties Name Type Description Notes target_url str type WebhookType events [EventsEnum] description str [optional] content_type WebhookContentType [optional] secret str [optional] is_active bool [optional] enable_ssl bool [optional] project_id int, none_type [optional] ","categories":"","description":"","excerpt":"Properties Name Type Description Notes target_url str type WebhookType …","ref":"/v2.43.0/docs/api_sdk/sdk/reference/models/webhook-write-request/","tags":"","title":"WebhookWriteRequest class reference"},{"body":"It is used for road sign annotation etc.\nFirst of all you need to select the ellipse on the controls sidebar.\nChoose a Label and click Shape or Track to start drawing. An ellipse can be created the same way as a rectangle, you need to specify two opposite points, and the ellipse will be inscribed in an imaginary rectangle. Press N or click the Done button on the top panel to complete the shape.\nYou can rotate ellipses using a rotation point in the same way as rectangles.\nAnnotation with ellipses video tutorial ","categories":"","description":"Guide to annotating tasks using ellipses.","excerpt":"Guide to annotating tasks using ellipses.","ref":"/v2.43.0/docs/manual/advanced/annotation-with-ellipses/","tags":"","title":"Annotation with ellipses"},{"body":"In the objects sidebar, you can see the list of available objects on the current frame. The following figure is an example of how the list might look like:\nShape mode Track mode Objects properties Filter input box\nThe way how to use filters is described in the advanced guide here.\nList of objects\nSwitch lock property for all - switches lock property of all objects in the frame. Switch hidden property for all - switches hide the property of all objects in the frame. Expand/collapse all - collapses/expands the details field of all objects in the frame. Sorting - sort the list of objects: updated time, ID - accent, ID - descent Objects on the sidebar\nThe type of shape can be changed by selecting the Label property. For instance, it can look like shown in the figure below:\nObject action menu\nThe action menu calls up the button:\nThe action menu contains:\nCreate object URL - puts a link to an object on the clipboard. After you open the link, this object will be filtered.\nMake a copy - copies an object. The keyboard shortcut is Ctrl + C \u003e Ctrl + V.\nPropagate function copies the form to multiple frames and displays a dialog box where you can specify the number of copies or the frame to which you want to copy the object. The keyboard shortcut is Ctrl + B. On how to propagate only filtered shapes, see Shapes converter\nThere are two options available:\nPropagate forward () creates a copy of the object on N subsequent frames at the same position. Propagate backward () creates a copy of the object on N previous frames at the same position. To background - moves the object to the background. The keyboard shortcut - or _\nTo foreground - moves the object to the foreground. The keyboard shortcut + or =\nChange instance color- choosing a color using the color picker (available only in instance mode).\nRemove - removes the object. The keyboard shortcut Del, Shift+Del.\nA shape can be locked to prevent its modification or moving by an accident. Shortcut to lock an object: L.\nA shape can be Occluded. Shortcut: Q. Such shapes have dashed boundaries.\nYou can change the way an object is displayed on a frame (show or hide).\nSwitch pinned property - when enabled, a shape cannot be moved by dragging or dropping.\nTracker switcher - enable/disable tracking for the object.\nBy clicking on the Details button you can collapse or expand the field with all the attributes of the object.\nLabels In this tab, you can lock or hide objects of a certain label. To change the color for a specific label, you need to go to the task page and select the color by clicking the edit button, this way you will change the label color for all jobs in the task.\nFast label change\nYou can change the label of an object using hotkeys. In order to do it, you need to assign a number (from 0 to 9) to labels. By default numbers 1,2…0 are assigned to the first ten labels. To assign a number, click on the button placed at the right of a label name on the sidebar.\nAfter that, you will be able to assign a corresponding label to an object by hovering your mouse cursor over it and pressing Ctrl + Num(0..9).\nIn case you do not point the cursor to the object, pressing Ctrl + Num(0..9) will set a chosen label as default, so that the next object you create (use the N key) will automatically have this label assigned.\nAppearance Color By options\nChange the color scheme of the annotation:\nInstance — every shape has a random color\nGroup — every group of shape has its own random color, ungrouped shapes are white\nLabel — every label (e.g. car, person) has its own random color\nYou can change any random color pointing to a needed box on a frame or on an object sidebar.\nFill Opacity slider\nChange the opacity of every shape in the annotation.\nSelected Fill Opacity slider\nChange the opacity of the selected object’s fill. It is possible to change the opacity while drawing an object in the case of rectangles, polygons, and cuboids.\nOutlined borders checkbox\nYou can change a special shape border color by clicking on the Eyedropper icon.\nShow bitmap checkbox\nIf enabled all shapes are displayed in white and the background is black.\nShow projections checkbox\nEnables/disables the display of auxiliary perspective lines. Only relevant for cuboids\nHide objects sidebar Hide - the button hides the object’s sidebar.\n","categories":"","description":" Displays annotated objects and includes a label filter, lists of objects (current frame) and labels (objects on the frame), and appearance settings. ","excerpt":" Displays annotated objects and includes a label filter, lists of …","ref":"/v2.43.0/docs/manual/basics/cvat-annotation-interface/objects-sidebar/","tags":"","title":"Objects sidebar"},{"body":"E2E tests Initial steps:\nRun CVAT instance: docker compose \\ -f docker-compose.yml \\ -f docker-compose.dev.yml \\ -f components/serverless/docker-compose.serverless.yml \\ -f tests/docker-compose.minio.yml \\ -f tests/docker-compose.file_share.yml up -d Add test user in CVAT: docker exec -i cvat_server \\ /bin/bash -c \\ \"echo \\\"from django.contrib.auth.models import User; User.objects.create_superuser('admin', 'admin@localhost.company', '12qwaszx')\\\" | python3 ~/manage.py shell\" Install npm dependencies: cd tests yarn --frozen-lockfile If you want to get a code coverage report, instrument the code:\nyarn --frozen-lockfile yarn run coverage Running tests\nyarn run cypress:run:chrome yarn run cypress:run:chrome:canvas3d REST API, SDK and CLI tests Initial steps\nFollow this guide to prepare cvat-sdk and cvat-cli source code Install all necessary requirements before running REST API tests: pip install -e ./cvat-sdk -e ./cvat-cli -r ./tests/python/requirements.txt Stop any other CVAT containers which you run previously. They keep ports which are used by containers for the testing system. Running tests\nRun all REST API tests:\npytest ./tests/python This command will automatically start all necessary docker containers.\nIf you want to start/stop these containers without running tests use special options for it:\npytest ./tests/python --start-services pytest ./tests/python --stop-services If you need to rebuild your CVAT images add --rebuild option:\npytest ./tests/python --rebuild If you want to get a code coverage report, use special option for it:\nCOVERAGE_PROCESS_START=.coveragerc pytest ./tests/python --rebuild --cov --cov-report xml Debugging\nCurrently, this is only supported in deployments based on Docker Compose, which should be enough to fix errors arising in REST API tests.\nTo debug a server deployed with Docker, you need to do the following:\nAdjust env variables in the docker-compose.dev.yml file for your test case\nRebuild the images and start the test containers:\nCVAT_DEBUG_ENABLED=yes pytest --rebuild --start-services tests/python Now, you can use VS Code tasks to attach to the running server containers. To attach to a container, run one of the following tasks:\nREST API tests: Attach to server for the server container REST API tests: Attach to RQ low for the low priority queue worker REST API tests: Attach to RQ default for the default priority queue worker If you have a custom development environment setup, you need to adjust host-remote path mappings in the .vscode/launch.json:\n... \"pathMappings\": [ { \"localRoot\": \"${workspaceFolder}/my_venv\", \"remoteRoot\": \"/opt/venv\", }, { \"localRoot\": \"/some/other/path\", \"remoteRoot\": \"/some/container/path\", } ] Extra options:\nIf you want the server to wait for a debugger on startup, use the CVAT_DEBUG_WAIT_CLIENT environment variable: CVAT_DEBUG_WAIT_CLIENT=yes pytest ... If you want to change the default debugging ports, check the *_DEBUG_PORT variables in the docker-compose.dev.yml Server unit tests Initial steps\nIf you run unit tests on Linux, ensure that poppler-utils and unrar are installed on your system: sudo apt-get update sudo apt-get install -y poppler-utils unrar Install necessary Python dependencies: pip install -r cvat/requirements/testing.txt Build CVAT server image docker compose -f docker-compose.yml -f docker-compose.dev.yml build cvat_server Run cvat_opa container docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d cvat_opa Running tests\nPython tests python manage.py test --settings cvat.settings.testing cvat/apps -v 2 If you want to get a code coverage report, run the next command:\ncoverage run manage.py test --settings cvat.settings.testing cvat/apps -v 2 Debugging\nRun server: tests debug task in VSCode If you want to debug particular tests then change the configuration of the corresponding task in ./vscode/launch.json, for example: { \"name\": \"server: tests\", \"type\": \"python\", \"request\": \"launch\", \"justMyCode\": false, \"stopOnEntry\": false, \"python\": \"${command:python.interpreterPath}\", \"program\": \"${workspaceRoot}/manage.py\", \"args\": [ \"test\", \"--settings\", \"cvat.settings.testing\", \"cvat/apps/engine\", \"-v\", \"2\", \"-k\", \"test_api_v2_projects_\", ], \"django\": true, \"cwd\": \"${workspaceFolder}\", \"env\": {}, \"console\": \"internalConsole\" } IAM and Open Policy Agent tests Generate tests python cvat/apps/iam/rules/tests/generate_tests.py Run testing In a Docker container docker compose run --rm -v \"$PWD:/mnt/src:ro\" -w /mnt/src \\ cvat_opa test -v cvat/apps/*/rules or execute OPA directly curl -L -o opa https://openpolicyagent.org/downloads/v0.63.0/opa_linux_amd64_static chmod +x ./opa ./opa test cvat/apps/*/rules Linting Rego The Rego policies in this project are linted using Regal.\nIn a Docker container docker run --rm -v ${PWD}:/mnt/src:ro -w /mnt/src \\ ghcr.io/styrainc/regal:0.11.0 \\ lint cvat/apps/*/rules or execute Regal directly curl -L -o regal https://github.com/StyraInc/regal/releases/download/v0.11.0/regal_Linux_x86_64 chmod +x ./regal ./regal lint cvat/apps/*/rules ","categories":"","description":"Instructions on how to run all existence tests.","excerpt":"Instructions on how to run all existence tests.","ref":"/v2.43.0/docs/contributing/running-tests/","tags":"","title":"Running tests"},{"body":"It is used to annotate 3 dimensional objects such as cars, boxes, etc… Currently the feature supports one point perspective and has the constraint where the vertical edges are exactly parallel to the sides.\n","categories":"","description":"Guide to creating and editing cuboids.","excerpt":"Guide to creating and editing cuboids.","ref":"/v2.43.0/docs/manual/advanced/annotation-with-cuboids/","tags":"","title":"Annotation with cuboids"},{"body":"In this guide, we delve into the efficient process of annotating complex structures through the implementation of Skeleton annotations.\nSkeletons serve as annotation templates for annotating complex objects with a consistent structure, such as human pose estimation or facial landmarks.\nA Skeleton is composed of numerous points (also referred to as elements), which may be connected by edges. Each point functions as an individual object, possessing unique attributes and properties like color, occlusion, and visibility.\nSkeletons can be exported in two formats: CVAT for image and COCO Keypoints.\nNote Skeletons’ labels cannot be imported in a label-less project by importing a dataset. You need to define the labels manually before the import. See:\nAdding Skeleton manually Skeleton Configurator Configuring Skeleton points Adding Skeleton labels manually Adding Skeleton labels from the model Annotation with Skeletons Automatic annotation with Skeletons Editing skeletons on the canvas Editing skeletons on the sidebar Adding Skeleton manually To start annotating using skeletons, you need to set up a Skeleton task in Configurator:\nTo open Configurator, when creating a task, click on the Setup skeleton button if you want to set up the skeleton manually, or From model if you want to add skeleton labels from a model.\nSkeleton Configurator The skeleton Configurator is a tool to build skeletons for annotation. It has the following fields:\nNumber Name Description 1 Upload background image (Optional) Use it to upload a background image, to draw a skeleton on top of it. 2 Add point Use it to add Skeleton points to the Drawing area (8). 3 Click and drag Use it to move points across the Drawing area (8). 4 Add edge Use it to add edge on the Drawing area (8) to connect the points (2). 5 Remove point Use it to remove points. Click on Remove point and then on any point (2) on the Drawing area (8) to delete the point. 6 Download skeleton Use it to download created skeleton in .SVG format. 7 Upload skeleton Use it to upload skeleton in .SVG format. 8 Drawing area Use it as a canvas to draw a skeleton. Configuring Skeleton points You can name labels, set attributes, and change the color of each point of the skeleton.\nTo do this, right-click on the skeleton point and select Configure:\nIn the opened menu, you can change the point setting. It is similar to adding labels and attributes of the regular task:\nA Skeleton point can only exist within its parent Skeleton.\nNote You cannot change the skeleton configuration for an existing task/project.\nYou can copy/insert skeleton configuration from the Raw tab of the label configurator.\nAdding Skeleton labels manually To create the Skeleton task, do the following:\nOpen Configurator. (Optional) Upload background image. In the Label name field, enter the name of the label. (Optional) Add attribute Note: you can add attributes exclusively to each point, for more information, see Configuring Skeleton points Use Add point to add points to the Drawing area. Use Add edge to add edges between points. Upload files. Click: Submit \u0026 Open to create and open the task. Submit \u0026 Continue to submit the configuration and start creating a new task. Adding Skeleton labels from the model To add points from the model, and annotate do the following:\nOpen Basic configurator.\nOn the Constructor tab, click From model.\nFrom the Select a model to pick labels select the Human pose estimation model or others if available.\nClick on the model’s labels, you want to use. Selected labels will become gray.\n(Optional) If you want to adjust labels, within the label, click the Update attributes icon. The Skeleton configurator will open, where you can configure the skeleton. Note: Labels cannot be adjusted after the task/project is created.\nClick Done. The labels, that you selected, will appear in the labels window.\nUpload data.\nClick:\nSubmit \u0026 Open to create and open the task. Submit \u0026 Continue to submit the configuration and start creating a new task. Annotation with Skeletons To annotate with Skeleton, do the following\nOpen job.\nOn the tools panel select Draw new skeleton.\nSelect Track to annotate with tracking or Shape to annotate without tracking.\nDraw a skeleton on the image.\nAutomatic annotation with Skeletons To automatically annotate with Skeleton, do the following\nOpen the job and on the tools panel select AI Tools \u003e Detectors\nFrom the drop-down list select the model. You will see a list of points to match and the name of the skeleton on the top of the list.\n(Optional) By clicking on the Bin icon, you can remove any mapped item:\nA skeleton together with all points. Certain points from two mapped skeletons. Click Annotate.\nEditing skeletons on the canvas A drawn skeleton is encompassed within a bounding box, it allows you to manipulate the skeleton as a regular bounding box, enabling actions such as dragging, resizing, or rotating:\nUpon repositioning a point, the bounding box adjusts automatically, without affecting other points:\nAdditionally, Shortcuts are applicable to both the skeleton as a whole and its elements:\nTo use a shortcut to the entire skeleton, hover over the bounding box and push the shortcut keyboard key. This action is applicable for shortcuts like the lock, occluded, pinned, keyframe, and outside for skeleton tracks. To use a shortcut to a specific skeleton point, hover over the point and push the shortcut keyboard key. The same list of shortcuts is available, with the addition of outside, which is also applicable to individual skeleton shape elements. Editing skeletons on the sidebar In CVAT, the sidebar offers an alternative method for setting up skeleton properties and attributes.\nThis approach is similar to that used for other object types supported by CVAT, but with a few specific alterations:\nAn additional collapsible section is provided for users to view a comprehensive list of skeleton parts.\nSkeleton points can have properties like Outside, Occluded, and Hidden.\nBoth Outside and Hidden make a skeleton point invisible.\nOutside property is part of annotations. Use it when part of the object is out of frame borders.\nHidden makes a point hidden only for the annotator’s convenience, this property will not be saved between different sessions.\nOccluded keeps the point visible on the frame and usually means that the point is still on a frame, just hidden behind another object.\n","categories":"","description":"Guide to annotating tasks using Skeletons","excerpt":"Guide to annotating tasks using Skeletons","ref":"/v2.43.0/docs/manual/advanced/skeletons/","tags":"","title":"Annotation with skeletons"},{"body":"In CVAT, the workspace serves as a work area where annotators interact with images, videos, and the various tools available to create high-quality annotations.\nSee:\nImage settings in CVAT Adding grid overlay to image in CVAT Changing color settings of image in CVAT Adding layers and Z-axis slider Interacting with Objects Image settings in CVAT The Image settings panel serves as a versatile tool for fine-tuning the visual aspects of your image. Whether you need to brighten the image, increase contrast, or make other adjustments, this panel is your go-to.\nAdditionally, the panel allows you to overlay a grid on the image for more precise annotation.\nNote Adjusting the image settings only alters how the pictures are displayed. The images themselves will remain unmodified and unchanged. By default, the Image settings panel is not visible. To access it, click on the Arrow Up () icon located at the bottom of the workspace.\nAdding grid overlay to image in CVAT To add the grid to the image, do the following:\nOpen the Image Settings panel. Locate and check the box that allows you to overlay a grid on the image. Specify the grid cell size in square millimeters by entering the desired number in the Size field. From the Color drop-down list, select the color of the grid. Use the Opacity slider to change the transparency of the grid overlay. Changing color settings of image in CVAT To change the color setting of the image is CVAT, do the following:\nOpen the Image Settings panel. Use the slider to change the color quality. There are four color quality settings in CVAT:\nBrightness increases and decreases the overall lightness of the image:\nContrast is the range of brightness, from lightest to darkest, in an image.\nSaturation describes the intensity of the color.\nGamma correction can be used to control the overall brightness of an image\nTo reset the setting to default values, click Reset color settings\nAdding layers and Z-axis slider Z-axis Slider enables you to add annotation layers while hiding the layers positioned beyond.\nYou can also move between layers by moving the slider to the layer you need.\nThe slider becomes active when multiple Z-layers are present within a frame. Click + on the slider to add a new layer; upon pressing it, a new layer is automatically created and activated.\nYou can also relocate objects between layers using the + and - keys.\nInteracting with Objects The workspace is also equipped with the following features:\nRight-clicking an object opens the Object Card. This interface contains essential controls for modifying the object’s label and attributes, as well as providing access to an action menu.\nRight-clicking on a polygon point will open a menu, from which you can Delete point or Set start point.\n","categories":"","description":"The main annotation area where images and videos are displayed for annotation..","excerpt":"The main annotation area where images and videos are displayed for …","ref":"/v2.43.0/docs/manual/basics/cvat-annotation-interface/workspace/","tags":"","title":"CVAT Workspace"},{"body":"CVAT stores all its components is a single (“monolithic”) repository. An explanation of CVAT components is available here.\nHere is the list of the main directories and files in the repository:\n./ - Various common files for the repository .github/ - GitHub configuration files .vscode/ - VS Code configuration files components/ - optional server services cvat/ - server source code apps/ - server modules sources requirements/ - server Python package requirements settings/ - server configurations cvat-canvas/ - UI package, responsible for the annotation canvas cvat-canvas3d/ - UI package, responsible for the annotation canvas for 3D cvat-cli/ - CLI utility cvat-core/ - UI package, responsible for server interaction cvat-data/ - UI package, responsible for media data decoding cvat-sdk/ - Python SDK package cvat-ui/ - UI package, responsible for UI elements helm-chart/ - Helm configuration for deployment on Kubernetes serverless/ - AI models site/ - Documentation website sources assets/ - Media content content/ - Documentation pages supervisord/ - supervisord deployment configuration tests/ - End-to-end tests cypress/ - UI end-to-end tests python/ - Tests for server, SDK, CLI and other Python components utils/ - Additional tools and utility scripts dataset_manifest/ - Python library and a tool to create dataset manifest files dicom_converter/ - Script to convert DICOM data to CVAT-compatible format docker-compose*.yml - Docker Compose local deployment configuration Dockerfile* - Docker image descriptions manage.py - Django utility to manipulate server components ","categories":"","description":"How to find the components needed","excerpt":"How to find the components needed","ref":"/v2.43.0/docs/contributing/repo-structure/","tags":"","title":"Repository structure"},{"body":"To access swagger documentation you need to be authorized.\nAutomatically generated Swagger documentation for Django REST API is available on \u003ccvat_origin\u003e/api/swagger(default: localhost:8080/api/swagger).\nSwagger documentation is visible on allowed hosts, Update environment variable in docker-compose.yml file with cvat hosted machine IP or domain name. Example - ALLOWED_HOSTS: 'localhost, 127.0.0.1'.\nMake a request to a resource stored on a server and the server will respond with the requested information. The HTTP protocol is used to transport a data. Requests are divided into groups:\nauth - user authentication queries comments - requests to post/delete comments to issues issues - update, delete and view problem comments jobs -requests to manage the job lambda - requests to work with lambda function projects - project management queries reviews -adding and removing the review of the job server - server information requests tasks - requests to manage tasks users - user management queries Besides it contains Models. Models - the data type is described using a schema object.\nEach group contains queries related to a different types of HTTP methods such as: GET, POST, PATCH, DELETE, etc. Different methods are highlighted in different color. Each item has a name and description. Clicking on an element opens a form with a name, description and settings input field or an example of json values.\nTo find out more, read swagger specification.\nTo try to send a request, click Try it now and type Execute. You’ll get a response in the form of Curl, Request URL and Server response.\n","categories":"","description":"Instructions on how to interact with REST API and getting swagger documentation.","excerpt":"Instructions on how to interact with REST API and getting swagger …","ref":"/v2.43.0/docs/administration/basics/rest_api_guide/","tags":"","title":"REST API guide"},{"body":"The VGGFace2 is primarily designed for face recognition tasks and is most commonly used with deep learning models specifically designed for face recognition, verification, and similar tasks.\nFor more information, see:\nVGGFace2 Github Dataset examples VGGFace2 export For export of images:\nSupported annotations: Bounding Boxes, Points (landmarks - groups of 5 points). Attributes: Not supported. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── labels.txt # optional ├── \u003cany_subset_name\u003e/ | ├── label0/ | | └── image1.jpg | └── label1/ | └── image2.jpg └── bb_landmark/ ├── loose_bb_\u003cany_subset_name\u003e.csv └── loose_landmark_\u003cany_subset_name\u003e.csv # labels.txt # n000001 car label0 \u003cclass0\u003e label1 \u003cclass1\u003e VGGFace2 import Uploaded file: a zip archive of the structure above\nsupported annotations: Rectangles, Points (landmarks - groups of 5 points) ","categories":"","description":"How to export and import data in VGGFace2 format","excerpt":"How to export and import data in VGGFace2 format","ref":"/v2.43.0/docs/manual/advanced/formats/format-vggface2/","tags":"","title":"VGGFace2"},{"body":"\nIf the related_images folder contains any images, a context image will be available in the perspective window. The contextual image could be compared to 3D data and would help to identify the labels of marked objects.\nPerspective – a main window for work with objects in a 3D task.\nProjections - projections are tied to an object so that a cuboid is in the center and looks like a rectangle. Projections show only the selected object.\nTop – a projection of the view from above. Side – a projection of the left side of the object. Front - a frontal projection of the object. ","categories":"","description":"","excerpt":"\nIf the related_images folder contains any images, a context image …","ref":"/v2.43.0/docs/manual/basics/3d-task-workspace/","tags":"","title":"3D task workspace"},{"body":"With a brush tool, you can create masks for disjoint objects, that have multiple parts, such as a house hiding behind trees, a car behind a pedestrian, or a pillar behind a traffic sign. The brush tool has several modes, for example: erase pixels, change brush shapes, and polygon-to-mask mode.\nUse brush tool for Semantic (Panoptic) and Instance Image Segmentation tasks. For more information about segmentation masks in CVAT, see Creating masks.\nSee:\nBrush tool menu Annotation with brush Annotation with polygon-to-mask Remove underlying pixels AI Tools Import and export Brush tool menu The brush tool menu appears on the top of the screen after you click Shape:\nIt has the following elements:\nElement Description Save mask saves the created mask. The saved mask will appear on the object sidebar Save mask and continue adds a new mask to the object sidebar and allows you to draw a new one immediately. Brush adds new mask/ new regions to the previously added mask). Eraser removes part of the mask. Polygon selection tool. Selection will become a mask. Remove polygon selection subtracts part of the polygon selection. Brush size in pixels. Note: Visible only when Brush or Eraser are selected. Brush shape with two options: circle and square. Note: Visible only when Brush or Eraser are selected. Remove underlying pixels. When you are drawing or editing a mask with this tool, pixels on other masks that are located at the same positions as the pixels of the current mask are deleted. Hide mask. When drawing or editing a mask, you can enable this feature to temporarily hide the mask, allowing you to see the objects underneath more clearly. Label that will be assigned to the newly created mask Move. Click and hold to move the menu bar to the other place on the screen Annotation with brush To annotate with brush, do the following:\nFrom the controls sidebar, select Brush .\nIn the Draw new mask menu, select label for your mask, and click Shape. The Brush tool will be selected by default.\nWith the brush, draw a mask on the object you want to label. To erase selection, use Eraser After you applied the mask, on the top menu bar click Save mask to finish the process (or N on the keyboard).\nAdded object will appear on the objects sidebar.\nTo add the next object, repeat steps 1 to 5. All added objects will be visible on the image and the objects sidebar.\nTo save the job with all added objects, on the top menu, click Save .\nAnnotation with polygon-to-mask To annotate with polygon-to-mask, do the following:\nFrom the controls sidebar, select Brush .\nIn the Draw new mask menu, select label for your mask, and click Shape.\nIn the brush tool menu, select Polygon .\nWith the Polygon tool, draw a mask for the object you want to label. To correct selection, use Remove polygon selection .\nUse Save mask (or N on the keyboard) to switch between add/remove polygon tools:\nAfter you added the polygon selection, on the top menu bar click Save mask to finish the process (or N on the keyboard).\nClick Save mask again (or N on the keyboard). The added object will appear on the objects sidebar.\nTo add the next object, repeat steps 1 to 5.\nAll added objects will be visible on the image and the objects sidebar.\nTo save the job with all added objects, on the top menu, click Save .\nRemove underlying pixels Use Remove underlying pixels tool when you want to add a mask and simultaneously delete the pixels of other masks that are located at the same positions. It is a highly useful feature to avoid meticulous drawing edges twice between two different objects.\nAI Tools You can convert AI tool masks to polygons. To do this, use the following AI tool menu:\nGo to the Detectors tab. Switch toggle Masks to polygons to the right. Add source and destination labels from the drop-down lists. Click Annotate. Import and export For export, see Export dataset\nImport follows the general import dataset procedure, with the additional option of converting masks to polygons.\nNote This option is available for formats that work with masks only. To use it, when uploading the dataset, switch the Convert masks to polygon toggle to the right:\n","categories":"","description":"Guide to annotating tasks using brush tools.","excerpt":"Guide to annotating tasks using brush tools.","ref":"/v2.43.0/docs/manual/advanced/annotation-with-brush-tool/","tags":"","title":"Annotation with brush tool"},{"body":"It is used to annotate frames, tags are not displayed in the workspace. Before you start, open the drop-down list in the top panel and select Tag annotation.\nThe objects sidebar will be replaced with a special panel for working with tags. Here you can select a label for a tag and add it by clicking on the Plus button. You can also customize hotkeys for each label.\nIf you need to use only one label for one frame, then enable the Automatically go to the next frame checkbox, then after you add the tag the frame will automatically switch to the next.\nTags will be shown in the top left corner of the canvas. You can show/hide them in the settings.\n","categories":"","description":"","excerpt":"It is used to annotate frames, tags are not displayed in the …","ref":"/v2.43.0/docs/manual/advanced/annotation-with-tags/","tags":"","title":"Annotation with tags"},{"body":"The Market-1501 dataset is widely used for person re-identification tasks. It is a challenging dataset that has gained significant attention in the computer vision community.\nFor more information, see:\nMarket-1501 Dataset examples Market-1501 export For export of images:\nSupported annotations: Bounding Boxes Attributes: query (checkbox), person_id (number), camera_id(number). Tracks: Not supported. Th downloaded file is a .zip archive with the following structure:\ntaskname.zip/ ├── bounding_box_\u003cany_subset_name\u003e/ │ └── image_name_1.jpg └── query ├── image_name_2.jpg └── image_name_3.jpg # if we keep only annotation: taskname.zip/ └── images_\u003cany_subset_name\u003e.txt # images_\u003cany_subset_name\u003e.txt query/image_name_1.jpg bounding_box_\u003cany_subset_name\u003e/image_name_2.jpg bounding_box_\u003cany_subset_name\u003e/image_name_3.jpg # image_name = 0001_c1s1_000015_00.jpg 0001 - person id c1 - camera id (there are totally 6 cameras) s1 - sequence 000015 - frame number in sequence 00 - means that this bounding box is the first one among the several Market-1501 import Uploaded file: a zip archive of the structure above\nsupported annotations: Label market-1501 with attributes (query, person_id, camera_id) ","categories":"","description":"How to export and import data in Market-1501 format","excerpt":"How to export and import data in Market-1501 format","ref":"/v2.43.0/docs/manual/advanced/formats/format-market1501/","tags":"","title":"Market-1501"},{"body":"To deploy the models, you will need to install the necessary components using Semi-automatic and Automatic Annotation guide. To learn how to deploy the model, read Serverless tutorial.\nThe Models page contains a list of deep learning (DL) models deployed for semi-automatic and automatic annotation. To open the Models page, click the Models button on the navigation bar. The list of models is presented in the form of a table. The parameters indicated for each model are the following:\nFramework the model is based on model Name model Type: detector - used for automatic annotation (available in detectors and automatic annotation) interactor - used for semi-automatic shape annotation (available in interactors) tracker - used for semi-automatic track annotation (available in trackers) reid - used to combine individual objects into a track (available in automatic annotation) Description - brief description of the model Labels - list of the supported labels (only for the models of the detectors type) ","categories":"","description":"","excerpt":"To deploy the models, you will need to install the necessary …","ref":"/v2.43.0/docs/manual/advanced/models/","tags":"","title":"Models"},{"body":"","categories":"","description":"Analytics and quality assessment in CVAT Cloud","excerpt":"Analytics and quality assessment in CVAT Cloud","ref":"/v2.43.0/docs/manual/advanced/analytics-and-monitoring/","tags":"","title":"CVAT Analytics and QA in Cloud"},{"body":"ICDAR 13/15 formats are typically used for text detection and recognition tasks and OCR (Optical Character Recognition).\nThese formats are usually paired with specialized text detection and recognition models.\nFor more information, see:\nICDAR13/15 Dataset examples ICDAR13/15 export For export of images:\nICDAR Recognition 1.0 (Text recognition): Supported annotations: Tag icdar Attributes: caption. ICDAR Detection 1.0 (Text detection): Supported annotations: Bounding Boxes, Polygons with label icdar added in constructor. Attributes: text. ICDAR Segmentation 1.0 (Text segmentation): Supported annotations: Bounding Boxes, Polygons with label icdar added in constructor. Attributes: index, text, color, center Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\n# text recognition task taskname.zip/ └── word_recognition/ └── \u003cany_subset_name\u003e/ ├── images | ├── word1.png | └── word2.png └── gt.txt # text localization task taskname.zip/ └── text_localization/ └── \u003cany_subset_name\u003e/ ├── images | ├── img_1.png | └── img_2.png ├── gt_img_1.txt └── gt_img_1.txt #text segmentation task taskname.zip/ └── text_localization/ └── \u003cany_subset_name\u003e/ ├── images | ├── 1.png | └── 2.png ├── 1_GT.bmp ├── 1_GT.txt ├── 2_GT.bmp └── 2_GT.txt ICDAR13/15 import Uploaded file: a zip archive of the structure above\nWord recognition task:\nsupported annotations: Label icdar with attribute caption Text localization task:\nsupported annotations: Rectangles and Polygons with label icdar and attribute text Text segmentation task:\nsupported annotations: Rectangles and Polygons with label icdar and attributes index, text, color, center ","categories":"","description":"How to export and import data in ICDAR13/15 format","excerpt":"How to export and import data in ICDAR13/15 format","ref":"/v2.43.0/docs/manual/advanced/formats/format-icdar/","tags":"","title":"ICDAR13/15"},{"body":"Label and annotate your data in semi-automatic and automatic mode with the help of AI and OpenCV tools.\nWhile interpolation is good for annotation of the videos made by the security cameras, AI and OpenCV tools are good for both: videos where the camera is stable and videos, where it moves together with the object, or movements of the object are chaotic.\nSee:\nInteractors AI tools: annotate with interactors AI tools: add extra points AI tools: delete points OpenCV: intelligent scissors Settings Interactors models Detectors Labels matching Annotate with detectors Detectors models Trackers AI tools: annotate with trackers OpenCV: annotate with trackers When tracking Trackers models OpenCV: histogram equalization Interactors Interactors are a part of AI and OpenCV tools.\nUse interactors to label objects in images by creating a polygon semi-automatically.\nWhen creating a polygon, you can use positive points or negative points (for some models):\nPositive points define the area in which the object is located. Negative points define the area in which the object is not located. AI tools: annotate with interactors To annotate with interactors, do the following:\nClick Magic wand , and go to the Interactors tab. From the Label drop-down, select a label for the polygon. From the Interactor drop-down, select a model (see Interactors models). Click the Question mark to see information about each model: (Optional) If the model returns masks, and you need to convert masks to polygons, use the Convert masks to polygons toggle. Click Interact. Use the left click to add positive points and the right click to add negative points. Number of points you can add depends on the model. On the top menu, click Done (or Shift+N, N). AI tools: add extra points Note More points improve outline accuracy, but make shape editing harder. Fewer points make shape editing easier, but reduce outline accuracy. Each model has a minimum required number of points for annotation. Once the required number of points is reached, the request is automatically sent to the server. The server processes the request and adds a polygon to the frame.\nFor a more accurate outline, postpone request to finish adding extra points first:\nHold down the Ctrl key. On the top panel, the Block button will turn blue. Add points to the image. Release the Ctrl key, when ready. In case you used Mask to polygon when the object is finished, you can edit it like a polygon.\nYou can change the number of points in the polygon with the slider:\nAI tools: delete points To delete a point, do the following:\nWith the cursor, hover over the point you want to delete. If the point can be deleted, it will enlarge and the cursor will turn into a cross. Left-click on the point. OpenCV: intelligent scissors To use Intelligent scissors, do the following:\nOn the menu toolbar, click OpenCV and wait for the library to load.\nGo to the Drawing tab, select the label, and click on the Intelligent scissors button.\nAdd the first point on the boundary of the allocated object. You will see a line repeating the outline of the object.\nAdd the second point, so that the previous point is within the restrictive threshold. After that a line repeating the object boundary will be automatically created between the points. To finish placing points, on the top menu click Done (or N on the keyboard).\nAs a result, a polygon will be created.\nYou can change the number of points in the polygon with the slider:\nTo increase or lower the action threshold, hold Ctrl and scroll the mouse wheel.\nDuring the drawing process, you can remove the last point by clicking on it with the left mouse button.\nSettings On how to adjust the polygon, see Objects sidebar.\nFor more information about polygons in general, see Annotation with polygons.\nInteractors models Model Tool Description Example Segment Anything Model (SAM) AI Tools The Segment Anything Model (SAM) produces high quality object masks, and it can be used to generate masks for all objects in an image. It has been trained on a dataset of 11 million images and 1.1 billion masks, and has strong zero-shot performance on a variety of segmentation tasks. For more information, see: GitHub: Segment Anything Site: Segment AnythingPaper: Segment Anything Deep extreme cut (DEXTR) AI Tool This is an optimized version of the original model, introduced at the end of 2017. It uses the information about extreme points of an object to get its mask. The mask is then converted to a polygon. For now this is the fastest interactor on the CPU. For more information, see: GitHub: DEXTR-PyTorch Site: DEXTR-PyTorchPaper: DEXTR-PyTorch Feature backpropagating refinement scheme (f-BRS) AI Tool The model allows to get a mask for an object using positive points (should be left-clicked on the foreground), and negative points (should be right-clicked on the background, if necessary). It is recommended to run the model on GPU, if possible. For more information, see: GitHub: f-BRS Paper: f-BRS High Resolution Net (HRNet) AI Tool The model allows to get a mask for an object using positive points (should be left-clicked on the foreground), and negative points (should be right-clicked on the background, if necessary). It is recommended to run the model on GPU, if possible. For more information, see: GitHub: HRNet Paper: HRNet Inside-Outside-Guidance\n(IOG) AI Tool The model uses a bounding box and inside/outside points to create a mask. First of all, you need to create a bounding\nbox, wrapping the object. Then you need to use positive and negative points to say the model where is a foreground, and where is a background.\nNegative points are optional. For more information, see: GitHub: IOG Paper: IOG Intelligent scissors OpenCV Intelligent scissors is a CV method of creating a polygon by placing points with the automatic drawing of a line between them. The distance\nbetween the adjacent points is limited by the threshold of action, displayed as a red square that is tied to the cursor. For more information, see: Site: Intelligent Scissors Specification Detectors Detectors are a part of AI tools.\nUse detectors to automatically identify and locate objects in images or videos.\nLabels matching Each model is trained on a dataset and supports only the dataset’s labels.\nFor example:\nDL model has the label car. Your task (or project) has the label vehicle. To annotate, you need to match these two labels to give DL model a hint, that in this case car = vehicle.\nIf you have a label that is not on the list of DL labels, you will not be able to match them.\nFor this reason, supported DL models are suitable only for certain labels. To check the list of labels for each model, see Detectors models.\nAnnotate with detectors To annotate with detectors, do the following:\nClick Magic wand , and go to the Detectors tab.\nFrom the Model drop-down, select model (see Detectors models).\nFrom the left drop-down select the DL model label, from the right drop-down select the matching label of your task.\n(Optional) If the model returns masks, and you need to convert masks to polygons, use the Convert masks to polygons toggle.\n(Optional) You can specify a Threshold for the model. If not provided, the default value from the model settings will be used.\nClick Annotate.\nThis action will automatically annotate one frame. For automatic annotation of multiple frames, see Automatic annotation.\nDetectors models Model Description Mask RCNN The model generates polygons for each instance of an object in the image. For more information, see: GitHub: Mask RCNN Paper: Mask RCNN Faster RCNN The model generates bounding boxes for each instance of an object in the image. In this model, RPN and Fast R-CNN are combined into a single network. For more information, see: GitHub: Faster RCNN Paper: Faster RCNN YOLO v3 YOLO v3 is a family of object detection architectures and models pre-trained on the COCO dataset. For more information, see: GitHub: YOLO v3 Site: YOLO v3 Paper: YOLO v3 Semantic segmentation for ADAS This is a segmentation network to classify each pixel into 20 classes. For more information, see: Site: ADAS Faster RCNN with Tensorflow Faster RCNN version with Tensorflow. The model generates bounding boxes for each instance of an object in the image. In this model, RPN and Fast R-CNN are combined into a single network. For more information, see: Site: Faster RCNN with Tensorflow Paper: Faster RCNN RetinaNet Pytorch implementation of RetinaNet object detection. For more information, see: Specification: RetinaNet Paper: RetinaNetDocumentation: RetinaNet Face Detection Face detector based on MobileNetV2 as a backbone for indoor and outdoor scenes shot by a front-facing camera. For more information, see: Site: Face Detection 0205 Trackers Trackers are part of AI and OpenCV tools.\nUse trackers to identify and label objects in a video or image sequence that are moving or changing over time.\nAI tools: annotate with trackers To annotate with trackers, do the following:\nClick Magic wand , and go to the Trackers tab.\nFrom the Label drop-down, select the label for the object.\nFrom Tracker drop-down, select tracker.\nClick Track, and annotate the objects with the bounding box in the first frame.\nGo to the top menu and click Next (or the F on the keyboard) to move to the next frame. All annotated objects will be automatically tracked.\nWhen tracking To enable/disable tracking, use Tracker switcher on the sidebar.\nTrackable objects have an indication on canvas with a model name.\nYou can follow the tracking by the messages appearing at the top.\nOpenCV: annotate with trackers To annotate with trackers, do the following:\nCreate basic rectangle shapes or tracks for tracker initialization\nOn the menu toolbar, click OpenCV and wait for the library to load.\nFrom Tracker drop-down, select tracker and Click Track\nAnnotation actions window will pop-up. Setup Target frame and Convert rectangle shapes to tracks parameters and click Run\nNote Tracking will be applied to all filtered rectangle annotations. All annotated objects will be automatically tracked up until target frame parameter.\nTrackers models Model Tool Description Example TrackerMIL OpenCV TrackerMIL model is not bound to labels and can be used for any object. It is a fast client-side model designed to track simple non-overlapping objects. For more information, see: Article: Object Tracking using OpenCV SiamMask AI Tools Fast online Object Tracking and Segmentation. The trackable object will be tracked automatically if the previous frame was the latest keyframe for the object. For more information, see: GitHub: SiamMask Paper: SiamMask Transformer Tracking (TransT) AI Tools Simple and efficient online tool for object tracking and segmentation. If the previous frame was the latest keyframe for the object, the trackable object will be tracked automatically.\nThis is a modified version of the PyTracking Python framework based on Pytorch\nFor more information, see: GitHub: TransT Paper: TransT OpenCV: histogram equalization Histogram equalization improves the contrast by stretching the intensity range.\nIt increases the global contrast of images when its usable data is represented by close contrast values.\nIt is useful in images with backgrounds and foregrounds that are bright or dark.\nTo improve the contrast of the image, do the following:\nIn the OpenCV menu, go to the Image tab. Click on Histogram equalization button. Histogram equalization will improve contrast on current and following frames.\nExample of the result:\nTo disable Histogram equalization, click on the button again.\n","categories":"","description":"Overview of semi-automatic and automatic annotation tools available in CVAT.","excerpt":"Overview of semi-automatic and automatic annotation tools available in …","ref":"/v2.43.0/docs/manual/advanced/ai-tools/","tags":"","title":"OpenCV and AI Tools"},{"body":"Standard 3d mode - Designed to work with 3D data. The mode is automatically available if you add PCD or Kitty BIN format data when you create a task (read more).\nYou can adjust the size of the projections, to do so, simply drag the boundary between the projections.\n","categories":"","description":"","excerpt":"Standard 3d mode - Designed to work with 3D data. The mode is …","ref":"/v2.43.0/docs/manual/basics/standard-3d-mode-basics/","tags":"","title":"Standard 3D mode (basics)"},{"body":"The Open Images format is based on a large-scale, diverse dataset that contains object detection, object segmentation, visual relationship, and localized narratives annotations.\nIts export data format is compatible with many object detection and segmentation models.\nFor more information, see:\nOpen Images site Format specification Dataset examples Open Images export For export of images:\nSupported annotations: Bounding Boxes (detection), Tags (classification), Polygons (segmentation).\nSupported attributes:\nTags: score must be defined for labels as text or number. The confidence level from 0 to 1. Bounding boxes: score must be defined for labels as text or number. The confidence level from 0 to 1. occluded as both UI option and a separate attribute. Whether the object is occluded by another object. truncated must be defined for labels as checkbox. Whether the object extends beyond the boundary of the image. is_group_of must be defined for labels as checkbox. Whether the object represents a group of objects of the same class. is_depiction must be defined for labels as checkbox. Whether the object is a depiction (such as a drawing) rather than a real object. is_inside must be defined for labels as checkbox. Whether the object is seen from the inside. Masks: box_id must be defined for labels as text. An identifier for the bounding box associated with the mask. predicted_iou must be defined for labels as text or number. Predicted IoU value with respect to the ground truth. Tracks: Not supported.\nThe downloaded file is a .zip archive with the following structure:\n└─ taskname.zip/ ├── annotations/ │ ├── bbox_labels_600_hierarchy.json │ ├── class-descriptions.csv | ├── images.meta # additional file with information about image sizes │ ├── \u003csubset_name\u003e-image_ids_and_rotation.csv │ ├── \u003csubset_name\u003e-annotations-bbox.csv │ ├── \u003csubset_name\u003e-annotations-human-imagelabels.csv │ └── \u003csubset_name\u003e-annotations-object-segmentation.csv ├── images/ │ ├── subset1/ │ │ ├── \u003cimage_name101.jpg\u003e │ │ ├── \u003cimage_name102.jpg\u003e │ │ └── ... │ ├── subset2/ │ │ ├── \u003cimage_name201.jpg\u003e │ │ ├── \u003cimage_name202.jpg\u003e │ │ └── ... | ├── ... └── masks/ ├── subset1/ │ ├── \u003cmask_name101.png\u003e │ ├── \u003cmask_name102.png\u003e │ └── ... ├── subset2/ │ ├── \u003cmask_name201.png\u003e │ ├── \u003cmask_name202.png\u003e │ └── ... ├── ... Open Images import Uploaded file: a zip archive of the following structure:\n└─ upload.zip/ ├── annotations/ │ ├── bbox_labels_600_hierarchy.json │ ├── class-descriptions.csv | ├── images.meta # optional, file with information about image sizes │ ├── \u003csubset_name\u003e-image_ids_and_rotation.csv │ ├── \u003csubset_name\u003e-annotations-bbox.csv │ ├── \u003csubset_name\u003e-annotations-human-imagelabels.csv │ └── \u003csubset_name\u003e-annotations-object-segmentation.csv └── masks/ ├── subset1/ │ ├── \u003cmask_name101.png\u003e │ ├── \u003cmask_name102.png\u003e │ └── ... ├── subset2/ │ ├── \u003cmask_name201.png\u003e │ ├── \u003cmask_name202.png\u003e │ └── ... ├── ... Image ids in the \u003csubset_name\u003e-image_ids_and_rotation.csv should match with image names in the task.\n","categories":"","description":"How to export and import data in Open Images format","excerpt":"How to export and import data in Open Images format","ref":"/v2.43.0/docs/manual/advanced/formats/format-openimages/","tags":"","title":"Open Images"},{"body":"To open the Settings, open the user menu in the header and select Settings. Or you can use the default F2 shortcut.\nThe Settings section has three tabs:\nPlayer Workspace Shortcuts Player In the Player tab, you can:\nControl step of C and V shortcuts. Control the speed of Space/Play button. Select canvas background color. You can choose a background color or enter manually (in RGB or HEX format). Reset zoom Show every image in full size or zoomed out like the previous (it is enabled by default for interpolation mode and disabled for annotation mode). Rotate all images checkbox — switch the rotation of all frames or an individual frame. Smooth image checkbox — smooth image when zoom-in it. smoothed pixelized Workspace In the Workspace tab, you can:\nEnable auto save checkbox — turned off by default.\nAuto save interval (min) input box — 15 minutes by default.\nShow all interpolation tracks checkbox — shows hidden objects on the side panel for every interpolated object (turned off by default).\nAlways show object details - show text for an object on the canvas not only when the object is activated:\nContent of a text - setup of the composition of the object details:\nID - object identifier. Attributes - attributes of the object. Label - object label. Source- source of creating of objects MANUAL, AUTO or SEMI-AUTO. Descriptions - description of attributes. Dimensions - width, height and rotation for rectangles and ellipses. Position of a text - text positioning mode selection:\nAuto - the object details will be automatically placed where free space is. Center - the object details will be embedded to a corresponding object if possible. Font size of a text - specifies the text size of the object details.\nAutomatic bordering - enable automatic bordering for polygons and polylines during drawing/editing. For more information To find out more, go to the section annotation with polygons.\nIntelligent polygon cropping - activates intelligent cropping when editing the polygon (read more in the section edit polygon\nShow tags on frame - shows/hides frame tags on the current frame\nAttribute annotation mode (AAM) zoom margin input box — defines margins (in px) for shape in the attribute annotation mode.\nControl points size — defines the size of any interactable points in the tool (polygon’s vertices, rectangle dragging points, etc.)\nDefault number of points in polygon approximation With this setting, you can choose the default number of points in polygon. Works for serverless interactors and OpenCV scissors.\nSelect Save to save settings (settings will be saved on the server and will not change after the page is refreshed). Select Cancel or press F2 to return to the annotation.\nShortcuts In the Shortcuts tab, you can set the keyboard combinations. Learn more in Shortcuts.\n","categories":"","description":"","excerpt":"To open the Settings, open the user menu in the header and select …","ref":"/v2.43.0/docs/manual/basics/settings/","tags":"","title":"Settings"},{"body":"Automatic annotation in CVAT is a tool that you can use to automatically pre-annotate your data with pre-trained models.\nCVAT can use models from the following sources:\nPre-installed models. Models integrated from Hugging Face and Roboflow. Self-hosted models deployed with Nuclio. The following table describes the available options:\nSelf-hosted Online Price Free See Pricing Models You have to add models You can use pre-installed models Hugging Face \u0026 Roboflow integration Not supported Supported See:\nRunning Automatic annotation Labels matching Models Adding models from Hugging Face and Roboflow Running Automatic annotation To start automatic annotation, do the following:\nOn the top menu, click Tasks.\nFind the task you want to annotate and click Action \u003e Automatic annotation.\nIn the Automatic annotation dialog, from the drop-down list, select a model.\nMatch the labels of the model and the task.\n(Optional) In case you need the model to return masks as polygons, switch toggle Return masks as polygons.\n(Optional) In case you need to remove all previous annotations, switch toggle Clean old annotations.\n(Optional) You can specify a Threshold for the model. If not provided, the default value from the model settings will be used.\nClick Annotate.\nCVAT will show the progress of annotation on the progress bar.\nYou can stop the automatic annotation at any moment by clicking cancel.\nLabels matching Each model is trained on a dataset and supports only the dataset’s labels.\nFor example:\nDL model has the label car. Your task (or project) has the label vehicle. To annotate, you need to match these two labels to give CVAT a hint that, in this case, car = vehicle.\nIf you have a label that is not on the list of DL labels, you will not be able to match them.\nFor this reason, supported DL models are suitable only for certain labels.\nTo check the list of labels for each model, see Models papers and official documentation.\nModels Automatic annotation uses pre-installed and added models.\nFor self-hosted solutions, you need to install Automatic Annotation first and add models.\nList of pre-installed models:\nModel Description Attributed face detection Three OpenVINO models work together: Face Detection 0205: face detector based on MobileNetV2 as a backbone with a FCOS head for indoor and outdoor scenes shot by a front-facing camera. Emotions recognition retail 0003: fully convolutional network for recognition of five emotions (‘neutral’, ‘happy’, ‘sad’, ‘surprise’, ‘anger’). Age gender recognition retail 0013: fully convolutional network for simultaneous Age/Gender recognition. The network can recognize the age of people in the [18 - 75] years old range; it is not applicable for children since their faces were not in the training set. RetinaNet R101 RetinaNet is a one-stage object detection model that utilizes a focal loss function to address class imbalance during training. Focal loss applies a modulating term to the cross entropy loss to focus learning on hard negative examples. RetinaNet is a single, unified network composed of a backbone network and two task-specific subnetworks. For more information, see: Site: RetinaNET Text detection Text detector based on PixelLink architecture with MobileNetV2, depth_multiplier=1.4 as a backbone for indoor/outdoor scenes. For more information, see: Site: OpenVINO Text detection 004 YOLO v3 YOLO v3 is a family of object detection architectures and models pre-trained on the COCO dataset. For more information, see: Site: YOLO v3 YOLO v7 YOLOv7 is an advanced object detection model that outperforms other detectors in terms of both speed and accuracy. It can process frames at a rate ranging from 5 to 160 frames per second (FPS) and achieves the highest accuracy with 56.8% average precision (AP) among real-time object detectors running at 30 FPS or higher on the V100 graphics processing unit (GPU). For more information, see: GitHub: YOLO v7 Paper: YOLO v7 Adding models from Hugging Face and Roboflow In case you did not find the model you need, you can add a model of your choice from Hugging Face or Roboflow.\nNote You cannot add models from Hugging Face and Roboflow to self-hosted CVAT. For more information, see Streamline annotation by integrating Hugging Face and Roboflow models.\nThis video demonstrates the process:\n","categories":"","description":"Automatic annotation of tasks","excerpt":"Automatic annotation of tasks","ref":"/v2.43.0/docs/manual/advanced/automatic-annotation/","tags":"","title":"Automatic annotation"},{"body":"The Cityscapes format is a widely-used standard in the field of computer vision, particularly for tasks involving semantic and instance segmentation in urban scenes. This dataset format typically comprises high-resolution images of cityscapes along with detailed pixel-level annotations.\nEach pixel is labeled with a category such as “road,” “pedestrian,” or “vehicle,” making it a valuable resource for training and validating machine learning models aimed at understanding urban environments. It’s a go-to choice for researchers and professionals working on autonomous vehicles, robotics, and smart cities.\nFor more information, see:\nCityscapes site Cityscapes format specification Cityscapes dataset examples Cityscapes export For export of images:\nSupported annotations: Polygons (segmentation), Bounding Boxes. Attributes: is_crowd boolean, should be defined for labels as checkbox. Specifies if the annotation label can distinguish between different instances. If False, the annotation id field encodes the instance id. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\n. ├── label_color.txt ├── gtFine │ ├── \u003csubset_name\u003e │ │ └── \u003ccity_name\u003e │ │ ├── image_0_gtFine_instanceIds.png │ │ ├── image_0_gtFine_color.png │ │ ├── image_0_gtFine_labelIds.png │ │ ├── image_1_gtFine_instanceIds.png │ │ ├── image_1_gtFine_color.png │ │ ├── image_1_gtFine_labelIds.png │ │ ├── ... └── imgsFine # if saving images was requested └── leftImg8bit ├── \u003csubset_name\u003e │ └── \u003ccity_name\u003e │ ├── image_0_leftImg8bit.png │ ├── image_1_leftImg8bit.png │ ├── ... label_color.txt a file that describes the color for each label # label_color.txt example # r g b label_name 0 0 0 background 0 255 0 tree ... *_gtFine_color.png class labels encoded by its color. *_gtFine_labelIds.png class labels are encoded by its index. *_gtFine_instanceIds.png class and instance labels encoded by an instance ID. The pixel values encode class and the individual instance: the integer part of a division by 1000 of each ID provides class ID, the remainder is the instance ID. If a certain annotation describes multiple instances, then the pixels have the regular ID of that class Cityscapes annotations import Uploaded file: a zip archive with the following structure:\n. ├── label_color.txt # optional └── gtFine └── \u003ccity_name\u003e ├── image_0_gtFine_instanceIds.png ├── image_1_gtFine_instanceIds.png ├── ... Creating task with Cityscapes dataset Create a task with the labels you need or you can use the labels and colors of the original dataset. To work with the Cityscapes format, you must have a black color label for the background.\nOriginal Cityscapes color map:\n[ {\"name\": \"unlabeled\", \"color\": \"#000000\", \"attributes\": []}, {\"name\": \"egovehicle\", \"color\": \"#000000\", \"attributes\": []}, {\"name\": \"rectificationborder\", \"color\": \"#000000\", \"attributes\": []}, {\"name\": \"outofroi\", \"color\": \"#000000\", \"attributes\": []}, {\"name\": \"static\", \"color\": \"#000000\", \"attributes\": []}, {\"name\": \"dynamic\", \"color\": \"#6f4a00\", \"attributes\": []}, {\"name\": \"ground\", \"color\": \"#510051\", \"attributes\": []}, {\"name\": \"road\", \"color\": \"#804080\", \"attributes\": []}, {\"name\": \"sidewalk\", \"color\": \"#f423e8\", \"attributes\": []}, {\"name\": \"parking\", \"color\": \"#faaaa0\", \"attributes\": []}, {\"name\": \"railtrack\", \"color\": \"#e6968c\", \"attributes\": []}, {\"name\": \"building\", \"color\": \"#464646\", \"attributes\": []}, {\"name\": \"wall\", \"color\": \"#66669c\", \"attributes\": []}, {\"name\": \"fence\", \"color\": \"#be9999\", \"attributes\": []}, {\"name\": \"guardrail\", \"color\": \"#b4a5b4\", \"attributes\": []}, {\"name\": \"bridge\", \"color\": \"#966464\", \"attributes\": []}, {\"name\": \"tunnel\", \"color\": \"#96785a\", \"attributes\": []}, {\"name\": \"pole\", \"color\": \"#999999\", \"attributes\": []}, {\"name\": \"polegroup\", \"color\": \"#999999\", \"attributes\": []}, {\"name\": \"trafficlight\", \"color\": \"#faaa1e\", \"attributes\": []}, {\"name\": \"trafficsign\", \"color\": \"#dcdc00\", \"attributes\": []}, {\"name\": \"vegetation\", \"color\": \"#6b8e23\", \"attributes\": []}, {\"name\": \"terrain\", \"color\": \"#98fb98\", \"attributes\": []}, {\"name\": \"sky\", \"color\": \"#4682b4\", \"attributes\": []}, {\"name\": \"person\", \"color\": \"#dc143c\", \"attributes\": []}, {\"name\": \"rider\", \"color\": \"#ff0000\", \"attributes\": []}, {\"name\": \"car\", \"color\": \"#00008e\", \"attributes\": []}, {\"name\": \"truck\", \"color\": \"#000046\", \"attributes\": []}, {\"name\": \"bus\", \"color\": \"#003c64\", \"attributes\": []}, {\"name\": \"caravan\", \"color\": \"#00005a\", \"attributes\": []}, {\"name\": \"trailer\", \"color\": \"#00006e\", \"attributes\": []}, {\"name\": \"train\", \"color\": \"#005064\", \"attributes\": []}, {\"name\": \"motorcycle\", \"color\": \"#0000e6\", \"attributes\": []}, {\"name\": \"bicycle\", \"color\": \"#770b20\", \"attributes\": []}, {\"name\": \"licenseplate\", \"color\": \"#00000e\", \"attributes\": []} ] Upload images when creating a task:\nimages.zip/ ├── image_0.jpg ├── image_1.jpg ├── ... After creating the task, upload the Cityscapes annotations as described in the previous section.\n","categories":"","description":"How to export and import data in Cityscapes format","excerpt":"How to export and import data in Cityscapes format","ref":"/v2.43.0/docs/manual/advanced/formats/format-cityscapes/","tags":"","title":"Cityscapes"},{"body":"The Guide feature provides a built-in markdown editor that allows you to create specification for annotators.\nOnce you create and submit the specification, it will be accessible from the annotation interface (see below).\nYou can attach the specification to Projects or to Tasks.\nThe attachment procedure is the same for individual users and organizations.\nSee:\nAdding specification to Project Editing rights Adding specification to Task Editing rights Access to specification for annotators Markdown editor guide Specification for annotators’ video tutorial Adding specification to Project To add specification to the Projects, do the following:\nGo to the Projects page and click on the project to which you want to add specification. Under the Project description, click Edit. Add instruction to the Markdown editor, and click Submit. Editing rights For individual users: only the project owner and the project assignee can edit the specification. For organizations: specification additionally can be edited by the organization owner and maintainer Adding specification to Task To add specification to the Task, do the following:\nGo to the Tasks page and click on the task to which you want to add specification.\nUnder the Task description, click Edit.\nAdd instruction to the Markdown editor, and click Submit.\nEditing rights For individual users: only the task owner and task assignee can edit the specification. For organizations: only the task owner, maintainer, and task assignee can edit the specification. Access to specification for annotators The specification is opened automatically when the job has new annotation state. It means, that it will open when the assigned user begins working on the first job within a Project or Task.\nThe specifications will not automatically reopen if the user moves to another job within the same Project or Task.\nIf a Project or Task is reassigned to another annotator, the specifications will automatically be shown when the annotator opens the first job but will not reappear for subsequent jobs.\nTo enable the option for specifications to always open automatically, append the ?openGuide parameter to the end of the job URL you share with the annotator:\n/tasks/\u003ctask_id\u003e/jobs/\u003cjob_id\u003e?openGuide For example:\nhttps://app.cvat.ai/tasks/taskID/jobs/jobID?openGuide To open specification manually, do the following:\nOpen the job to see the annotation interface. In the top right corner, click Guide button(). Markdown editor guide The markdown editor for Guide has two panes. Add instructions to the left pane, and the editor will immediately show the formatted result on the right.\nYou can write in raw markdown or use the toolbar on the top of the editor.\nElement Description 1 Text formatting: bold, cursive, and strikethrough. 2 Insert a horizontal rule (horizontal line). 3 Add a title, heading, or subheading. It provides a drop-down list to select the title level (from 1 to 6). 4 Add a link. Note: If you left-click on the link, it will open in the same window. 5 Add a quote. 6 Add a single line of code. 7 Add a block of code. 8 Add a comment. The comment is only visible to Guide editors and remains invisible to annotators. 9 Add a picture. To use this option, first, upload the picture to an external resource and then add the link in the editor. Alternatively, you can drag and drop a picture into the editor, which will upload it to the CVAT server and add it to the specification. 10 Add a list: bullet list, numbered list, and checklist. 11 Hide the editor pane: options to hide the right pane, show both panes or hide the left pane. 12 Enable full-screen mode. Specification for annotators’ video tutorial Video tutorial on how to use the Guide feature.\n","categories":"","description":"Learn how to easily create and add specification for annotators using the Guide feature.","excerpt":"Learn how to easily create and add specification for annotators using …","ref":"/v2.43.0/docs/manual/advanced/specification/","tags":"","title":"Specification for annotators"},{"body":"There are several shapes with which you can annotate your images:\nRectangle or Bounding box Polygon Polyline Points Ellipse Cuboid Cuboid in 3d task Skeleton Tag And there is what they look like:\nTag - has no shape in the workspace, but is displayed in objects sidebar.\n","categories":"","description":"List of shapes available for annotation.","excerpt":"List of shapes available for annotation.","ref":"/v2.43.0/docs/manual/basics/types-of-shapes/","tags":"","title":"Types of shapes"},{"body":"Overview In CVAT you can backup tasks and projects. This can be used to backup a task or project on your PC or to transfer to another server.\nCreate backup To backup a task or project, open the action menu and select Backup Task or Backup Project.\nYou can backup a project or a task locally on your PC or using an attached cloud storage.\n(Optional) Specify the name in the Custom name text field for backup, otherwise the file of backup name will be given by the mask project_\u003cproject_name\u003e_backup_\u003cdate\u003e_\u003ctime\u003e.zip for the projects and task_\u003ctask_name\u003e_backup_\u003cdate\u003e_\u003ctime\u003e.zip for the tasks.\nIf you want to save a backup to a specific attached cloud storage, you should additionally turn off the switch Use default settings, select the Cloud storage value in the Target storage and select this storage in the list of the attached cloud storages.\nCreate backup APIs endpoints: /tasks/{id}/backup /projects/{id}/backup method: GET responses: 202, 201 with zip archive payload Upload backup APIs endpoints: /api/tasks/backup /api/projects/backup method: POST Content-Type: multipart/form-data responses: 202, 201 with json payload Create from backup To create a task or project from a backup, go to the tasks or projects page, click the Create from backup button and select the archive you need.\nAs a result, you’ll get a task containing data, parameters, and annotations of the previously exported task.\nBackup file structure As a result, you’ll get a zip archive containing data, task or project and task specification and annotations with the following structure:\nTask Backup Structure Project Backup Structure . ├── data │ └── {user uploaded data} ├── task.json └── annotations.json . ├── task_{id} │ ├── data │ │ └── {user uploaded data} │ ├── task.json │ └── annotations.json └── project.json ","categories":"","description":"","excerpt":"Overview In CVAT you can backup tasks and projects. This can be used …","ref":"/v2.43.0/docs/manual/advanced/backup/","tags":"","title":"Backup Task and Project"},{"body":"The KITTI format is widely used for a range of computer vision tasks related to autonomous driving, including but not limited to 3D object detection, multi-object tracking, and scene flow estimation. Given its special focus on automotive scenes, the KITTI format is generally used with models that are designed or adapted for these types of tasks.\nFor more information, see:\nKITTI site Format specification for KITTI detection Format specification for KITTI segmentation Dataset examples KITTI annotations export For export of images:\nSupported annotations: Bounding Boxes (detection), Polygons (segmentation). Supported attributes: occluded (Available both as a UI option and a separate attribute) Denotes that a major portion of the object within the bounding box is obstructed by another object. truncated (Only applicable to bounding boxes) Must be represented as checkboxes for labels. Suggests that the bounding box does not encompass the entire object; some part is cut off. is_crowd (Only valid for polygons). Should be indicated using checkboxes for labels. Signifies that the annotation encapsulates multiple instances of the same object class. Tracks: Not supported. The downloaded file is a .zip archive with the following structure:\n└─ annotations.zip/ ├── label_colors.txt # list of pairs r g b label_name ├── labels.txt # list of labels └── default/ ├── label_2/ # left color camera label files │ ├── \u003cimage_name_1\u003e.txt │ ├── \u003cimage_name_2\u003e.txt │ └── ... ├── instance/ # instance segmentation masks │ ├── \u003cimage_name_1\u003e.png │ ├── \u003cimage_name_2\u003e.png │ └── ... ├── semantic/ # semantic segmentation masks (labels are encoded by its id) │ ├── \u003cimage_name_1\u003e.png │ ├── \u003cimage_name_2\u003e.png │ └── ... └── semantic_rgb/ # semantic segmentation masks (labels are encoded by its color) ├── \u003cimage_name_1\u003e.png ├── \u003cimage_name_2\u003e.png └── ... KITTI annotations import You can upload KITTI annotations in two ways: rectangles for the detection task and masks for the segmentation task.\nFor detection tasks the uploading archive should have the following structure:\n└─ annotations.zip/ ├── labels.txt # optional, labels list for non-original detection labels └── \u003csubset_name\u003e/ ├── label_2/ # left color camera label files │ ├── \u003cimage_name_1\u003e.txt │ ├── \u003cimage_name_2\u003e.txt │ └── ... For segmentation tasks the uploading archive should have the following structure:\n└─ annotations.zip/ ├── label_colors.txt # optional, color map for non-original segmentation labels └── \u003csubset_name\u003e/ ├── instance/ # instance segmentation masks │ ├── \u003cimage_name_1\u003e.png │ ├── \u003cimage_name_2\u003e.png │ └── ... ├── semantic/ # optional, semantic segmentation masks (labels are encoded by its id) │ ├── \u003cimage_name_1\u003e.png │ ├── \u003cimage_name_2\u003e.png │ └── ... └── semantic_rgb/ # optional, semantic segmentation masks (labels are encoded by its color) ├── \u003cimage_name_1\u003e.png ├── \u003cimage_name_2\u003e.png └── ... All annotation files and masks should have structures that are described in the original format specification.\n","categories":"","description":"How to export and import data in KITTI format","excerpt":"How to export and import data in KITTI format","ref":"/v2.43.0/docs/manual/advanced/formats/format-kitti/","tags":"","title":"KITTI"},{"body":"The Labeled Faces in the Wild (LFW) format is primarily used for face verification and face recognition tasks. The LFW format is designed to be straightforward and is compatible with a variety of machine learning and deep learning frameworks.\nFor more information, see:\nLFW site Format specification Dataset examples Export LFW annotation For export of images:\nSupported annotations: Tags, Skeletons.\nAttributes:\nnegative_pairs (should be defined for labels as text): list of image names with mismatched persons. positive_pairs (should be defined for labels as text): list of image names with matched persons. Tracks: Not supported.\nThe downloaded file is a .zip archive with the following structure:\n\u003carchive_name\u003e.zip/ └── images/ # if the option save images was selected │ ├── name1/ │ │ ├── name1_0001.jpg │ │ ├── name1_0002.jpg │ │ ├── ... │ ├── name2/ │ │ ├── name2_0001.jpg │ │ ├── name2_0002.jpg │ │ ├── ... │ ├── ... ├── landmarks.txt ├── pairs.txt └── people.txt Import LFW annotation The uploaded annotations file should be a zip file with the following structure:\n\u003carchive_name\u003e.zip/ └── annotations/ ├── landmarks.txt # list with landmark points for each image ├── pairs.txt # list of matched and mismatched pairs of person └── people.txt # optional file with a list of persons name Full information about the content of annotation files is available here\nExample: create task with images and upload LFW annotations into it This is one of the possible ways to create a task and add LFW annotations for it.\nOn the task creation page: Add labels that correspond to the names of the persons. For each label define text attributes with names positive_pairs and negative_pairs Add images using zip archive from local repository: images.zip/ ├── name1_0001.jpg ├── name1_0002.jpg ├── ... ├── name1_\u003cN\u003e.jpg ├── name2_0001.jpg ├── ... On the annotation page: Upload annotation -\u003e LFW 1.0 -\u003e choose archive with structure that described in the import section. ","categories":"","description":"How to export and import data in LFW format","excerpt":"How to export and import data in LFW format","ref":"/v2.43.0/docs/manual/advanced/formats/format-lfw/","tags":"","title":"LFW"},{"body":"Usage examples:\nCreate new annotations for a set of images. Add/modify/delete objects for existing annotations. You need to select Rectangle on the controls sidebar:\nBefore you start, select the correct Label (should be specified by you when creating the task) and Drawing Method (by 2 points or by 4 points):\nCreating a new annotation in Shape mode:\nCreate a separate Rectangle by selecting Shape.\nChoose the opposite points. Your first rectangle is ready!\nTo learn more about creating a rectangle read here.\nIt is possible to adjust boundaries and location of the rectangle using a mouse. The rectangle’s size is shown in the top right corner, you can check it by selecting any point of the shape. You can also undo your actions using Ctrl+Z and redo them with Shift+Ctrl+Z or Ctrl+Y.\nYou can see the Object card in the objects sidebar or open it by right-clicking on the object. You can change the attributes in the details section. You can perform basic operations or delete an object by selecting on the action menu button.\nThe following figure is an example of a fully annotated frame with separate shapes.\nRead more in the section shape mode (advanced).\n","categories":"","description":"Usage examples and basic operations available during annotation in shape mode.","excerpt":"Usage examples and basic operations available during annotation in …","ref":"/v2.43.0/docs/manual/basics/shape-mode-basics/","tags":"","title":"Shape mode (basics)"},{"body":"Delete frame You can delete the current frame from a task. This frame will not be presented either in the UI or in the exported annotation. Thus, it is possible to mark corrupted frames that are not subject to annotation.\nGo to the Job annotation view and click on the Delete frame button (Alt+Del).\nNote When you delete with the shortcut, the frame will be deleted immediately without additional confirmation. After that you will be asked to confirm frame deleting.\nNote all annotations from that frame will be deleted, unsaved annotations will be saved and the frame will be invisible in the annotation view (Until you make it visible in the settings). If there is some overlap in the task and the deleted frame falls within this interval, then this will cause this frame to become unavailable in another job as well. When you delete a frame in a job with tracks, you may need to adjust some tracks manually. Common adjustments are:\nAdd keyframes at the edges of the deleted interval for the interpolation to look correct; Move the keyframe start or end keyframe to the correct side of the deleted interval. Configure deleted frames visibility and navigation If you need to enable showing the deleted frames, you can do it in the settings.\nGo to the settings and chose Player settings.\nClick on the Show deleted frames checkbox. And close the settings dialog.\nThen you will be able to navigate through deleted frames. But annotation tools will be unavailable. Deleted frames differ in the corresponding overlay.\nThere are ways to navigate through deleted frames without enabling this option:\nGo to the frame via direct navigation methods: navigation slider or frame input field, Go to the frame via the direct link, for example: /api/tasks/{id}/jobs/{id}?frame={frame_id}. Navigation with step will not count deleted frames.\nRestore deleted frame You can also restore deleted frames in the task.\nTurn on deleted frames visibility, as it was told in the previous part, and go to the deleted frame you want to restore.\nClick on the Restore icon. The frame will be restored immediately.\n","categories":"","description":"This section explains how to delete and restore a frame from a task.","excerpt":"This section explains how to delete and restore a frame from a task.","ref":"/v2.43.0/docs/manual/advanced/delete-frame/","tags":"","title":"Frame deleting"},{"body":"In CVAT you can modify shapes by either joining multiple shapes into a single label or slicing a single label into several shapes.\nThis document provides guidance on how to perform these operations effectively.\nSee:\nJoining masks Slicing polygons and masks Joining masks The Join masks tool (), is specifically designed to work with mask annotations.\nThis tool is useful in scenarios where a single object in an image is annotated with multiple shapes, and there is a need to merge these shapes into a single one.\nTo join masks, do the following:\nFrom the Edit block, select Join masks . Click on the canvas area, to select masks that you want to join. (Optional) To remove the selection click the mask one more time. Click again on Join masks (J) to execute the join operation. Upon completion, the selected masks will be joined into a single mask.\nSlicing polygons and masks The Slice mask/polygon () is compatible with both mask and polygon annotations.\nThis tool is useful in scenarios where multiple objects in an image are annotated with one shape, and there is a need to slice this shape into multiple parts.\nNote The shape can be sliced only in two parts at a time. Use the slice tool several times to split a shape to as many parts as you need. To slice mask or polygon, do the following:\nFrom the Edit block, select Slice mask/polygon . Click on the shape you intend to slice. A black contour will appear around the selected shape. Set an initial point for slicing by clicking on the contour. Draw a line across the shape to define the slicing path. Hold Shift to add points automatically on cursor movement. Note: The line cannot cross itself. Note: The line cannot cross the contour more than twice. (Optional)\u003e Right-click to cancel the latest point. Click on the contour (Alt+J) (outside the contour) to finalize the slicing. ","categories":"","description":"This section explains how to slice or join several labels","excerpt":"This section explains how to slice or join several labels","ref":"/v2.43.0/docs/manual/advanced/slice-and-join/","tags":"","title":"Join and slice tools"},{"body":"Usage examples:\nCreate new annotations for a sequence of frames. Add/modify/delete objects for existing annotations. Edit tracks, merge several rectangles into one track. Like in the Shape mode, you need to select a Rectangle on the sidebar, in the appearing form, select the desired Label and the Drawing method.\nCreating a track for an object (look at the selected car as an example):\nCreate a Rectangle in Track mode by selecting Track.\nIn Track mode, the rectangle will be automatically interpolated on the next frames.\nThe cyclist starts moving on frame #2270. Let’s mark the frame as a key frame. You can press K for that or select the star button (see the screenshot below).\nIf the object starts to change its position, you need to modify the rectangle where it happens. It isn’t necessary to change the rectangle on each frame, simply update several keyframes and the frames between them will be interpolated automatically.\nLet’s jump 30 frames forward and adjust the boundaries of the object. See an example below:\nAfter that the rectangle of the object will be changed automatically on frames 2270 to 2300:\nWhen the annotated object disappears or becomes too small, you need to finish the track. You have to choose Outside Property, shortcut O.\nIf the object isn’t visible on a couple of frames and then appears again, you can use the Merge feature to merge several individual tracks into one.\nCreate tracks for moments when the cyclist is visible:\nSelect Merge button or press key M and select on any rectangle of the first track and on any rectangle of the second track and so on:\nSelect Merge button or press M to apply changes.\nThe final annotated sequence of frames in Interpolation mode can look like the clip below:\nRead more in the section track mode (advanced).\n","categories":"","description":"Usage examples and basic operations available during annotation in track mode.","excerpt":"Usage examples and basic operations available during annotation in …","ref":"/v2.43.0/docs/manual/basics/track-mode-basics/","tags":"","title":"Track mode (basics)"},{"body":"Use the 3D Annotation tool for labeling 3D objects and scenes, such as vehicles, buildings, landscapes, and others.\nCheck out:\nNavigation Annotation with cuboids Annotation with shapes Tracking with cuboids Navigation The 3D annotation canvas looks like the following:\nNote If you added contextual images to the dataset, the canvas will include them. For more information, consult Contextual images For information on the available tools, consult Controls sidebar.\nYou can navigate, using the mouse, or navigation keys:\nYou can also use keyboard shortcuts to navigate:\nAction Keys Camera rotation Shift + Arrow (Up, Down, Left, Right) Left/Right Alt+J/ Alt+L Up/down Alt+U/ Alt+O Zoom in/ou Alt+K/ Alt+I Annotation with cuboids There are two options available for 3D annotation:\nShape: for tasks like object detection. Track: uses interpolation to predict the position of objects in subsequent frames. A unique ID will be assigned to each object and maintained throughout the sequence of images. Annotation with shapes To add a 3D shape:\nOn the objects pane, select Draw new cuboid \u003e select the label from the drop-down list \u003e Shape.\nThe cursor will be followed by a cuboid. Place the cuboid on the 3D scene.\nUse projections to adjust the cuboid. Click and hold the left mouse button to edit the label shape on the projection.\n(Optional) Move one of the four points to change the size of the cuboid.\n(Optional) To rotate the cuboid, select the middle point and then drag the cuboid up/down or to left/right.\nTracking with cuboids To track with cuboids:\nOn the objects pane, select Draw new cuboid \u003e select the label from the drop-down list \u003e Track.\nThe cursor will be followed by a cuboid. Place the cuboid on the 3D scene.\nUse projections to adjust the cuboid. Select and hold the left mouse button to edit the label shape on the projection.\n(Optional) Move one of the four points to change the size of the cuboid.\n(Optional) To rotate the cuboid, click on the middle point and then drag the cuboid up/down or to left/right.\nMove several frames forward. You will see the cuboid you’ve added in frame 1. Adjust it, if needed.\nRepeat to the last frame with the presence of the object you are tracking.\nFor more information about tracking, consult Track mode.\n","categories":"","description":"Overview of basic operations available when annotating 3D objects.","excerpt":"Overview of basic operations available when annotating 3D objects.","ref":"/v2.43.0/docs/manual/basics/3d-object-annotation/","tags":"","title":"3D Object annotation"},{"body":"Export dataset You can export a dataset to a project, task or job.\nTo download the latest annotations, you have to save all changes first. Click the Save button. There is a Ctrl+S shortcut to save annotations quickly.\nAfter that, click the Menu button. Exporting and importing of task and project datasets takes place through the Action menu.\nPress the Export task dataset button.\nChoose the format for exporting the dataset. Exporting and importing is available in:\nStandard CVAT formats:\nCVAT for video choose if the task is created in interpolation mode.\nCVAT for images choose if a task is created in annotation mode.\nAnd also in formats from the list of annotation formats supported by CVAT.\nFor 3D tasks, the following formats are available:\nKitti Raw Format 1.0 Sly Point Cloud Format 1.0 - Supervisely Point Cloud dataset To download images with the dataset, enable the Save images option.\n(Optional) To name the resulting archive, use the Custom name field.\nYou can choose a storage for dataset export by selecting a target storage Local or Cloud storage. The default settings are the settings that had been selected when the project was created (for example, if you specified a local storage when you created the project, then by default, you will be prompted to export the dataset to your PC). You can find out the default value by hovering the mouse over the ?. Learn more about attach cloud storage.\nImport dataset You can import dataset only to a project. In this case, the data will be split into subsets. To import a dataset, do the following on the Project page:\nOpen the Actions menu. Press the Import dataset button. Select the dataset format (if you did not specify a custom name during export, the format will be in the archive name). Drag the file to the file upload area or click on the upload area to select the file through the explorer. You can also import a dataset from an attached cloud storage. Here you should select the annotation format, then select a cloud storage from the list or use default settings if you have already specified required cloud storage for task or project and specify a zip archive to the text field File name. During the import process, you will be able to track the progress of the import.\nUpload annotations In the task or job you can upload an annotation. For this select the item Upload annotation in the menu Action of the task or in the job Menu on the Top panel select the format in which you plan to upload the annotation and select the annotation file or archive via explorer.\nOr you can also use the attached cloud storage to upload the annotation file.\n","categories":"","description":"This section explains how to download and upload datasets (including annotation, images, and metadata) of projects, tasks, and jobs.","excerpt":"This section explains how to download and upload datasets (including …","ref":"/v2.43.0/docs/manual/advanced/import-datasets/","tags":"","title":"Import datasets and upload annotation"},{"body":" In this mode, you can edit attributes with fast navigation between objects and frames using a keyboard. Open the drop-down list in the top panel and select Attribute annotation.\nIn this mode, objects panel change to a special panel:\nThe active attribute will be red. In this case, it is gender. Look at the bottom side panel to see all possible shortcuts for changing the attribute. Press key 2 on your keyboard to assign a value (female) for the attribute or select from the drop-down list.\nPress Up Arrow/Down Arrow on your keyboard or select the buttons in the UI to go to the next/previous attribute. In this case, after pressing Down Arrow you will be able to edit the Age attribute.\nUse Right Arrow/Left Arrow keys to move to the previous/next image with annotation.\nTo display all the hot keys available in the attribute annotation mode, press F2. Learn more in the section attribute annotation mode (advanced).\n","categories":"","description":"Usage examples and basic operations available in attribute annotation mode.","excerpt":"Usage examples and basic operations available in attribute annotation …","ref":"/v2.43.0/docs/manual/basics/attribute-annotation-mode-basics/","tags":"","title":"Attribute annotation mode (basics)"},{"body":"CVAT Analytics suite of tools is designed to track and understand users’ behavior, system performance, and for identifying potential issues in your application.\nYou can also visualize user activity through Grafana, and aggregate user working time by the jobs.\nGathered logs can be additionally filtered for efficient debugging.\nBy using analytics, you’ll gain valuable insights to optimize your system and enhance user satisfaction.\nCVAT analytics are available from the top menu.\nSuperusers and users with administrator role have access to analytics. Permission to access analytics can also be granted when editing a user on admin page by Has access to analytics checkbox.\nNote CVAT analytics and monitoring are available only for on-prem solution. See:\nHigh-level architecture CVAT Analytics Ports settings Events log structure Types of supported events Working time calculation Request id for tracking Fetching event data as CSV from the /api/events endpoint Dashboards Dashboard: All Events Dashboard: Management Dashboard: Monitoring Dashboards setup Example of use High-level architecture The CVAT analytics is based on Vector, ClickHouse, and Grafana.\nCVAT Analytics CVAT and its analytics module can be set up locally, for self-hosted solution analytics are enabled by default.\nFor detailed CVAT installation instructions, see Installation Guide or refer to the CVAT Course for installation videos.\nAll analytics-related features will be launched when you start CVAT containers with the following command:\ndocker compose up -d Ports settings If you cannot access analytics on development environment, see Analytics Ports\nEvents log structure Relational database schema with the following fields:\nField Description scope Scope of the event (e.g., zoomin:image, add:annotations, delete:image, update:assignee). obj_name Object name or None (e.g., task, job, cloudstorage, model, organization). obj_id Object identifier as in DB or None. obj_val Value for the event as string or None (e.g., frame number, number of added annotations). source Who generates the log event (e.g., server, ui). timestamp Local event time (in general for UI and server, the time is different). count How many times in the row it occurs. duration How much time does it take (it can be 0 for events without duration). project_id Project ID or None. task_id Task ID or None. job_id Job ID or None. user_id User ID or None. user_name User name or None. user_email User email or None. org_id Organization ID or None. org_slug Organization slug or None. payload JSON payload or None. Extra fields can be added to the JSON blob. Types of supported events Supported events change the scope of information displayed in Grafana.\nServer events:\ncreate:project, update:project, delete:project\ncreate:task, update:task, delete:task\ncreate:job, update:job, delete:job\ncreate:organization, update:organization, delete:organization\ncreate:user, update:user, delete:user\ncreate:cloudstorage, update:cloudstorage, delete:cloudstorage\ncreate:issue, update:issue, delete:issue\ncreate:comment, update:comment, delete:comment\ncreate:annotations, update:annotations, delete:annotations\ncreate:label, update:label, delete:label\nexport:dataset, import:dataset\ncall:function\ncreate:membership, update:membership, delete:membership\ncreate:webhook, update:webhook, delete:webhook\ncreate:invitation, delete:invitation\nClient events:\nload:cvat\nload:job, save:job\nsend:exception\ndraw:object, paste:object, copy:object, propagate:object, drag:object, resize:object, delete:object, merge:objects, split:objects, group:objects, slice:object, join:objects\nchange:frame\nzoom:image, fit:image, rotate:image\naction:undo, action:redo\nrun:annotations_action\nclick:element\ndebug:info\nWorking time calculation Here is a short overview of how CVAT deals with the user’s working time:\nThe user interface collects events when a user interacts with the interface (resizing canvas, drawing objects, clicking buttons, etc) The structure of one single event is described here.\nThe user interface sends these events in bulk to the server. Currently, it uses the following triggers to send events:\nPeriodical timer (~90 seconds) A user clicks the “Save” button on the annotation view A user opens the annotation view A user closes the annotation view (but not the tab/browser) A user clicks Logout button When events reach the server, it calculates working time based on timestamps of the events.\nThe working time for an event is computed as the sum of the following:\nThe difference between the start time of the event and the end time of the previous event, if it is not more than 100 seconds. The duration of the event, for events of type change:frame. After calculation, the server generates send:working_time events with time value in payload. These events may or may not be bound to a certain job/task/project, depending on the client-side events that were used to generate them.\nCVAT saves the event in the database and later these events are used to compute metrics for analytics.\nRequest id for tracking Note, that every response to an API request made to the the server includes a header named X-Request-Id, for example: X-Request-Id: 6a2b7102-c4b9-4d57-8754-5658132ba37d.\nThis identifier is also recorded in all server events that occur as a result of the respective request.\nFor example, when an operation to create a task is performed, other related entities such as labels and attributes are generated on the server in addition to the Task object.\nAll events associated with this operation will have the same request_id in the payload field.\nExport event data You can export the event data as a CSV file locally and to cloud storage.\nTo export the data locally:\nInitiate the export process by sending a POST request to /api/events/export endpoint. The endpoint accepts several query parameters to filter events: org_id, project_id, task_id, job_id, user_id, to and from. For more details, see Swagger API Documentation. For example:\ncurl -X POST -u 'user:pass' https://app.cvat.ai/api/events/export?job_id=123 You can check the status of the export process by sending a GET request with the rq_id to the /api/requests/{id} endpoint:\ncurl -I --user 'user:pass' https://app.cvat.ai/api/requests/rq_id Once the export process finishes, the request returns an object with \"status\": \"finished\" and \"result_url\": \"URL\".\nDownload the event data file locally using result_url:\ncurl -u user:password -o path/to/file.csv result_url This command will download and save the CSV file to path/to/file.csv on your local machine.\nTo save the CSV file with the event data to cloud storage, you can use the /api/events/export endpoint with cloud_storage_id and location=cloud_storage parameters, for example:\ncurl -X POST -u user:password \"https://app.cvat.ai/api/events/export?cloud_storage_id=your_cloud_storage_id\u0026location=cloud_storage\" Dashboards By default, three dashboards are available in CVAT.\nTo access them, click General, you will be forwarded to the page with available dashboards.\nDashboard Description All Events Dashboard that shows all event logs, timestamps, and source. Management Dashboard with information about user activities such as working time by job and so on. Monitoring Dashboard showing server logs, including errors. Dashboard: All Events The dashboard shows all events, their timestamps, and their source.\nElement Description Filters Can be used as drop-down lists or search fields. Click on the arrow to activate. Overall activity Graph that shows the overall activity by the selected filters. Scope Users’ activity, see Types of supported events. obj_name Object or item related to the Scope. obj_id Object’s id. Might be empty. source Source of the event, can be client or server. timestamp Time when the event happened. count Common field for all events, not null where it makes sense, for example, the number of saved objects in an annotation. duration Duration in milliseconds. project_id Id of the project. project_id Id of the project. task_id ID of the task. job_id ID of the job. There are two fields with statistics at the bottom of the dashboard, about browser and OS users use.\nClick on the column name to enable a filter.\nIf you want to inspect the value, hover over it and click on the eye icon.\nDashboard: Management The dashboard shows user activity.\nElement Description Filters Can be used as drop-down lists or search fields. Click on the arrow to activate. User activity Graph that shows when the user was active (data and time), click on the user id below, to see the graph for the dedicated user. Overall activity Graph shows common activity for all users. User User ID. Project Project ID. Might be empty. Task Task ID. Might be empty. Job Job ID. Might be empty. Working time(h) Time spent on task in hours. Activity Number of events for each user. Click on the column name to enable a filter.\nIf you want to inspect the value, hover over it and click on the eye icon.\nDashboard: Monitoring The dashboard shows server logs, helps handle errors, and shows user activity.\nElement Description Filters Can be used as drop-down lists or search fields. Click on the arrow to activate. Active users (now) Number of active users on an instance. Overall activity Graph that shows the number of active users. Exceptions Graph that shows the number of errors that happened in the instance. timestamp Time when the error happened. user_id User ID. user_name User nickname. project_id Id of the project. Might be empty. task_id Task ID. Might be empty. job_id Job ID. Might be empty. error Error description stack Error description payload Error description stack Stack trace, which is a report of the active stack frames at a certain point in time during the execution. This information is typically used for debugging purposes to locate where an issue occurred. payload JSON that describes the entire object, which contains several properties. This data in the payload is related to an event that was created as a result of a failed API request. The payload contains information about this event. Click on the column name to enable a filter.\nIf you want to inspect the value, hover over it and click on the eye icon.\nDashboards setup You can adjust the dashboards. To do this, click on the graph or table name and from the drop-down menu select Edit.\nAdjust the query in the editor.\nExample of query:\nSELECT time, uniqExact(user_id) Users FROM ( SELECT user_id, toStartOfInterval(timestamp, INTERVAL 15 minute) as time FROM cvat.events WHERE user_id IS NOT NULL GROUP BY user_id, time ORDER BY time ASC WITH FILL STEP toIntervalMinute(15) ) GROUP BY time ORDER BY time Note By default the updated configuration will not be saved and will be reset to the default parameters after you restart the container. To save the updated configuration, do the following:\nUpdate Configuration: Start by making your desired changes in the query.\nApply Changes: Once you’ve made your changes, click the Apply button to ensure the changes are implemented.\nSave Configuration: To save your applied changes, on the top of the dashboard, click the Save button.\nReplace Configuration File: After saving, replace the existing Grafana dashboard configuration file is located at components/analytics/grafana/dashboards with the new JSON configuration file.\nRestart Grafana Service: To ensure, that all changes take effect, restart the Grafana service. If you’re using Docker Compose, execute the following command: docker compose restart cvat_grafana.\nFor more information, see Grafana Dashboards.\nExample of use This video demonstrates available by default CVAT analytics features.\n","categories":"","description":"Instructions for deployment and customization of analytics and monitoring.","excerpt":"Instructions for deployment and customization of analytics and …","ref":"/v2.43.0/docs/administration/advanced/analytics/","tags":"","title":"CVAT Analytics and monitoring"},{"body":"In CVAT, you have the option to export data in various formats. The choice of export format depends on the type of annotation as well as the intended future use of the dataset.\nSee:\nData export formats Exporting dataset in CVAT Exporting dataset from Task Exporting dataset from Job Data export video tutorial Data export formats The table below outlines the available formats for data export in CVAT.\nFormat Type Computer Vision Task Models Shapes Attributes Video Tracks CamVid 1.0 .txt .png Semantic Segmentation U-Net, SegNet, DeepLab, PSPNet, FCN, Mask R-CNN, ICNet, ERFNet, HRNet, V-Net, and others. Polygons Not supported Not supported Cityscapes 1.0 .txt\n.png Semantic\nSegmentation U-Net, SegNet, DeepLab, PSPNet, FCN, ERFNet, ICNet, Mask R-CNN, HRNet, ENet, and others. Polygons Specific attributes Not supported COCO 1.0 JSON Detection, Semantic Segmentation YOLO (You Only Look Once), Faster R-CNN, Mask R-CNN, SSD (Single Shot MultiBox Detector), RetinaNet, EfficientDet, UNet, DeepLabv3+, CenterNet, Cascade R-CNN, and others. Bounding Boxes, Polygons Specific attributes Not supported COCO Keypoints 1.0 .xml Keypoints OpenPose, PoseNet, AlphaPose, SPM (Single Person Model), Mask R-CNN with Keypoint Detection:, and others. Skeletons Specific attributes Not supported CVAT for images 1.1 .xml Any in 2D except for Video Tracking Any model that can decode the format. Bounding Boxes, Polygons, Polylines, Points, Cuboids, Skeletons, Ellipses, Masks, Tags. All attributes Not supported CVAT for video 1.1 .xml Any in 2D except for Classification Any model that can decode the format. Bounding Boxes, Polygons, Polylines, Points, Cuboids, Skeletons, Ellipses, Masks. All attributes Supported Datumaro 1.0 JSON Any Any model that can decode the format. Main format in Datumaro framework Bounding Boxes, Polygons, Polylines, Points, Cuboids, Skeletons, Ellipses, Masks, Tags. All attributes Supported ICDAR\nIncludes ICDAR Recognition 1.0, ICDAR Detection 1.0, and ICDAR Segmentation 1.0 descriptions. .txt Text recognition, Text detection, Text segmentation EAST: Efficient and Accurate Scene Text Detector, CRNN, Mask TextSpotter, TextSnake, and others. Tag, Bounding Boxes, Polygons Specific attributes Not supported ImageNet 1.0 .jpg .txt Semantic Segmentation, Classification, Detection VGG (VGG16, VGG19), Inception, YOLO, Faster R-CNN , U-Net, and others Tags No attributes Not supported KITTI 1.0 .txt .png Semantic Segmentation, Detection, 3D PointPillars, SECOND, AVOD, YOLO, DeepSORT, PWC-Net, ORB-SLAM, and others. Bounding Boxes, Polygons Specific attributes Not supported LabelMe 3.0 .xml Compatibility, Semantic Segmentation U-Net, Mask R-CNN, Fast R-CNN,\nFaster R-CNN, DeepLab, YOLO, and others. Bounding Boxes, Polygons Supported (Polygons) Not supported LFW 1.0 .txt Verification, Face recognition OpenFace, VGGFace \u0026 VGGFace2, FaceNet, ArcFace, and others. Tags, Skeletons Specific attributes Not supported Market-1501 1.0 .txt Re-identification Triplet Loss Networks, Deep ReID models, and others. Bounding Boxes Specific attributes Not supported MOT 1.0 .txt Video Tracking, Detection SORT, MOT-Net, IOU Tracker, and others. Bounding Boxes Specific attributes Supported MOTS PNG 1.0 .png\n.txt Video Tracking, Detection SORT, MOT-Net, IOU Tracker, and others. Bounding Boxes, Masks Specific attributes Supported Open Images 1.0 .csv Detection, Classification, Semantic Segmentation Faster R-CNN, YOLO, U-Net, CornerNet, and others. Bounding Boxes, Tags, Polygons Specific attributes Not supported PASCAL VOC 1.0 .xml Classification, Detection Faster R-CNN, SSD, YOLO, AlexNet, and others. Bounding Boxes, Tags, Polygons Specific attributes Not supported Segmentation Mask 1.0 .txt Semantic Segmentation Faster R-CNN, SSD, YOLO, AlexNet, and others. Polygons No attributes Not supported VGGFace2 1.0 .csv Face recognition VGGFace, ResNet, Inception, and others. Bounding Boxes, Points No attributes Not supported WIDER Face 1.0 .txt Detection SSD (Single Shot MultiBox Detector), Faster R-CNN, YOLO, and others. Bounding Boxes, Tags Specific attributes Not supported YOLO 1.0 .txt Detection YOLOv1, YOLOv2 (YOLO9000), YOLOv3, YOLOv4, and others. Bounding Boxes No attributes Not supported Ultralytics YOLO Detection 1.0 .txt Detection YOLOv8 Bounding Boxes No attributes Supported Ultralytics YOLO Segmentation 1.0 .txt Instance Segmentation YOLOv8 Polygons, Masks No attributes Supported Ultralytics YOLO Pose 1.0 .txt Keypoints YOLOv8 Skeletons No attributes Supported Ultralytics YOLO Oriented Bounding Boxes 1.0 .txt Detection YOLOv8 Bounding Boxes No attributes Supported Ultralytics YOLO Classification 1.0 .jpg Classification YOLOv8 Tags No attributes Not supported Exporting dataset in CVAT Exporting dataset from Task To export the dataset from the task, follow these steps:\nOpen Task.\nGo to Actions \u003e Export task dataset.\nChoose the desired format from the list of available options.\n(Optional) Toggle the Save images switch if you wish to include images in the export.\nNote The Save images option is a paid feature. Input a name for the resulting .zip archive.\nClick OK to initiate the export.\nExporting dataset from Job To export a dataset from Job follow these steps:\nNavigate to Menu \u003e Export job dataset.\nChoose the desired format from the list of available options.\n(Optional) Toggle the Save images switch if you wish to include images in the export.\nNote The Save images option is a paid feature. Input a name for the resulting .zip archive.\nClick OK to initiate the export.\nData export video tutorial For more information on the process, see the following tutorial:\n","categories":"","description":"List of data export formats formats supported by CVAT.","excerpt":"List of data export formats formats supported by CVAT.","ref":"/v2.43.0/docs/manual/advanced/formats/","tags":"","title":"Export annotations and data from CVAT"},{"body":"CVAT has the following features for automated quality control of annotations:\nValidation set configuration for a task Job validation on job finish (Immediate feedback) Review mode for problems found Quality analytics In this section, we highlight only the key steps in quality estimation. Consult the detailed guide on quality estimation in CVAT in the Advanced section.\nHow to enable quality control In a new task In an existing task Go to task creation\nSelect the source media, configure other task parameters\nScroll down to the Quality Control section\nSelect one of the validation modes available\nCreate the task\nUpload or create Ground Truth annotations in the Ground Truth job in the task\nSwitch the Ground Truth job into the acceptance stage and completed state\nFor already existing tasks only the Ground Truth validation mode is available. If you want to use Honeypots for your task, you will need to recreate the task.\nOpen the task page\nSelect the + button next to the job list\nSelect Job Type Ground truth and configure the job parameters\nUpload or create Ground Truth annotations in the Ground Truth job in the task\nSwitch the Ground Truth job into the acceptancestage and completed state\nHow to enable immediate job feedback Note This feature requires a configured validation set in the task. Learn more in How to enable quality control and in the full guide. Open the task Actions menu \u003e Quality control \u003e Settings\nSet Max validations per job to above zero. 3 is a good starting number\nSave the updated settings\nAssign an annotator to an annotation job\nAnnotate the job\nMark the job finished using the corresponding button in the menu\nOnce the job is completed, you’ll see the job validation dialog\nEach assignee gets no more than the specified number of validation attempts.\nLearn more about this functionality in the Immediate Feedback section.\nHow to check task quality metrics Open the task Actions menu \u003e Quality control\n(Optional) Request quality metrics computation, and wait for completion\nReview summaries or detailed reports\nLearn more about this functionality here.\nHow to review problems found Open the task Actions menu \u003e Quality control Find an annotation job to be reviewed, it must have at least 1 validation frame Select the job link Switch to the Review mode Enable display of Ground Truth annotations and conflicts Learn more about this functionality here.\n","categories":"","description":"Overview of quality control features","excerpt":"Overview of quality control features","ref":"/v2.43.0/docs/manual/basics/quality-control/","tags":"","title":"Quality control"},{"body":"Label Label is a type of an annotated object (e.g. person, car, vehicle, etc.)\nAttribute Attribute is a property of an annotated object (e.g. color, model, quality, etc.). There are two types of attributes:\nUnique Unique immutable and can’t be changed from frame to frame (e.g. age, gender, color, etc.)\nTemporary Temporary mutable and can be changed on any frame (e.g. quality, pose, truncated, etc.)\nTrack Track is a set of shapes on different frames which corresponds to one object. Tracks are created in Track mode\nAnnotation Annotation is a set of shapes and tracks. There are several types of annotations:\nManual which is created by a person Semi-automatic which is created mainly automatically, but the user provides some data (e.g. interpolation) Automatic which is created automatically without a person in the loop Approximation Approximation allows you to reduce the number of points in the polygon. Can be used to reduce the annotation file and to facilitate editing polygons.\nTrackable Trackable object will be tracked automatically if the previous frame was a latest keyframe for the object. More details in the section trackers.\nMode Interpolation Mode for video annotation, which uses track objects. Only objects on keyframes are manually annotation, and intermediate frames are linearly interpolated.\nRelated sections:\nTrack mode Annotation Mode for images annotation, which uses shape objects.\nRelated sections:\nShape mode Dimension Depends on the task data type that is defined when the task is created.\n2D The data format of 2d tasks are images and videos. Related sections:\nCreating an annotation task 3D The data format of 3d tasks is a cloud of points. Data formats for a 3D task\nRelated sections:\n3D task workspace Standard 3D mode 3D Object annotation State State of the job. The state can be changed by an assigned user in the menu inside the job. There are several possible states: new, in progress, rejected, completed.\nStage Stage of the job. The stage is specified with the drop-down list on the task page. There are three stages: annotation, validation or acceptance. This value affects the task progress bar.\nSubset A project can have subsets. Subsets are groups for tasks that make it easier to work with the dataset. It could be test, train, validation or custom subset.\nCredentials Under credentials is understood Key \u0026 secret key, Account name and token, Anonymous access, Key file. Used to attach cloud storage.\nResource Under resource is understood bucket name or container name. Used to attach cloud storage.\n","categories":"","description":"List of terms pertaining to annotation in CVAT.","excerpt":"List of terms pertaining to annotation in CVAT.","ref":"/v2.43.0/docs/manual/basics/vocabulary/","tags":"","title":"Vocabulary"},{"body":"\nThe cloud storages page contains elements, each of them relating to a separate cloud storage. Each element contains: preview, cloud storage name, provider, creation and update info, status, ? button for displaying the description and the actions menu.\nEach button in the action menu is responsible for a specific function:\nUpdate — update this cloud storage Delete — delete cloud storage. This preview will appear when it is impossible to get a real preview (e.g. storage is empty or invalid credentials were used).\nIn the upper left corner, there is a search bar, using which you can find the cloud storage by display name, provider, etc. In the upper right corner, there are sorting, quick filters, and filter.\nFilter Applying the filter disables the quick filters.\nThe filter works similarly to the filters for annotation, you can create rules from properties, operators, and values and group rules into groups. For more details, consult the filter section. Learn more about date and time selection.\nTo clear all filters, select Clear filters.\nSupported properties for cloud storages list Properties Supported values Description ID number or range of task ID Provider type AWS S3, Azure, Google cloud Credentials type Key \u0026 secret key, Account name and token,\nAnonymous access, Key file Resource name Bucket name or container name Display name Set when creating cloud storage Description Description of the cloud storage Owner username The user who owns the project, task, or job Last updated last modified date and time (or value range) The date can be entered in the dd.MM.yyyy HH:mm format or by selecting the date in the window that appears when you select the input field Select the + button to attach a new cloud storage.\n","categories":"","description":"Overview of the cloud storages page.","excerpt":"Overview of the cloud storages page.","ref":"/v2.43.0/docs/manual/basics/cloud-storages/","tags":"","title":"Cloud storages page"},{"body":" When you want to download annotations from Computer Vision Annotation Tool (CVAT) you can choose one of several data formats. The document describes XML annotation format. Each format has X.Y version (e.g. 1.0). In general the major version (X) is incremented when the data format has incompatible changes and the minor version (Y) is incremented when the data format is slightly modified (e.g. it has one or several extra fields inside meta information). The document will describe all changes for all versions of XML annotation format.\nVersion 1.1 There are two different formats for images and video tasks at the moment. The both formats have a common part which is described below. From the previous version flipped tag was added. Also original_size tag was added for interpolation mode to specify frame size. In annotation mode each image tag has width and height attributes for the same purpose.\nFor what is rle, see Run-length encoding\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cannotations\u003e \u003cversion\u003e1.1\u003c/version\u003e \u003cmeta\u003e \u003ctask\u003e \u003cid\u003eNumber: id of the task\u003c/id\u003e \u003cname\u003eString: some task name\u003c/name\u003e \u003csize\u003eNumber: count of frames/images in the task\u003c/size\u003e \u003cmode\u003eString: interpolation or annotation\u003c/mode\u003e \u003coverlap\u003eNumber: number of overlapped frames between segments\u003c/overlap\u003e \u003cbugtracker\u003eString: URL on an page which describe the task\u003c/bugtracker\u003e \u003cflipped\u003eBoolean: were images of the task flipped? (True/False)\u003c/flipped\u003e \u003ccreated\u003eString: date when the task was created\u003c/created\u003e \u003cupdated\u003eString: date when the task was updated\u003c/updated\u003e \u003clabels\u003e \u003clabel\u003e \u003cname\u003eString: name of the label (e.g. car, person)\u003c/name\u003e \u003ctype\u003eString: any, bbox, cuboid, ellipse, mask, polygon, polyline, points, skeleton, tag\u003c/type\u003e \u003cattributes\u003e \u003cattribute\u003e \u003cname\u003eString: attribute name\u003c/name\u003e \u003cmutable\u003eBoolean: mutable (allow different values between frames)\u003c/mutable\u003e \u003cinput_type\u003eString: select, checkbox, radio, number, text\u003c/input_type\u003e \u003cdefault_value\u003eString: default value\u003c/default_value\u003e \u003cvalues\u003eString: possible values, separated by newlines ex. value 2 ex. value 3\u003c/values\u003e \u003c/attribute\u003e \u003c/attributes\u003e \u003csvg\u003eString: label representation in svg, only for skeletons\u003c/svg\u003e \u003cparent\u003eString: label parent name, only for skeletons\u003c/parent\u003e \u003c/label\u003e \u003c/labels\u003e \u003csegments\u003e \u003csegment\u003e \u003cid\u003eNumber: id of the segment\u003c/id\u003e \u003cstart\u003eNumber: first frame\u003c/start\u003e \u003cstop\u003eNumber: last frame\u003c/stop\u003e \u003curl\u003eString: URL (e.g. http://cvat.example.com/?id=213)\u003c/url\u003e \u003c/segment\u003e \u003c/segments\u003e \u003cowner\u003e \u003cusername\u003eString: the author of the task\u003c/username\u003e \u003cemail\u003eString: email of the author\u003c/email\u003e \u003c/owner\u003e \u003coriginal_size\u003e \u003cwidth\u003eNumber: frame width\u003c/width\u003e \u003cheight\u003eNumber: frame height\u003c/height\u003e \u003c/original_size\u003e \u003c/task\u003e \u003cdumped\u003eString: date when the annotation was dumped\u003c/dumped\u003e \u003c/meta\u003e ... \u003c/annotations\u003e Annotation Below you can find description of the data format for images tasks. On each image it is possible to have many different objects. Each object can have multiple attributes. If an annotation task is created with z_order flag then each object will have z_order attribute which is used to draw objects properly when they are intersected (if z_order is bigger the object is closer to camera). In previous versions of the format only box shape was available. In later releases mask, polygon, polyline, points, skeletons and tags were added. Please see below for more details:\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cannotations\u003e ... \u003cimage id=\"Number: id of the image (the index in lexical order of images)\" name=\"String: path to the image\" width=\"Number: image width\" height=\"Number: image height\"\u003e \u003cbox label=\"String: the associated label\" xtl=\"Number: float\" ytl=\"Number: float\" xbr=\"Number: float\" ybr=\"Number: float\" occluded=\"Number: 0 - False, 1 - True\" z_order=\"Number: z-order of the object\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/box\u003e \u003cpolygon label=\"String: the associated label\" points=\"x0,y0;x1,y1;...\" occluded=\"Number: 0 - False, 1 - True\" z_order=\"Number: z-order of the object\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/polygon\u003e \u003cpolyline label=\"String: the associated label\" points=\"x0,y0;x1,y1;...\" occluded=\"Number: 0 - False, 1 - True\" z_order=\"Number: z-order of the object\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/polyline\u003e \u003cpolyline label=\"String: the associated label\" points=\"x0,y0;x1,y1;...\" occluded=\"Number: 0 - False, 1 - True\" z_order=\"Number: z-order of the object\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/polyline\u003e \u003cpoints label=\"String: the associated label\" points=\"x0,y0;x1,y1;...\" occluded=\"Number: 0 - False, 1 - True\" z_order=\"Number: z-order of the object\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/points\u003e \u003ctag label=\"String: the associated label\" source=\"manual or auto\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/tag\u003e \u003cskeleton label=\"String: the associated label\" z_order=\"Number: z-order of the object\"\u003e \u003cpoints label=\"String: the associated label\" occluded=\"Number: 0 - False, 1 - True\" outside=\"Number: 0 - False, 1 - True\" points=\"x0,y0;x1,y1\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e \u003c/points\u003e ... \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/skeleton\u003e \u003cmask label=\"String: the associated label\" source=\"manual or auto\" occluded=\"Number: 0 - False, 1 - True\" rle=\"RLE mask\" left=\"Number: left coordinate of the image where the mask begins\" top=\"Number: top coordinate of the image where the mask begins\" width=\"Number: width of the mask\" height=\"Number: height of the mask\" z_order=\"Number: z-order of the object\"\u003e \u003c/mask\u003e ... \u003c/image\u003e ... \u003c/annotations\u003e Example:\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cannotations\u003e \u003cversion\u003e1.1\u003c/version\u003e \u003cmeta\u003e \u003ctask\u003e \u003cid\u003e4\u003c/id\u003e \u003cname\u003esegmentation\u003c/name\u003e \u003csize\u003e27\u003c/size\u003e \u003cmode\u003eannotation\u003c/mode\u003e \u003coverlap\u003e0\u003c/overlap\u003e \u003cbugtracker\u003e\u003c/bugtracker\u003e \u003cflipped\u003eFalse\u003c/flipped\u003e \u003ccreated\u003e2018-09-25 11:34:24.617558+03:00\u003c/created\u003e \u003cupdated\u003e2018-09-25 11:38:27.301183+03:00\u003c/updated\u003e \u003clabels\u003e \u003clabel\u003e \u003cname\u003ecar\u003c/name\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003etraffic_line\u003c/name\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003ewheel\u003c/name\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003eplate\u003c/name\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003es1\u003c/name\u003e \u003ctype\u003eskeleton\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003csvg\u003e\u0026lt;line x1=\"36.87290954589844\" y1=\"47.732025146484375\" x2=\"86.87290954589844\" y2=\"10.775501251220703\" stroke=\"black\" data-type=\"edge\" data-node-from=\"2\" stroke-width=\"0.5\" data-node-to=\"3\"\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;line x1=\"25.167224884033203\" y1=\"22.64841079711914\" x2=\"36.87290954589844\" y2=\"47.732025146484375\" stroke=\"black\" data-type=\"edge\" data-node-from=\"1\" stroke-width=\"0.5\" data-node-to=\"2\"\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;circle r=\"1.5\" stroke=\"black\" fill=\"#b3b3b3\" cx=\"25.167224884033203\" cy=\"22.64841079711914\" stroke-width=\"0.1\" data-type=\"element node\" data-element-id=\"1\" data-node-id=\"1\" data-label-name=\"1\"\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;circle r=\"1.5\" stroke=\"black\" fill=\"#b3b3b3\" cx=\"36.87290954589844\" cy=\"47.732025146484375\" stroke-width=\"0.1\" data-type=\"element node\" data-element-id=\"2\" data-node-id=\"2\" data-label-name=\"2\"\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;circle r=\"1.5\" stroke=\"black\" fill=\"#b3b3b3\" cx=\"86.87290954589844\" cy=\"10.775501251220703\" stroke-width=\"0.1\" data-type=\"element node\" data-element-id=\"3\" data-node-id=\"3\" data-label-name=\"3\"\u0026gt;\u0026lt;/circle\u0026gt;\u003c/svg\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003e1\u003c/name\u003e \u003ctype\u003epoints\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003cparent\u003es1\u003c/parent\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003e2\u003c/name\u003e \u003ctype\u003epoints\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003cparent\u003es1\u003c/parent\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003e3\u003c/name\u003e \u003ctype\u003epoints\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003cparent\u003es1\u003c/parent\u003e \u003c/label\u003e \u003c/labels\u003e \u003csegments\u003e \u003csegment\u003e \u003cid\u003e4\u003c/id\u003e \u003cstart\u003e0\u003c/start\u003e \u003cstop\u003e26\u003c/stop\u003e \u003curl\u003ehttp://localhost:8080/?id=4\u003c/url\u003e \u003c/segment\u003e \u003c/segments\u003e \u003cowner\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cemail\u003e\u003c/email\u003e \u003c/owner\u003e \u003c/task\u003e \u003cdumped\u003e2018-09-25 11:38:28.799808+03:00\u003c/dumped\u003e \u003c/meta\u003e \u003cimage id=\"0\" name=\"filename000.jpg\" width=\"1600\" height=\"1200\"\u003e \u003cbox label=\"plate\" xtl=\"797.33\" ytl=\"870.92\" xbr=\"965.52\" ybr=\"928.94\" occluded=\"0\" z_order=\"4\"\u003e \u003c/box\u003e \u003cpolygon label=\"car\" points=\"561.30,916.23;561.30,842.77;554.72,761.63;553.62,716.67;565.68,677.20;577.74,566.45;547.04,559.87;536.08,542.33;528.40,520.40;541.56,512.72;559.10,509.43;582.13,506.14;588.71,464.48;583.23,448.03;587.61,434.87;594.19,431.58;609.54,399.78;633.66,369.08;676.43,294.52;695.07,279.17;703.84,279.17;735.64,268.20;817.88,264.91;923.14,266.01;997.70,274.78;1047.04,283.55;1063.49,289.04;1090.90,330.70;1111.74,371.27;1135.86,397.59;1147.92,428.29;1155.60,435.97;1157.79,451.32;1156.69,462.28;1159.98,491.89;1163.27,522.59;1173.14,513.82;1199.46,516.01;1224.68,521.49;1225.77,544.52;1207.13,568.64;1181.91,576.32;1178.62,582.90;1177.53,619.08;1186.30,680.48;1199.46,711.19;1206.03,733.12;1203.84,760.53;1197.26,818.64;1199.46,840.57;1203.84,908.56;1192.88,930.49;1184.10,939.26;1162.17,944.74;1139.15,960.09;1058.01,976.54;1028.40,969.96;1002.09,972.15;931.91,974.35;844.19,972.15;772.92,972.15;729.06,967.77;713.71,971.06;685.20,973.25;659.98,968.86;644.63,984.21;623.80,983.12;588.71,985.31;560.20,966.67\" occluded=\"0\" z_order=\"1\"\u003e \u003c/polygon\u003e \u003cpolyline label=\"traffic_line\" points=\"462.10,0.00;126.80,1200.00\" occluded=\"0\" z_order=\"3\"\u003e \u003c/polyline\u003e \u003cpolyline label=\"traffic_line\" points=\"1212.40,0.00;1568.66,1200.00\" occluded=\"0\" z_order=\"2\"\u003e \u003c/polyline\u003e \u003cpoints label=\"wheel\" points=\"574.90,939.48;1170.16,907.90;1130.69,445.26;600.16,459.48\" occluded=\"0\" z_order=\"5\"\u003e \u003c/points\u003e \u003ctag label=\"good_frame\" source=\"manual\"\u003e \u003c/tag\u003e \u003cskeleton label=\"s1\" source=\"manual\" z_order=\"0\"\u003e \u003cpoints label=\"1\" occluded=\"0\" source=\"manual\" outside=\"0\" points=\"54.47,94.81\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" occluded=\"0\" source=\"manual\" outside=\"0\" points=\"68.02,162.34\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" occluded=\"0\" source=\"manual\" outside=\"0\" points=\"125.87,62.85\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003cmask label=\"car\" source=\"manual\" occluded=\"0\" rle=\"3, 5, 7, 7, 5, 9, 3, 11, 2, 11, 2, 12, 1, 12, 1, 26, 1, 12, 1, 12, 2, 11, 3, 9, 5, 7, 7, 5, 3\" left=\"707\" top=\"888\" width=\"13\" height=\"15\" z_order=\"0\"\u003e \u003c/mask\u003e \u003c/image\u003e \u003c/annotations\u003e Interpolation Below you can find description of the data format for video tasks. The annotation contains tracks. Each track corresponds to an object which can be presented on multiple frames. The same object cannot be presented on the same frame in multiple locations. Each location of the object can have multiple attributes even if an attribute is immutable for the object it will be cloned for each location (a known redundancy).\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cannotations\u003e ... \u003ctrack id=\"Number: id of the track (doesn't have any special meeting)\" label=\"String: the associated label\" source=\"manual or auto\"\u003e \u003cbox frame=\"Number: frame\" xtl=\"Number: float\" ytl=\"Number: float\" xbr=\"Number: float\" ybr=\"Number: float\" outside=\"Number: 0 - False, 1 - True\" occluded=\"Number: 0 - False, 1 - True\" keyframe=\"Number: 0 - False, 1 - True\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e ... \u003c/box\u003e \u003cpolygon frame=\"Number: frame\" points=\"x0,y0;x1,y1;...\" outside=\"Number: 0 - False, 1 - True\" occluded=\"Number: 0 - False, 1 - True\" keyframe=\"Number: 0 - False, 1 - True\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e \u003c/polygon\u003e \u003cpolyline frame=\"Number: frame\" points=\"x0,y0;x1,y1;...\" outside=\"Number: 0 - False, 1 - True\" occluded=\"Number: 0 - False, 1 - True\" keyframe=\"Number: 0 - False, 1 - True\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e \u003c/polyline\u003e \u003cpoints frame=\"Number: frame\" points=\"x0,y0;x1,y1;...\" outside=\"Number: 0 - False, 1 - True\" occluded=\"Number: 0 - False, 1 - True\" keyframe=\"Number: 0 - False, 1 - True\"\u003e \u003cattribute name=\"String: an attribute name\"\u003eString: the attribute value\u003c/attribute\u003e \u003c/points\u003e \u003cmask frame=\"Number: frame\" outside=\"Number: 0 - False, 1 - True\" occluded=\"Number: 0 - False, 1 - True\" rle=\"RLE mask\" left=\"Number: left coordinate of the image where the mask begins\" top=\"Number: top coordinate of the image where the mask begins\" width=\"Number: width of the mask\" height=\"Number: height of the mask\" z_order=\"Number: z-order of the object\"\u003e \u003c/mask\u003e ... \u003c/track\u003e \u003ctrack id=\"Number: id of the track (doesn't have any special meeting)\" label=\"String: the associated label\" source=\"manual or auto\"\u003e \u003cskeleton frame=\"Number: frame\" keyframe=\"Number: 0 - False, 1 - True\"\u003e \u003cpoints label=\"String: the associated label\" outside=\"Number: 0 - False, 1 - True\" occluded=\"Number: 0 - False, 1 - True\" keyframe=\"Number: 0 - False, 1 - True\" points=\"x0,y0;x1,y1\"\u003e \u003c/points\u003e ... \u003c/skeleton\u003e ... \u003c/track\u003e ... \u003c/annotations\u003e Example:\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cannotations\u003e \u003cversion\u003e1.1\u003c/version\u003e \u003cmeta\u003e \u003ctask\u003e \u003cid\u003e5\u003c/id\u003e \u003cname\u003einterpolation\u003c/name\u003e \u003csize\u003e4620\u003c/size\u003e \u003cmode\u003einterpolation\u003c/mode\u003e \u003coverlap\u003e5\u003c/overlap\u003e \u003cbugtracker\u003e\u003c/bugtracker\u003e \u003cflipped\u003eFalse\u003c/flipped\u003e \u003ccreated\u003e2018-09-25 12:32:09.868194+03:00\u003c/created\u003e \u003cupdated\u003e2018-09-25 16:05:05.619841+03:00\u003c/updated\u003e \u003clabels\u003e \u003clabel\u003e \u003cname\u003eperson\u003c/name\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003ecar\u003c/name\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003es1\u003c/name\u003e \u003ctype\u003eskeleton\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003csvg\u003e\u0026lt;line x1=\"36.87290954589844\" y1=\"47.732025146484375\" x2=\"86.87290954589844\" y2=\"10.775501251220703\" stroke=\"black\" data-type=\"edge\" data-node-from=\"2\" stroke-width=\"0.5\" data-node-to=\"3\"\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;line x1=\"25.167224884033203\" y1=\"22.64841079711914\" x2=\"36.87290954589844\" y2=\"47.732025146484375\" stroke=\"black\" data-type=\"edge\" data-node-from=\"1\" stroke-width=\"0.5\" data-node-to=\"2\"\u0026gt;\u0026lt;/line\u0026gt;\u0026lt;circle r=\"1.5\" stroke=\"black\" fill=\"#b3b3b3\" cx=\"25.167224884033203\" cy=\"22.64841079711914\" stroke-width=\"0.1\" data-type=\"element node\" data-element-id=\"1\" data-node-id=\"1\" data-label-name=\"1\"\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;circle r=\"1.5\" stroke=\"black\" fill=\"#b3b3b3\" cx=\"36.87290954589844\" cy=\"47.732025146484375\" stroke-width=\"0.1\" data-type=\"element node\" data-element-id=\"2\" data-node-id=\"2\" data-label-name=\"2\"\u0026gt;\u0026lt;/circle\u0026gt;\u0026lt;circle r=\"1.5\" stroke=\"black\" fill=\"#b3b3b3\" cx=\"86.87290954589844\" cy=\"10.775501251220703\" stroke-width=\"0.1\" data-type=\"element node\" data-element-id=\"3\" data-node-id=\"3\" data-label-name=\"3\"\u0026gt;\u0026lt;/circle\u0026gt;\u003c/svg\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003e1\u003c/name\u003e \u003ctype\u003epoints\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003cparent\u003es1\u003c/parent\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003e2\u003c/name\u003e \u003ctype\u003epoints\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003cparent\u003es1\u003c/parent\u003e \u003c/label\u003e \u003clabel\u003e \u003cname\u003e3\u003c/name\u003e \u003ctype\u003epoints\u003c/type\u003e \u003cattributes\u003e \u003c/attributes\u003e \u003cparent\u003es1\u003c/parent\u003e \u003c/label\u003e \u003c/labels\u003e \u003csegments\u003e \u003csegment\u003e \u003cid\u003e5\u003c/id\u003e \u003cstart\u003e0\u003c/start\u003e \u003cstop\u003e4619\u003c/stop\u003e \u003curl\u003ehttp://localhost:8080/?id=5\u003c/url\u003e \u003c/segment\u003e \u003c/segments\u003e \u003cowner\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cemail\u003e\u003c/email\u003e \u003c/owner\u003e \u003coriginal_size\u003e \u003cwidth\u003e640\u003c/width\u003e \u003cheight\u003e480\u003c/height\u003e \u003c/original_size\u003e \u003c/task\u003e \u003cdumped\u003e2018-09-25 16:05:07.134046+03:00\u003c/dumped\u003e \u003c/meta\u003e \u003ctrack id=\"0\" label=\"car\"\u003e \u003cpolygon frame=\"0\" points=\"324.79,213.16;323.74,227.90;347.42,237.37;371.11,217.37;350.05,190.00;318.47,191.58\" outside=\"0\" occluded=\"0\" keyframe=\"1\"\u003e \u003c/polygon\u003e \u003cpolygon frame=\"1\" points=\"324.79,213.16;323.74,227.90;347.42,237.37;371.11,217.37;350.05,190.00;318.47,191.58\" outside=\"1\" occluded=\"0\" keyframe=\"1\"\u003e \u003c/polygon\u003e \u003cpolygon frame=\"6\" points=\"305.32,237.90;312.16,207.90;352.69,206.32;355.32,233.16;331.11,254.74\" outside=\"0\" occluded=\"0\" keyframe=\"1\"\u003e \u003c/polygon\u003e \u003cpolygon frame=\"7\" points=\"305.32,237.90;312.16,207.90;352.69,206.32;355.32,233.16;331.11,254.74\" outside=\"1\" occluded=\"0\" keyframe=\"1\"\u003e \u003c/polygon\u003e \u003cpolygon frame=\"13\" points=\"313.74,233.16;331.11,220.00;359.53,243.16;333.21,283.16;287.95,274.74\" outside=\"0\" occluded=\"0\" keyframe=\"1\"\u003e \u003c/polygon\u003e \u003cpolygon frame=\"14\" points=\"313.74,233.16;331.11,220.00;359.53,243.16;333.21,283.16;287.95,274.74\" outside=\"1\" occluded=\"0\" keyframe=\"1\"\u003e \u003c/polygon\u003e \u003c/track\u003e \u003ctrack id=\"1\" label=\"s1\" source=\"manual\"\u003e \u003cskeleton frame=\"0\" keyframe=\"1\" z_order=\"0\"\u003e \u003cpoints label=\"1\" outside=\"0\" occluded=\"0\" keyframe=\"1\" points=\"112.07,258.59\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" outside=\"0\" occluded=\"0\" keyframe=\"1\" points=\"127.87,333.23\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" outside=\"0\" occluded=\"0\" keyframe=\"1\" points=\"195.37,223.27\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003cskeleton frame=\"1\" keyframe=\"1\" z_order=\"0\"\u003e \u003cpoints label=\"1\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"112.07,258.59\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"127.87,333.23\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"195.37,223.27\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003cskeleton frame=\"6\" keyframe=\"1\" z_order=\"0\"\u003e \u003cpoints label=\"1\" outside=\"0\" occluded=\"0\" keyframe=\"0\" points=\"120.07,270.59\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" outside=\"0\" occluded=\"0\" keyframe=\"0\" points=\"140.87,350.23\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" outside=\"0\" occluded=\"0\" keyframe=\"0\" points=\"210.37,260.27\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003cskeleton frame=\"7\" keyframe=\"1\" z_order=\"0\"\u003e \u003cpoints label=\"1\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"120.07,270.59\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"140.87,350.23\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"210.37,260.27\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003cskeleton frame=\"13\" keyframe=\"0\" z_order=\"0\"\u003e \u003cpoints label=\"1\" outside=\"0\" occluded=\"0\" keyframe=\"0\" points=\"112.07,258.59\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" outside=\"0\" occluded=\"0\" keyframe=\"0\" points=\"127.87,333.23\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" outside=\"0\" occluded=\"0\" keyframe=\"0\" points=\"195.37,223.27\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003cskeleton frame=\"14\" keyframe=\"1\" z_order=\"0\"\u003e \u003cpoints label=\"1\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"112.07,258.59\"\u003e \u003c/points\u003e \u003cpoints label=\"2\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"127.87,333.23\"\u003e \u003c/points\u003e \u003cpoints label=\"3\" outside=\"1\" occluded=\"0\" keyframe=\"1\" points=\"195.37,223.27\"\u003e \u003c/points\u003e \u003c/skeleton\u003e \u003c/track\u003e \u003c/annotations\u003e ","categories":"","description":"","excerpt":" When you want to download annotations from Computer Vision Annotation …","ref":"/v2.43.0/docs/manual/advanced/xml_format/","tags":"","title":"XML annotation format"},{"body":"In CVAT, you can use AWS S3, Azure Blob Storage and Google Cloud Storage storages to import and export image datasets for your tasks.\nCheck out:\nAWS S3 Create a bucket Upload data Access permissions Authenticated access Anonymous access Attach AWS S3 storage AWS S3 manifest file Video tutorial: Add AWS S3 as Cloud Storage in CVAT Google Cloud Storage Create a bucket Upload data Access permissions Authenticated access Anonymous access Attach Google Cloud Storage Video tutorial: Add Google Cloud Storage as Cloud Storage in CVAT Microsoft Azure Blob Storage Create a bucket Create a container Upload data SAS token and connection string Personal use Attach Azure Blob Storage Video tutorial: Add Microsoft Azure Blob Storage as Cloud Storage in CVAT Prepare the dataset AWS S3 Create a bucket To create bucket, do the following:\nCreate an AWS account.\nGo to console AWS-S3, and select Create bucket.\nSpecify the name and region of the bucket. You can also copy the settings of another bucket by selecting Choose bucket.\nEnable Block all public access. For access, you will use access key ID and secret access key.\nSelect Create bucket.\nA new bucket will appear on the list of buckets.\nUpload data Note The manifest file is optional. You need to upload data for annotation and the manifest.jsonl file.\nPrepare data. For more information, refer on how to prepare the dataset.\nOpen the bucket and select Upload.\nDrag the manifest file and image folder on the page and select Upload:\nAccess permissions Authenticated access To add access permissions, do the following:\nGo to IAM and select Add users.\nSet User name and enable Access key - programmatic access.\nSelect Next: Permissions.\nSelect Create group, enter the group name.\nUse search to find and select:\nFor read-only access: AmazonS3ReadOnlyAccess. For full access: AmazonS3FullAccess. (Optional) Add tags for the user and go to the next page.\nSave Access key ID and Secret access key.\nFor more information, consult Creating an IAM user in your AWS account\nAnonymous access On how to grant public access to the bucket, consult Configuring block public access settings for your S3 buckets\nAttach AWS S3 storage To attach storage, do the following:\nLog into CVAT and in the separate tab open your bucket page. In the CVAT, on the top menu select Cloud storages \u003e on the opened page select +. Fill in the following fields:\nCVAT AWS S3 Display name Preferred display name for your storage. Description (Optional) Add description of storage. Provider From drop-down list select AWS S3. Bucket name Name of the Bucket. Authentication type Depends on the bucket setup: Key id and secret access key pair: available on IAM. Anonymous access: for anonymous access. Public access to the bucket must be enabled. Region (Optional) Choose a region from the list or add a new one. For more information, consult Available locations. Prefix (Optional) Prefix is used to filter bucket content. By setting a default prefix, you ensure that only data from a specific folder in the cloud is used in CVAT. This will affect which files you see when creating a task with cloud data. Manifests (Optional) Select + Add manifest and enter the name of the manifest file with an extension. For example: manifest.jsonl. After filling in all the fields, select Submit.\nAWS S3 manifest file Note The manifest file is optional. To prepare the manifest file, do the following:\nGo to AWS CLI and run script for prepare manifest file.\nPerform the installation, following the aws-shell manual, You can configure credentials by running aws configure. You will need to enter Access Key ID and Secret Access Key as well as the region.\naws configure Access Key ID: \u003cyour Access Key ID\u003e Secret Access Key: \u003cyour Secret Access Key\u003e Copy the content of the bucket to a folder on your computer:\naws s3 cp \u003cs3://bucket-name\u003e \u003cyourfolder\u003e --recursive After copying the files, you can create a manifest file as described in prepare manifest file section:\npython \u003ccvat repository\u003e/utils/dataset_manifest/create.py --output-dir \u003cyourfolder\u003e \u003cyourfolder\u003e When the manifest file is ready, upload it to aws s3 bucket:\nFor read and write permissions when you created the user, run:\naws s3 cp \u003cyourfolder\u003e/manifest.jsonl \u003cs3://bucket-name\u003e For read-only permissions, use the download through the browser, select upload, drag the manifest file to the page and select upload.\nVideo tutorial: Add AWS S3 as Cloud Storage in CVAT Google Cloud Storage Create a bucket To create bucket, do the following:\nCreate Google account and log into it.\nOn the Google Cloud page, select Start Free, then enter the required data and accept the terms of service.\nNote Google requires to add payment, you will need a bank card to accomplish step 2. Create a Bucket with the following parameters:\nName your bucket: Unique name. Choose where to store your data: Set up a location nearest to you. Choose a storage class for your data: Set a default class \u003e Standard. Choose how to control access to objects: Enforce public access prevention on this bucket \u003e Uniform (default). How to protect data: None You will be forwarded to the bucket.\nUpload data Note The manifest file is optional. You need to upload data for annotation and the manifest.jsonl file.\nPrepare data. For more information, consult prepare the dataset. Open the bucket and from the top menu select Upload files or Upload folder (depends on how your files are organized). Access permissions To access Google Cloud Storage get a Project ID from cloud resource manager page\nAnd follow instructions below based on the preferable type of access.\nAuthenticated access For authenticated access you need to create a service account and key file.\nTo create a service account:\nOn the Google Cloud platform, go to IAM \u0026 Admin \u003e Service Accounts and select +Create Service Account. Enter your account name and select Create And Continue. Select a role, for example Basic \u003e Viewer, and select Continue. (Optional) Give access rights to the service account. Select Done. To create a key:\nGo to IAM \u0026 Admin \u003e Service Accounts \u003e select on account name \u003e Keys. Select Add key and select Create new key \u003e JSON Select Create. The key file will be downloaded automatically. For more information about keys, consult Learn more about creating keys.\nAnonymous access To configure anonymous access:\nOpen the bucket and go to the Permissions tab. Click + Grant access to add new principals. In the New principals field specify allUsers, select roles: Cloud Storage Legacy \u003e Storage Legacy Bucket Reader. Select Save. Now you can attach the Google Cloud Storage bucket to CVAT.\nAttach Google Cloud Storage To attach storage, do the following:\nLog into CVAT and in the separate tab open your bucket page. In the CVAT, on the top menu select Cloud storages \u003e on the opened page select +. Fill in the following fields:\nCVAT Google Cloud Storage Display name Preferred display name for your storage. Description (Optional) Add description of storage. Provider From drop-down list select Google Cloud Storage. Bucket name Name of the bucket. You can find it on the storage browser page. Authentication type Depends on the bucket setup: Authenticated access: Select Key file and upload the key file from computer. Advanced: For self-hosted solution, if the key file was not attached, then environment variable GOOGLE_APPLICATION_CREDENTIALS that was specified for an environment will be used. For more information, consult Authenticate to Cloud services using client libraries.\nAnonymous access: for anonymous access. Public access to the bucket must be enabled. Prefix (Optional) Used to filter data from the bucket. By setting a default prefix, you ensure that only data from a specific folder in the cloud is used in CVAT. This will affect which files you see when creating a task with cloud data. Project ID Project ID. For more information, consult projects page and cloud resource manager page. Note: Project name does not match the project ID. Location (Optional) Choose a region from the list or add a new one. For more information, consult Available locations. Manifests (Optional) Select + Add manifest and enter the name of the manifest file with an extension. For example: manifest.jsonl. After filling in all the fields, select Submit.\nVideo tutorial: Add Google Cloud Storage as Cloud Storage in CVAT Microsoft Azure Blob Storage Create a bucket To create bucket, do the following:\nCreate an Microsoft Azure account and log into it.\nGo to Azure portal, hover over the resource , and in the pop-up window select Create.\nEnter a name for the group and select Review + create, check the entered data and select Create.\nGo to the resource groups page, navigate to the group that you created and select Create resources.\nOn the marketplace page, use search to find Storage account.\nSelect on Storage account and on the next page select Create.\nOn the Basics tab, fill in the following fields:\nStorage account name: to access container from CVAT. Select a region closest to you. Select Performance \u003e Standard. Select Local-redundancy storage (LRS). Select next: Advanced\u003e. On the Advanced page, fill in the following fields:\n(Optional) Disable Allow enabling public access on containers to prohibit anonymous access to the container. Select Next \u003e Networking. On the Networking tab, fill in the following fields:\nIf you want to change public access, enable Public access from all networks.\nSelect Next\u003eData protection.\nYou do not need to change anything in other tabs until you need some specific setup.\nSelect Review and wait for the data to load.\nSelect Create. Deployment will start.\nAfter deployment is over, select Go to resource.\nCreate a container To create container, do the following:\nGo to the containers section and on the top menu select +Container\nEnter the name of the container.\n(Optional) In the Public access level drop-down, select type of the access. Note: this field will inactive if you disabled Allow enabling public access on containers.\nSelect Create.\nUpload data You need to upload data for annotation and the manifest.jsonl file.\nPrepare data. For more information, refer on how to prepare the dataset.\nGo to container and select Upload.\nSelect Browse for files and select images.\nNote If images are in folder, specify folder in the Advanced settings \u003e Upload to folder. Select Upload.\nSAS token and connection string Use the SAS token or connection string to grant secure access to the container.\nTo configure the credentials:\nGo to Home \u003e Resource groups \u003e You resource name \u003e Your storage account. On the left menu, select Shared access signature. Change the following fields: Allowed services: Enable Blob . Disable all other fields. Allowed resource types: Enable Container and Object. Disable all other fields. Allowed permissions: Enable Read, Write, and List. Disable all other fields. Start and expiry date: Set up start and expiry dates. Allowed protocols: Select HTTPS and HTTP Leave all other fields with default parameters. Select Generate SAS and connection string and copy SAS token or Connection string. Personal use For personal use, you can use the Access Key from your storage account in the CVAT SAS Token field.\nTo get the Access Key:\nIn the Azure Portal, go to the Security + networking \u003e Access Keys Select Show and copy the key. Attach Azure Blob Storage To attach storage, do the following:\nLog into CVAT and in the separate tab open your bucket page. In the CVAT, on the top menu select Cloud storages \u003e on the opened page select +. Fill in the following fields:\nCVAT Azure Display name Preferred display name for your storage. Description (Optional) Add description of storage. Provider From drop-down list select Azure Blob Container. Container name` Name of the cloud storage container. Authentication type Depends on the container setup. Account name and SAS token: Account name enter storage account name. SAS token is located in the Shared access signature section of your Storage account.. Anonymous access: for anonymous access Allow enabling public access on containers must be enabled. Prefix (Optional) Used to filter data from the bucket. By setting a default prefix, you ensure that only data from a specific folder in the cloud is used in CVAT. This will affect which files you see when creating a task with cloud data. Manifests (Optional) Select + Add manifest and enter the name of the manifest file with an extension. For example: manifest.jsonl. After filling in all the fields, select Submit.\nVideo tutorial: Add Microsoft Azure Blob Storage as Cloud Storage in CVAT Prepare the dataset For example, the dataset is The Oxford-IIIT Pet Dataset:\nDownload the archive with images. Unpack the archive into the prepared folder. Create a manifest. For more information, consult Dataset manifest: python \u003ccvat repository\u003e/utils/dataset_manifest/create.py --output-dir \u003cyour_folder\u003e \u003cyour_folder\u003e ","categories":"","description":"Instructions on how to attach cloud storage using UI","excerpt":"Instructions on how to attach cloud storage using UI","ref":"/v2.43.0/docs/manual/basics/attach-cloud-storage/","tags":"","title":"Attach cloud storage"},{"body":"CVAT provides a wide range of customizable shortcuts, with many UI elements offering shortcut hints when hovered over with the mouse.\nThese shortcuts are organized by scopes. Some are global, meaning they work across the entire application, while others are specific to certain sections or workspaces. This approach allows reusing the same shortcuts in different scopes, depending on whether they might conflict. For example, global shortcuts must be unique since they apply across all pages and workspaces. However, similar shortcuts can be used in different workspaces, like having the same shortcuts in both the Standard Workspace and the Standard 3D Workspace, as these two do not coexist.\nScope Shortcut Conflicts Global Must be unique across all scopes, as they apply universally. Annotation Page Must be unique across all scopes, except Labels Editor. Standard Workspace Must be unique across itself, Annotation Page and Global Scope. Standard 3D Workspace Must be unique across itself, Annotation Page and Global Scope. Attribute Annotation Workspace Must be unique across itself, Annotation Page and Global Scope. Review Workspace Must be unique across itself, Annotation Page and Global Scope. Tag Annotation Workspace Must be unique across itself, Annotation Page and Global Scope. Control Sidebar Must be unique across itself, all workspaces, Annotation Page and Global Scope. Objects Sidebar Must be unique across itself, all workspaces, Annotation Page and Global Scope. Labels Editor Must be unique across itself and Global Scope. Shortcuts Customization You can customize shortcuts in CVAT settings.\nOpen Settings:\nGo to the Shortcuts tab:\nYou’ll see the shortcuts customization menu:\nAs it can be seen there is a warning, that some shortcuts are reserved by a browser and cannot be overridden in CVAT, there isn’t a specific list available for such combinations, but shortcuts such as ctrl + tab (switching tabs) or ctrl + w (closing tabs) etc, are reserved by the browser and shortcuts such as alt + f4 (closing the window) are usually reserved by your operating system.\nAll sections collapsible, so you can easily navigate through the list of shortcuts. Here is the Global scope expanded:\nTo add a custom shortcut all you have to do is to click the input field and start pressing the sequence you want to assign to the action. As an example f3 has been set here for Show Shortcuts along with f1:\nShortcuts can be any combination of modifiers (ctrl, shift or alt) and up to one non-modifier key e.g. ctrl+shift+f1 etc.\nIf you try to add a shortcut that is already in use, you will get a warning message:\nIf pressed cancel it will remain the same otherwise the conflicting shortcut will be unset.\nIf you want to reset all the shortcuts to default, you can do so by clicking the Restore Defaults button at the top of the shortcut settings.\n","categories":"","description":"List of available keyboard shortcuts and notes about their customization.","excerpt":"List of available keyboard shortcuts and notes about their …","ref":"/v2.43.0/docs/manual/advanced/shortcuts/","tags":"","title":"Shortcuts"},{"body":"There are some reasons to use the feature:\nWhen you use a filter, objects that don’t match the filter will be hidden. The fast navigation between frames which have an object of interest. Use the Left Arrow / Right Arrow keys for this purpose or customize the UI buttons by right-clicking and select switching by filter. If there are no objects which correspond to the filter, you will go to the previous / next frame which contains any annotated objects. To apply filters you need to click on the button on the top panel.\nCreate a filter It will open a window for filter input. Here you will find two buttons: Add rule and Add group.\nRules The Add rule button adds a rule for objects display. A rule may use the following properties:\nSupported properties for annotation Properties Supported values Description Label all the label names that are in the task label name Type shape, track or tag type of object Shape all shape types type of shape Occluded true or false occluded (read more) Width number of px or field shape width Height number of px or field shape height ServerID number or field ID of the object on the server (You can find out by forming a link to the object through the Action menu) ObjectID number or field ID of the object in your client (indicated on the objects sidebar) Attributes some other fields including attributes with a similar type or a specific attribute value any fields specified by a label Supported properties for projects list Supported properties for tasks list Supported properties for jobs list Supported properties for cloud storages list Supported operators for properties == - Equally; != - Not equal; \u003e - More; \u003e= - More or equal; \u003c - Less; \u003c= - Less or equal;\nAny in; Not in - these operators allow you to set multiple values in one rule;\nIs empty; is not empty – these operators don’t require to input a value.\nBetween; Not between – these operators allow you to choose a range between two values.\nLike - this operator indicate that the property must contain a value.\nStarts with; Ends with - filter by beginning or end.\nSome properties support two types of values that you can choose:\nYou can add multiple rules, to do so click the add rule button and set another rule. Once you’ve set a new rule, you’ll be able to choose which operator they will be connected by: And or Or.\nAll subsequent rules will be joined by the chosen operator. Click Submit to apply the filter or if you want multiple rules to be connected by different operators, use groups.\nGroups To add a group, click the Add group button. Inside the group you can create rules or groups.\nIf there is more than one rule in the group, they can be connected by And or Or operators. The rule group will work as well as a separate rule outside the group and will be joined by an operator outside the group. You can create groups within other groups, to do so you need to click the add group button within the group.\nYou can move rules and groups. To move the rule or group, drag it by the button. To remove the rule or group, click on the Delete button.\nIf you activate the Not button, objects that don’t match the group will be filtered out. Click Submit to apply the filter. The Cancel button undoes the filter. The Clear filter button removes the filter.\nOnce applied filter automatically appears in Recent used list. Maximum length of the list is 10.\nSort and filter lists On the projects, task list on the project page, tasks, jobs, and cloud storage pages, you can use sorting and filters.\nThe applied filter and sorting will be displayed in the URL of your browser, Thus, you can share the page with sorting and filter applied.\nSort by You can sort by the following parameters:\nJobs list: ID, assignee, updated date, stage, state, task ID, project ID, task name, project name. Tasks list or tasks list on project page: ID, owner, status, assignee, updated date, subset, mode, dimension, project ID, name, project name. Projects list: ID, assignee, owner, status, name, updated date. Cloud storages list: ID, provider type, updated date, display name, resource, credentials, owner, description. To apply sorting, drag the parameter to the top area above the horizontal bar. The parameters below the horizontal line will not be applied. By moving the parameters you can change the priority, first of all sorting will occur according to the parameters that are above.\nPressing the Sort button switches Ascending sort/Descending sort.\nQuick filters Quick Filters contain several frequently used filters:\nAssigned to me - show only those projects, tasks or jobs that are assigned to you. Owned by me - show only those projects or tasks that are owned by you. Not completed - show only those projects, tasks or jobs that have a status other than completed. AWS storages - show only AWS cloud storages Azure storages - show only Azure cloud storages Google cloud storages - show only Google cloud storages Date and time selection When creating a Last updated rule, you can select the date and time by using the selection window.\nYou can select the year and month using the arrows or by clicking on the year and month. To select a day, click on it in the calendar, To select the time, you can select the hours and minutes using the scrolling list. Or you can select the current date and time by clicking the Now button. To apply, click Ok.\n","categories":"","description":"Guide to using the Filter feature in CVAT.","excerpt":"Guide to using the Filter feature in CVAT.","ref":"/v2.43.0/docs/manual/advanced/filter/","tags":"","title":"Filter"},{"body":"Contextual images are additional images that provide context or additional information related to the primary image.\nUse them to add extra contextual about the object to improve the accuracy of annotation.\nContextual images are available for 2D and 3D tasks.\nSee:\nFolder structure Data format Contextual images Folder structure To add contextual images to the task, you need to organize the images folder.\nBefore uploading the archive to CVAT, do the following:\nIn the folder with the images for annotation, create a folder: related_images. Add to the related_images a subfolder with the same name as the primary image to which it should be linked. Place the contextual image(s) within the subfolder created in step 2. Add folder to the archive. Create task. Data format Example file structure for 2D and 3D tasks:\n2D task 3D option 1 3D option 2 3D task KITTI format root_directory image_1_to_be_annotated.jpg image_2_to_be_annotated.jpg related_images/ image_1_to_be_annotated_jpg/ context_image_for_image_1.jpg image_2_to_be_annotated_jpg/ context_image_for_image_2.jpg subdirectory_example/ image_3_to_be_annotated.jpg related_images/ image_3_to_be_annotated_jpg/ context_image_for_image_3.jpg root_directory pointcloud/ image_1_to_be_annotated.pcd image_2_to_be_annotated.pcd related_images/ image_1_to_be_annotated_pcd/ context_image_for_image_1.jpg image_2_to_be_annotated_pcd/ context_image_for_image_2.jpg /any_directory pointcloud.pcd pointcloud.jpg /any_other_directory /any_subdirectory pointcloud.pcd pointcloud.png /image_00 /data /0000000000.png /0000000001.png /0000000002.png /0000000003.png /image_01 /data /0000000000.png /0000000001.png /0000000002.png /0000000003.png /image_02 /data /0000000000.png /0000000001.png /0000000002.png /0000000003.png /image_N /data /0000000000.png /0000000001.png /0000000002.png /0000000003.png /velodyne_points /data /0000000000.bin /0000000001.bin /0000000002.bin /0000000003.bin For KITTI: image_00, image_01, image_02, image_N, (where N is any number \u003c= 12) are context images. For 3D option 3: a regular image file placed near a .pcd file with the same name is considered to be a context image. For more general information about 3D data formats, see 3D data formats.\nContextual images The maximum amount of contextual images is twelve.\nBy default they will be positioned on the right side of the main image.\nNote By default, only three contextual images will be visible. When you add contextual images to the set, small toolbar will appear on the top of the screen, with the following elements:\nElement Description Fit views. Click to restore the layout to its original appearance. If you’ve expanded any images in the layout, they will returned to their original size. This won’t affect the number of context images on the screen. Add new image. Click to add context image to the layout. Reload layout. Click to reload layout to the default view. Note, that this action can change the number of context images resetting them back to three. Each context image has the following elements:\nElement Description 1 Full screen. Click to expand the contextual image in to the full screen mode. Click again to revert contextual image to windowed mode. 2 Move contextual image. Hold and move contextual image to the other place on the screen. 3 Name. Unique contextual image name 4 Select contextual image. Click to open a horizontal listview of all available contextual images. Click on one to select. 5 Close. Click to remove image from contextual images menu. 6 Extend Hold and pull to extend the image. ","categories":"","description":"Contextual images of the task","excerpt":"Contextual images of the task","ref":"/v2.43.0/docs/manual/advanced/contextual-images/","tags":"","title":"Contextual images"},{"body":"This feature allows us to group several shapes.\nYou may use the Group Shapes button or shortcuts:\nG — start selection / end selection in group mode Esc — close group mode Shift+G — reset group for selected shapes You may select shapes clicking on them or selecting an area.\nGrouped shapes will have group_id filed in dumped annotation.\nAlso you may switch color distribution from an instance (default) to a group. You have to switch Color By Group checkbox for that.\nShapes that don’t have group_id, will be highlighted in white.\nShapes grouping video tutorial ","categories":"","description":"Grouping multiple shapes during annotation.","excerpt":"Grouping multiple shapes during annotation.","ref":"/v2.43.0/docs/manual/advanced/shape-grouping/","tags":"","title":"Shape grouping"},{"body":"Overview When we create a new task in CVAT, we need to specify where to get the input data from. CVAT allows to use different data sources, including local file uploads, a mounted file share on the server, cloud storages and remote URLs. In some cases CVAT needs to have extra information about the input data. This information can be provided in Dataset manifest files. They are mainly used when working with cloud storages to reduce the amount of network traffic used and speed up the task creation process. However, they can also be used in other cases, which will be explained below.\nA dataset manifest file is a text file in the JSONL format. These files can be created automatically with the special command-line tool, or manually, following the manifest file format specification.\nHow and when to use manifest files Manifest files can be used in the following cases:\nA video file or a set of images is used as the data source and the caching mode is enabled. Read more The data is located in a cloud storage. Read more The predefined file sorting method is specified. Read more The predefined sorting method Independently of the file source being used, when the predefined sorting method is selected in the task configuration, the source files will be ordered according to the .jsonl manifest file, if it is found in the input list of files. If a manifest is not found, the order provided in the input file list is used.\nFor image archives (e.g. .zip), a manifest file (*.jsonl) is required when using the predefined file ordering. A manifest file must be provided next to the archive in the input list of files, it must not be inside the archive.\nIf there are multiple manifest files in the input file list, an error will be raised.\nHow to generate manifest files CVAT provides a dedicated Python tool to generate manifest files. The source code can be found here.\nUsing the tool is the recommended way to create manifest files for you data. The data must be available locally to the tool to generate manifest.\nUsage usage: create.py [-h] [--force] [--output-dir .] source positional arguments: source Source paths optional arguments: -h, --help show this help message and exit --force Use this flag to prepare the manifest file for video data if by default the video does not meet the requirements and a manifest file is not prepared --output-dir OUTPUT_DIR Directory where the manifest file will be saved Use the script from a Docker image This is the recommended way to use the tool.\nThe script can be used from the cvat/server image:\ndocker run -it --rm -u \"$(id -u)\":\"$(id -g)\" \\ -v \"${PWD}\":\"/local\" \\ --entrypoint python3 \\ cvat/server \\ utils/dataset_manifest/create.py --output-dir /local /local/\u003cpath/to/sources\u003e Make sure to adapt the command to your file locations.\nUse the script directly Ubuntu 20.04 Install dependencies:\n# General sudo apt-get update \u0026\u0026 sudo apt-get --no-install-recommends install -y \\ python3-dev python3-pip python3-venv pkg-config # Library components sudo apt-get install --no-install-recommends -y \\ libavformat-dev libavcodec-dev libavdevice-dev \\ libavutil-dev libswscale-dev libswresample-dev libavfilter-dev Create an environment and install the necessary python modules:\npython3 -m venv .env . .env/bin/activate pip install -U pip pip install -r utils/dataset_manifest/requirements.in Please note that if used with video this way, the results may be different from what would the server decode. It is related to the ffmpeg library version. For this reason, using the Docker-based version of the tool is recommended.\nExamples Create a dataset manifest in the current directory with video which contains enough keyframes:\npython utils/dataset_manifest/create.py ~/Documents/video.mp4 Create a dataset manifest with video which does not contain enough keyframes:\npython utils/dataset_manifest/create.py --force --output-dir ~/Documents ~/Documents/video.mp4 Create a dataset manifest with images:\npython utils/dataset_manifest/create.py --output-dir ~/Documents ~/Documents/images/ Create a dataset manifest with pattern (may be used *, ?, []):\npython utils/dataset_manifest/create.py --output-dir ~/Documents \"/home/${USER}/Documents/**/image*.jpeg\" Create a dataset manifest using Docker image:\ndocker run -it --rm -u \"$(id -u)\":\"$(id -g)\" \\ -v ~/Documents/data/:${HOME}/manifest/:rw \\ --entrypoint '/usr/bin/bash' \\ cvat/server \\ utils/dataset_manifest/create.py --output-dir ~/manifest/ ~/manifest/images/ File format The dataset manifest files are text files in JSONL format. These files have 2 sub-formats: for video and for images and 3d data.\nEach top-level entry enclosed in curly braces must use 1 string, no empty strings is allowed. The formatting in the descriptions below is only for demonstration.\nDataset manifest for video The file describes a single video.\npts - time at which the frame should be shown to the user checksum - md5 hash sum for the specific image/frame decoded\n{ \"version\": \u003cstring, version id\u003e } { \"type\": \"video\" } { \"properties\": { \"name\": \u003cstring, filename\u003e, \"resolution\": [\u003cint, width\u003e, \u003cint, height\u003e], \"length\": \u003cint, frame count\u003e }} { \"number\": \u003cint, frame number\u003e, \"pts\": \u003cint, frame pts\u003e, \"checksum\": \u003cstring, md5 frame hash\u003e } (repeatable) Dataset manifest for images and other data types The file describes an ordered set of images and 3d point clouds.\nname - file basename and leading directories from the dataset root checksum - md5 hash sum for the specific image/frame decoded\n{ \"version\": \u003cstring, version id\u003e } { \"type\": \"images\" } { \"name\": \u003cstring, image filename\u003e, \"extension\": \u003cstring, . + file extension\u003e, \"width\": \u003cint, width\u003e, \"height\": \u003cint, height\u003e, \"meta\": \u003cdict, optional\u003e, \"checksum\": \u003cstring, md5 hash, optional\u003e } (repeatable) Example files Manifest for a video {\"version\":\"1.0\"} {\"type\":\"video\"} {\"properties\":{\"name\":\"video.mp4\",\"resolution\":[1280,720],\"length\":778}} {\"number\":0,\"pts\":0,\"checksum\":\"17bb40d76887b56fe8213c6fded3d540\"} {\"number\":135,\"pts\":486000,\"checksum\":\"9da9b4d42c1206d71bf17a7070a05847\"} {\"number\":270,\"pts\":972000,\"checksum\":\"a1c3a61814f9b58b00a795fa18bb6d3e\"} {\"number\":405,\"pts\":1458000,\"checksum\":\"18c0803b3cc1aa62ac75b112439d2b62\"} {\"number\":540,\"pts\":1944000,\"checksum\":\"4551ecea0f80e95a6c32c32e70cac59e\"} {\"number\":675,\"pts\":2430000,\"checksum\":\"0e72faf67e5218c70b506445ac91cdd7\"} Manifest for a dataset with images {\"version\":\"1.0\"} {\"type\":\"images\"} {\"name\":\"image1\",\"extension\":\".jpg\",\"width\":720,\"height\":405,\"meta\":{\"related_images\":[]},\"checksum\":\"548918ec4b56132a5cff1d4acabe9947\"} {\"name\":\"image2\",\"extension\":\".jpg\",\"width\":183,\"height\":275,\"meta\":{\"related_images\":[]},\"checksum\":\"4b4eefd03cc6a45c1c068b98477fb639\"} {\"name\":\"image3\",\"extension\":\".jpg\",\"width\":301,\"height\":167,\"meta\":{\"related_images\":[]},\"checksum\":\"0e454a6f4a13d56c82890c98be063663\"} ","categories":"","description":"","excerpt":"Overview When we create a new task in CVAT, we need to specify where …","ref":"/v2.43.0/docs/manual/advanced/dataset_manifest/","tags":"","title":"Dataset Manifest"},{"body":" AWS S3 bucket as filesystem Ubuntu 20.04 Mount Install s3fs:\nsudo apt install s3fs Enter your credentials in a file ${HOME}/.passwd-s3fs and set owner-only permissions:\necho ACCESS_KEY_ID:SECRET_ACCESS_KEY \u003e ${HOME}/.passwd-s3fs chmod 600 ${HOME}/.passwd-s3fs Uncomment user_allow_other in the /etc/fuse.conf file: sudo nano /etc/fuse.conf\nRun s3fs, replace bucket_name, mount_point:\ns3fs \u003cbucket_name\u003e \u003cmount_point\u003e -o allow_other -o passwd_file=${HOME}/.passwd-s3fs For more details see here.\nAutomatically mount Follow the first 3 mounting steps above.\nUsing fstab Create a bash script named aws_s3_fuse(e.g in /usr/bin, as root) with this content (replace user_name on whose behalf the disk will be mounted, backet_name, mount_point, /path/to/.passwd-s3fs):\n#!/bin/bash sudo -u \u003cuser_name\u003e s3fs \u003cbacket_name\u003e \u003cmount_point\u003e -o passwd_file=/path/to/.passwd-s3fs -o allow_other exit 0 Give it the execution permission:\nsudo chmod +x /usr/bin/aws_s3_fuse Edit /etc/fstab adding a line like this, replace mount_point):\n/absolute/path/to/aws_s3_fuse \u003cmount_point\u003e fuse allow_other,user,_netdev 0 0 Using systemd Create unit file sudo nano /etc/systemd/system/s3fs.service (replace user_name, bucket_name, mount_point, /path/to/.passwd-s3fs):\n[Unit] Description=FUSE filesystem over AWS S3 bucket After=network.target [Service] Environment=\"MOUNT_POINT=\u003cmount_point\u003e\" User=\u003cuser_name\u003e Group=\u003cuser_name\u003e ExecStart=s3fs \u003cbucket_name\u003e ${MOUNT_POINT} -o passwd_file=/path/to/.passwd-s3fs -o allow_other ExecStop=fusermount -u ${MOUNT_POINT} Restart=always Type=forking [Install] WantedBy=multi-user.target Update the system configurations, enable unit autorun when the system boots, mount the bucket:\nsudo systemctl daemon-reload sudo systemctl enable s3fs.service sudo systemctl start s3fs.service Check A file /etc/mtab contains records of currently mounted filesystems.\ncat /etc/mtab | grep 's3fs' Unmount filesystem fusermount -u \u003cmount_point\u003e If you used systemd to mount a bucket:\nsudo systemctl stop s3fs.service sudo systemctl disable s3fs.service Microsoft Azure container as filesystem Ubuntu 20.04 Mount Set up the Microsoft package repository.(More here)\nwget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb sudo dpkg -i packages-microsoft-prod.deb sudo apt-get update Install blobfuse and fuse:\nsudo apt-get install blobfuse fuse For more details see here\nCreate environments (replace account_name, account_key, mount_point):\nexport AZURE_STORAGE_ACCOUNT=\u003caccount_name\u003e export AZURE_STORAGE_ACCESS_KEY=\u003caccount_key\u003e MOUNT_POINT=\u003cmount_point\u003e Create a folder for cache:\nsudo mkdir -p /mnt/blobfusetmp Make sure the file must be owned by the user who mounts the container:\nsudo chown \u003cuser\u003e /mnt/blobfusetmp Create the mount point, if it doesn’t exists:\nmkdir -p ${MOUNT_POINT} Uncomment user_allow_other in the /etc/fuse.conf file: sudo nano /etc/fuse.conf\nMount container(replace your_container):\nblobfuse ${MOUNT_POINT} --container-name=\u003cyour_container\u003e --tmp-path=/mnt/blobfusetmp -o allow_other Automatically mount Follow the first 7 mounting steps above.\nUsing fstab Create configuration file connection.cfg with same content, change accountName, select one from accountKey or sasToken and replace with your value:\naccountName \u003caccount-name-here\u003e # Please provide either an account key or a SAS token, and delete the other line. accountKey \u003caccount-key-here-delete-next-line\u003e #change authType to specify only 1 sasToken \u003cshared-access-token-here-delete-previous-line\u003e authType \u003cMSI/SAS/SPN/Key/empty\u003e containerName \u003cinsert-container-name-here\u003e Create a bash script named azure_fuse(e.g in /usr/bin, as root) with content below (replace user_name on whose behalf the disk will be mounted, mount_point, /path/to/blobfusetmp,/path/to/connection.cfg):\n#!/bin/bash sudo -u \u003cuser_name\u003e blobfuse \u003cmount_point\u003e --tmp-path=/path/to/blobfusetmp --config-file=/path/to/connection.cfg -o allow_other exit 0 Give it the execution permission:\nsudo chmod +x /usr/bin/azure_fuse Edit /etc/fstab with the blobfuse script. Add the following line(replace paths):\n/absolute/path/to/azure_fuse \u003c/path/to/desired/mountpoint\u003e fuse allow_other,user,_netdev Using systemd Create unit file sudo nano /etc/systemd/system/blobfuse.service. (replace user_name, mount_point, container_name,/path/to/connection.cfg):\n[Unit] Description=FUSE filesystem over Azure container After=network.target [Service] Environment=\"MOUNT_POINT=\u003cmount_point\u003e\" User=\u003cuser_name\u003e Group=\u003cuser_name\u003e ExecStart=blobfuse ${MOUNT_POINT} --container-name=\u003ccontainer_name\u003e --tmp-path=/mnt/blobfusetmp --config-file=/path/to/connection.cfg -o allow_other ExecStop=fusermount -u ${MOUNT_POINT} Restart=always Type=forking [Install] WantedBy=multi-user.target Update the system configurations, enable unit autorun when the system boots, mount the container:\nsudo systemctl daemon-reload sudo systemctl enable blobfuse.service sudo systemctl start blobfuse.service Or for more detail see here\nCheck A file /etc/mtab contains records of currently mounted filesystems.\ncat /etc/mtab | grep 'blobfuse' Unmount filesystem fusermount -u \u003cmount_point\u003e If you used systemd to mount a container:\nsudo systemctl stop blobfuse.service sudo systemctl disable blobfuse.service If you have any mounting problems, check out the answers to common problems\nGoogle Drive as filesystem Ubuntu 20.04 Mount To mount a google drive as a filesystem in user space(FUSE) you can use google-drive-ocamlfuse To do this follow the instructions below:\nInstall google-drive-ocamlfuse:\nsudo add-apt-repository ppa:alessandro-strada/ppa sudo apt-get update sudo apt-get install google-drive-ocamlfuse Run google-drive-ocamlfuse without parameters:\ngoogle-drive-ocamlfuse This command will create the default application directory (~/.gdfuse/default), containing the configuration file config (see the wiki page for more details about configuration). And it will start a web browser to obtain authorization to access your Google Drive. This will let you modify default configuration before mounting the filesystem.\nThen you can choose a local directory to mount your Google Drive (e.g.: ~/GoogleDrive).\nCreate the mount point, if it doesn’t exist(replace mount_point):\nmountpoint=\"\u003cmount_point\u003e\" mkdir -p $mountpoint Uncomment user_allow_other in the /etc/fuse.conf file: sudo nano /etc/fuse.conf\nMount the filesystem:\ngoogle-drive-ocamlfuse -o allow_other $mountpoint Automatically mount Follow the first 4 mounting steps above.\nUsing fstab Create a bash script named gdfuse(e.g in /usr/bin, as root) with this content (replace user_name on whose behalf the disk will be mounted, label, mount_point):\n#!/bin/bash sudo -u \u003cuser_name\u003e google-drive-ocamlfuse -o allow_other -label \u003clabel\u003e \u003cmount_point\u003e exit 0 Give it the execution permission:\nsudo chmod +x /usr/bin/gdfuse Edit /etc/fstab adding a line like this, replace mount_point):\n/absolute/path/to/gdfuse \u003cmount_point\u003e fuse allow_other,user,_netdev 0 0 For more details see here\nUsing systemd Create unit file sudo nano /etc/systemd/system/google-drive-ocamlfuse.service. (replace user_name, label(default label=default), mount_point):\n[Unit] Description=FUSE filesystem over Google Drive After=network.target [Service] Environment=\"MOUNT_POINT=\u003cmount_point\u003e\" User=\u003cuser_name\u003e Group=\u003cuser_name\u003e ExecStart=google-drive-ocamlfuse -label \u003clabel\u003e ${MOUNT_POINT} ExecStop=fusermount -u ${MOUNT_POINT} Restart=always Type=forking [Install] WantedBy=multi-user.target Update the system configurations, enable unit autorun when the system boots, mount the drive:\nsudo systemctl daemon-reload sudo systemctl enable google-drive-ocamlfuse.service sudo systemctl start google-drive-ocamlfuse.service For more details see here\nCheck A file /etc/mtab contains records of currently mounted filesystems.\ncat /etc/mtab | grep 'google-drive-ocamlfuse' Unmount filesystem fusermount -u \u003cmount_point\u003e If you used systemd to mount a drive:\nsudo systemctl stop google-drive-ocamlfuse.service sudo systemctl disable google-drive-ocamlfuse.service ","categories":"","description":"Instructions on how to mount AWS S3 bucket, Microsoft Azure container or Google Drive as a filesystem.","excerpt":"Instructions on how to mount AWS S3 bucket, Microsoft Azure container …","ref":"/v2.43.0/docs/administration/advanced/mounting_cloud_storages/","tags":"","title":"Mounting cloud storage"},{"body":" Description Data on the fly processing is a way of working with data, the main idea of which is as follows: when creating a task, the minimum necessary meta information is collected. This meta information allows in the future to create necessary chunks when receiving a request from a client.\nGenerated chunks are stored in a cache of the limited size with a policy of evicting less popular items.\nWhen a request is received from a client, the required chunk is searched for in the cache. If the chunk does not exist yet, it is created using prepared meta information and then put into the cache.\nThis method of working with data allows:\nreduce the task creation time. store data in a cache of the limited size with a policy of evicting less popular items. Unfortunately, this method has several drawbacks:\nThe first access to the data will take more time. It will not work for some videos, even if they have a valid manifest file. If there are not enough keyframes in the video for smooth video decoding, the task data chunks will be created with the default method, i.e. during the task creation. If the data has not been cached yet, and is not reachable during the access time, it cannot be retrieved. How to use To enable or disable this feature for a new task, use the Use Cache toggle in the task configuration.\nUploading a manifest with data When creating a task, you can upload a manifest.jsonl file along with the video or dataset with images. You can see how to prepare it here.\n","categories":"","description":"","excerpt":" Description Data on the fly processing is a way of working with data, …","ref":"/v2.43.0/docs/manual/advanced/data-on-fly/","tags":"","title":"Data preparation on the fly"},{"body":"Introduction Leveraging the power of computers to solve daily routine problems, fix mistakes, and find information has become second nature. It is therefore natural to use computing power in annotating datasets. There are multiple publicly available DL models for classification, object detection, and semantic segmentation which can be used for data annotation. Whilst some of these publicly available DL models can be found on CVAT, it is relatively simple to integrate your privately trained ML/DL model into CVAT.\nWith the imperfection of the world, alongside the unavailability of a silver bullet that can solve all our problems; publicly available DL models cannot be used when we want to detect niche or specific objects on which these publicly available models were not trained. As annotation requirements can be sometimes strict, automatically annotated objects cannot be accepted as it is, and it is easier to annotate them from scratch. With these limitations in mind, a DL solution that can perfectly annotate 50% of your data equates to reducing manual annotation by half.\nSince we know DL models can help us to annotate faster, how then do we use them? In CVAT all such DL models are implemented as serverless functions using the Nuclio serverless platform. There are multiple implemented functions that can be found in the serverless directory such as Mask RCNN, Faster RCNN, SiamMask, Inside Outside Guidance, Deep Extreme Cut, etc. Follow the installation guide to build and deploy these serverless functions. See the user guide to understand how to use these functions in the UI to automatically annotate data.\nWhat is a serverless function and why is it used for automatic annotation in CVAT? Let’s assume that you have a DL model and want to use it for AI-assisted annotation. The naive approach is to implement a Python script which uses the DL model to prepare a file with annotations in a public format like MS COCO or Pascal VOC. After that you can upload the annotation file into CVAT. It works but it is not user-friendly. How to make CVAT run the script for you?\nYou can pack the script with your DL model into a container which provides a standard interface for interacting with it. One way to do that is to use the function as a service approach. Your script becomes a function inside cloud infrastructure which can be called over HTTP. The Nuclio serverless platform helps us to implement and manage such functions.\nCVAT supports Nuclio out of the box if it is built properly. See the installation guide for instructions. Thus if you deploy a serverless function, the CVAT server can see it and call it with appropriate arguments. Of course there are some tricks how to create serverless functions for CVAT and we will discuss them in next sections of the tutorial.\nUsing builtin DL models in practice In the tutorial it is assumed that you already have the cloned CVAT GitHub repo. To build CVAT with serverless support you need to run docker compose command with specific configuration files. In the case it is docker-compose.serverless.yml. It has necessary instructions how to build and deploy Nuclio platform as a docker container and enable corresponding support in CVAT.\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml -f components/serverless/docker-compose.serverless.yml up -d --build docker compose -f docker-compose.yml -f docker-compose.dev.yml -f components/serverless/docker-compose.serverless.yml ps Name Command State Ports ------------------------------------------------------------------------------------------------------------- cvat /usr/bin/supervisord Up 8080/tcp cvat_db docker-entrypoint.sh postgres Up 5432/tcp cvat_proxy /docker-entrypoint.sh /bin ... Up 0.0.0.0:8080-\u003e80/tcp,:::8080-\u003e80/tcp cvat_redis docker-entrypoint.sh redis ... Up 6379/tcp cvat_ui /docker-entrypoint.sh ngin ... Up 80/tcp nuclio /docker-entrypoint.sh sh - ... Up (healthy) 80/tcp, 0.0.0.0:8070-\u003e8070/tcp,:::8070-\u003e8070/tcp Next step is to deploy builtin serverless functions using Nuclio command line tool (aka nuctl). It is assumed that you followed the installation guide and nuctl is already installed on your operating system. Run the following command to check that it works. In the beginning you should not have any deployed serverless functions.\nnuctl get functions No functions found Let’s see on examples how to use DL models for annotation in different computer vision tasks.\nTracking using SiamMask In this use case a user needs to annotate all individual objects on a video as tracks. Basically for every object we need to know its location on every frame.\nFirst step is to deploy SiamMask. The deployment process can depend on your operating system. On Linux you can use serverless/deploy_cpu.sh auxiliary script, but below we are using nuctl directly.\nnuctl create project cvat nuctl deploy --project-name cvat --path \"./serverless/pytorch/foolwood/siammask/nuclio\" --platform local 24.04.18 20:52:47.910 (I) nuctl Deploying function {\"name\": \"pth-foolwood-siammask\"} 24.04.18 20:52:47.910 (I) nuctl Building {\"builderKind\": \"docker\", \"versionInfo\": \"Label: 1.13.0, Git commit: c4422eb772781fb50fbf017698aae96199d81388, OS: linux, Arch: amd64, Go version: go1.21.7\", \"name\": \"pth-foolwood-siammask\"} 24.04.18 20:52:47.929 (W) nuctl.platform MaxWorkers is deprecated and will be removed in v1.15.x, use NumWorkers instead 24.04.18 20:52:48.044 (I) nuctl Staging files and preparing base images 24.04.18 20:52:48.044 (W) nuctl Using user provided base image, runtime interpreter version is provided by the base image {\"baseImage\": \"ubuntu:20.04\"} 24.04.18 20:52:48.044 (I) nuctl Building processor image {\"registryURL\": \"\", \"taggedImageName\": \"cvat.pth.foolwood.siammask:latest\"} 24.04.18 20:52:48.044 (I) nuctl.platform.docker Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.13.0-amd64\"} 24.04.18 20:52:49.717 (I) nuctl.platform.docker Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"} 24.04.18 20:52:51.363 (I) nuctl.platform Building docker image {\"image\": \"cvat.pth.foolwood.siammask:latest\"} 24.04.18 20:55:58.853 (I) nuctl.platform Pushing docker image into registry {\"image\": \"cvat.pth.foolwood.siammask:latest\", \"registry\": \"\"} 24.04.18 20:55:58.853 (I) nuctl.platform Docker image was successfully built and pushed into docker registry {\"image\": \"cvat.pth.foolwood.siammask:latest\"} 24.04.18 20:55:58.853 (I) nuctl Build complete {\"image\": \"cvat.pth.foolwood.siammask:latest\"} 24.04.18 20:55:58.861 (I) nuctl Cleaning up before deployment {\"functionName\": \"pth-foolwood-siammask\"} 24.04.18 20:55:59.593 (I) nuctl.platform Waiting for function to be ready {\"timeout\": 120} 24.04.18 20:56:01.315 (I) nuctl Function deploy complete {\"functionName\": \"pth-foolwood-siammask\", \"httpPort\": 33453, \"internalInvocationURLs\": [\"172.17.0.5:8080\"], \"externalInvocationURLs\": [\"0.0.0.0:33453\"]} nuctl get functions NAMESPACE | NAME | PROJECT | STATE | NODE PORT | REPLICAS nuclio | pth-foolwood-siammask | cvat | ready | 49155 | 1/1 Let’s see how it works in the UI. Go to the models tab and check that you can see SiamMask in the list. If you cannot, it means that there are some problems. Go to one of our public channels and ask for help.\nAfter that, go to the new task page and create a task with this video file. You can choose any task name, any labels, and even another video file if you like. In this case, the Remote sources option was used to specify the video file. Press submit button at the end to finish the process.\nOpen the task and use AI tools to start tracking an object. Draw a bounding box around an object, and sequentially switch through the frame and correct the restrictive box if necessary.\nFinally you will get bounding boxes.\nSiamMask model is more optimized to work on Nvidia GPUs.\nFor more information about deploying the model for the GPU, read on. Object detection using YOLO-v3 First of all let’s deploy the DL model. The deployment process is similar for all serverless functions. Need to run nuctl deploy command with appropriate arguments. To simplify the process, you can use serverless/deploy_cpu.sh command. Inference of the serverless function is optimized for CPU using Intel OpenVINO framework.\nserverless/deploy_cpu.sh serverless/openvino/omz/public/yolo-v3-tf/ Deploying serverless/openvino/omz/public/yolo-v3-tf function... 21.07.12 15:55:17.314 nuctl (I) Deploying function {\"name\": \"\"} 21.07.12 15:55:17.314 nuctl (I) Building {\"versionInfo\": \"Label: 1.5.16, Git commit: ae43a6a560c2bec42d7ccfdf6e8e11a1e3cc3774, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"} 21.07.12 15:55:17.682 nuctl (I) Cleaning up before deployment {\"functionName\": \"openvino-omz-public-yolo-v3-tf\"} 21.07.12 15:55:17.739 nuctl (I) Staging files and preparing base images 21.07.12 15:55:17.743 nuctl (I) Building processor image {\"imageName\": \"cvat/openvino.omz.public.yolo-v3-tf:latest\"} 21.07.12 15:55:17.743 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.5.16-amd64\"} 21.07.12 15:55:21.048 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"} 21.07.12 15:55:24.595 nuctl.platform (I) Building docker image {\"image\": \"cvat/openvino.omz.public.yolo-v3-tf:latest\"} 21.07.12 15:55:30.359 nuctl.platform (I) Pushing docker image into registry {\"image\": \"cvat/openvino.omz.public.yolo-v3-tf:latest\", \"registry\": \"\"} 21.07.12 15:55:30.359 nuctl.platform (I) Docker image was successfully built and pushed into docker registry {\"image\": \"cvat/openvino.omz.public.yolo-v3-tf:latest\"} 21.07.12 15:55:30.359 nuctl (I) Build complete {\"result\": {\"Image\":\"cvat/openvino.omz.public.yolo-v3-tf:latest\",\"UpdatedFunctionConfig\":{\"metadata\":{\"name\":\"openvino-omz-public-yolo-v3-tf\",\"namespace\":\"nuclio\",\"labels\":{\"nuclio.io/project-name\":\"cvat\"},\"annotations\":{\"framework\":\"openvino\",\"name\":\"YOLO v3\",\"spec\":\"[\\n { \\\"id\\\": 0, \\\"name\\\": \\\"person\\\" },\\n { \\\"id\\\": 1, \\\"name\\\": \\\"bicycle\\\" },\\n { \\\"id\\\": 2, \\\"name\\\": \\\"car\\\" },\\n { \\\"id\\\": 3, \\\"name\\\": \\\"motorbike\\\" },\\n { \\\"id\\\": 4, \\\"name\\\": \\\"aeroplane\\\" },\\n { \\\"id\\\": 5, \\\"name\\\": \\\"bus\\\" },\\n { \\\"id\\\": 6, \\\"name\\\": \\\"train\\\" },\\n { \\\"id\\\": 7, \\\"name\\\": \\\"truck\\\" },\\n { \\\"id\\\": 8, \\\"name\\\": \\\"boat\\\" },\\n { \\\"id\\\": 9, \\\"name\\\": \\\"traffic light\\\" },\\n { \\\"id\\\": 10, \\\"name\\\": \\\"fire hydrant\\\" },\\n { \\\"id\\\": 11, \\\"name\\\": \\\"stop sign\\\" },\\n { \\\"id\\\": 12, \\\"name\\\": \\\"parking meter\\\" },\\n { \\\"id\\\": 13, \\\"name\\\": \\\"bench\\\" },\\n { \\\"id\\\": 14, \\\"name\\\": \\\"bird\\\" },\\n { \\\"id\\\": 15, \\\"name\\\": \\\"cat\\\" },\\n { \\\"id\\\": 16, \\\"name\\\": \\\"dog\\\" },\\n { \\\"id\\\": 17, \\\"name\\\": \\\"horse\\\" },\\n { \\\"id\\\": 18, \\\"name\\\": \\\"sheep\\\" },\\n { \\\"id\\\": 19, \\\"name\\\": \\\"cow\\\" },\\n { \\\"id\\\": 20, \\\"name\\\": \\\"elephant\\\" },\\n { \\\"id\\\": 21, \\\"name\\\": \\\"bear\\\" },\\n { \\\"id\\\": 22, \\\"name\\\": \\\"zebra\\\" },\\n { \\\"id\\\": 23, \\\"name\\\": \\\"giraffe\\\" },\\n { \\\"id\\\": 24, \\\"name\\\": \\\"backpack\\\" },\\n { \\\"id\\\": 25, \\\"name\\\": \\\"umbrella\\\" },\\n { \\\"id\\\": 26, \\\"name\\\": \\\"handbag\\\" },\\n { \\\"id\\\": 27, \\\"name\\\": \\\"tie\\\" },\\n { \\\"id\\\": 28, \\\"name\\\": \\\"suitcase\\\" },\\n { \\\"id\\\": 29, \\\"name\\\": \\\"frisbee\\\" },\\n { \\\"id\\\": 30, \\\"name\\\": \\\"skis\\\" },\\n { \\\"id\\\": 31, \\\"name\\\": \\\"snowboard\\\" },\\n { \\\"id\\\": 32, \\\"name\\\": \\\"sports ball\\\" },\\n { \\\"id\\\": 33, \\\"name\\\": \\\"kite\\\" },\\n { \\\"id\\\": 34, \\\"name\\\": \\\"baseball bat\\\" },\\n { \\\"id\\\": 35, \\\"name\\\": \\\"baseball glove\\\" },\\n { \\\"id\\\": 36, \\\"name\\\": \\\"skateboard\\\" },\\n { \\\"id\\\": 37, \\\"name\\\": \\\"surfboard\\\" },\\n { \\\"id\\\": 38, \\\"name\\\": \\\"tennis racket\\\" },\\n { \\\"id\\\": 39, \\\"name\\\": \\\"bottle\\\" },\\n { \\\"id\\\": 40, \\\"name\\\": \\\"wine glass\\\" },\\n { \\\"id\\\": 41, \\\"name\\\": \\\"cup\\\" },\\n { \\\"id\\\": 42, \\\"name\\\": \\\"fork\\\" },\\n { \\\"id\\\": 43, \\\"name\\\": \\\"knife\\\" },\\n { \\\"id\\\": 44, \\\"name\\\": \\\"spoon\\\" },\\n { \\\"id\\\": 45, \\\"name\\\": \\\"bowl\\\" },\\n { \\\"id\\\": 46, \\\"name\\\": \\\"banana\\\" },\\n { \\\"id\\\": 47, \\\"name\\\": \\\"apple\\\" },\\n { \\\"id\\\": 48, \\\"name\\\": \\\"sandwich\\\" },\\n { \\\"id\\\": 49, \\\"name\\\": \\\"orange\\\" },\\n { \\\"id\\\": 50, \\\"name\\\": \\\"broccoli\\\" },\\n { \\\"id\\\": 51, \\\"name\\\": \\\"carrot\\\" },\\n { \\\"id\\\": 52, \\\"name\\\": \\\"hot dog\\\" },\\n { \\\"id\\\": 53, \\\"name\\\": \\\"pizza\\\" },\\n { \\\"id\\\": 54, \\\"name\\\": \\\"donut\\\" },\\n { \\\"id\\\": 55, \\\"name\\\": \\\"cake\\\" },\\n { \\\"id\\\": 56, \\\"name\\\": \\\"chair\\\" },\\n { \\\"id\\\": 57, \\\"name\\\": \\\"sofa\\\" },\\n { \\\"id\\\": 58, \\\"name\\\": \\\"pottedplant\\\" },\\n { \\\"id\\\": 59, \\\"name\\\": \\\"bed\\\" },\\n { \\\"id\\\": 60, \\\"name\\\": \\\"diningtable\\\" },\\n { \\\"id\\\": 61, \\\"name\\\": \\\"toilet\\\" },\\n { \\\"id\\\": 62, \\\"name\\\": \\\"tvmonitor\\\" },\\n { \\\"id\\\": 63, \\\"name\\\": \\\"laptop\\\" },\\n { \\\"id\\\": 64, \\\"name\\\": \\\"mouse\\\" },\\n { \\\"id\\\": 65, \\\"name\\\": \\\"remote\\\" },\\n { \\\"id\\\": 66, \\\"name\\\": \\\"keyboard\\\" },\\n { \\\"id\\\": 67, \\\"name\\\": \\\"cell phone\\\" },\\n { \\\"id\\\": 68, \\\"name\\\": \\\"microwave\\\" },\\n { \\\"id\\\": 69, \\\"name\\\": \\\"oven\\\" },\\n { \\\"id\\\": 70, \\\"name\\\": \\\"toaster\\\" },\\n { \\\"id\\\": 71, \\\"name\\\": \\\"sink\\\" },\\n { \\\"id\\\": 72, \\\"name\\\": \\\"refrigerator\\\" },\\n { \\\"id\\\": 73, \\\"name\\\": \\\"book\\\" },\\n { \\\"id\\\": 74, \\\"name\\\": \\\"clock\\\" },\\n { \\\"id\\\": 75, \\\"name\\\": \\\"vase\\\" },\\n { \\\"id\\\": 76, \\\"name\\\": \\\"scissors\\\" },\\n { \\\"id\\\": 77, \\\"name\\\": \\\"teddy bear\\\" },\\n { \\\"id\\\": 78, \\\"name\\\": \\\"hair drier\\\" },\\n { \\\"id\\\": 79, \\\"name\\\": \\\"toothbrush\\\" }\\n]\\n\",\"type\":\"detector\"}},\"spec\":{\"description\":\"YOLO v3 via Intel OpenVINO\",\"handler\":\"main:handler\",\"runtime\":\"python:3.6\",\"env\":[{\"name\":\"NUCLIO_PYTHON_EXE_PATH\",\"value\":\"/opt/nuclio/common/openvino/python3\"}],\"resources\":{},\"image\":\"cvat/openvino.omz.public.yolo-v3-tf:latest\",\"targetCPU\":75,\"triggers\":{\"myHttpTrigger\":{\"class\":\"\",\"kind\":\"http\",\"name\":\"myHttpTrigger\",\"maxWorkers\":2,\"workerAvailabilityTimeoutMilliseconds\":10000,\"attributes\":{\"maxRequestBodySize\":33554432}}},\"volumes\":[{\"volume\":{\"name\":\"volume-1\",\"hostPath\":{\"path\":\"/home/nmanovic/Workspace/cvat/serverless/common\"}},\"volumeMount\":{\"name\":\"volume-1\",\"mountPath\":\"/opt/nuclio/common\"}}],\"build\":{\"image\":\"cvat/openvino.omz.public.yolo-v3-tf\",\"baseImage\":\"openvino/ubuntu18_dev:2020.2\",\"directives\":{\"preCopy\":[{\"kind\":\"USER\",\"value\":\"root\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"RUN\",\"value\":\"ln -s /usr/bin/pip3 /usr/bin/pip\"},{\"kind\":\"RUN\",\"value\":\"/opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/downloader.py --name yolo-v3-tf -o /opt/nuclio/open_model_zoo\"},{\"kind\":\"RUN\",\"value\":\"/opt/intel/openvino/deployment_tools/open_model_zoo/tools/downloader/converter.py --name yolo-v3-tf --precisions FP32 -d /opt/nuclio/open_model_zoo -o /opt/nuclio/open_model_zoo\"}]},\"codeEntryType\":\"image\"},\"platform\":{\"attributes\":{\"mountMode\":\"volume\",\"restartPolicy\":{\"maximumRetryCount\":3,\"name\":\"always\"}}},\"readinessTimeoutSeconds\":60,\"securityContext\":{},\"eventTimeout\":\"30s\"}}}} 21.07.12 15:55:31.496 nuctl.platform (I) Waiting for function to be ready {\"timeout\": 60} 21.07.12 15:55:32.894 nuctl (I) Function deploy complete {\"functionName\": \"openvino-omz-public-yolo-v3-tf\", \"httpPort\": 49156} Again, go to models tab and check that you can see YOLO v3 in the list. If you cannot by a reason it means that there are some problems. Go to one of our public channels and ask for help.\nLet us reuse the task which you created for testing SiamMask serverless function above. Choose the magic wand tool, go to the Detectors tab, and select YOLO v3 model. Press Annotate button and after a couple of seconds you should see detection results. Do not forget to save annotations.\nAlso it is possible to run a detector for the whole annotation task. Thus CVAT will run the serverless function on every frame of the task and submit results directly into database. For more details please read the guide.\nObject segmentation using Segment Anything If you have an interactor that returns masks, you can use it to segment objects. One such interactor is Segment Anything. Several implementations are available out of the box:\nserverless/pytorch/facebookresearch/sam/ Includes two versions: one optimized for CPU and another for GPU. Deploying a serverless function optimized for GPU follows a similar process. You only need to run the serverless/deploy_gpu.sh script, which executes the same commands but utilizes the function-gpu.yaml configuration file instead of function.yaml. See the following sections for details on the differences.\nNote: Please do not run several GPU functions at the same time. In many cases, it will not work out of the box. For now, you should manually schedule different functions on different GPUs and it requires source code modification. Nuclio autoscaler does not support the local platform (docker).\nserverless/deploy_gpu.sh serverless/pytorch/facebookresearch/sam/ 25.01.30 11:02:07.034 (I) nuctl Deploying function {\"name\": \"pth-facebookresearch-sam-vit-h\"} 25.01.30 11:02:07.034 (I) nuctl Building {\"builderKind\": \"docker\", \"versionInfo\": \"Label: 1.13.0, Git commit: c4422eb772781fb50fbf017698aae96199d81388, OS: linux, Arch: amd64, Go version: go1.21.7\", \"name\": \"pth-facebookresearch-sam-vit-h\"} 25.01.30 11:02:07.159 (I) nuctl Staging files and preparing base images 25.01.30 11:02:07.160 (W) nuctl Using user provided base image, runtime interpreter version is provided by the base image {\"baseImage\": \"ubuntu:22.04\"} 25.01.30 11:02:07.160 (I) nuctl Building processor image {\"registryURL\": \"\", \"taggedImageName\": \"cvat.pth.facebookresearch.sam.vit_h:latest\"} 25.01.30 11:02:07.160 (I) nuctl.platform.docker Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.13.0-amd64\"} 25.01.30 11:02:09.656 (I) nuctl.platform.docker Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"} 25.01.30 11:02:12.174 (I) nuctl.platform Building docker image {\"image\": \"cvat.pth.facebookresearch.sam.vit_h:latest\"} 25.01.30 11:20:54.431 (I) nuctl.platform Pushing docker image into registry {\"image\": \"cvat.pth.facebookresearch.sam.vit_h:latest\", \"registry\": \"\"} 25.01.30 11:20:54.431 (I) nuctl.platform Docker image was successfully built and pushed into docker registry {\"image\": \"cvat.pth.facebookresearch.sam.vit_h:latest\"} 25.01.30 11:20:54.431 (I) nuctl Build complete {\"image\": \"cvat.pth.facebookresearch.sam.vit_h:latest\"} 25.01.30 11:20:54.436 (I) nuctl Cleaning up before deployment {\"functionName\": \"pth-facebookresearch-sam-vit-h\"} 25.01.30 11:20:55.018 (I) nuctl.platform Waiting for function to be ready {\"timeout\": 120} 25.01.30 11:20:56.719 (I) nuctl Function deploy complete {\"functionName\": \"pth-facebookresearch-sam-vit-h\", \"httpPort\": 32771, \"internalInvocationURLs\": [\"172.18.0.22:8080\"], \"externalInvocationURLs\": [\"0.0.0.0:32771\"]} Now you should be able to annotate objects using segment anything.\nAdding your own DL models Choose a DL model For the tutorial I will choose a popular AI library with a lot of models inside. In your case it can be your own model. If it is based on detectron2 it will be easy to integrate. Just follow the tutorial.\nDetectron2 is Facebook AI Research’s next generation library that provides state-of-the-art detection and segmentation algorithms. It is the successor of Detectron and maskrcnn-benchmark. It supports a number of computer vision research projects and production applications in Facebook.\nClone the repository somewhere. I assume that all other experiments will be run from the cloned detectron2 directory.\ngit clone https://github.com/facebookresearch/detectron2 cd detectron2 Run local experiments Let’s run a detection model locally. First of all need to install requirements for the library.\nIn my case I have Ubuntu 20.04 with python 3.8.5. I installed PyTorch 1.8.1 for Linux with pip, python, and CPU inside a virtual environment. Follow opencv-python installation guide to get the library for demo and visualization.\npython3 -m venv .detectron2 . .detectron2/bin/activate pip install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html pip install opencv-python Install the detectron2 library from your local clone (you should be inside detectron2 directory).\npython -m pip install -e . After the library from Facebook AI Research is installed, we can run a couple of experiments. See the official tutorial for more examples. I decided to experiment with RetinaNet. First step is to download model weights.\ncurl -O https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl To run experiments let’s download an image with cats from wikipedia.\ncurl -O https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/Cat_poster_1.jpg/1920px-Cat_poster_1.jpg Finally let’s run the DL model inference on CPU. If all is fine, you will see a window with cats and bounding boxes around them with scores.\npython demo/demo.py --config-file configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml \\ --input 1920px-Cat_poster_1.jpg --opts MODEL.WEIGHTS model_final_971ab9.pkl MODEL.DEVICE cpu Next step is to minimize demo/demo.py script and keep code which is necessary to load, run, and interpret output of the model only. Let’s hard code parameters and remove argparse. Keep only code which is responsible for working with an image. There is no common advice how to minimize some code.\nFinally you should get something like the code below which has fixed config, read a predefined image, initialize predictor, and run inference. As the final step it prints all detected bounding boxes with scores and labels.\nfrom detectron2.config import get_cfg from detectron2.data.detection_utils import read_image from detectron2.engine.defaults import DefaultPredictor from detectron2.data.datasets.builtin_meta import COCO_CATEGORIES CONFIG_FILE = \"configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml\" CONFIG_OPTS = [\"MODEL.WEIGHTS\", \"model_final_971ab9.pkl\", \"MODEL.DEVICE\", \"cpu\"] CONFIDENCE_THRESHOLD = 0.5 def setup_cfg(): cfg = get_cfg() cfg.merge_from_file(CONFIG_FILE) cfg.merge_from_list(CONFIG_OPTS) cfg.MODEL.RETINANET.SCORE_THRESH_TEST = CONFIDENCE_THRESHOLD cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = CONFIDENCE_THRESHOLD cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = CONFIDENCE_THRESHOLD cfg.freeze() return cfg if __name__ == \"__main__\": cfg = setup_cfg() input = \"1920px-Cat_poster_1.jpg\" img = read_image(input, format=\"BGR\") predictor = DefaultPredictor(cfg) predictions = predictor(img) instances = predictions['instances'] pred_boxes = instances.pred_boxes scores = instances.scores pred_classes = instances.pred_classes for box, score, label in zip(pred_boxes, scores, pred_classes): label = COCO_CATEGORIES[int(label)][\"name\"] print(box.tolist(), float(score), label) DL model as a serverless function When we know how to run the DL model locally, we can prepare a serverless function which can be used by CVAT to annotate data. Let’s see how function.yaml will look like…\nLet’s look at faster_rcnn_inception_v2_coco serverless function configuration as an example and try adapting it to our case. First of all let’s invent an unique name for the new function: pth-facebookresearch-detectron2-retinanet-r101. Section annotations describes our function for CVAT serverless subsystem:\nannotations.name is a display name annotations.type is a type of the serverless function. It can have several different values. Basically it affects input and output of the function. In our case it has detector type and it means that the integrated DL model can generate shapes with labels for an image. annotations.framework is used for information only and can have arbitrary value. Usually it has values like OpenVINO, PyTorch, TensorFlow, etc. annotations.spec describes the list of labels which the model supports. In the case the DL model was trained on MS COCO dataset and the list of labels correspond to the dataset. spec.description is used to provide basic information for the model. All other parameters are described in Nuclio documentation.\nspec.handler is the entry point to your function. spec.runtime is the name of the language runtime. spec.eventTimeout is the global event timeout Next step is to describe how to build our serverless function:\nspec.build.image is the name of your docker image spec.build.baseImage is the name of a base container image from which to build the function spec.build.directives are commands to build your docker image In our case we start from Ubuntu 20.04 base image, install curl to download weights for our model, git to clone detectron2 project from GitHub, and python together with pip. Repeat installation steps which we used to setup the DL model locally with minor modifications.\nFor Nuclio platform we have to specify a couple of more parameters:\nspec.triggers.myHttpTrigger describes HTTP trigger to handle incoming HTTP requests. spec.platform describes some important parameters to run your functions like restartPolicy and mountMode. Read Nuclio documentation for more details. metadata: name: pth-facebookresearch-detectron2-retinanet-r101 namespace: cvat annotations: name: RetinaNet R101 type: detector spec: | [ { \"id\": 1, \"name\": \"person\" }, { \"id\": 2, \"name\": \"bicycle\" }, ... { \"id\":89, \"name\": \"hair_drier\" }, { \"id\":90, \"name\": \"toothbrush\" } ] spec: description: RetinaNet R101 from Detectron2 runtime: 'python:3.8' handler: main:handler eventTimeout: 30s build: image: cvat/pth.facebookresearch.detectron2.retinanet_r101 baseImage: ubuntu:20.04 directives: preCopy: - kind: ENV value: DEBIAN_FRONTEND=noninteractive - kind: RUN value: apt-get update \u0026\u0026 apt-get -y install curl git python3 python3-pip - kind: WORKDIR value: /opt/nuclio - kind: RUN value: pip3 install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html - kind: RUN value: pip3 install 'git+https://github.com/facebookresearch/detectron2@v0.4' - kind: RUN value: curl -O https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl - kind: RUN value: ln -s /usr/bin/pip3 /usr/local/bin/pip triggers: myHttpTrigger: maxWorkers: 2 kind: 'http' workerAvailabilityTimeoutMilliseconds: 10000 attributes: maxRequestBodySize: 33554432 # 32MB platform: attributes: restartPolicy: name: always maximumRetryCount: 3 mountMode: volume Full code can be found here: detectron2/retinanet/nuclio/function.yaml\nNext step is to adapt our source code which we implemented to run the DL model locally to requirements of Nuclio platform. First step is to load the model into memory using init_context(context) function. Read more about the function in Best Practices and Common Pitfalls.\nAfter that we need to accept incoming HTTP requests, run inference, reply with detection results. For the process our entry point is responsible which we specified in our function specification handler(context, event). Again in accordance to function specification the entry point should be located inside main.py.\ndef init_context(context): context.logger.info(\"Init context... 0%\") cfg = get_config('COCO-Detection/retinanet_R_101_FPN_3x.yaml') cfg.merge_from_list(CONFIG_OPTS) cfg.MODEL.RETINANET.SCORE_THRESH_TEST = CONFIDENCE_THRESHOLD cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = CONFIDENCE_THRESHOLD cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = CONFIDENCE_THRESHOLD cfg.freeze() predictor = DefaultPredictor(cfg) context.user_data.model_handler = predictor context.logger.info(\"Init context...100%\") def handler(context, event): context.logger.info(\"Run retinanet-R101 model\") data = event.body buf = io.BytesIO(base64.b64decode(data[\"image\"])) threshold = float(data.get(\"threshold\", 0.5)) image = convert_PIL_to_numpy(Image.open(buf), format=\"BGR\") predictions = context.user_data.model_handler(image) instances = predictions['instances'] pred_boxes = instances.pred_boxes scores = instances.scores pred_classes = instances.pred_classes results = [] for box, score, label in zip(pred_boxes, scores, pred_classes): label = COCO_CATEGORIES[int(label)][\"name\"] if score \u003e= threshold: results.append({ \"confidence\": str(float(score)), \"label\": label, \"points\": box.tolist(), \"type\": \"rectangle\", }) return context.Response(body=json.dumps(results), headers={}, content_type='application/json', status_code=200) Full code can be found here: detectron2/retinanet/nuclio/main.py\nDeploy RetinaNet serverless function To use the new serverless function you have to deploy it using nuctl command. The actual deployment process is described in automatic annotation guide.\n./serverless/deploy_cpu.sh ./serverless/pytorch/facebookresearch/detectron2/retinanet/ 21.07.21 15:20:31.011 nuctl (I) Deploying function {\"name\": \"\"} 21.07.21 15:20:31.011 nuctl (I) Building {\"versionInfo\": \"Label: 1.5.16, Git commit: ae43a6a560c2bec42d7ccfdf6e8e11a1e3cc3774, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"} 21.07.21 15:20:31.407 nuctl (I) Cleaning up before deployment {\"functionName\": \"pth-facebookresearch-detectron2-retinanet-r101\"} 21.07.21 15:20:31.497 nuctl (I) Function already exists, deleting function containers {\"functionName\": \"pth-facebookresearch-detectron2-retinanet-r101\"} 21.07.21 15:20:31.914 nuctl (I) Staging files and preparing base images 21.07.21 15:20:31.915 nuctl (I) Building processor image {\"imageName\": \"cvat/pth.facebookresearch.detectron2.retinanet_r101:latest\"} 21.07.21 15:20:31.916 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.5.16-amd64\"} 21.07.21 15:20:34.495 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"} 21.07.21 15:20:37.524 nuctl.platform (I) Building docker image {\"image\": \"cvat/pth.facebookresearch.detectron2.retinanet_r101:latest\"} 21.07.21 15:20:37.852 nuctl.platform (I) Pushing docker image into registry {\"image\": \"cvat/pth.facebookresearch.detectron2.retinanet_r101:latest\", \"registry\": \"\"} 21.07.21 15:20:37.853 nuctl.platform (I) Docker image was successfully built and pushed into docker registry {\"image\": \"cvat/pth.facebookresearch.detectron2.retinanet_r101:latest\"} 21.07.21 15:20:37.853 nuctl (I) Build complete {\"result\": {\"Image\":\"cvat/pth.facebookresearch.detectron2.retinanet_r101:latest\",\"UpdatedFunctionConfig\":{\"metadata\":{\"name\":\"pth-facebookresearch-detectron2-retinanet-r101\",\"namespace\":\"nuclio\",\"labels\":{\"nuclio.io/project-name\":\"cvat\"},\"annotations\":{\"framework\":\"pytorch\",\"name\":\"RetinaNet R101\",\"spec\":\"[\\n { \\\"id\\\": 1, \\\"name\\\": \\\"person\\\" },\\n { \\\"id\\\": 2, \\\"name\\\": \\\"bicycle\\\" },\\n { \\\"id\\\": 3, \\\"name\\\": \\\"car\\\" },\\n { \\\"id\\\": 4, \\\"name\\\": \\\"motorcycle\\\" },\\n { \\\"id\\\": 5, \\\"name\\\": \\\"airplane\\\" },\\n { \\\"id\\\": 6, \\\"name\\\": \\\"bus\\\" },\\n { \\\"id\\\": 7, \\\"name\\\": \\\"train\\\" },\\n { \\\"id\\\": 8, \\\"name\\\": \\\"truck\\\" },\\n { \\\"id\\\": 9, \\\"name\\\": \\\"boat\\\" },\\n { \\\"id\\\":10, \\\"name\\\": \\\"traffic_light\\\" },\\n { \\\"id\\\":11, \\\"name\\\": \\\"fire_hydrant\\\" },\\n { \\\"id\\\":13, \\\"name\\\": \\\"stop_sign\\\" },\\n { \\\"id\\\":14, \\\"name\\\": \\\"parking_meter\\\" },\\n { \\\"id\\\":15, \\\"name\\\": \\\"bench\\\" },\\n { \\\"id\\\":16, \\\"name\\\": \\\"bird\\\" },\\n { \\\"id\\\":17, \\\"name\\\": \\\"cat\\\" },\\n { \\\"id\\\":18, \\\"name\\\": \\\"dog\\\" },\\n { \\\"id\\\":19, \\\"name\\\": \\\"horse\\\" },\\n { \\\"id\\\":20, \\\"name\\\": \\\"sheep\\\" },\\n { \\\"id\\\":21, \\\"name\\\": \\\"cow\\\" },\\n { \\\"id\\\":22, \\\"name\\\": \\\"elephant\\\" },\\n { \\\"id\\\":23, \\\"name\\\": \\\"bear\\\" },\\n { \\\"id\\\":24, \\\"name\\\": \\\"zebra\\\" },\\n { \\\"id\\\":25, \\\"name\\\": \\\"giraffe\\\" },\\n { \\\"id\\\":27, \\\"name\\\": \\\"backpack\\\" },\\n { \\\"id\\\":28, \\\"name\\\": \\\"umbrella\\\" },\\n { \\\"id\\\":31, \\\"name\\\": \\\"handbag\\\" },\\n { \\\"id\\\":32, \\\"name\\\": \\\"tie\\\" },\\n { \\\"id\\\":33, \\\"name\\\": \\\"suitcase\\\" },\\n { \\\"id\\\":34, \\\"name\\\": \\\"frisbee\\\" },\\n { \\\"id\\\":35, \\\"name\\\": \\\"skis\\\" },\\n { \\\"id\\\":36, \\\"name\\\": \\\"snowboard\\\" },\\n { \\\"id\\\":37, \\\"name\\\": \\\"sports_ball\\\" },\\n { \\\"id\\\":38, \\\"name\\\": \\\"kite\\\" },\\n { \\\"id\\\":39, \\\"name\\\": \\\"baseball_bat\\\" },\\n { \\\"id\\\":40, \\\"name\\\": \\\"baseball_glove\\\" },\\n { \\\"id\\\":41, \\\"name\\\": \\\"skateboard\\\" },\\n { \\\"id\\\":42, \\\"name\\\": \\\"surfboard\\\" },\\n { \\\"id\\\":43, \\\"name\\\": \\\"tennis_racket\\\" },\\n { \\\"id\\\":44, \\\"name\\\": \\\"bottle\\\" },\\n { \\\"id\\\":46, \\\"name\\\": \\\"wine_glass\\\" },\\n { \\\"id\\\":47, \\\"name\\\": \\\"cup\\\" },\\n { \\\"id\\\":48, \\\"name\\\": \\\"fork\\\" },\\n { \\\"id\\\":49, \\\"name\\\": \\\"knife\\\" },\\n { \\\"id\\\":50, \\\"name\\\": \\\"spoon\\\" },\\n { \\\"id\\\":51, \\\"name\\\": \\\"bowl\\\" },\\n { \\\"id\\\":52, \\\"name\\\": \\\"banana\\\" },\\n { \\\"id\\\":53, \\\"name\\\": \\\"apple\\\" },\\n { \\\"id\\\":54, \\\"name\\\": \\\"sandwich\\\" },\\n { \\\"id\\\":55, \\\"name\\\": \\\"orange\\\" },\\n { \\\"id\\\":56, \\\"name\\\": \\\"broccoli\\\" },\\n { \\\"id\\\":57, \\\"name\\\": \\\"carrot\\\" },\\n { \\\"id\\\":58, \\\"name\\\": \\\"hot_dog\\\" },\\n { \\\"id\\\":59, \\\"name\\\": \\\"pizza\\\" },\\n { \\\"id\\\":60, \\\"name\\\": \\\"donut\\\" },\\n { \\\"id\\\":61, \\\"name\\\": \\\"cake\\\" },\\n { \\\"id\\\":62, \\\"name\\\": \\\"chair\\\" },\\n { \\\"id\\\":63, \\\"name\\\": \\\"couch\\\" },\\n { \\\"id\\\":64, \\\"name\\\": \\\"potted_plant\\\" },\\n { \\\"id\\\":65, \\\"name\\\": \\\"bed\\\" },\\n { \\\"id\\\":67, \\\"name\\\": \\\"dining_table\\\" },\\n { \\\"id\\\":70, \\\"name\\\": \\\"toilet\\\" },\\n { \\\"id\\\":72, \\\"name\\\": \\\"tv\\\" },\\n { \\\"id\\\":73, \\\"name\\\": \\\"laptop\\\" },\\n { \\\"id\\\":74, \\\"name\\\": \\\"mouse\\\" },\\n { \\\"id\\\":75, \\\"name\\\": \\\"remote\\\" },\\n { \\\"id\\\":76, \\\"name\\\": \\\"keyboard\\\" },\\n { \\\"id\\\":77, \\\"name\\\": \\\"cell_phone\\\" },\\n { \\\"id\\\":78, \\\"name\\\": \\\"microwave\\\" },\\n { \\\"id\\\":79, \\\"name\\\": \\\"oven\\\" },\\n { \\\"id\\\":80, \\\"name\\\": \\\"toaster\\\" },\\n { \\\"id\\\":81, \\\"name\\\": \\\"sink\\\" },\\n { \\\"id\\\":83, \\\"name\\\": \\\"refrigerator\\\" },\\n { \\\"id\\\":84, \\\"name\\\": \\\"book\\\" },\\n { \\\"id\\\":85, \\\"name\\\": \\\"clock\\\" },\\n { \\\"id\\\":86, \\\"name\\\": \\\"vase\\\" },\\n { \\\"id\\\":87, \\\"name\\\": \\\"scissors\\\" },\\n { \\\"id\\\":88, \\\"name\\\": \\\"teddy_bear\\\" },\\n { \\\"id\\\":89, \\\"name\\\": \\\"hair_drier\\\" },\\n { \\\"id\\\":90, \\\"name\\\": \\\"toothbrush\\\" }\\n]\\n\",\"type\":\"detector\"}},\"spec\":{\"description\":\"RetinaNet R101 from Detectron2\",\"handler\":\"main:handler\",\"runtime\":\"python:3.8\",\"resources\":{},\"image\":\"cvat/pth.facebookresearch.detectron2.retinanet_r101:latest\",\"targetCPU\":75,\"triggers\":{\"myHttpTrigger\":{\"class\":\"\",\"kind\":\"http\",\"name\":\"myHttpTrigger\",\"maxWorkers\":2,\"workerAvailabilityTimeoutMilliseconds\":10000,\"attributes\":{\"maxRequestBodySize\":33554432}}},\"volumes\":[{\"volume\":{\"name\":\"volume-1\",\"hostPath\":{\"path\":\"/home/nmanovic/Workspace/cvat/serverless/common\"}},\"volumeMount\":{\"name\":\"volume-1\",\"mountPath\":\"/opt/nuclio/common\"}}],\"build\":{\"image\":\"cvat/pth.facebookresearch.detectron2.retinanet_r101\",\"baseImage\":\"ubuntu:20.04\",\"directives\":{\"preCopy\":[{\"kind\":\"ENV\",\"value\":\"DEBIAN_FRONTEND=noninteractive\"},{\"kind\":\"RUN\",\"value\":\"apt-get update \\u0026\\u0026 apt-get -y install curl git python3 python3-pip\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"RUN\",\"value\":\"pip3 install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\"},{\"kind\":\"RUN\",\"value\":\"pip3 install 'git+https://github.com/facebookresearch/detectron2@v0.4'\"},{\"kind\":\"RUN\",\"value\":\"curl -O https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl\"},{\"kind\":\"RUN\",\"value\":\"ln -s /usr/bin/pip3 /usr/local/bin/pip\"}]},\"codeEntryType\":\"image\"},\"platform\":{\"attributes\":{\"mountMode\":\"volume\",\"restartPolicy\":{\"maximumRetryCount\":3,\"name\":\"always\"}}},\"readinessTimeoutSeconds\":60,\"securityContext\":{},\"eventTimeout\":\"30s\"}}}} 21.07.21 15:20:39.042 nuctl.platform (I) Waiting for function to be ready {\"timeout\": 60} 21.07.21 15:20:40.480 nuctl (I) Function deploy complete {\"functionName\": \"pth-facebookresearch-detectron2-retinanet-r101\", \"httpPort\": 49153} Advanced capabilities Optimize using GPU To optimize a function for a specific device (e.g. GPU), basically you just need to modify instructions above to run the function on the target device. In most cases it will be necessary to modify installation instructions only.\nFor RetinaNet R101 which was added above modifications will look like:\n--- function.yaml\t2021-06-25 21:06:51.603281723 +0300 +++ function-gpu.yaml\t2021-07-07 22:38:53.454202637 +0300 @@ -90,7 +90,7 @@ ] spec: - description: RetinaNet R101 from Detectron2 + description: RetinaNet R101 from Detectron2 optimized for GPU runtime: 'python:3.8' handler: main:handler eventTimeout: 30s @@ -108,7 +108,7 @@ - kind: WORKDIR value: /opt/nuclio - kind: RUN - value: pip3 install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html + value: pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html - kind: RUN value: git clone https://github.com/facebookresearch/detectron2 - kind: RUN @@ -120,12 +120,16 @@ triggers: myHttpTrigger: - maxWorkers: 2 + maxWorkers: 1 kind: 'http' workerAvailabilityTimeoutMilliseconds: 10000 attributes: maxRequestBodySize: 33554432 # 32MB + resources: + limits: + nvidia.com/gpu: 1 + platform: attributes: restartPolicy: Note: GPU has very limited amount of memory and it doesn’t allow to run multiple serverless functions in parallel for now using free open-source Nuclio version on the local platform because scaling to zero feature is absent. Theoretically it is possible to run different functions on different GPUs, but it requires to change source code on corresponding serverless functions to choose a free GPU.\nDebugging a serverless function Let’s say you have a problem with your serverless function and want to debug it. Of course you can use context.logger.info or similar methods to print the intermediate state of your function. Another way is to debug using Visual Studio Code. Please see instructions below to setup your environment step by step.\nLet’s modify our function.yaml to include debugpy package and specify that maxWorkers count is 1. Otherwise both workers will try to use the same port and it will lead to an exception in python code.\n- kind: RUN value: pip3 install debugpy triggers: myHttpTrigger: maxWorkers: 1 Change main.py to listen to a port (e.g. 5678). Insert code below in the beginning of your file with entry point.\nimport debugpy debugpy.listen(5678) After these changes deploy the serverless function once again. For serverless/pytorch/facebookresearch/detectron2/retinanet/nuclio/ you should run the command below:\nserverless/deploy_cpu.sh serverless/pytorch/facebookresearch/detectron2/retinanet To debug python code inside a container you have to publish the port (in this tutorial it is 5678). Nuclio deploy command doesn’t support that and we have to workaround it using SSH port forwarding.\nInstall SSH server on your host machine using sudo apt install openssh-server In /etc/ssh/sshd_config host file set GatewayPorts yes Restart ssh service to apply changes using sudo systemctl restart ssh.service Next step is to install ssh client inside the container and run port forwarding. In the snippet below instead of user and ipaddress provide username and IP address of your host (usually IP address starts from 192.168.). You will need to confirm that you want to connect to your host computer and enter your password. Keep the terminal open after that.\ndocker exec -it nuclio-nuclio-pth-facebookresearch-detectron2-retinanet-r101 /bin/bash apt update \u0026\u0026 apt install -y ssh ssh -R 5678:localhost:5678 user@ipaddress See how the latest command looks like in my case:\nroot@2d6cceec8f70:/opt/nuclio# ssh -R 5678:localhost:5678 nmanovic@192.168.50.188 The authenticity of host '192.168.50.188 (192.168.50.188)' can't be established. ECDSA key fingerprint is SHA256:0sD6IWi+FKAhtUXr2TroHqyjcnYRIGLLx/wkGaZeRuo. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added '192.168.50.188' (ECDSA) to the list of known hosts. nmanovic@192.168.50.188's password: Welcome to Ubuntu 20.04.2 LTS (GNU/Linux 5.8.0-53-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage 223 updates can be applied immediately. 132 of these updates are standard security updates. To see these additional updates run: apt list --upgradable Your Hardware Enablement Stack (HWE) is supported until April 2025. Last login: Fri Jun 25 16:39:04 2021 from 172.17.0.5 [setupvars.sh] OpenVINO environment initialized nmanovic@nmanovic-dl-node:~$ Finally, add the configuration below into your launch.json. Open Visual Studio Code and run Serverless Debug configuration, set a breakpoint in main.py and try to call the serverless function from CVAT UI. The breakpoint should be triggered in Visual Studio Code and it should be possible to inspect variables and debug code.\n{ \"name\": \"Serverless Debug\", \"type\": \"python\", \"request\": \"attach\", \"connect\": { \"host\": \"localhost\", \"port\": 5678 }, \"pathMappings\": [ { \"localRoot\": \"${workspaceFolder}/serverless/pytorch/facebookresearch/detectron2/retinanet/nuclio\", \"remoteRoot\": \"/opt/nuclio\" } ] } Note: In case of changes in the source code, need to re-deploy the function and initiate port forwarding again.\nTroubleshooting First of all need to check that you are using the recommended version of Nuclio framework. In my case it is 1.5.16 but you need to check the installation manual.\nnuctl version Client version: \"Label: 1.5.16, Git commit: ae43a6a560c2bec42d7ccfdf6e8e11a1e3cc3774, OS: linux, Arch: amd64, Go version: go1.14.3\" Check that Nuclio dashboard is running and its version corresponds to nuctl.\ndocker ps --filter NAME=^nuclio$ CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7ab0c076c927 quay.io/nuclio/dashboard:1.5.16-amd64 \"/docker-entrypoint.…\" 6 weeks ago Up 46 minutes (healthy) 80/tcp, 0.0.0.0:8070-\u003e8070/tcp, :::8070-\u003e8070/tcp nuclio Be sure that the model, which doesn’t work, is healthy. In my case Inside Outside Guidance is not running.\ndocker ps --filter NAME=iog CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Let’s run it. Go to the root of CVAT repository and run the deploying command.\nserverless/deploy_cpu.sh serverless/pytorch/shiyinzhang/iog Deploying serverless/pytorch/shiyinzhang/iog function... 21.07.06 12:49:08.763 nuctl (I) Deploying function {\"name\": \"\"} 21.07.06 12:49:08.763 nuctl (I) Building {\"versionInfo\": \"Label: 1.5.16, Git commit: ae43a6a560c2bec42d7ccfdf6e8e11a1e3cc3774, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"} 21.07.06 12:49:09.085 nuctl (I) Cleaning up before deployment {\"functionName\": \"pth-shiyinzhang-iog\"} 21.07.06 12:49:09.162 nuctl (I) Function already exists, deleting function containers {\"functionName\": \"pth-shiyinzhang-iog\"} 21.07.06 12:49:09.230 nuctl (I) Staging files and preparing base images 21.07.06 12:49:09.232 nuctl (I) Building processor image {\"imageName\": \"cvat/pth.shiyinzhang.iog:latest\"} 21.07.06 12:49:09.232 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.5.16-amd64\"} 21.07.06 12:49:12.525 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"} 21.07.06 12:49:16.222 nuctl.platform (I) Building docker image {\"image\": \"cvat/pth.shiyinzhang.iog:latest\"} 21.07.06 12:49:16.555 nuctl.platform (I) Pushing docker image into registry {\"image\": \"cvat/pth.shiyinzhang.iog:latest\", \"registry\": \"\"} 21.07.06 12:49:16.555 nuctl.platform (I) Docker image was successfully built and pushed into docker registry {\"image\": \"cvat/pth.shiyinzhang.iog:latest\"} 21.07.06 12:49:16.555 nuctl (I) Build complete {\"result\": {\"Image\":\"cvat/pth.shiyinzhang.iog:latest\",\"UpdatedFunctionConfig\":{\"metadata\":{\"name\":\"pth-shiyinzhang-iog\",\"namespace\":\"nuclio\",\"labels\":{\"nuclio.io/project-name\":\"cvat\"},\"annotations\":{\"framework\":\"pytorch\",\"min_pos_points\":\"1\",\"name\":\"IOG\",\"spec\":\"\",\"startswith_box\":\"true\",\"type\":\"interactor\"}},\"spec\":{\"description\":\"Interactive Object Segmentation with Inside-Outside Guidance\",\"handler\":\"main:handler\",\"runtime\":\"python:3.6\",\"env\":[{\"name\":\"PYTHONPATH\",\"value\":\"/opt/nuclio/iog\"}],\"resources\":{},\"image\":\"cvat/pth.shiyinzhang.iog:latest\",\"targetCPU\":75,\"triggers\":{\"myHttpTrigger\":{\"class\":\"\",\"kind\":\"http\",\"name\":\"myHttpTrigger\",\"maxWorkers\":2,\"workerAvailabilityTimeoutMilliseconds\":10000,\"attributes\":{\"maxRequestBodySize\":33554432}}},\"volumes\":[{\"volume\":{\"name\":\"volume-1\",\"hostPath\":{\"path\":\"/home/nmanovic/Workspace/cvat/serverless/common\"}},\"volumeMount\":{\"name\":\"volume-1\",\"mountPath\":\"/opt/nuclio/common\"}}],\"build\":{\"image\":\"cvat/pth.shiyinzhang.iog\",\"baseImage\":\"continuumio/miniconda3\",\"directives\":{\"preCopy\":[{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"RUN\",\"value\":\"conda create -y -n iog python=3.6\"},{\"kind\":\"SHELL\",\"value\":\"[\\\"conda\\\", \\\"run\\\", \\\"-n\\\", \\\"iog\\\", \\\"/bin/bash\\\", \\\"-c\\\"]\"},{\"kind\":\"RUN\",\"value\":\"conda install -y -c anaconda curl\"},{\"kind\":\"RUN\",\"value\":\"conda install -y pytorch=0.4 torchvision=0.2 -c pytorch\"},{\"kind\":\"RUN\",\"value\":\"conda install -y -c conda-forge pycocotools opencv scipy\"},{\"kind\":\"RUN\",\"value\":\"git clone https://github.com/shiyinzhang/Inside-Outside-Guidance.git iog\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio/iog\"},{\"kind\":\"ENV\",\"value\":\"fileid=1Lm1hhMhhjjnNwO4Pf7SC6tXLayH2iH0l\"},{\"kind\":\"ENV\",\"value\":\"filename=IOG_PASCAL_SBD.pth\"},{\"kind\":\"RUN\",\"value\":\"curl -c ./cookie -s -L \\\"https://drive.google.com/uc?export=download\\u0026id=${fileid}\\\"\"},{\"kind\":\"RUN\",\"value\":\"echo \\\"/download/ {print \\\\$NF}\\\" \\u003e confirm_code.awk\"},{\"kind\":\"RUN\",\"value\":\"curl -Lb ./cookie \\\"https://drive.google.com/uc?export=download\\u0026confirm=`awk -f confirm_code.awk ./cookie`\\u0026id=${fileid}\\\" -o ${filename}\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"ENTRYPOINT\",\"value\":\"[\\\"conda\\\", \\\"run\\\", \\\"-n\\\", \\\"iog\\\"]\"}]},\"codeEntryType\":\"image\"},\"platform\":{\"attributes\":{\"mountMode\":\"volume\",\"restartPolicy\":{\"maximumRetryCount\":3,\"name\":\"always\"}}},\"readinessTimeoutSeconds\":60,\"securityContext\":{},\"eventTimeout\":\"30s\"}}}} 21.07.06 12:49:17.422 nuctl.platform.docker (W) Failed to run container {\"err\": \"stdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\", \"errVerbose\": \"\\nError - exit status 125\\n /nuclio/pkg/cmdrunner/shellrunner.go:96\\n\\nCall stack:\\nstdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\\n /nuclio/pkg/cmdrunner/shellrunner.go:96\\nstdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\", \"errCauses\": [{\"error\": \"exit status 125\"}], \"stdout\": \"1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\", \"stderr\": \"\"} 21.07.06 12:49:17.422 nuctl (W) Failed to create a function; setting the function status {\"err\": \"Failed to run a Docker container\", \"errVerbose\": \"\\nError - exit status 125\\n /nuclio/pkg/cmdrunner/shellrunner.go:96\\n\\nCall stack:\\nstdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\\n /nuclio/pkg/cmdrunner/shellrunner.go:96\\nFailed to run a Docker container\\n /nuclio/pkg/platform/local/platform.go:653\\nFailed to run a Docker container\", \"errCauses\": [{\"error\": \"stdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\", \"errorVerbose\": \"\\nError - exit status 125\\n /nuclio/pkg/cmdrunner/shellrunner.go:96\\n\\nCall stack:\\nstdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\\n /nuclio/pkg/cmdrunner/shellrunner.go:96\\nstdout:\\n1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb\\ndocker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated.\\n\\nstderr:\\n\", \"errorCauses\": [{\"error\": \"exit status 125\"}]}]} Error - exit status 125 /nuclio/pkg/cmdrunner/shellrunner.go:96 Call stack: stdout: 1373cb432a178a3606685b5975e40a0755bc7958786c182304f5d1bbc0873ceb docker: Error response from daemon: driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (df68e7b4a60e553ee3079f1f1622b050cc958bd50f2cd359a20164d8a417d0ea): Bind for 0.0.0.0:49154 failed: port is already allocated. stderr: /nuclio/pkg/cmdrunner/shellrunner.go:96 Failed to run a Docker container /nuclio/pkg/platform/local/platform.go:653 Failed to deploy function ...//nuclio/pkg/platform/abstract/platform.go:182 NAMESPACE | NAME | PROJECT | STATE | NODE PORT | REPLICAS nuclio | openvino-dextr | cvat | ready | 49154 | 1/1 nuclio | pth-foolwood-siammask | cvat | ready | 49155 | 1/1 nuclio | pth-facebookresearch-detectron2-retinanet-r101 | cvat | ready | 49155 | 1/1 nuclio | pth-shiyinzhang-iog | cvat | error | 0 | 1/1 In this case the container was built some time ago and the port 49154 was assigned by Nuclio. Now the port is used by openvino-dextr as we can see in logs. To prove our hypothesis just need to run a couple of docker commands:\ndocker container ls -a | grep iog eb0c1ee46630 cvat/pth.shiyinzhang.iog:latest \"conda run -n iog pr…\" 9 minutes ago Created nuclio-nuclio-pth-shiyinzhang-iog docker inspect eb0c1ee46630 | grep 49154 \"Error\": \"driver failed programming external connectivity on endpoint nuclio-nuclio-pth-shiyinzhang-iog (02384290f91b2216162b1603322dadee426afe7f439d3d090f598af5d4863b2d): Bind for 0.0.0.0:49154 failed: port is already allocated\", \"HostPort\": \"49154\" To solve the problem let’s just remove the previous container for the function. In this case it is eb0c1ee46630. After that the deploying command works as expected.\ndocker container rm eb0c1ee46630 eb0c1ee46630 serverless/deploy_cpu.sh serverless/pytorch/shiyinzhang/iog Deploying serverless/pytorch/shiyinzhang/iog function... 21.07.06 13:09:52.934 nuctl (I) Deploying function {\"name\": \"\"} 21.07.06 13:09:52.934 nuctl (I) Building {\"versionInfo\": \"Label: 1.5.16, Git commit: ae43a6a560c2bec42d7ccfdf6e8e11a1e3cc3774, OS: linux, Arch: amd64, Go version: go1.14.3\", \"name\": \"\"} 21.07.06 13:09:53.282 nuctl (I) Cleaning up before deployment {\"functionName\": \"pth-shiyinzhang-iog\"} 21.07.06 13:09:53.341 nuctl (I) Staging files and preparing base images 21.07.06 13:09:53.342 nuctl (I) Building processor image {\"imageName\": \"cvat/pth.shiyinzhang.iog:latest\"} 21.07.06 13:09:53.342 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/handler-builder-python-onbuild:1.5.16-amd64\"} 21.07.06 13:09:56.633 nuctl.platform.docker (I) Pulling image {\"imageName\": \"quay.io/nuclio/uhttpc:0.0.1-amd64\"} 21.07.06 13:10:00.163 nuctl.platform (I) Building docker image {\"image\": \"cvat/pth.shiyinzhang.iog:latest\"} 21.07.06 13:10:00.452 nuctl.platform (I) Pushing docker image into registry {\"image\": \"cvat/pth.shiyinzhang.iog:latest\", \"registry\": \"\"} 21.07.06 13:10:00.452 nuctl.platform (I) Docker image was successfully built and pushed into docker registry {\"image\": \"cvat/pth.shiyinzhang.iog:latest\"} 21.07.06 13:10:00.452 nuctl (I) Build complete {\"result\": {\"Image\":\"cvat/pth.shiyinzhang.iog:latest\",\"UpdatedFunctionConfig\":{\"metadata\":{\"name\":\"pth-shiyinzhang-iog\",\"namespace\":\"nuclio\",\"labels\":{\"nuclio.io/project-name\":\"cvat\"},\"annotations\":{\"framework\":\"pytorch\",\"min_pos_points\":\"1\",\"name\":\"IOG\",\"spec\":\"\",\"startswith_box\":\"true\",\"type\":\"interactor\"}},\"spec\":{\"description\":\"Interactive Object Segmentation with Inside-Outside Guidance\",\"handler\":\"main:handler\",\"runtime\":\"python:3.6\",\"env\":[{\"name\":\"PYTHONPATH\",\"value\":\"/opt/nuclio/iog\"}],\"resources\":{},\"image\":\"cvat/pth.shiyinzhang.iog:latest\",\"targetCPU\":75,\"triggers\":{\"myHttpTrigger\":{\"class\":\"\",\"kind\":\"http\",\"name\":\"myHttpTrigger\",\"maxWorkers\":2,\"workerAvailabilityTimeoutMilliseconds\":10000,\"attributes\":{\"maxRequestBodySize\":33554432}}},\"volumes\":[{\"volume\":{\"name\":\"volume-1\",\"hostPath\":{\"path\":\"/home/nmanovic/Workspace/cvat/serverless/common\"}},\"volumeMount\":{\"name\":\"volume-1\",\"mountPath\":\"/opt/nuclio/common\"}}],\"build\":{\"image\":\"cvat/pth.shiyinzhang.iog\",\"baseImage\":\"continuumio/miniconda3\",\"directives\":{\"preCopy\":[{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"RUN\",\"value\":\"conda create -y -n iog python=3.6\"},{\"kind\":\"SHELL\",\"value\":\"[\\\"conda\\\", \\\"run\\\", \\\"-n\\\", \\\"iog\\\", \\\"/bin/bash\\\", \\\"-c\\\"]\"},{\"kind\":\"RUN\",\"value\":\"conda install -y -c anaconda curl\"},{\"kind\":\"RUN\",\"value\":\"conda install -y pytorch=0.4 torchvision=0.2 -c pytorch\"},{\"kind\":\"RUN\",\"value\":\"conda install -y -c conda-forge pycocotools opencv scipy\"},{\"kind\":\"RUN\",\"value\":\"git clone https://github.com/shiyinzhang/Inside-Outside-Guidance.git iog\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio/iog\"},{\"kind\":\"ENV\",\"value\":\"fileid=1Lm1hhMhhjjnNwO4Pf7SC6tXLayH2iH0l\"},{\"kind\":\"ENV\",\"value\":\"filename=IOG_PASCAL_SBD.pth\"},{\"kind\":\"RUN\",\"value\":\"curl -c ./cookie -s -L \\\"https://drive.google.com/uc?export=download\\u0026id=${fileid}\\\"\"},{\"kind\":\"RUN\",\"value\":\"echo \\\"/download/ {print \\\\$NF}\\\" \\u003e confirm_code.awk\"},{\"kind\":\"RUN\",\"value\":\"curl -Lb ./cookie \\\"https://drive.google.com/uc?export=download\\u0026confirm=`awk -f confirm_code.awk ./cookie`\\u0026id=${fileid}\\\" -o ${filename}\"},{\"kind\":\"WORKDIR\",\"value\":\"/opt/nuclio\"},{\"kind\":\"ENTRYPOINT\",\"value\":\"[\\\"conda\\\", \\\"run\\\", \\\"-n\\\", \\\"iog\\\"]\"}]},\"codeEntryType\":\"image\"},\"platform\":{\"attributes\":{\"mountMode\":\"volume\",\"restartPolicy\":{\"maximumRetryCount\":3,\"name\":\"always\"}}},\"readinessTimeoutSeconds\":60,\"securityContext\":{},\"eventTimeout\":\"30s\"}}}} 21.07.06 13:10:01.604 nuctl.platform (I) Waiting for function to be ready {\"timeout\": 60} 21.07.06 13:10:02.976 nuctl (I) Function deploy complete {\"functionName\": \"pth-shiyinzhang-iog\", \"httpPort\": 49159} NAMESPACE | NAME | PROJECT | STATE | NODE PORT | REPLICAS nuclio | openvino-dextr | cvat | ready | 49154 | 1/1 nuclio | pth-foolwood-siammask | cvat | ready | 49155 | 1/1 nuclio | pth-saic-vul-fbrs | cvat | ready | 49156 | 1/1 nuclio | pth-facebookresearch-detectron2-retinanet-r101 | cvat | ready | 49155 | 1/1 nuclio | pth-shiyinzhang-iog | cvat | ready | 49159 | 1/1 When you investigate an issue with a serverless function, it is extremely useful to look at logs. Just run a couple of commands like docker logs \u003ccontainer\u003e.\ndocker logs cvat 2021-07-06 13:44:54,699 DEBG 'runserver' stderr output: [Tue Jul 06 13:44:54.699431 2021] [wsgi:error] [pid 625:tid 140010969868032] [remote 172.28.0.3:40972] [2021-07-06 13:44:54,699] ERROR django.request: Internal Server Error: /api/lambda/functions/pth-shiyinzhang-iog 2021-07-06 13:44:54,700 DEBG 'runserver' stderr output: [Tue Jul 06 13:44:54.699712 2021] [wsgi:error] [pid 625:tid 140010969868032] [remote 172.28.0.3:40972] ERROR - 2021-07-06 13:44:54,699 - log - Internal Server Error: /api/lambda/functions/pth-shiyinzhang-iog docker container ls --filter name=iog CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3b6ef9a9f3e2 cvat/pth.shiyinzhang.iog:latest \"conda run -n iog pr…\" 4 hours ago Up 4 hours (healthy) 0.0.0.0:49159-\u003e8080/tcp, :::49159-\u003e8080/tcp nuclio-nuclio-pth-shiyinzhang-iog docker logs nuclio-nuclio-pth-shiyinzhang-iog If before model deployment you see that the NODE PORT is 0, you need to assign it manually. Add the port: 32001 attribute to the function.yaml file of each model, before you deploy the model. Different ports should be prescribed for different models.\ntriggers: myHttpTrigger: maxWorkers: 1 kind: 'http' workerAvailabilityTimeoutMilliseconds: 10000 attributes: + port: 32001 maxRequestBodySize: 33554432 # 32MB Installation serverless functions on Windows 10 with using the Ubuntu subsystem If you encounter a problem running serverless functions on Windows 10, you can use the Ubuntu subsystem, for this do the following:\nInstall WSL 2 and Docker Desktop as described in installation manual\nInstall Ubuntu 18.04 from Microsoft store.\nEnable integration for Ubuntu-18.04 in the settings of Docker Desktop in the Resources WSL integration tab:\nThen you can download and install nuctl on Ubuntu, using the automatic annotation guide.\nInstall git and clone repository on Ubuntu, as described in the installation manual.\nAfter that, run the commands from this tutorial through Ubuntu.\n","categories":"","description":"","excerpt":"Introduction Leveraging the power of computers to solve daily routine …","ref":"/v2.43.0/docs/manual/advanced/serverless-tutorial/","tags":"","title":"Serverless tutorial"},{"body":"The creation of settings.py When integrating LDAP login, we need to create an overlay to the default CVAT settings located in cvat/settings/production.py. This overlay is where we will configure Django to connect to the LDAP server.\nThe main issue with using LDAP is that different LDAP implementations have different parameters. So the options used for Active Directory backed authentication will differ if you were to be using FreeIPA.\nUpdate docker-compose.override.yml In your override config you need to passthrough your settings and tell CVAT to use them by setting the DJANGO_SETTINGS_MODULE variable.\nservices: cvat_server: environment: DJANGO_SETTINGS_MODULE: settings volumes: - ./settings.py:/home/django/settings.py:ro Active Directory Example The following example should allow for users to authenticate themselves against Active Directory. This example requires a dummy user named cvat_bind. The configuration for the bind account does not need any special permissions.\nWhen updating AUTH_LDAP_BIND_DN, you can write out the account info in two ways. Both are documented in the config below.\nThis config is known to work with Windows Server 2022, but should work for older versions and Samba’s implementation of Active Directory.\n# We are overlaying production from cvat.settings.production import * # Custom code below import ldap from django_auth_ldap.config import LDAPSearch from django_auth_ldap.config import NestedActiveDirectoryGroupType # Notify CVAT that we are using LDAP authentication IAM_TYPE = 'LDAP' # Talking to the LDAP server AUTH_LDAP_SERVER_URI = \"ldap://ad.example.com\" # IP Addresses also work ldap.set_option(ldap.OPT_REFERRALS, 0) _BASE_DN = \"CN=Users,DC=ad,DC=example,DC=com\" # Authenticating with the LDAP server AUTH_LDAP_BIND_DN = \"CN=cvat_bind,%s\" % _BASE_DN # AUTH_LDAP_BIND_DN = \"cvat_bind@ad.example.com\" AUTH_LDAP_BIND_PASSWORD = \"SuperSecurePassword^21\" AUTH_LDAP_USER_SEARCH = LDAPSearch( _BASE_DN, ldap.SCOPE_SUBTREE, \"(sAMAccountName=%(user)s)\" ) AUTH_LDAP_GROUP_SEARCH = LDAPSearch( _BASE_DN, ldap.SCOPE_SUBTREE, \"(objectClass=group)\" ) # Mapping Django field names to Active Directory attributes AUTH_LDAP_USER_ATTR_MAP = { \"user_name\": \"sAMAccountName\", \"first_name\": \"givenName\", \"last_name\": \"sn\", \"email\": \"mail\", } # Group Management AUTH_LDAP_GROUP_TYPE = NestedActiveDirectoryGroupType() # Register Django LDAP backend AUTHENTICATION_BACKENDS += ['django_auth_ldap.backend.LDAPBackend'] # Map Active Directory groups to Django/CVAT groups. AUTH_LDAP_ADMIN_GROUPS = [ 'CN=CVAT Admins,%s' % _BASE_DN, ] AUTH_LDAP_WORKER_GROUPS = [ 'CN=CVAT Workers,%s' % _BASE_DN, ] AUTH_LDAP_USER_GROUPS = [ 'CN=CVAT Users,%s' % _BASE_DN, ] DJANGO_AUTH_LDAP_GROUPS = { \"admin\": AUTH_LDAP_ADMIN_GROUPS, \"user\": AUTH_LDAP_USER_GROUPS, \"worker\": AUTH_LDAP_WORKER_GROUPS, } FreeIPA Example The following example should allow for users to authenticate themselves against FreeIPA. This example requires a dummy user named cvat_bind. The configuration for the bind account does not need any special permissions.\nWhen updating AUTH_LDAP_BIND_DN, you can only write the user info in one way, unlike with Active Directory\nThis config is known to work with AlmaLinux 8, but may work for other versions and flavors of Enterprise Linux.\n# We are overlaying production from cvat.settings.production import * # Custom code below import ldap from django_auth_ldap.config import LDAPSearch from django_auth_ldap.config import GroupOfNamesType # Notify CVAT that we are using LDAP authentication IAM_TYPE = 'LDAP' _BASE_DN = \"CN=Accounts,DC=ipa,DC=example,DC=com\" # Talking to the LDAP server AUTH_LDAP_SERVER_URI = \"ldap://ipa.example.com\" # IP Addresses also work ldap.set_option(ldap.OPT_REFERRALS, 0) # Authenticating with the LDAP server AUTH_LDAP_BIND_DN = \"UID=cvat_bind,CN=Users,%s\" % _BASE_DN AUTH_LDAP_BIND_PASSWORD = \"SuperSecurePassword^21\" AUTH_LDAP_USER_SEARCH = LDAPSearch( \"CN=Users,%s\" % _BASE_DN, ldap.SCOPE_SUBTREE, \"(uid=%(user)s)\" ) AUTH_LDAP_GROUP_SEARCH = LDAPSearch( \"CN=Groups,%s\" % _BASE_DN, ldap.SCOPE_SUBTREE, \"(objectClass=groupOfNames)\" ) # Mapping Django field names to FreeIPA attributes AUTH_LDAP_USER_ATTR_MAP = { \"user_name\": \"uid\", \"first_name\": \"givenName\", \"last_name\": \"sn\", \"email\": \"mail\", } # Group Management AUTH_LDAP_GROUP_TYPE = GroupOfNamesType() # Register Django LDAP backend AUTHENTICATION_BACKENDS += ['django_auth_ldap.backend.LDAPBackend'] # Map FreeIPA groups to Django/CVAT groups. AUTH_LDAP_ADMIN_GROUPS = [ 'CN=cvat_admins,CN=Groups,%s' % _BASE_DN, ] AUTH_LDAP_WORKER_GROUPS = [ 'CN=cvat_workers,CN=Groups,%s' % _BASE_DN, ] AUTH_LDAP_USER_GROUPS = [ 'CN=cvat_users,CN=Groups,%s' % _BASE_DN, ] DJANGO_AUTH_LDAP_GROUPS = { \"admin\": AUTH_LDAP_ADMIN_GROUPS, \"user\": AUTH_LDAP_USER_GROUPS, \"worker\": AUTH_LDAP_WORKER_GROUPS, } Resources Microsoft - LDAP Distinguished Names Elements that make up a distinguished name. Used with user/group searches. Django LDAP Reference Manual Other options that can be used for LDAP authentication in Django. Django LDAP guide using Active Directory (Unofficial) This is not specific to CVAT but can provide insight about firewall rules. ","categories":"","description":"Allow users to login with credentials from a central source","excerpt":"Allow users to login with credentials from a central source","ref":"/v2.43.0/docs/administration/advanced/ldap/","tags":"","title":"LDAP Backed Authentication"},{"body":" About CVAT data volumes Docker volumes are used to store all CVAT data:\ncvat_db: PostgreSQL database files, used to store information about users, tasks, projects, annotations, etc. Mounted into cvat_db container by /var/lib/postgresql/data path.\ncvat_data: used to store uploaded and prepared media data. Mounted into cvat container by /home/django/data path.\ncvat_keys: used to store the Django secret key. Mounted into cvat container by /home/django/keys path.\ncvat_logs: used to store logs of CVAT backend processes managed by the supervisord service. Mounted into cvat container by /home/django/logs path.\ncvat_events_db: this volume is used to store Clickhouse database files. Mounted into cvat_clickhouse container by /var/lib/clickhouse path.\nHow to backup all CVAT data All CVAT containers should be stopped before backup:\ndocker compose stop Please don’t forget to include all the compose config files that were used in the docker compose command using the -f parameter.\nBackup data:\nmkdir backup docker run --rm --name temp_backup --volumes-from cvat_db -v $(pwd)/backup:/backup ubuntu tar -czvf /backup/cvat_db.tar.gz /var/lib/postgresql/data docker run --rm --name temp_backup --volumes-from cvat_server -v $(pwd)/backup:/backup ubuntu tar -czvf /backup/cvat_data.tar.gz /home/django/data docker run --rm --name temp_backup --volumes-from cvat_clickhouse -v $(pwd)/backup:/backup ubuntu tar -czvf /backup/cvat_events_db.tar.gz /var/lib/clickhouse Make sure the backup archives have been created, the output of ls backup command should look like this:\nls backup cvat_data.tar.gz cvat_db.tar.gz cvat_events_db.tar.gz How to restore CVAT from backup Warning: use exactly the same CVAT version to restore DB. Otherwise it will not work because between CVAT releases the layout of DB can be changed. You always can upgrade CVAT later. It will take care to migrate your data properly internally.\nNote: CVAT containers must exist (if no, please follow the installation guide). Stop all CVAT containers:\ndocker compose stop Restore data:\ncd \u003cpath_to_backup_folder\u003e docker run --rm --name temp_backup --volumes-from cvat_db -v $(pwd):/backup ubuntu bash -c \"cd /var/lib/postgresql/data \u0026\u0026 tar -xvf /backup/cvat_db.tar.gz --strip 4\" docker run --rm --name temp_backup --volumes-from cvat_server -v $(pwd):/backup ubuntu bash -c \"cd /home/django/data \u0026\u0026 tar -xvf /backup/cvat_data.tar.gz --strip 3\" docker run --rm --name temp_backup --volumes-from cvat_clickhouse -v $(pwd):/backup ubuntu bash -c \"cd /var/lib/clickhouse \u0026\u0026 tar -xvf /backup/cvat_events_db.tar.gz --strip 3\" After that run CVAT as usual:\ndocker compose up -d Additional resources Docker guide about volume backups\n","categories":"","description":"Instructions on how to backup CVAT data with Docker.","excerpt":"Instructions on how to backup CVAT data with Docker.","ref":"/v2.43.0/docs/administration/advanced/backup_guide/","tags":"","title":"Backup guide"},{"body":" Upgrade guide Note: updating CVAT from version 2.2.0 to version 2.3.0 requires additional manual actions with database data due to upgrading PostgreSQL base image major version. See details here\nTo upgrade CVAT, follow these steps:\nIt is highly recommended backup all CVAT data before updating, follow the backup guide and backup all CVAT volumes.\nGo to the previously cloned CVAT directory and stop all CVAT containers with:\ndocker compose down If you have included additional components, include all compose configuration files that are used, e.g.:\ndocker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml down Update CVAT source code by any preferable way: clone with git or download zip file from GitHub. Note that you need to download the entire source code, not just the Docker Compose configuration file. Check the installation guide for details.\nVerify settings: The installation process is changed/modified from version to version and you may need to export some environment variables, for example CVAT_HOST.\nUpdate local CVAT images. Pull or build new CVAT images, see How to pull/build/update CVAT images section for details.\nStart CVAT with:\ndocker compose up -d When CVAT starts, it will upgrade its DB in accordance with the latest schema. It can take time especially if you have a lot of data. Please do not terminate the migration and wait till the process is complete. You can monitor the startup process with the following command:\ndocker logs cvat_server -f Upgrade CVAT after v2.26.0 In version 2.26.0, CVAT changed the location where the export cache is stored. To clean up the outdated cache, run the command depending on how CVAT is deployed:\nDocker Kubernetes Development docker exec -it cvat_server python manage.py cleanuplegacyexportcache cvat_backend_pod=$(kubectl get pods -l component=server -o 'jsonpath={.items[0].metadata.name}') kubectl exec -it ${cvat_backend_pod} -- python manage.py cleanuplegacyexportcache python manage.py cleanuplegacyexportcache How to upgrade CVAT from v2.2.0 to v2.3.0. Step by step commands how to upgrade CVAT from v2.2.0 to v2.3.0. Let’s assume that you have CVAT v2.2.0 working.\ndocker exec -it cvat_db pg_dumpall \u003e cvat.db.dump cd cvat docker compose down docker volume rm cvat_cvat_db export CVAT_VERSION=\"v2.3.0\" cd .. mv cvat cvat_220 wget https://github.com/cvat-ai/cvat/archive/refs/tags/${CVAT_VERSION}.zip unzip ${CVAT_VERSION}.zip \u0026\u0026 mv cvat-${CVAT_VERSION:1} cvat unset CVAT_VERSION cd cvat export CVAT_HOST=cvat.example.com export ACME_EMAIL=example@example.com docker compose pull docker compose up -d cvat_db docker exec -i cvat_db psql -q -d postgres \u003c ../cvat.db.dump docker compose -f docker-compose.yml -f docker-compose.dev.yml -f docker-compose.https.yml up -d How to upgrade CVAT from v1.7.0 to v2.2.0. Step by step commands how to upgrade CVAT from v1.7.0 to v2.2.0. Let’s assume that you have CVAT v1.7.0 working.\nexport CVAT_VERSION=\"v2.2.0\" cd cvat docker compose down cd .. mv cvat cvat_170 wget https://github.com/cvat-ai/cvat/archive/refs/tags/${CVAT_VERSION}.zip unzip ${CVAT_VERSION}.zip \u0026\u0026 mv cvat-${CVAT_VERSION:1} cvat cd cvat docker pull cvat/server:${CVAT_VERSION} docker tag cvat/server:${CVAT_VERSION} openvino/cvat_server:latest docker pull cvat/ui:${CVAT_VERSION} docker tag cvat/ui:${CVAT_VERSION} openvino/cvat_ui:latest docker compose up -d How to upgrade PostgreSQL database base image It is highly recommended backup all CVAT data before updating, follow the backup guide and backup CVAT database volume.\nRun previously used CVAT version as usual\nBackup current database with pg_dumpall tool:\ndocker exec -it cvat_db pg_dumpall \u003e cvat.db.dump Stop CVAT:\ndocker compose down Delete current PostgreSQL’s volume, that’s why it’s important to have a backup:\ndocker volume rm cvat_cvat_db Update CVAT source code by any preferable way: clone with git or download zip file from GitHub. Check the installation guide for details.\nStart database container only:\ndocker compose up -d cvat_db Import PostgreSQL dump into new DB container:\ndocker exec -i cvat_db psql -q -d postgres \u003c cvat.db.dump Start CVAT:\ndocker compose up -d ","categories":"","description":"Instructions for upgrading CVAT deployed with docker compose","excerpt":"Instructions for upgrading CVAT deployed with docker compose","ref":"/v2.43.0/docs/administration/advanced/upgrade_guide/","tags":"","title":"Upgrade guide"},{"body":"Webhooks are user-defined HTTP callbacks that are triggered by specific events. When an event that triggers a webhook occurs, CVAT makes an HTTP request to the URL configured for the webhook. The request will include a payload with information about the event.\nCVAT, webhooks can be triggered by a variety of events, such as the creation, deletion, or modification of tasks, jobs, and so on. This makes it easy to set up automated processes that respond to changes made in CVAT.\nFor example, you can set up webhooks to alert you when a job’s assignee is changed or when a job/task’s status is updated, for instance, when a job is completed and ready for review or has been reviewed. New task creation can also trigger notifications.\nThese capabilities allow you to keep track of progress and changes in your CVAT workflow instantly.\nIn CVAT you can create a webhook for a project or organization. You can use CVAT GUI or direct API calls.\nSee:\nCreate Webhook For project For organization Webhooks forms List of events Payloads Create event Update event Delete event Webhook secret Ping Webhook Webhooks with API calls Example of setup and use Create Webhook For project To create a webhook for Project, do the following:\nCreate a Project.\nGo to the Projects and click on the project’s widget.\nIn the top right corner, click Actions \u003e Setup Webhooks.\nIn the top right corner click +\nFill in the Setup webhook form and click Submit.\nFor organization To create a webhook for Organization, do the following:\nCreate Organization Go to the Organization \u003e Settings \u003e Actions \u003e Setup Webhooks. In the top right corner click + Fill in the Setup webhook form and click Submit. Webhooks forms The Setup a webhook forms look like the following.\nForms have the following fields:\nField Description Target URL The URL where the event data will be sent. Description Provides a brief summary of the webhook’s purpose. Project A drop-down list that lets you select from available projects. Content type Defines the data type for the payload in the webhook request via the HTTP Content-Type field. Secret A unique key for verifying the webhook’s origin, ensuring it’s genuinely from CVAT. For more information, see Webhook secret Enable SSL A checkbox for enabling or disabling SSL verification. Active Uncheck this box if you want to stop the delivery of specific webhook payloads. Send everything Check this box to send all event types through the webhook. Specify individual events Choose this option to send only certain event types. Refer to the List of available events for more information on event types. List of events The following events are available for webhook alerts.\nResource Create Update Delete Description Organization ✅ Alerts for changes made to an Organization. Membership ✅ ✅ Alerts when a member is added to or removed from an organization. Invitation ✅ ✅ Alerts when an invitation to an Organization is issued or revoked. Project ✅ ✅ ✅ Alerts for any actions taken within a project. Task ✅ ✅ ✅ Alerts for actions related to a task, such as status changes, assignments, etc. Job ✅ Alerts for any updates made to a job. Issue ✅ ✅ ✅ Alerts for any activities involving issues. Comment ✅ ✅ ✅ Alerts for actions involving comments, such as creation, deletion, or modification. Payloads Create event Webhook payload object for create:\u003cresource\u003e events:\nKey Type Description event string Identifies the event that triggered the webhook, following the create:\u003cresource\u003e pattern. \u003cresource\u003e object Complete information about the created resource. Refer to the Swagger docs for individual resource details. webhook_id integer The identifier for the webhook that sends the payload. sender object Details about the user that triggered the webhook. An example of payload for the create:task event:\n{ \"event\": \"create:task\", \"task\": { \"url\": \"\u003chttp://localhost:8080/api/tasks/15\u003e\", \"id\": 15, \"name\": \"task\", \"project_id\": 7, \"mode\": \"\", \"owner\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" }, \"assignee\": null, \"bug_tracker\": \"\", \"created_date\": \"2022-10-04T08:05:50.419259Z\", \"updated_date\": \"2022-10-04T08:05:50.422917Z\", \"overlap\": null, \"segment_size\": 0, \"status\": \"annotation\", \"labels\": \\[ { \"id\": 28, \"name\": \"label_0\", \"color\": \"#bde94a\", \"attributes\": [], \"type\": \"any\", \"sublabels\": [], \"has_parent\": false } \\], \"segments\": [], \"dimension\": \"2d\", \"subset\": \"\", \"organization\": null, \"target_storage\": { \"id\": 14, \"location\": \"local\", \"cloud_storage_id\": null }, \"source_storage\": { \"id\": 13, \"location\": \"local\", \"cloud_storage_id\": null } }, \"webhook_id\": 7, \"sender\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" } } Update event Webhook payload object for update:\u003cresource\u003e events:\nKey Type Description event string Identifies the event that triggered the webhook, following the update:\u003cresource\u003e pattern. \u003cresource\u003e object Provides complete information about the updated resource. See the Swagger docs for resource details. before_update object Contains keys of \u003cresource\u003e that were updated, along with their old values. webhook_id integer The identifier for the webhook that dispatched the payload. sender object Details about the user that triggered the webhook. An example of update:\u003cresource\u003e event:\n{ \"event\": \"update:task\", \"task\": { \"url\": \"\u003chttp://localhost:8080/api/tasks/15\u003e\", \"id\": 15, \"name\": \"new task name\", \"project_id\": 7, \"mode\": \"annotation\", \"owner\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" }, \"assignee\": null, \"bug_tracker\": \"\", \"created_date\": \"2022-10-04T08:05:50.419259Z\", \"updated_date\": \"2022-10-04T11:04:51.451681Z\", \"overlap\": 0, \"segment_size\": 1, \"status\": \"annotation\", \"labels\": \\[ { \"id\": 28, \"name\": \"label_0\", \"color\": \"#bde94a\", \"attributes\": [], \"type\": \"any\", \"sublabels\": [], \"has_parent\": false } \\], \"segments\": \\[ { \"start_frame\": 0, \"stop_frame\": 0, \"jobs\": \\[ { \"url\": \"\u003chttp://localhost:8080/api/jobs/19\u003e\", \"id\": 19, \"assignee\": null, \"status\": \"annotation\", \"stage\": \"annotation\", \"state\": \"new\" } \\] } \\], \"data_chunk_size\": 14, \"data_compressed_chunk_type\": \"imageset\", \"data_original_chunk_type\": \"imageset\", \"size\": 1, \"image_quality\": 70, \"data\": 14, \"dimension\": \"2d\", \"subset\": \"\", \"organization\": null, \"target_storage\": { \"id\": 14, \"location\": \"local\", \"cloud_storage_id\": null }, \"source_storage\": { \"id\": 13, \"location\": \"local\", \"cloud_storage_id\": null } }, \"before_update\": { \"name\": \"task\" }, \"webhook_id\": 7, \"sender\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" } } Delete event Webhook payload object for delete:\u003cresource\u003e events:\nKey Type Description event string Identifies the event that triggered the webhook, following the delete:\u003cresource\u003e pattern. \u003cresource\u003e object Provides complete information about the deleted resource. See the Swagger docs for resource details. webhook_id integer The identifier for the webhook that dispatched the payload. sender object Details about the user that triggered the webhook. Here is an example of the payload for the delete:task event:\n{ \"event\": \"delete:task\", \"task\": { \"url\": \"\u003chttp://localhost:8080/api/tasks/15\u003e\", \"id\": 15, \"name\": \"task\", \"project_id\": 7, \"mode\": \"\", \"owner\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" }, \"assignee\": null, \"bug_tracker\": \"\", \"created_date\": \"2022-10-04T08:05:50.419259Z\", \"updated_date\": \"2022-10-04T08:05:50.422917Z\", \"overlap\": null, \"segment_size\": 0, \"status\": \"annotation\", \"labels\": \\[ { \"id\": 28, \"name\": \"label_0\", \"color\": \"#bde94a\", \"attributes\": [], \"type\": \"any\", \"sublabels\": [], \"has_parent\": false } \\], \"segments\": [], \"dimension\": \"2d\", \"subset\": \"\", \"organization\": null, \"target_storage\": { \"id\": 14, \"location\": \"local\", \"cloud_storage_id\": null }, \"source_storage\": { \"id\": 13, \"location\": \"local\", \"cloud_storage_id\": null } }, \"webhook_id\": 7, \"sender\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" } } Webhook secret To validate that webhook requests originate from CVAT, include a secret during the webhook creation process. This helps ensure the authenticity of incoming webhook requests.\nWhen a secret is provided, CVAT includes an X-Signature-256 header in the webhook request. This header contains a SHA256 hash of the request body, signed using the secret key.\nHow it works:\nCVAT computes the SHA256 HMAC of the request body using the secret. The computed hash is included in the X-Signature-256 header. The webhook receiver verifies the request by recalculating the hash using the same secret and comparing it with the received signature. Here’s an example of the X-Signature-256 header for a request with an empty body and secret = mykey:\nX-Signature-256: e1b24265bf2e0b20c81837993b4f1415f7b68c503114d100a40601eca6a2745f Verifying webhook signature You can verify the webhook signature in your webhook receiver service using Python:\n# webhook_receiver.py import hmac from hashlib import sha256 from flask import Flask, request app = Flask(__name__) @app.route(\"/webhook\", methods=[\"POST\"]) def webhook(): secret = \"mykey\".encode(\"utf-8\") received_signature = request.headers.get(\"X-Signature-256\", \"\") expected_signature = \"sha256=\" + hmac.new(secret, request.data, digestmod=sha256).hexdigest() if hmac.compare_digest(received_signature, expected_signature): return app.response_class(status=200, response=\"Valid signature\") return app.response_class(status=403, response=\"Invalid Signature\") if __name__ == \"__main__\": app.run(port=5000) Ping webhook The Ping webhook feature helps confirm that CVAT can successfully send webhook events to the configured target URL.\nClick the Ping button in the CVAT UI. Alternatively, send a POST /webhooks/{id}/ping request via the API. CVAT will send a webhook event to the target URL with basic details. Ping webhook payload Key Type Description event string Always set to ping. webhook object Contains webhook details (refer to Swagger docs for a complete structure). sender object Includes information about the user who triggered the ping. Example ping event payload:\n{ \"event\": \"ping\", \"webhook\": { \"id\": 7, \"url\": \"\u003chttp://localhost:8080/api/webhooks/7\u003e\", \"target_url\": \"\u003chttps://example.com\u003e\", \"description\": \"\", \"type\": \"project\", \"content_type\": \"application/json\", \"is_active\": true, \"enable_ssl\": true, \"created_date\": \"2022-10-04T08:05:23.007381Z\", \"updated_date\": \"2022-10-04T08:05:23.007395Z\", \"owner\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" }, \"project\": 7, \"organization\": null, \"events\": \\[ \"create:comment\", \"create:issue\", \"create:task\", \"delete:comment\", \"delete:issue\", \"delete:task\", \"update:comment\", \"update:issue\", \"update:job\", \"update:project\", \"update:task\" \\], \"last_status\": 200, \"last_delivery_date\": \"2022-10-04T11:04:52.538638Z\" }, \"sender\": { \"url\": \"\u003chttp://localhost:8080/api/users/1\u003e\", \"id\": 1, \"username\": \"admin1\", \"first_name\": \"Admin\", \"last_name\": \"First\" } } Webhooks with API calls You can create and manage webhooks via API calls. Refer to the Swagger API documentation for details.\nFor implementation examples, check the REST API tests.\nExample: setting up email alerts via webhooks This video demonstrates configuring email alerts for a project using Zapier and Gmail:\n","categories":"","description":"CVAT Webhooks: set up and use","excerpt":"CVAT Webhooks: set up and use","ref":"/v2.43.0/docs/administration/advanced/webhooks/","tags":"","title":"Webhooks"},{"body":"CVAT use traefik as a reverse proxy to manage SSL certificates. By default, traefik uses Let’s Encrypt to generate SSL certificates. However, you can use your own certificates instead of Let’s Encrypt.\nSee:\nSetup Custom Certificates Create Certificates Directory Change Traefik Configuration Start CVAT Setup Custom Certificates Create Certificates Directory Create a certs directory in the root of the project:\nmkdir -p ./certs Move your certificates to the ./certs directory:\nmv /path/to/cert.pem ./certs/cert.pem mv /path/to/key.pem ./certs/key.pem Change Traefik Configuration Create tls.yml in the root of the project directory with the following content:\ntls: stores: default: defaultCertificate: certFile: /certs/cert.pem keyFile: /certs/key.pem Edit the docker-compose.https.yml file and change the traefik service configuration as follows:\ntraefik: environment: TRAEFIK_ENTRYPOINTS_web_ADDRESS: :80 TRAEFIK_ENTRYPOINTS_web_HTTP_REDIRECTIONS_ENTRYPOINT_TO: websecure TRAEFIK_ENTRYPOINTS_web_HTTP_REDIRECTIONS_ENTRYPOINT_SCHEME: https TRAEFIK_ENTRYPOINTS_websecure_ADDRESS: :443 # Disable Let's Encrypt # TRAEFIK_CERTIFICATESRESOLVERS_lets-encrypt_ACME_EMAIL: \"${ACME_EMAIL:?Please set the ACME_EMAIL env variable}\" # TRAEFIK_CERTIFICATESRESOLVERS_lets-encrypt_ACME_TLSCHALLENGE: \"true\" # TRAEFIK_CERTIFICATESRESOLVERS_lets-encrypt_ACME_STORAGE: /letsencrypt/acme.json ports: - 80:80 - 443:443 # Add certificates volume and tls.yml rules volumes: - ./certs:/certs - ./tls.yml:/etc/traefik/rules/tls.yml Start CVAT Start CVAT with the following command:\ndocker compose -f docker-compose.yml -f docker-compose.https.yml up -d ","categories":"","description":"Use Custom Certificates in CVAT","excerpt":"Use Custom Certificates in CVAT","ref":"/v2.43.0/docs/administration/advanced/custom_certificates/","tags":"","title":"Custom Certificates"},{"body":" 404 Not found\nOops! This page doesn't exist. Try going back to the documentation page.\n","categories":"","description":"","excerpt":" 404 Not found\nOops! This page doesn't exist. Try going back to the …","ref":"/v2.43.0/page_404/","tags":"","title":"404"},{"body":"","categories":"","description":"","excerpt":"","ref":"/v2.43.0/","tags":"","title":"CVAT"},{"body":"CVAT is a free, online, interactive video and image annotation tool for computer vision. It is being developed and used by CVAT.ai to annotate millions of objects with different properties. Many UI and UX decisions are based on feedbacks from professional data annotation team. Try it online app.cvat.ai.\nOur documentation provides information for annotators, AI researchers, system administrators, and developers. The documentation is divided into three sections, and each section is divided into subsections basic and advanced.\nGetting started Basic information and sections needed for a quick start.\nFAQ Answers to frequently asked questions.\nGitHub Repository Computer Vision Annotation Tool GitHub repository.\nManual This section contains documents for CVAT simple and advanced users.\nAdministration This section contains documents for system administrators.\nContributing This section contains documents for developers.\n","categories":"","description":"Welcome to the documentation of Computer Vision Annotation Tool.","excerpt":"Welcome to the documentation of Computer Vision Annotation Tool.","ref":"/v2.43.0/docs/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/v2.43.0/search/","tags":"","title":"Search Results"}]